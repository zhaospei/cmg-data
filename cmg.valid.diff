check_for_cached_appliance ( guestfs_h * g , <nl> snprintf ( filename , len , "% s / checksum ", cachedir ); <nl>  <nl> ( void ) mkdir ( cachedir , 0755 ); <nl> - ( void ) utime ( cachedir , NULL ); <nl>  <nl> /* See if the cache directory exists and passes some simple checks <nl> * to make sure it has not been tampered with . <nl> check_for_cached_appliance ( guestfs_h * g , <nl> return - 1 ; <nl> } <nl>  <nl> + ( void ) utime ( cachedir , NULL ); <nl> + <nl> garbage_collect_appliances ( cachedir ); <nl>  <nl> /* Try to open and acquire a lock on the checksum file . */
static int mb_config_add_host ( oconfig_item_t * ci ) /* {{{ */ <nl>  <nl> status = cf_util_get_string_buffer ( ci , host -> host , sizeof ( host -> host )); <nl> if ( status != 0 ) <nl> + { <nl> + sfree ( host ); <nl> return ( status ); <nl> + } <nl> if ( host -> host [ 0 ] == 0 ) <nl> + { <nl> + sfree ( host ); <nl> return ( EINVAL ); <nl> + } <nl>  <nl> for ( i = 0 ; i < ci -> children_num ; i ++) <nl> {
static int rra_get ( char *** ret , const value_list_t * vl , /* {{{ */ <nl> if ( rra_num >= rra_max ) <nl> break ; <nl>  <nl> - status = ssnprintf ( buffer , sizeof ( buffer ), " RRA :% s :% 3 . 1f :% u :% u ", <nl> + status = ssnprintf ( buffer , sizeof ( buffer ), " RRA :% s :%. 10f :% u :% u ", <nl> rra_types [ j ], cfg -> xff , cdp_len , cdp_num ); <nl>  <nl> if (( status < 0 ) || (( size_t ) status >= sizeof ( buffer )))
static int varnish_read ( user_data_t * ud ) /* {{{ */ <nl>  <nl> vd = VSM_New (); <nl> VSC_Setup ( vd ); <nl> + if ( VSM_n_Arg ( vd , conf -> instance ) == - 1 ) <nl> + { <nl> + ERROR (" Varnish plugin : unable to load statistics from instance "); <nl> + return (- 1 ); <nl> + } <nl> if ( VSC_Open ( vd , /* diag = */ 1 )) <nl> { <nl> ERROR (" varnish plugin : Unable to load statistics .");
static int wt_send_message ( const char * key , const char * value , <nl> char * temp = NULL ; <nl> char * tags = ""; <nl> char message [ 1024 ]; <nl> + char * host_tags = cb -> host_tags ? cb -> host_tags : ""; <nl> const char * message_fmt ; <nl> const char * meta_tsdb = " tsdb_tags "; <nl>  <nl> static int wt_send_message ( const char * key , const char * value , <nl> value , <nl> host , <nl> tags , <nl> - cb -> host_tags ); <nl> + host_tags ); <nl>  <nl> sfree ( temp ); <nl> 
rd_req_decrypt_tkt_part ( krb5_context context , const krb5_ap_req * req , <nl>  <nl> while (( code = krb5_kt_next_entry ( context , keytab , <nl> & ktent , & cursor )) == 0 ) { <nl> - if ( ktent . key . enctype != req -> ticket -> enc_part . enctype ) <nl> + if ( ktent . key . enctype != req -> ticket -> enc_part . enctype ) { <nl> + ( void ) krb5_free_keytab_entry_contents ( context , & ktent ); <nl> continue ; <nl> + } <nl>  <nl> retval = krb5_decrypt_tkt_part ( context , & ktent . key , <nl> req -> ticket );
register int * error ; <nl> * error = ENOMEM ; <nl> return ( 0 ); <nl> } <nl> + xbzero ( rv2 , sizeof (* rv2 )); <nl>  <nl> retval -> pvno = KRB5_PVNO ; <nl> retval -> msg__type = KRB5_SAFE ;
krb5_get_cred_from_kdc ( ccache , cred , tgts ) <nl> int nservers ; <nl>  <nl> /* in case we never get a TGT , zero the return */ <nl> - tgts = 0 ; <nl> + * tgts = 0 ; <nl>  <nl> /* <nl> * we know that the desired credentials aren ' t in the cache yet . <nl> krb5_get_cred_from_kdc ( ccache , cred , tgts ) <nl> */ <nl> tgtq . client = cred -> client ; <nl>  <nl> - if ( retval = krb5_tgtname ( cred -> server , cred -> client , & tgtq . server )) <nl> + if ( retval = krb5_tgtname ( krb5_princ_realm ( cred -> client ), <nl> + krb5_princ_realm ( cred -> server ), & tgtq . server )) <nl> return retval ; <nl>  <nl> /* try to fetch it directly */ <nl> krb5_get_cred_from_kdc ( ccache , cred , tgts ) <nl> next_server ++; <nl> break ; /* found one ! */ <nl> } <nl> + krb5_free_realm_tree ( tgs_list ); <nl> /* allocate storage for TGT pointers . */ <nl> ret_tgts = ( krb5_creds **) calloc ( nservers + 1 , sizeof ( krb5_creds )); <nl> if (! ret_tgts ) { <nl> retval = ENOMEM ; <nl> goto out ; <nl> } <nl> + * tgts = ret_tgts ; <nl> for ( nservers = 0 ; next_server ; next_server ++, nservers ++) { <nl> /* now get the TGTs */ <nl> tgtq . times = tgt . times ;
krb5_ktfile_close ( id ) <nl> * This routine should undo anything done by krb5_ktfile_resolve (). <nl> */ <nl> { <nl> - ( void ) free ( KTFILENAME ( id )); <nl> - ( void ) free (( krb5_pointer )( id )-> data ); <nl> + xfree ( KTFILENAME ( id )); <nl> + xfree ( id -> data ); <nl> id -> ops = 0 ; <nl> + xfree ( id ); <nl> return ( 0 ); /* XXX */ <nl> }
cm_select_or_poll ( const struct select_state * in , struct select_state * out , <nl> return e ; <nl> timeout = ( in -> end_time . tv_sec - now . tv_sec ) * 1000 + <nl> ( in -> end_time . tv_usec - now . tv_usec ) / 1000 ; <nl> + if ( timeout < 0 ) { <nl> + * sret = 0 ; <nl> + return 0 ; <nl> + } <nl> } <nl> /* We don ' t need a separate copy of the selstate for poll , but use one <nl> * anyone for consistency with the select wrapper . */
krb5_locate_kpasswd ( krb5_context context , const krb5_data * realm , <nl> locate_service_kadmin , SOCK_STREAM , 0 ); <nl> if (! code ) { <nl> /* Success with admin_server but now we need to change the <nl> - port number to use DEFAULT_KPASSWD_PORT . */ <nl> + port number to use DEFAULT_KPASSWD_PORT and the socktype . */ <nl> int i ; <nl> for ( i = 0 ; i < addrlist -> naddrs ; i ++) { <nl> struct addrinfo * a = addrlist -> addrs [ i ]. ai ; <nl> if ( a -> ai_family == AF_INET ) <nl> sa2sin ( a -> ai_addr )-> sin_port = htons ( DEFAULT_KPASSWD_PORT ); <nl> + if ( sockType != SOCK_STREAM ) <nl> + a -> ai_socktype = sockType ; <nl> } <nl> } <nl> }
krb5_get_realm_domain ( realm , domain ) <nl> krb5_xfree ( realmlist [ 0 ]); <nl> krb5_xfree ( realmlist ); <nl> } <nl> - * domain = NULL ; <nl> + if (( retdomain = malloc ( strlen ( realm ) + 2 )) == NULL ) <nl> + return ENOMEM ; <nl> + strcpy ( retdomain , "."); <nl> + strcat ( retdomain , realm ); /* return the realm as the domain <nl> + if lookup fails */ <nl> + * domain = retdomain ; <nl> return 0 ; <nl> } <nl> continue ;
do_ccache ( krb5_ccache cache ) <nl> return 1 ; <nl> } <nl> while (!( code = krb5_cc_next_cred ( kcontext , cache , & cur , & creds ))) { <nl> - if (! show_config && krb5_is_config_principal ( kcontext , creds . server )) <nl> - continue ; <nl> - if ( status_only ) { <nl> + if (! show_config && krb5_is_config_principal ( kcontext , creds . server )) { <nl> + /* Do nothing with this entry . */ <nl> + } else if ( status_only ) { <nl> if ( exit_status && creds . server -> length == 2 && <nl> data_eq ( creds . server -> realm , princ -> realm ) && <nl> data_eq_string ( creds . server -> data [ 0 ], " krbtgt ") && <nl> do_ccache ( krb5_ccache cache ) <nl> com_err ( progname , code , _ (" while retrieving a ticket ")); <nl> return 1 ; <nl> } <nl> + krb5_free_principal ( kcontext , princ ); <nl> } <nl>  <nl> char *
# endif /* NO_STDLIB_H */ <nl> # else <nl> extern char * malloc (), * realloc (), * calloc (); <nl> - extern char * getenv (), * index (); <nl> + extern char * getenv (); <nl> # endif /* ! __STDC__ */ <nl>  <nl> # include < string . h >
try_one_princ ( krb5_context context , const krb5_ap_req * req , <nl> if ( ret ) <nl> return ret ; <nl> ret = try_one_entry ( context , req , & ent , keyblock_out ); <nl> + if ( ret == 0 ) <nl> + TRACE_RD_REQ_DECRYPT_SPECIFIC ( context , ent . principal , & ent . key ); <nl> ( void ) krb5_free_keytab_entry_contents ( context , & ent ); <nl> if ( ret ) <nl> return ret ; <nl>  <nl> - TRACE_RD_REQ_DECRYPT_SPECIFIC ( context , ent . principal , & ent . key ); <nl> return 0 ; <nl> } <nl> 
void doit ( fd ) <nl> exit ( 1 ); <nl> } <nl> omask = umask ( 077 ); <nl> - lock_fd = fopen ( temp_file_name , O_RDONLY ); <nl> + lock_fd = open ( temp_file_name , O_RDONLY , 0600 ); <nl> ( void ) umask ( omask ); <nl> retval = krb5_lock_file ( kpropd_context , lock_fd , <nl> KRB5_LOCKMODE_EXCLUSIVE | KRB5_LOCKMODE_DONTBLOCK );
krb5_get_in_tkt ( krb5_context context , <nl> retval = send_as_request ( context , encoded_request , <nl> krb5_princ_realm ( context , request . client ), & err_reply , <nl> & as_reply , & use_master ); <nl> - krb5_free_data_contents ( context , encoded_request ); <nl> + krb5_free_data ( context , encoded_request ); <nl> if ( retval != 0 ) <nl> goto cleanup ; <nl> 
kdc_process_tgs_req ( krb5_kdc_req * request , const krb5_fulladdr * from , <nl> if (( retval = krb5_auth_con_init ( kdc_context , & auth_context ))) <nl> goto cleanup ; <nl>  <nl> + /* Don ' t use a replay cache . */ <nl> + if (( retval = krb5_auth_con_setflags ( kdc_context , auth_context , 0 ))) <nl> + goto cleanup ; <nl> + <nl> if (( retval = krb5_auth_con_setaddrs ( kdc_context , auth_context , NULL , <nl> from -> address )) ) <nl> goto cleanup_auth_context ;
static struct { <nl> } <nl>  <nl> void StopTracingAgent () { <nl> - tracing_agent_ -> Stop (); <nl> + if ( tracing_agent_ ) <nl> + tracing_agent_ -> Stop (); <nl> } <nl>  <nl> tracing :: Agent * GetTracingAgent () const {
enum encoding ParseEncoding ( Handle < Value > encoding_v , enum encoding _default ) { <nl>  <nl> if ( strcasecmp (* encoding , " utf8 ") == 0 ) { <nl> return UTF8 ; <nl> + } else if ( strcasecmp (* encoding , " utf - 8 ") == 0 ) { <nl> + return UTF8 ; <nl> } else if ( strcasecmp (* encoding , " ascii ") == 0 ) { <nl> return ASCII ; <nl> } else if ( strcasecmp (* encoding , " binary ") == 0 ) {
static void GetStringWidth ( const FunctionCallbackInfo < Value >& args ) { <nl> TwoByteValue value ( env -> isolate (), args [ 0 ]); <nl> // reinterpret_cast is required by windows to compile <nl> UChar * str = reinterpret_cast < UChar *>(* value ); <nl> - UChar32 c ; <nl> + static_assert ( sizeof (* str ) == sizeof (** value ), <nl> + " sizeof (* str ) == sizeof (** value )"); <nl> + UChar32 c = 0 ; <nl> UChar32 p ; <nl> size_t n = 0 ; <nl> uint32_t width = 0 ;
class CipherBase : public BaseObject { <nl> private : <nl> EVP_CIPHER_CTX ctx_ ; /* coverity [ member_decl ] */ <nl> bool initialised_ ; <nl> - CipherKind kind_ ; <nl> + const CipherKind kind_ ; <nl> unsigned int auth_tag_len_ ; <nl> char auth_tag_ [ EVP_GCM_TLS_TAG_LEN ]; <nl> };
static int ea05 ( cli_ctx * ctx , const uint8_t * base , char * tmpd ) { <nl> continue ; <nl> } <nl>  <nl> - if ( UNP . csize < sizeof ( union unaligned_32 )) { <nl> + if ( comp == 1 && UNP . csize < sizeof ( union unaligned_32 )) { <nl> cli_dbgmsg (" autoit : compressed size too small , skipping \ n "); <nl> continue ; <nl> } <nl> static int ea06 ( cli_ctx * ctx , const uint8_t * base , char * tmpd ) { <nl> continue ; <nl> } <nl>  <nl> - if ( UNP . csize < sizeof ( union unaligned_32 )) { <nl> + if ( comp == 1 && UNP . csize < sizeof ( union unaligned_32 )) { <nl> cli_dbgmsg (" autoit : compressed size too small , skipping \ n "); <nl> continue ; <nl> }
int cli_bytecode_prepare ( struct cl_engine * engine , struct cli_all_bc * bcs , unsig <nl> } <nl> cli_bytecode_context_destroy ( ctx ); <nl>  <nl> + <nl> if ( engine -> bytecode_mode != CL_BYTECODE_MODE_INTERPRETER && <nl> engine -> bytecode_mode != CL_BYTECODE_MODE_OFF ) { <nl> + selfcheck ( 1 , bcs -> engine ); <nl> rc = cli_bytecode_prepare_jit ( bcs ); <nl> if ( rc == CL_SUCCESS ) { <nl> jitok = 1 ;
int unrar_open ( int fd , const char * dirname , unrar_state_t * state ) <nl> unrar_dbgmsg (" UNRAR : Offset : % x \ n ", offset ); <nl> if ( offset < 0 ){ <nl> unrar_dbgmsg (" UNRAR : Error Offset : % d \ n ", offset ); <nl> - offset = 0 ; <nl> + free ( main_hdr ); <nl> + free ( state -> comment_dir ); <nl> + free ( unpack_data ); <nl> + return UNRAR_ERR ; <nl> } <nl> comment_header = read_header ( fd , COMM_HEAD ); <nl> if ( comment_header ) {
int wwunpack ( uint8_t * exe , uint32_t exesz , uint8_t * wwsect , struct cli_exe_secti <nl> return CL_EFORMAT ; <nl> exe [ pe + 6 ]=( uint8_t ) scount ; <nl> exe [ pe + 7 ]=( uint8_t )( scount >> 8 ); <nl> + if (! CLI_ISCONTAINED ( wwsect , sects [ scount ]. rsz , wwsect + 0x295 , 4 ) || <nl> + ! CLI_ISCONTAINED ( wwsect , sects [ scount ]. rsz , wwsect + 0x295 + sects [ scount ]. rva , 4 ) || <nl> + ! CLI_ISCONTAINED ( wwsect , sects [ scount ]. rsz , wwsect + 0x295 + sects [ scount ]. rva + 0x299 , 4 )) { <nl> + cli_dbgmsg (" WWPack : unpack memory address out of bounds .\ n "); <nl> + return CL_EFORMAT ; <nl> + } <nl> cli_writeint32 (& exe [ pe + 0x28 ], cli_readint32 ( wwsect + 0x295 )+ sects [ scount ]. rva + 0x299 ); <nl> cli_writeint32 (& exe [ pe + 0x50 ], cli_readint32 (& exe [ pe + 0x50 ])- sects [ scount ]. vsz ); <nl> 
messageAddArgument ( message * m , const char * arg ) <nl> * FIXME : Bounce message handling is corrupting the in <nl> * core copies of headers <nl> */ <nl> - cli_dbgmsg (" Possible data corruption fixed \ n "); <nl> - p [ 8 ] = '='; <nl> + if ( strlen ( p ) > 8 ) { <nl> + cli_dbgmsg (" Possible data corruption fixed \ n "); <nl> + p [ 8 ] = '='; <nl> + } else { <nl> + cli_dbgmsg (" Possible data corruption not fixed \ n "); <nl> + } <nl> } else { <nl> if (* p ) <nl> cli_dbgmsg (" messageAddArgument , '% s ' contains no '='\ n ", p ); <nl> messageFindArgument ( const message * m , const char * variable ) <nl> cli_dbgmsg (" messageFindArgument : no '=' sign found in MIME header '% s ' (% s )\ n ", variable , messageGetArgument ( m , i )); <nl> return NULL ; <nl> } <nl> - if ((*++ ptr == '"') && ( strchr (& ptr [ 1 ], '"') != NULL )) { <nl> + if (( strlen ( ptr ) > 2 ) && (*++ ptr == '"') && ( strchr (& ptr [ 1 ], '"') != NULL )) { <nl> /* Remove any quote characters */ <nl> char * ret = cli_strdup (++ ptr ); <nl> char * p ;
do_cl_join_result ( long long action , <nl> if ( AM_I_DC == FALSE && safe_str_eq ( welcome_from , fsa_our_uname )) { <nl> crm_warn (" Discarding our own welcome - we ' re no longer the DC "); <nl> return I_NULL ; <nl> - <nl> + <nl> + } else if ( g_hash_table_lookup ( <nl> + fsa_membership_copy -> members , welcome_from ) == NULL ){ <nl> + crm_warn (" Discarding welcome from % s ." <nl> + " They are no longer part of the cluster ", <nl> + welcome_from ); <nl> + return I_NULL ; <nl> + <nl> } else if ( fsa_our_dc == NULL ) { <nl> crm_info (" Set DC to % s ", welcome_from ); <nl> fsa_our_dc = crm_strdup ( welcome_from );
stonith_cleanup ( void ) <nl> static struct crm_option long_options [] = { <nl> {" stand - alone ", 0 , 0 , ' s '}, <nl> {" stand - alone - w - cpg ", 0 , 0 , ' c '}, <nl> + {" logfile ", 1 , 0 , ' l '}, <nl> {" verbose ", 0 , 0 , ' V '}, <nl> {" version ", 0 , 0 , '$'}, <nl> {" help ", 0 , 0 , '?'}, <nl> main ( int argc , char ** argv ) <nl> case ' V ': <nl> crm_bump_log_level ( argc , argv ); <nl> break ; <nl> + case ' l ': <nl> + crm_add_logfile ( optarg ); <nl> + break ; <nl> case ' s ': <nl> stand_alone = TRUE ; <nl> break ;
attrd_client_update ( xmlNode * xml ) <nl>  <nl> } else if ( attr == NULL ) { <nl> crm_err (" Update request did not specify attribute or regular expression "); <nl> + free ( key ); <nl> + free ( set ); <nl> + free ( host ); <nl> return ; <nl> } <nl> 
build_operation_update ( <nl> op -> user_data = generate_transition_key (- 1 , fsa_our_uname ); <nl> } <nl> fail_state = generate_transition_magic ( op -> user_data , op -> op_status ); <nl> + crm_xml_add ( xml_op , XML_ATTR_TRANSITION_KEY , op -> user_data ); <nl> crm_xml_add ( xml_op , XML_ATTR_TRANSITION_MAGIC , fail_state ); <nl> crm_free ( fail_state ); <nl> 
static void rsc_order_first ( resource_t * lh_rsc , order_constraint_t * order , pe_wo <nl>  <nl> crm_free ( op_type ); <nl> crm_free ( rsc_id ); <nl> + crm_free ( key ); <nl> } <nl>  <nl> slist_iter (
get_uname ( const char * uuid ) <nl> char * uuid_copy = crm_strdup ( uuid ); <nl>  <nl> cl_uuid_parse ( uuid_copy , & uuid_raw ); <nl> - crm_malloc ( uname , MAX_NAME ); <nl> + crm_malloc ( hb_uname , MAX_NAME ); <nl>  <nl> if ( heartbeat_cluster -> llc_ops -> get_name_by_uuid ( heartbeat_cluster , & uuid_raw , hb_uname , <nl> MAX_NAME ) == HA_FAIL ) {
cib_process_command ( xmlNode * request , xmlNode ** reply , xmlNode ** cib_diff , gb <nl> } <nl>  <nl> if ( rc == pcmk_ok && is_not_set ( call_options , cib_dryrun )) { <nl> - crm_trace (" Activating % d % s % s ", is_set ( call_options , cib_zero_copy ), <nl> + crm_trace (" Activating % s ->% s % s % s ", <nl> crm_element_value ( current_cib , XML_ATTR_NUMUPDATES ), <nl> - crm_element_value ( result_cib , XML_ATTR_NUMUPDATES )); <nl> + crm_element_value ( result_cib , XML_ATTR_NUMUPDATES ), <nl> + ( is_set ( call_options , cib_zero_copy )? " zero - copy " : ""), <nl> + ( config_changed ? " changed " : "")); <nl> if ( is_not_set ( call_options , cib_zero_copy )) { <nl> rc = activateCibXml ( result_cib , config_changed , op ); <nl> - crm_trace (" Activated % d % s ", rc , crm_element_value ( current_cib , XML_ATTR_NUMUPDATES )); <nl> + crm_trace (" Activated % s (% d )", <nl> + crm_element_value ( current_cib , XML_ATTR_NUMUPDATES ), rc ); <nl> } <nl>  <nl> if ( rc == pcmk_ok && cib_internal_config_changed (* cib_diff )) {
-/* $ Id : callbacks . c , v 1 . 70 2005 / 06 / 27 08 : 22 : 01 andrew Exp $ */ <nl> +/* $ Id : callbacks . c , v 1 . 71 2005 / 06 / 28 08 : 11 : 07 andrew Exp $ */ <nl> /* <nl> * Copyright ( C ) 2004 Andrew Beekhof < andrew @ beekhof . net > <nl> * <nl> cib_process_request ( const HA_Message * request , gboolean privileged , <nl> crm_debug_3 (" Processing complete "); <nl>  <nl> if ( rc == cib_diff_resync || rc == cib_diff_failed <nl> -/* || rc == cib_old_data */ <nl> - ) { <nl> + || rc == cib_old_data ) { <nl> crm_warn ("% s operation failed : % s ", <nl> crm_str ( op ), cib_error2string ( rc )); <nl> 
complex_migrate_reload ( resource_t * rsc , pe_working_set_t * data_set ) <nl> if ( other -> optional || other -> rsc != NULL ) { <nl> continue ; <nl> } <nl> - crm_err (" Ordering % s before % s ( stop )", start -> uuid , other_w -> action -> uuid ); <nl> + crm_debug (" Ordering % s before % s ( stop )", start -> uuid , other_w -> action -> uuid ); <nl> order_actions ( start , other , other_w -> type ); <nl> ); <nl>  <nl> complex_migrate_reload ( resource_t * rsc , pe_working_set_t * data_set ) <nl> } else if ( other -> optional || other -> rsc == rsc || other -> rsc == rsc -> parent ) { <nl> continue ; <nl> } <nl> - crm_err (" Ordering % s before % s ( start )", other_w -> action -> uuid , stop -> uuid ); <nl> + crm_debug (" Ordering % s before % s ( start )", other_w -> action -> uuid , stop -> uuid ); <nl> order_actions ( other , stop , other_w -> type ); <nl> ); <nl> 
void GetOSRand ( unsigned char * ent32 ) <nl> RandFailure (); <nl> } <nl> } <nl> -# elif defined ( HAVE_GETENTROPY ) <nl> +# elif defined ( HAVE_GETENTROPY ) && defined ( __OpenBSD__ ) <nl> /* On OpenBSD this can return up to 256 bytes of entropy , will return an <nl> * error if more are requested . <nl> * The call cannot return less than the requested number of bytes . <nl> + getentropy is explicitly limited to openbsd here , as a similar ( but not <nl> + the same ) function may exist on other platforms via glibc . <nl> */ <nl> if ( getentropy ( ent32 , NUM_OS_RANDOM_BYTES ) != 0 ) { <nl> RandFailure ();
bool ParseHDKeypath ( std :: string keypath_str , std :: vector < uint32_t >& keypath ) <nl> return false ; <nl> } <nl> uint32_t number ; <nl> - ParseUInt32 ( item , & number ); <nl> + if (! ParseUInt32 ( item , & number )) { <nl> + return false ; <nl> + } <nl> path |= number ; <nl>  <nl> keypath . push_back ( path );
static int ng_pkt ( git_pkt ** out , const char * line , size_t len ) <nl> pkt -> ref = NULL ; <nl> pkt -> type = GIT_PKT_NG ; <nl>  <nl> + if ( len < 3 ) <nl> + goto out_err ; <nl> line += 3 ; /* skip " ng " */ <nl> - if (!( ptr = strchr ( line , ' '))) <nl> + len -= 3 ; <nl> + if (!( ptr = memchr ( line , ' ', len ))) <nl> goto out_err ; <nl> len = ptr - line ; <nl>  <nl> static int ng_pkt ( git_pkt ** out , const char * line , size_t len ) <nl> memcpy ( pkt -> ref , line , len ); <nl> pkt -> ref [ len ] = '\ 0 '; <nl>  <nl> + if ( len < 1 ) <nl> + goto out_err ; <nl> line = ptr + 1 ; <nl> - if (!( ptr = strchr ( line , '\ n '))) <nl> + len -= 1 ; <nl> + if (!( ptr = memchr ( line , '\ n ', len ))) <nl> goto out_err ; <nl> len = ptr - line ; <nl> 
void git_branch_iterator_free ( git_branch_iterator * _iter ) <nl> { <nl> branch_iter * iter = ( branch_iter *) _iter ; <nl>  <nl> + if ( iter == NULL ) <nl> + return ; <nl> + <nl> git_reference_iterator_free ( iter -> iter ); <nl> git__free ( iter ); <nl> }
int git_path_dirload_with_stat ( <nl> if ( error != 0 ) { <nl> giterr_clear (); <nl> error = 0 ; <nl> + memset (& ps -> st , 0 , sizeof ( ps -> st )); <nl> ps -> st . st_mode = GIT_FILEMODE_UNREADABLE ; <nl> continue ; <nl> }
static int git_smart__connect ( <nl> /* We now have loaded the refs . */ <nl> t -> have_refs = 1 ; <nl>  <nl> - first = ( git_pkt_ref *) git_vector_get (& t -> refs , 0 ); <nl> + pkt = ( git_pkt *) git_vector_get (& t -> refs , 0 ); <nl> + if ( pkt && GIT_PKT_REF != pkt -> type ) { <nl> + giterr_set ( GITERR_NET , " invalid response "); <nl> + return - 1 ; <nl> + } <nl> + first = ( git_pkt_ref *) pkt ; <nl>  <nl> if (( error = git_vector_init (& symrefs , 1 , NULL )) < 0 ) <nl> return error ;
int git_reference_rename ( git_reference * ref , const char * new_name , int force ) <nl> head_target = git_reference_target ( head ); <nl>  <nl> if ( head_target && ! strcmp ( head_target , ref -> name )) { <nl> + git_reference_free ( head ); <nl> + head = NULL ; <nl> + <nl> if ( git_reference_create_symbolic (& head , ref -> owner , " HEAD ", new_name , 1 ) < 0 ) { <nl> giterr_set ( GITERR_REFERENCE , <nl> " Failed to update HEAD after renaming reference ");
int git_repository_head_unborn ( git_repository * repo ) <nl> error = git_repository_head (& ref , repo ); <nl> git_reference_free ( ref ); <nl>  <nl> - if ( error == GIT_EUNBORNBRANCH ) <nl> + if ( error == GIT_EUNBORNBRANCH ) { <nl> + giterr_clear (); <nl> return 1 ; <nl> + } <nl>  <nl> if ( error < 0 ) <nl> return - 1 ;
cmsPipeline * DefaultICCintents ( cmsContext ContextID , <nl> // Concatenate to the output LUT <nl> if (! cmsPipelineCat ( Result , Lut )) <nl> goto Error ; <nl> + <nl> cmsPipelineFree ( Lut ); <nl> + Lut = NULL ; <nl>  <nl> // Update current space <nl> CurrentColorSpace = ColorSpaceOut ; <nl> cmsPipeline * DefaultICCintents ( cmsContext ContextID , <nl>  <nl> Error : <nl>  <nl> - cmsPipelineFree ( Lut ); <nl> + if ( Lut != NULL ) cmsPipelineFree ( Lut ); <nl> if ( Result != NULL ) cmsPipelineFree ( Result ); <nl> return NULL ; <nl> 
# define BLOCKSIZE ( RECORDSIZE * 20 ) <nl>  <nl> static const char tar_tree_usage [] = <nl> -" git - tar - tree [-- remote =< repo >] < ent > [ basedir ]"; <nl> +" git - tar - tree [-- remote =< repo >] < tree - ish > [ basedir ]"; <nl>  <nl> static char block [ BLOCKSIZE ]; <nl> static unsigned long offset ;
static struct cache_entry * refresh_cache_ent ( struct index_state * istate , <nl> if ( ce_uptodate ( ce )) <nl> return ce ; <nl>  <nl> + /* <nl> + * CE_VALID means the user promised us that the change to <nl> + * the work tree does not matter and told us not to worry . <nl> + */ <nl> + if (! ignore_valid && ( ce -> ce_flags & CE_VALID )) { <nl> + ce_mark_uptodate ( ce ); <nl> + return ce ; <nl> + } <nl> + <nl> if ( lstat ( ce -> name , & st ) < 0 ) { <nl> if ( err ) <nl> * err = errno ;
static struct ref_entry * search_ref_array ( struct ref_array * array , const char * n <nl> if ( name == NULL ) <nl> return NULL ; <nl>  <nl> + if (! array -> nr ) <nl> + return NULL ; <nl> + <nl> len = strlen ( name ) + 1 ; <nl> e = xmalloc ( sizeof ( struct ref_entry ) + len ); <nl> memcpy ( e -> name , name , len );
int read_mailmap ( struct path_list * map , const char * filename , char ** repo_abbrev <nl> int abblen = sizeof ( abbrev ) - 1 ; <nl> int len = strlen ( buffer ); <nl>  <nl> + if (! repo_abbrev ) <nl> + continue ; <nl> + <nl> if ( len && buffer [ len - 1 ] == '\ n ') <nl> buffer [-- len ] = 0 ; <nl> if (! strncmp ( buffer , abbrev , abblen )) {
const char * resolve_ref ( const char * ref , unsigned char * sha1 , int reading , int * <nl> /* Follow " normalized " - ie " refs /.." symlinks by hand */ <nl> if ( S_ISLNK ( st . st_mode )) { <nl> len = readlink ( path , buffer , sizeof ( buffer )- 1 ); <nl> + if ( len < 0 ) <nl> + return NULL ; <nl> if ( len >= 5 && ! memcmp (" refs /", buffer , 5 )) { <nl> buffer [ len ] = 0 ; <nl> strcpy ( ref_buffer , buffer );
*/ <nl>  <nl> typedef struct { <nl> + unsigned long long size ; <nl> unsigned int H [ 5 ]; <nl> unsigned int W [ 16 ]; <nl> - unsigned long long size ; <nl> } blk_SHA_CTX ; <nl>  <nl> void blk_SHA1_Init ( blk_SHA_CTX * ctx );
static void parse_args ( int argc , const char ** argv ) <nl>  <nl> if ( get_sha1 ( arg , sha1 )) <nl> die (" Cannot find '% s '", arg ); <nl> - commit = ( struct commit *) parse_object ( sha1 ); <nl> + commit = lookup_commit_reference ( sha1 ); <nl> if (! commit ) <nl> - die (" Could not find % s ", sha1_to_hex ( sha1 )); <nl> - if ( commit -> object . type == OBJ_TAG ) { <nl> - commit = ( struct commit *) <nl> - deref_tag (( struct object *) commit , arg , strlen ( arg )); <nl> - } <nl> - if ( commit -> object . type != OBJ_COMMIT ) <nl> - die ("'% s ' does not point to a commit ", arg ); <nl> + exit ( 1 ); <nl> } <nl>  <nl> static char * get_oneline ( const char * message )
static struct child_process * git_connect_git ( int fd [ 2 ], char * hostandport , <nl> target_host = xstrdup ( hostandport ); <nl>  <nl> transport_check_allowed (" git "); <nl> + if ( strchr ( target_host , '\ n ') || strchr ( path , '\ n ')) <nl> + die ( _ (" newline is forbidden in git :// hosts and repo paths ")); <nl>  <nl> /* <nl> * These underlying connection commands die () if they
struct child_process * git_connect ( int fd [ 2 ], const char * url_orig , <nl> c = ':'; <nl> } <nl>  <nl> + /* <nl> + * Don ' t do destructive transforms with git :// as that <nl> + * protocol code does '[]' dewrapping of its own . <nl> + */ <nl> if ( host [ 0 ] == '[') { <nl> end = strchr ( host + 1 , ']'); <nl> if ( end ) { <nl> - * end = 0 ; <nl> + if ( protocol != PROTO_GIT ) { <nl> + * end = 0 ; <nl> + host ++; <nl> + } <nl> end ++; <nl> - host ++; <nl> } else <nl> end = host ; <nl> } else
int main ( int argc , const char ** argv ) <nl>  <nl> git_extract_argv0_path ( argv [ 0 ]); <nl>  <nl> + if ( argc == 2 && ! strcmp ( argv [ 1 ], "- h ")) <nl> + usage ( fast_import_usage ); <nl> + <nl> setup_git_directory (); <nl> git_config ( git_pack_config , NULL ); <nl> if (! pack_compression_seen && core_compression_seen )
static void * add_to_trie ( struct trie * root , const char * key , void * value ) <nl> * Split this node : child will contain this node ' s <nl> * existing children . <nl> */ <nl> - child = malloc ( sizeof (* child )); <nl> + child = xmalloc ( sizeof (* child )); <nl> memcpy ( child -> children , root -> children , sizeof ( root -> children )); <nl>  <nl> child -> len = root -> len - i - 1 ;
static int tags ; /* Allow lightweight tags */ <nl> static int longformat ; <nl> static int abbrev = DEFAULT_ABBREV ; <nl> static int max_candidates = 10 ; <nl> + static int found_names ; <nl> static const char * pattern ; <nl> static int always ; <nl>  <nl> static void add_to_known_names ( const char * path , <nl> memcpy ( e -> path , path , len ); <nl> commit -> util = e ; <nl> } <nl> + found_names = 1 ; <nl> } <nl>  <nl> static int get_name ( const char * path , const unsigned char * sha1 , int flag , void * cb_data ) <nl> static void describe ( const char * arg , int last_one ) <nl> for_each_ref ( get_name , NULL ); <nl> } <nl>  <nl> + if (! found_names ) <nl> + die (" cannot describe '% s '", sha1_to_hex ( sha1 )); <nl> + <nl> n = cmit -> util ; <nl> if ( n ) { <nl> /*
static void prune_directory ( struct dir_struct * dir , const char ** pathspec , int p <nl> free ( entry ); <nl> continue ; <nl> } <nl> + if ( entry -> ignored_entry ) <nl> + fprintf ( stderr , " warning : '% s ' is an ignored path .\ n ", <nl> + entry -> name ); <nl> * dst ++ = entry ; <nl> } <nl> dir -> nr = dst - dir -> entries ;
static int write_tree ( struct cache_entry ** cachep , int maxentries , const char * b <nl> offset = 0 ; <nl>  <nl> nr = 0 ; <nl> - do { <nl> + while ( nr < maxentries ) { <nl> struct cache_entry * ce = cachep [ nr ]; <nl> const char * pathname = ce -> name , * filename , * dirname ; <nl> int pathlen = ce_namelen ( ce ), entrylen ; <nl> static int write_tree ( struct cache_entry ** cachep , int maxentries , const char * b <nl> memcpy ( buffer + offset , sha1 , 20 ); <nl> offset += 20 ; <nl> nr ++; <nl> - } while ( nr < maxentries ); <nl> + } <nl>  <nl> write_sha1_file ( buffer , offset , " tree ", returnsha1 ); <nl> free ( buffer ); <nl> int main ( int argc , char ** argv ) <nl> int entries = read_cache (); <nl> unsigned char sha1 [ 20 ]; <nl>  <nl> - if ( entries <= 0 ) <nl> - die (" write - tree : no cache contents to write "); <nl> + if ( entries < 0 ) <nl> + die (" write - tree : error reading cache "); <nl>  <nl> /* Verify that the tree is merged */ <nl> unmerged = 0 ;
int main ( int argc , const char ** argv ) <nl> else <nl> revs . header_prefix = " commit "; <nl> } <nl> + else if ( revs . verbose_header ) <nl> + /* Only -- header was specified */ <nl> + revs . commit_format = CMIT_FMT_RAW ; <nl>  <nl> list = revs . commits ; <nl> 
static void process_blob ( struct rev_info * revs , <nl>  <nl> if (! revs -> blob_objects ) <nl> return ; <nl> + if (! obj ) <nl> + die (" bad blob object "); <nl> if ( obj -> flags & ( UNINTERESTING | SEEN )) <nl> return ; <nl> obj -> flags |= SEEN ; <nl> static void process_tree ( struct rev_info * revs , <nl>  <nl> if (! revs -> tree_objects ) <nl> return ; <nl> + if (! obj ) <nl> + die (" bad tree object "); <nl> if ( obj -> flags & ( UNINTERESTING | SEEN )) <nl> return ; <nl> if ( parse_tree ( tree ) < 0 )
static int fetch_indices ( struct alt_base * repo ) <nl> switch ( data [ i ]) { <nl> case ' P ': <nl> i ++; <nl> - if ( i + 52 < buffer . posn && <nl> + if ( i + 52 <= buffer . posn && <nl> ! strncmp ( data + i , " pack -", 6 ) && <nl> ! strncmp ( data + i + 46 , ". pack \ n ", 6 )) { <nl> get_sha1_hex ( data + i + 6 , sha1 ); <nl> static int fetch_indices ( struct alt_base * repo ) <nl> break ; <nl> } <nl> default : <nl> - while ( data [ i ] != '\ n ') <nl> + while ( i < buffer . posn && data [ i ] != '\ n ') <nl> i ++; <nl> } <nl> i ++;
unsigned long count_delta ( void * delta_buf , unsigned long delta_size ) <nl> /* delete size is what was _not_ copied from source . <nl> * edit size is that and literal additions . <nl> */ <nl> + if ( src_size + added_literal < copied_from_source ) <nl> + /* we ended up overcounting and underflowed */ <nl> + return 0 ; <nl> return ( src_size - copied_from_source ) + added_literal ; <nl> }
void add_object ( struct object * obj , <nl>  <nl> static void mark_blob_uninteresting ( struct blob * blob ) <nl> { <nl> + if (! blob ) <nl> + return ; <nl> if ( blob -> object . flags & UNINTERESTING ) <nl> return ; <nl> blob -> object . flags |= UNINTERESTING ; <nl> void mark_tree_uninteresting ( struct tree * tree ) <nl> struct name_entry entry ; <nl> struct object * obj = & tree -> object ; <nl>  <nl> + if (! tree ) <nl> + return ; <nl> if ( obj -> flags & UNINTERESTING ) <nl> return ; <nl> obj -> flags |= UNINTERESTING ;
static int setup_index ( unsigned char * sha1 ) <nl> return - 1 ; <nl>  <nl> new_pack = parse_pack_index ( sha1 ); <nl> + if (! new_pack ) <nl> + return - 1 ; /* parse_pack_index () already issued error message */ <nl> new_pack -> next = repo -> packs ; <nl> repo -> packs = new_pack ; <nl> return 0 ;
void mark_parents_uninteresting ( struct commit * commit ) <nl> * it is popped next time around , we won ' t be trying <nl> * to parse it and get an error . <nl> */ <nl> - if (! has_object_file (& commit -> object . oid )) <nl> + if (! commit -> object . parsed && <nl> + ! has_object_file (& commit -> object . oid )) <nl> commit -> object . parsed = 1 ; <nl>  <nl> if ( commit -> object . flags & UNINTERESTING )
static void create_one_file ( char * path , unsigned mode , const char * buf , unsigned <nl> unsigned int nr = getpid (); <nl>  <nl> for (;;) { <nl> - const char * newpath ; <nl> - newpath = mkpath ("% s ~% u ", path , nr ); <nl> + char newpath [ PATH_MAX ]; <nl> + mksnpath ( newpath , sizeof ( newpath ), "% s ~% u ", path , nr ); <nl> if (! try_create_file ( newpath , mode , buf , size )) { <nl> if (! rename ( newpath , path )) <nl> return ;
dsl_pool_dirty_delta ( dsl_pool_t * dp , int64_t delta ) <nl> * Note : we signal even when increasing dp_dirty_total . <nl> * This ensures forward progress -- each thread wakes the next waiter . <nl> */ <nl> - if ( dp -> dp_dirty_total <= zfs_dirty_data_max ) <nl> + if ( dp -> dp_dirty_total < zfs_dirty_data_max ) <nl> cv_signal (& dp -> dp_spaceavail_cv ); <nl> } <nl> 
dnode_hold_impl ( objset_t * os , uint64_t object , int flag , <nl> int i ; <nl> dnode_children_t * winner ; <nl> children_dnodes = kmem_alloc ( sizeof ( dnode_children_t ) + <nl> - ( epb - 1 ) * sizeof ( dnode_handle_t ), KM_SLEEP | KM_NODEBUG ); <nl> + ( epb - 1 ) * sizeof ( dnode_handle_t ), <nl> + KM_PUSHPAGE | KM_NODEBUG ); <nl> children_dnodes -> dnc_count = epb ; <nl> dnh = & children_dnodes -> dnc_children [ 0 ]; <nl> for ( i = 0 ; i < epb ; i ++) {
typedef struct refcount { <nl> boolean_t rc_tracked ; <nl> list_t rc_list ; <nl> list_t rc_removed ; <nl> - int64_t rc_count ; <nl> - int64_t rc_removed_count ; <nl> + uint64_t rc_count ; <nl> + uint64_t rc_removed_count ; <nl> } refcount_t ; <nl>  <nl> /* Note : refcount_t must be initialized with refcount_create [ _untracked ]() */
static void doveadm_close ( struct doveadm_connection * conn ) <nl> conn -> fd = - 1 ; <nl> conn -> end_of_print = FALSE ; <nl> conn -> cmd_sent = FALSE ; <nl> + conn -> handshaked = FALSE ; <nl> } <nl>  <nl> static void doveadm_disconnect ( struct doveadm_connection * conn )
void main_unref ( void ) <nl> /* last login finished , close all communications <nl> to master process */ <nl> master_close (); <nl> + /* we might still be proxying . close the connection to <nl> + dovecot - auth , since it ' s not needed anymore . */ <nl> + auth_client_free (& auth_client ); <nl> } <nl> } <nl>  <nl> static void main_deinit ( void ) <nl> ssl_proxy_deinit (); <nl> login_proxy_deinit (); <nl>  <nl> - auth_client_free (& auth_client ); <nl> + if ( auth_client != NULL ) <nl> + auth_client_free (& auth_client ); <nl> clients_deinit (); <nl> master_deinit (); <nl> 
void smtp_server_connection_data_chunk_init ( struct smtp_server_cmd_ctx * cmd ) <nl> command -> hook_replied = cmd_data_chunk_replied ; <nl> command -> hook_destroy = cmd_data_destroy ; <nl>  <nl> - if ( conn -> state . data_chain == NULL ) { <nl> + if (! conn -> state . data_failed && conn -> state . data_chain == NULL ) { <nl> i_assert ( data_cmd -> chunk_first ); <nl> i_assert ( conn -> state . data_chain_input == NULL ); <nl> conn -> state . data_chain_input =
static void o_stream_metawrap_call_callback ( struct metawrap_ostream * mstream ) <nl> if ( write_callback != NULL ) { <nl> mstream -> write_callback = NULL ; <nl> write_callback ( mstream -> context ); <nl> + /* metadata headers aren ' t counted as part of the offset */ <nl> + mstream -> ostream . ostream . offset = 0 ; <nl> } <nl> } <nl> 
cmd_dsync_run ( struct doveadm_mail_cmd_context * _ctx , struct mail_user * user ) <nl> brain = dsync_brain_master_init ( user , ibc , ctx -> sync_type , <nl> brain_flags , & set ); <nl>  <nl> - if ( ctx -> run_type == DSYNC_RUN_TYPE_LOCAL ) { <nl> + switch ( ctx -> run_type ) { <nl> + case DSYNC_RUN_TYPE_LOCAL : <nl> if ( cmd_dsync_run_local ( ctx , user , brain , ibc2 , <nl> & changes_during_sync , & mail_error ) < 0 ) <nl> ret = - 1 ; <nl> - } else { <nl> + break ; <nl> + case DSYNC_RUN_TYPE_CMD : <nl> ctx -> child_wait = child_wait_new_with_pid ( ctx -> remote_pid , <nl> cmd_dsync_remote_exited , ctx ); <nl> + /* fall through */ <nl> + case DSYNC_RUN_TYPE_STREAM : <nl> cmd_dsync_run_remote ( user ); <nl> + break ; <nl> } <nl>  <nl> if ( ctx -> state_input != NULL ) {
static const char * find_next_secret ( const char * input , const char ** secret_r ) <nl> { <nl> const char * const * secret ; <nl> const char * ptr = NULL ; <nl> + * secret_r = NULL ; <nl> for ( secret = secrets ; * secret != NULL ; secret ++) { <nl> const char * cptr ; <nl> if (( cptr = strstr ( input , * secret )) != NULL ) { <nl> static const char * find_next_secret ( const char * input , const char ** secret_r ) <nl> } <nl> } <nl> } <nl> + i_assert (* secret_r != NULL || ptr == NULL ); <nl> return ptr ; <nl> } <nl> 
int index_mail_set_seq ( struct mail * _mail , uint32_t seq ) <nl> unsigned int cache_field2 = <nl> cache_fields [ MAIL_CACHE_IMAP_ENVELOPE ]. idx ; <nl>  <nl> - if ( mail_cache_field_exists ( cache_view , seq , <nl> - cache_field1 ) == 0 && <nl> + if (( cache_field1 == ( unsigned int )- 1 || <nl> + mail_cache_field_exists ( cache_view , seq , <nl> + cache_field1 ) == 0 ) && <nl> mail_cache_field_exists ( cache_view , seq , <nl> cache_field2 ) == 0 ) <nl> data -> access_part |= PARSE_HDR ;
static int search_arg_match_text ( struct mail_search_arg * args , <nl> i_zero (& body_ctx ); <nl> body_ctx . index_ctx = ctx ; <nl> body_ctx . input = input ; <nl> + /* Get parts if they already exist in cache . If they don ' t , <nl> + message - search will parse the mail automatically . */ <nl> + ctx -> cur_mail -> lookup_abort = MAIL_LOOKUP_ABORT_NOT_IN_CACHE ; <nl> ( void ) mail_get_parts ( ctx -> cur_mail , & body_ctx . part ); <nl> + ctx -> cur_mail -> lookup_abort = MAIL_LOOKUP_ABORT_NEVER ; <nl>  <nl> return mail_search_args_foreach ( args , search_body , & body_ctx ); <nl> }
static int index_list_mailbox_open ( struct mailbox * box ) <nl> if ( ibox -> module_ctx . super . open ( box ) < 0 ) <nl> return - 1 ; <nl>  <nl> + if ( box -> view == NULL ) { <nl> + /* FIXME : dsync - merge is performing a delete in obox - remove <nl> + this check once dsync - merging is no longer used . */ <nl> + return 0 ; <nl> + } <nl> + <nl> /* if mailbox name has changed , update it to the header . Use \ 0 <nl> as the hierarchy separator in the header . This is to make sure <nl> we don ' t keep rewriting the name just in case some backend switches
DOVEADM_CMD_PARAMS_END <nl>  <nl> struct doveadm_cmd_ver2 doveadm_cmd_mailbox_delete_ver2 = { <nl> . name = " mailbox delete ", <nl> - . mail_cmd = cmd_mailbox_delete_alloc , <nl> - . usage = DOVEADM_CMD_MAIL_USAGE_PREFIX "[- s ] < mailbox > [...]", <nl> + . mail_cmd = cmd_mailbox_delete_alloc , <nl> + . usage = DOVEADM_CMD_MAIL_USAGE_PREFIX "[- s ] < mailbox > [...]", <nl> DOVEADM_CMD_PARAMS_START <nl> DOVEADM_CMD_MAIL_COMMON <nl> DOVEADM_CMD_PARAM (' s ', " subscriptions ", CMD_PARAM_BOOL , 0 )
index_mail_body_parsed_cache_bodystructure ( struct index_mail * mail , <nl> } <nl> } <nl>  <nl> + if (! data -> parsed_bodystructure ) <nl> + return ; <nl> + <nl> /* If BODY is fetched first but BODYSTRUCTURE is also wanted , we don ' t <nl> normally want to first cache BODY and then BODYSTRUCTURE . So check <nl> the wanted_fields also in here . */
master_service_exec_config ( struct master_service * service , bool preserve_home ) <nl> /* @ UNSAFE */ <nl> conf_argv = t_new ( const char *, 6 + ( service -> argc + 1 ) + 1 ); <nl> conf_argv [ 0 ] = DOVECOT_CONFIG_BIN_PATH ; <nl> - conf_argv [ 1 ] = "- p "; <nl> - conf_argv [ 2 ] = service -> name ; <nl> + conf_argv [ 1 ] = "- f "; <nl> + conf_argv [ 2 ] = t_strconcat (" service =", service -> name , NULL ); <nl> conf_argv [ 3 ] = "- c "; <nl> conf_argv [ 4 ] = service -> config_path ; <nl> conf_argv [ 5 ] = "- e ";
cmd_append_handle_args ( struct client_command_context * cmd , <nl> /* invalid keywords - delay failure */ <nl> client_send_box_error ( cmd , ctx -> box ); <nl> ctx -> failed = TRUE ; <nl> + keywords = NULL ; <nl> } <nl> } <nl> 
int shared_storage_get_namespace ( struct mail_namespace ** _ns , <nl> /* this user doesn ' t have a usable storage */ <nl> new_ns -> flags |= NAMESPACE_FLAG_UNUSABLE ; <nl> } <nl> + /* mark the shared namespace root as usable , since it now has <nl> + child namespaces */ <nl> + ns -> flags |= NAMESPACE_FLAG_USABLE ; <nl> * _name = mailbox_list_get_storage_name ( new_ns -> list , <nl> t_strconcat ( new_ns -> prefix , name , NULL )); <nl> * _ns = new_ns ;
ssize_t o_stream_send ( struct ostream * stream , const void * data , size_t size ) <nl> if ( stream -> closed ) <nl> return - 1 ; <nl>  <nl> + if ( size == 0 ) <nl> + return 0 ; <nl> + <nl> return _stream -> send ( _stream , data , size ); <nl> } <nl> 
static bool inotify_input_more ( struct ioloop * ioloop ) <nl> break ; <nl>  <nl> event = ( struct inotify_event *)( event_buf + pos ); <nl> - i_assert ( event -> len < ret ); <nl> + i_assert ( event -> len < ( size_t ) ret ); <nl> pos += sizeof (* event ) + event -> len ; <nl>  <nl> io = io_notify_fd_find (& ctx -> fd_ctx , event -> wd );
static void index_mail_reset ( struct index_mail * mail ) <nl> data -> save_date = ( time_t )- 1 ; <nl> data -> received_date = ( time_t )- 1 ; <nl> data -> sent_date . time = ( uint32_t )- 1 ; <nl> + <nl> + mail -> mail . mail . seq = 0 ; <nl> + mail -> mail . mail . uid = 0 ; <nl> + mail -> mail . mail . expunged = FALSE ; <nl> + mail -> mail . mail . has_nuls = FALSE ; <nl> + mail -> mail . mail . has_no_nuls = FALSE ; <nl> } <nl>  <nl> static void check_envelope ( struct index_mail * mail )
static void hook_build_update ( struct hook_build_context * ctx , void * _vlast ) <nl> void (** vlast )() = _vlast ; <nl> struct hook_stack * stack ; <nl>  <nl> + if ( ctx -> tail -> vfuncs == vlast ) { <nl> + /* no vfuncs overridden */ <nl> + return ; <nl> + } <nl> + <nl> /* ctx -> vfuncs_stack -> vfuncs points to the root vfuncs , <nl> ctx -> vfuncs_stack -> next -> vfuncs points to the first super function <nl> that is being called , and so on .
uid_range_to_seqs ( struct fts_search_context * fctx , <nl> if (! array_is_created ( seq_range )) <nl> p_array_init ( seq_range , fctx -> result_pool , count ); <nl> for ( i = 0 ; i < count ; i ++) { <nl> + if ( range [ i ]. seq1 > range [ i ]. seq2 ) <nl> + continue ; <nl> mailbox_get_seq_range ( fctx -> box , range [ i ]. seq1 , range [ i ]. seq2 , <nl> & seq1 , & seq2 ); <nl> if ( seq1 != 0 )
uint64_t mail_index_transaction_get_highest_modseq ( struct mail_index_transaction <nl> new_highest_modseq ++; <nl> } <nl> if ( array_is_created (& t -> updates ) && <nl> - transaction_flag_updates_have_non_internal ( t ) > 0 ) <nl> + transaction_flag_updates_have_non_internal ( t )) <nl> new_highest_modseq ++; <nl> if ( array_is_created (& t -> keyword_updates )) { <nl> new_highest_modseq +=
void ssl_iostream_destroy ( struct ssl_iostream ** _ssl_io ) <nl> { <nl> struct ssl_iostream * ssl_io = * _ssl_io ; <nl>  <nl> + if ( _ssl_io == NULL || * _ssl_io == NULL ) <nl> + return ; <nl> + <nl> + ssl_io = * _ssl_io ; <nl> * _ssl_io = NULL ; <nl> ssl_vfuncs -> destroy ( ssl_io ); <nl> }
int mail_cache_lookup_headers ( struct mail_cache_view * view , string_t * dest , <nl> } <nl> } <nl>  <nl> + for ( i = 0 ; i < fields_count ; i ++) <nl> + mail_cache_decision_lookup ( view , seq , fields [ i ]); <nl> + <nl> data = buffer_get_modifiable_data ( ctx . data , & size ); <nl> size /= sizeof (* data ); <nl> qsort ( data , size , sizeof (* data ), header_lookup_data_cmp );
static int list_uids_iter ( struct client * client , struct cmd_uidl_context * ctx ) <nl> if (( uidl_keymask & UIDL_MD5 ) != 0 ) { <nl> tab [ 2 ]. value = mail_get_special ( ctx -> mail , <nl> MAIL_FETCH_HEADER_MD5 ); <nl> + if ( tab [ 2 ]. value == NULL ) { <nl> + /* broken */ <nl> + t_pop (); <nl> + break ; <nl> + } <nl> } <nl> if (( uidl_keymask & UIDL_FILE_NAME ) != 0 ) { <nl> tab [ 3 ]. value = <nl> mail_get_special ( ctx -> mail , <nl> MAIL_FETCH_UIDL_FILE_NAME ); <nl> + if ( tab [ 3 ]. value == NULL ) { <nl> + /* broken */ <nl> + t_pop (); <nl> + break ; <nl> + } <nl> } <nl>  <nl> str_truncate ( str , 0 );
index_list_get_view_status ( struct mailbox * box , struct mail_index_view * view , <nl> ret = FALSE ; <nl> else { <nl> status_r -> uidvalidity = rec -> uid_validity ; <nl> - memcpy ( mailbox_guid , rec -> guid , GUID_128_SIZE ); <nl> + if ( mailbox_guid != NULL ) <nl> + memcpy ( mailbox_guid , rec -> guid , GUID_128_SIZE ); <nl> } <nl> } <nl> 
static bool remote_ip_is_usable ( const struct ip_addr * ip ) <nl> return FALSE ; /* 10 / 8 */ <nl> if ( addr >= 3232235520 && addr <= 3232301055 ) <nl> return FALSE ; /* 192 . 168 / 16 */ <nl> + if ( addr >= 2886729728 && addr <= 2887778303 ) <nl> + return FALSE ; /* 172 . 16 / 12 */ <nl> if ( addr >= 2130706432 && addr <= 2147483647 ) <nl> return FALSE ; /* 127 / 8 */ <nl> }
cmd_save_to_mailbox ( struct save_cmd_context * ctx , struct mailbox * box , <nl> i_error (" open (% s ) failed : % s ", <nl> i_stream_get_name ( input ), <nl> i_stream_get_error ( input )); <nl> + ctx -> ctx . exit_code = EX_TEMPFAIL ; <nl> return - 1 ; <nl> } <nl> 
cap_req ( struct Client * source_p , const char * arg ) <nl> } <nl>  <nl> strcat ( pbuf [ i ], cap -> name ); <nl> - strcat ( pbuf [ i ], " "); <nl> - plen += ( cap -> namelen + 1 ); <nl> + if (! finished ) { <nl> + strcat ( pbuf [ i ], " "); <nl> + plen += ( cap -> namelen + 1 ); <nl> + } <nl> } <nl>  <nl> if (! finished )
rb_get_ssl_certfp ( rb_fde_t * F , uint8_t certfp [ RB_SSL_CERTFP_LEN ]) <nl> res == X509_V_ERR_DEPTH_ZERO_SELF_SIGNED_CERT ) <nl> { <nl> memcpy ( certfp , cert -> sha1_hash , RB_SSL_CERTFP_LEN ); <nl> + X509_free ( cert ); <nl> return 1 ; <nl> } <nl> X509_free ( cert );
CURLcode Curl_readwrite ( struct connectdata * conn , <nl> conn -> size - k -> bytecount ); <nl> return CURLE_PARTIAL_FILE ; <nl> } <nl> - else if ( conn -> bits . chunk && <nl> + else if (!( conn -> bits . no_body ) && <nl> + conn -> bits . chunk && <nl> ( conn -> proto . http -> chunk . state != CHUNK_STOP )) { <nl> /* <nl> * In chunked mode , return an error if the connection is closed prior to
int Curl_GetFTPResponse ( char * buf , <nl> int i ; <nl> for ( meow = line_start , i = 0 ; meow < ptr ; meow ++, i ++) <nl> buf [ i ] = * meow ; <nl> - meow [ i ]= 0 ; /* zero terminate */ <nl> + * meow = 0 ; /* zero terminate */ <nl> keepon = FALSE ; <nl> break ; <nl> }
static CURLcode ssh_statemach_act ( struct connectdata * conn , bool * block ) <nl> case SSH_SFTP_QUOTE_MKDIR : <nl> rc = libssh2_sftp_mkdir_ex ( sshc -> sftp_session , sshc -> quote_path1 , <nl> ( unsigned int ) strlen ( sshc -> quote_path1 ), <nl> - 0755 ); <nl> + data -> set . new_directory_perms ); <nl> if ( rc == LIBSSH2_ERROR_EAGAIN ) { <nl> break ; <nl> }
void curl_mime_free ( curl_mime * mime ) <nl> curl_mimepart * part ; <nl>  <nl> if ( mime ) { <nl> + mime_subparts_unbind ( mime ); /* Be sure it ' s not referenced anymore . */ <nl> while ( mime -> firstpart ) { <nl> part = mime -> firstpart ; <nl> mime -> firstpart = part -> nextpart ;
static CURLcode parse_proxy ( struct Curl_easy * data , <nl> with reserved characters like ':' in them . */ <nl> Curl_safefree ( proxyinfo -> user ); <nl> proxyinfo -> user = curl_easy_unescape ( data , proxyuser , 0 , NULL ); <nl> + Curl_safefree ( proxyuser ); <nl>  <nl> - if (! proxyinfo -> user ) <nl> + if (! proxyinfo -> user ) { <nl> + Curl_safefree ( proxypasswd ); <nl> return CURLE_OUT_OF_MEMORY ; <nl> + } <nl>  <nl> Curl_safefree ( proxyinfo -> passwd ); <nl> if ( proxypasswd && strlen ( proxypasswd ) < MAX_CURL_PASSWORD_LENGTH ) <nl> proxyinfo -> passwd = curl_easy_unescape ( data , proxypasswd , 0 , NULL ); <nl> else <nl> proxyinfo -> passwd = strdup (""); <nl> + Curl_safefree ( proxypasswd ); <nl>  <nl> if (! proxyinfo -> passwd ) <nl> return CURLE_OUT_OF_MEMORY ;
 <nl> char * curl_escape ( char * string ) <nl> { <nl> - int alloc = strlen ( string ); <nl> + int alloc = strlen ( string )+ 1 ; <nl> char * ns = malloc ( alloc ); <nl> unsigned char in ; <nl> int newlen = alloc ; <nl> char * curl_escape ( char * string ) <nl>  <nl> char * curl_unescape ( char * string ) <nl> { <nl> - int alloc = strlen ( string ); <nl> + int alloc = strlen ( string )+ 1 ; <nl> char * ns = malloc ( alloc ); <nl> unsigned char in ; <nl> int index = 0 ;
* | ( __ | | _ | | _ <| | ___ <nl> * \ ___ |\ ___ /| _ | \ _ \ _____ | <nl> * <nl> - * Copyright ( C ) 1998 - 2016 , Daniel Stenberg , < daniel @ haxx . se >, et al . <nl> + * Copyright ( C ) 1998 - 2017 , Daniel Stenberg , < daniel @ haxx . se >, et al . <nl> * <nl> * This software is licensed as described in the file COPYING , which <nl> * you should have received as part of this distribution . The terms <nl> Curl_addrinfo * Curl_unix2addr ( const char * path , bool * longpath , bool abstract ) <nl>  <nl> ai -> ai_family = AF_UNIX ; <nl> ai -> ai_socktype = SOCK_STREAM ; /* assume reliable transport for HTTP */ <nl> - ai -> ai_addrlen = offsetof ( struct sockaddr_un , sun_path ) + path_len ; <nl> + ai -> ai_addrlen = ( curl_socklen_t ) <nl> + (( offsetof ( struct sockaddr_un , sun_path ) + path_len ) & 0x7FFFFFFF ); <nl>  <nl> /* Abstract Unix domain socket have NULL prefix instead of suffix */ <nl> if ( abstract )
int Curl_read ( struct connectdata * conn , <nl> do { <nl> nread = SSL_read ( conn -> ssl . handle , buf , buffersize ); <nl>  <nl> - if ( nread > 0 ) <nl> + if ( nread >= 0 ) <nl> /* successful read */ <nl> break ; <nl> 
static ssize_t http2_send ( struct connectdata * conn , int sockindex , <nl> authority_idx = 0 ; <nl>  <nl> for ( i = 3 ; i < nheader ; ++ i ) { <nl> + size_t hlen ; <nl> end = strchr ( hdbuf , ':'); <nl> if (! end ) <nl> goto fail ; <nl> - if ( end - hdbuf == 4 && Curl_raw_nequal (" host ", hdbuf , 4 )) { <nl> + hlen = end - hdbuf ; <nl> + if ( hlen == 10 && Curl_raw_nequal (" connection ", hdbuf , 10 )) <nl> + ; /* skip Connection : headers ! */ <nl> + else if ( hlen == 4 && Curl_raw_nequal (" host ", hdbuf , 4 )) { <nl> authority_idx = i ; <nl> nva [ i ]. name = ( unsigned char *)": authority "; <nl> nva [ i ]. namelen = ( uint16_t ) strlen (( char *) nva [ i ]. name );
static ParameterError getparameter ( char * flag , /* f or - long - flag */ <nl> break ; <nl> case ' F ': /* -- resolve */ <nl> err = add2list (& config -> resolve , nextarg ); <nl> + if ( err ) <nl> + return err ; <nl> break ; <nl> } <nl> break ;
static GlobCode glob_range ( URLGlob * glob , char ** patternp , <nl> } <nl> else <nl> step_n = 1 ; <nl> - if (* endp == ']') { <nl> + if ( endp && (* endp == ']')) { <nl> pattern = endp + 1 ; <nl> } <nl> else
static int loop ( const unsigned char * pattern , const unsigned char * string ) <nl> else if (* p == '[') { <nl> unsigned char * pp = p + 1 ; /* cannot handle with pointer to register */ <nl> if ( setcharset (& pp , charset )) { <nl> - bool found = FALSE ; <nl> + int found = FALSE ; <nl> if ( charset [( unsigned int )* s ]) <nl> found = TRUE ; <nl> else if ( charset [ CURLFNM_ALNUM ])
process_module_file ( FILE * module_file , const gchar * module_file_dir ) <nl> switch ( i ) <nl> { <nl> case 0 : <nl> - if (! g_path_is_absolute ( tmp_buf -> str )) <nl> + if (! g_path_is_absolute ( tmp_buf -> str ) <nl> +# ifdef __APPLE__ <nl> + && strncmp ( tmp_buf -> str , "@ executable_path /", 17 ) <nl> + && strncmp ( tmp_buf -> str , "@ loader_path /", 13 ) <nl> + && strncmp ( tmp_buf -> str , "@ rpath /", 7 ) <nl> +# endif <nl> + ) <nl> { <nl> const gchar * lib_dir = pango_get_lib_subdirectory (); <nl> const gchar * abs_file_name = g_build_filename ( lib_dir ,
dynamic_string * prepare_mom_hierarchy () <nl> int fds ; <nl> dynamic_string * send_format = NULL ; <nl>  <nl> + mh = initialize_mom_hierarchy (); <nl> + <nl> if (( fds = open ( path_mom_hierarchy , O_RDONLY , 0 )) < 0 ) <nl> { <nl> if ( errno == ENOENT )
int authorize_socket ( <nl> if ( trq_server_addr != NULL ) <nl> free ( trq_server_addr ); <nl>  <nl> + if ( server_name != NULL ) <nl> + free ( server_name ); <nl> + <nl> return ( rc ); <nl> } // END authorize_socket () <nl> 
int disrsi_ ( <nl> if ( dis_umaxd == 0 ) <nl> disiui_ (); <nl>  <nl> + if ( count >= dis_umaxd ) <nl> + { <nl> + if ( count > dis_umaxd ) <nl> + goto overflow ; <nl> + <nl> + if ( memcmp ( scratch , dis_umax , dis_umaxd ) > 0 ) <nl> + goto overflow ; <nl> + } <nl> + <nl> switch ( c = (* dis_getc )( stream )) <nl> { <nl> 
START_TEST ( add_node_attribute_to_list_test ) <nl> snprintf ( line , sizeof ( line ), " bob , tom "); <nl> ptr = line ; <nl> fail_unless ( add_node_attribute_to_list ( strdup (" acl "), & ptr , & th , 1 ) == PBSE_NONE ); <nl> - fail_unless ( attrname . c_str () != NULL ); <nl> fail_unless ( strcmp ( attrname . c_str (), " acl ") == 0 ); <nl> - fail_unless ( attrval . c_str () != NULL ); <nl> fail_unless ( strcmp ( attrval . c_str (), " bob , tom ") == 0 ); <nl> } <nl> END_TEST
bool Chip :: spread_place_cores ( <nl>  <nl> if ( fits == true ) <nl> { <nl> - int step_count = 1 ; <nl> + int step_count = step ; <nl> + <nl> + if ( lprocs_per_task_remaining == 1 ) <nl> + step_count = 1 ; <nl> + <nl>  <nl> /* cores_placed and cores_to_fill are used because we only want to make sure we <nl> fill the number of cores for this task */
START_TEST ( add_node_attribute_to_list_test ) <nl> snprintf ( line , sizeof ( line ), " 100 "); <nl> ptr = line ; <nl> fail_unless ( add_node_attribute_to_list ( strdup (" TTL "), & ptr , & th , 1 ) == PBSE_NONE ); <nl> - fail_unless ( strcmp ( attrname . c_str (), " TTL ") == 0 ); <nl> - fail_unless ( strcmp ( attrval . c_str (), " 100 ") == 0 ); <nl> + fail_unless ( attrname == " TTL "); <nl> + fail_unless ( attrval == " 100 "); <nl> attrlist_free (); <nl> attrname . clear (); <nl> attrval . clear (); <nl> START_TEST ( add_node_attribute_to_list_test ) <nl> snprintf ( line , sizeof ( line ), " bob , tom "); <nl> ptr = line ; <nl> fail_unless ( add_node_attribute_to_list ( strdup (" acl "), & ptr , & th , 1 ) == PBSE_NONE ); <nl> - fail_unless ( strcmp ( attrname . c_str (), " acl ") == 0 ); <nl> - fail_unless ( strcmp ( attrval . c_str (), " bob , tom ") == 0 ); <nl> + fail_unless ( attrname == " acl "); <nl> + fail_unless ( attrval == " bob , tom "); <nl> attrlist_free (); <nl> attrname . clear (); <nl> attrval . clear ();
char * pbse_to_txt ( int err ) <nl> return ( NULL ); <nl> } <nl> } <nl> + <nl> + int pbs_getaddrinfo ( const char * hostname , struct addrinfo * in , struct addrinfo ** out ) <nl> + { <nl> + return ( 0 ); <nl> + }
job_array * get_array ( <nl> char * tmpjobid ; <nl>  <nl> tmpjobid = get_correct_jobname ( id ); <nl> + if ( tmpjobid == NULL ) <nl> + return ( NULL ); <nl>  <nl> pthread_mutex_lock ( allarrays . allarrays_mutex ); <nl> 
int procs_requested ( <nl> if ( proplist (& str , & prop , & num_procs , & num_gpus , & num_mics )) <nl> { <nl> free ( tmp_spec ); <nl> + if ( prop != NULL ) <nl> + free_prop ( prop ); <nl> return (- 1 ); <nl> } <nl> } <nl> int procs_requested ( <nl> { <nl> /* must be a prop list with no number in front */ <nl> free ( tmp_spec ); <nl> + if ( prop != NULL ) <nl> + free_prop ( prop ); <nl>  <nl> return (- 1 ); <nl> }
 <nl> START_TEST ( test_one ) <nl> { <nl> + /* As this is site specific , there is no implementation in this function */ <nl> + char * user = NULL ; <nl> + char * host = NULL ; <nl> + int rc = - 1 ; <nl> + rc = site_allow_u ( user , host ); <nl> + fail_unless ( rc == 0 , " The return value has changed !!!"); <nl> } <nl> END_TEST <nl> 
work_task * next_task ( <nl> pthread_mutex_lock ( at -> alltasks_mutex ); <nl>  <nl> wt = next_thing ( at -> ra , iter ); <nl> + if ( wt != NULL ) <nl> + pthread_mutex_lock ( wt -> wt_mutex ); <nl>  <nl> pthread_mutex_unlock ( at -> alltasks_mutex ); <nl>  <nl> if ( wt != NULL ) <nl> { <nl> - pthread_mutex_lock ( wt -> wt_mutex ); <nl> - <nl> if ( wt -> wt_being_recycled == TRUE ) <nl> { <nl> pthread_mutex_unlock ( wt -> wt_mutex );
int user_route_uri ( struct sip_msg * _msg , char * _user , char * _domain ) { <nl> domain = ( int ) _domain ; <nl> struct rewrite_data * rd = NULL ; <nl> struct carrier_tree * ct = NULL ; <nl> + // TODO it would be better to use the new introduced pv_parse and pv_print functions <nl> + // like in textops : append_to_reply_f and : it_list_fixup . <nl> switch ( hf_type -> id ) { <nl> case REQ_URI : /* Request - URI */ <nl> if ( get_request_uri ( _msg , & uri ) < 0 ) { <nl> int user_route_uri ( struct sip_msg * _msg , char * _user , char * _domain ) { <nl> } else { <nl> LM_ERR (" desired routing tree with id % i doesn ' t exist \ n ", <nl> carrier_id ); <nl> + release_data ( rd ); <nl> return - 1 ; <nl> } <nl> } else {
static int carrier_fixup ( void ** param ) { <nl> s . len = strlen ( s . s ); <nl>  <nl> if ( s . s [ 0 ]!='$') { <nl> + /* This is a name string */ <nl> mp -> type = MP_INT ; <nl>  <nl> /* get carrier id */ <nl> static int carrier_fixup ( void ** param ) { <nl> * param = ( void *) mp ; <nl> } <nl> else { <nl> + /* This is a pseudo - variable */ <nl> if ( pv_parse_spec (& s , & avp_spec )== 0 ) { <nl> LM_ERR (" pv_parse_spec failed for '% s '\ n ", ( char *)(* param )); <nl> + pkg_free ( mp ); <nl> return - 1 ; <nl> } <nl> if ( avp_spec . type == PVT_AVP ) { <nl> static int carrier_fixup ( void ** param ) { <nl> mp -> type = MP_PVE ; <nl> if ( pv_parse_format (& s , &( mp -> u . p ))< 0 ) { <nl> LM_ERR (" pv_parse_format failed for '% s '\ n ", ( char *)(* param )); <nl> + pkg_free ( mp ); <nl> return - 1 ; <nl> } <nl> } <nl> static int domain_fixup ( void ** param ) { <nl> s . len = strlen ( s . s ); <nl>  <nl> if ( s . s [ 0 ]!='$') { <nl> - /* This is a name */ <nl> + /* This is a name string */ <nl> mp -> type = MP_INT ; <nl>  <nl> /* get domain id */ <nl> static int domain_fixup ( void ** param ) { <nl> * param = ( void *) mp ; <nl> } <nl> else { <nl> + /* This is a pseudo - variable */ <nl> if ( pv_parse_spec (& s , & avp_spec )== 0 ) { <nl> LM_ERR (" pv_parse_spec failed for '% s '\ n ", ( char *)(* param )); <nl> + pkg_free ( mp ); <nl> return - 1 ; <nl> } <nl> if ( avp_spec . type == PVT_AVP ) { <nl> static int domain_fixup ( void ** param ) { <nl> mp -> type = MP_PVE ; <nl> if ( pv_parse_format (& s , &( mp -> u . p ))< 0 ) { <nl> LM_ERR (" pv_parse_format failed for '% s '\ n ", ( char *)(* param )); <nl> + pkg_free ( mp ); <nl> return - 1 ; <nl> } <nl> }
struct tcp_connection * get_cur_connection ( struct sip_msg * msg ) <nl> return 0 ; <nl> } <nl>  <nl> - c = tcpconn_get ( msg -> rcv . proto_reserved1 , 0 , 0 , tls_con_lifetime ); <nl> + c = tcpconn_get ( msg -> rcv . proto_reserved1 , 0 , 0 , 0 , tls_con_lifetime ); <nl> if ( c && c -> type != PROTO_TLS ) { <nl> ERR (" Connection found but is not TLS \ n "); <nl> tcpconn_put ( c );
int curl_con_query_url_f ( struct sip_msg * _m , const str * connection , <nl> query_params . cacert = default_tls_cacert ; <nl> query_params . ciphersuites = conn -> ciphersuites ; <nl> query_params . tlsversion = conn -> tlsversion ; <nl> + query_params . useragent = conn -> useragent ; <nl> query_params . verify_peer = conn -> verify_peer ; <nl> query_params . verify_host = conn -> verify_host ; <nl> query_params . timeout = conn -> timeout ;
int th_msg_received ( void * data ) <nl> { <nl> sip_msg_t msg ; <nl> str * obuf ; <nl> - char * nbuf ; <nl> + char * nbuf = NULL ; <nl> int direction ; <nl> int dialog ; <nl>  <nl> int th_msg_received ( void * data ) <nl> obuf -> s [ obuf -> len ] = '\ 0 '; <nl>  <nl> done : <nl> + if ( nbuf != NULL ) <nl> + pkg_free ( nbuf ); <nl> free_sip_msg (& msg ); <nl> return 0 ; <nl> }
int parse_servers ( char * _servers , struct jsonrpc_server_group ** group_ptr ) <nl>  <nl> struct jsonrpc_server * server = pkg_malloc ( sizeof ( struct jsonrpc_server )); <nl> CHECK_MALLOC ( server ); <nl> + memset ( server , 0 , sizeof ( struct jsonrpc_server )); <nl> char * h = pkg_malloc ( strlen ( host )+ 1 ); <nl> CHECK_MALLOC ( h ); <nl>  <nl> int parse_servers ( char * _servers , struct jsonrpc_server_group ** group_ptr ) <nl>  <nl> selected_group = pkg_malloc ( sizeof ( struct jsonrpc_server_group )); <nl> CHECK_MALLOC ( selected_group ); <nl> + memset ( selected_group , 0 , sizeof ( struct jsonrpc_server_group )); <nl> selected_group -> priority = priority ; <nl> selected_group -> next_server = server ; <nl> 
int unregister ( struct sip_msg * _m , udomain_t * _d , str * _uri , str * _ruid ) <nl> urecord_t * r ; <nl> ucontact_t * c ; <nl>  <nl> - u = parse_to_uri ( _m ); <nl> - if ( u == NULL ) <nl> - return - 2 ; <nl> - <nl> if ( extract_aor ( _uri , & aor , NULL ) < 0 ) { <nl> LM_ERR (" failed to extract Address Of Record \ n "); <nl> return - 1 ; <nl> int unregister ( struct sip_msg * _m , udomain_t * _d , str * _uri , str * _ruid ) <nl> if ( _ruid == NULL ) { <nl> /* No ruid provided - remove all contacts for aor */ <nl>  <nl> + u = parse_to_uri ( _m ); <nl> + if ( u == NULL ) <nl> + return - 2 ; <nl> + <nl> if ( star ( _m , _d , & aor , & u -> host ) < 0 ) <nl> { <nl> LM_ERR (" error unregistering user [%.* s ]\ n ", aor . len , aor . s );
static int child_init ( int _rank ) <nl> dlist_t * ptr ; <nl> int i ; <nl>  <nl> + if ( sruid_init (& _ul_sruid , '-', " ulcx ", SRUID_INC )< 0 ) <nl> + return - 1 ; <nl> + <nl> if ( _rank == PROC_MAIN && ul_timer_procs > 0 ) <nl> { <nl> for ( i = 0 ; i < ul_timer_procs ; i ++)
static int mi_child_init ( void ) <nl> return - 1 ; <nl> } <nl> } <nl> + <nl> + if ( sruid_init (& _ul_sruid , '-', " ulcx ", SRUID_INC )< 0 ) <nl> + return - 1 ; <nl> done = 1 ; <nl>  <nl> return 0 ;
struct hostent * dns_srv_sip_resolvehost ( str * name , unsigned short * port , <nl> } else { <nl> srv_proto = PROTO_UDP ; <nl> } <nl> + if ( srv_proto == PROTO_WS || srv_proto == PROTO_WS ) { <nl> + /* no srv records for web sockets */ <nl> + return 0 ; <nl> + } <nl> /* try SRV if no port specified ( draft - ietf - sip - srv - 06 ) */ <nl> if (( port )&&(* port == 0 )){ <nl> * port =( srv_proto == PROTO_TLS )? SIPS_PORT : SIP_PORT ; /* just in case we
inline static int binrpc_add_tag ( struct binrpc_pkt * pkt , int type , int end ) <nl>  <nl> /* writes a minimal int , returns the new offset and sets <nl> * len to the number of bytes written (<= 4 ) <nl> - * to check for oveflow use : returned_value - p < * len <nl> + * to check for oveflow use : returned_value >= end <nl> + * or returned_value - p < * len && * len != 0 <nl> */ <nl> inline static unsigned char * binrpc_write_int ( unsigned char * p , <nl> unsigned char * end , <nl> inline static int binrpc_add_int_type ( struct binrpc_pkt * pkt , int i , int type ) <nl> int size ; <nl>  <nl> p = binrpc_write_int ( pkt -> crt + 1 , pkt -> end , i , & size ); <nl> - if (( int )( p - pkt -> crt )<( size + 1 )) goto error_len ; <nl> + if ( p >= pkt -> end ) goto error_len ; <nl> *( pkt -> crt )=( size << 4 ) | type ; <nl> pkt -> crt = p ; <nl> return 0 ; <nl> inline static int binrpc_add_str_mark ( struct binrpc_pkt * pkt , int type , <nl> p = pkt -> crt + 1 ; <nl> } else { /* we need a separate len */ <nl> p = binrpc_write_int ( pkt -> crt + 1 , pkt -> end , l , & size ); <nl> - if (( int )( p - pkt -> crt )<( size + 1 )) goto error_len ; <nl> + if ( p >= pkt -> end ) goto error_len ; <nl> size |= 8 ; /* mark it as having external len */ <nl> } <nl> *( pkt -> crt )=( size )<< 4 | type ;
static int sip_trace_store ( struct _siptrace_data * sto , struct dest_info * dst ) <nl>  <nl> static int sip_trace_store_db ( struct _siptrace_data * sto ) <nl> { <nl> + if ( db_con == NULL ) { <nl> + LM_DBG (" database connection not initialized \ n "); <nl> + return - 1 ; <nl> + } <nl> + <nl> if ( trace_to_database_flag == NULL || * trace_to_database_flag == 0 ) <nl> goto done ; <nl> 
sca_reply ( sca_mod * scam , int status_code , char * status_msg , <nl> SCA_STR_COPY_CSTR ( & extra_headers , " Expires : " ); <nl>  <nl> len = snprintf ( extra_headers . s + extra_headers . len , <nl> - sizeof ( hdr_buf - extra_headers . len ), <nl> + sizeof ( hdr_buf ) - extra_headers . len , <nl> "% d % s ", expires , CRLF ); <nl> extra_headers . len += len ; <nl> 
static inline char * print_from ( char * w , dlg_t * dialog , struct cell * t ) <nl> { <nl> t -> from . s = w ; <nl> t -> from . len = FROM_LEN + dialog -> loc_uri . len + CRLF_LEN <nl> - + ( dialog -> rem_uri . s [ 0 ]!='<')? 2 : 0 ; <nl> + + ( dialog -> loc_uri . s [ 0 ]!='<')? 2 : 0 ; <nl>  <nl> memapp ( w , FROM , FROM_LEN ); <nl> if ( dialog -> loc_uri . s [ 0 ]!='<') memapp ( w , "<", 1 );
static int fixup_routes ( char * r_type , struct route_list * rt , void ** param ) <nl> LOG ( L_ERR , " ERROR : tm : fixup_routes : route_get failed \ n "); <nl> return E_UNSPEC ; <nl> } <nl> - if ( rt -> rlist [ i ]== 0 ){ <nl> + if ( r_type && rt -> rlist [ i ]== 0 ){ <nl> LOG ( L_WARN , " WARNING : % s (\"% s \"): empty / non existing route \ n ", <nl> r_type , ( char *)* param ); <nl> } <nl> static int fixup_on_sl_reply ( modparam_t type , void * val ) <nl> return - 1 ; <nl> } <nl>  <nl> - if ( fixup_routes (" on_sl_reply ", & onreply_rt , & val )) <nl> + if ( fixup_routes ( 0 , & onreply_rt , & val )) <nl> return - 1 ; <nl>  <nl> goto_on_sl_reply = ( int )( long ) val ; <nl> static int mod_init ( void ) <nl> if ( goto_on_local_req >= 0 && event_rt . rlist [ goto_on_local_req ]== 0 ) <nl> goto_on_local_req =- 1 ; /* disable */ <nl> # endif /* WITH_EVENT_LOCAL_REQUEST */ <nl> + if ( goto_on_sl_reply && onreply_rt . rlist [ goto_on_sl_reply ]== 0 ) <nl> + WARN (" empty / non existing on_sl_reply route \ n "); <nl> tm_init = 1 ; <nl> return 0 ; <nl> }
pcontact_t * getContactP ( struct sip_msg * _m , udomain_t * _d ) { <nl> } <nl>  <nl> for ( ct = b -> contacts ; ct ; ct = ct -> next ) { <nl> - if ( ul . get_pcontact ( _d , & ct -> uri , & c ) == 1 ) { <nl> + if ( ul . get_pcontact ( _d , & ct -> uri , & c ) == 0 ) { <nl> if (( c -> reg_state == PCONTACT_REGISTERED ) && ( c -> received_port == _m -> rcv . src_port ) && ( c -> received_proto == _m -> rcv . proto )) { <nl> received_host . len = ip_addr2sbuf (& _m -> rcv . src_ip , srcip , sizeof ( srcip )); <nl> received_host . s = srcip ;
rs_photo_open_dcraw ( const gchar * filename ) <nl> register gint r , g , b ; <nl> r = ( src [ srcoffset ++] - raw -> black )<< shift ; <nl> g = ( src [ srcoffset ++] - raw -> black )<< shift ; <nl> - b = ( src [ srcoffset += 2 ] - raw -> black )<< shift ; <nl> + b = ( src [ srcoffset ++] - raw -> black )<< shift ; <nl> + srcoffset ++; <nl> _CLAMP65535_TRIPLET ( r , g , b ); <nl> buffer [ destoffset ++] = r ; <nl> buffer [ destoffset ++] = g ;
rs_facebook_client_upload_image ( RSFacebookClient * facebook , const gchar * filenam <nl>  <nl> struct stat st ; <nl> g_stat ( filename , & st ); <nl> - const gchar * filesize = g_strdup_printf ("% d ", ( gint ) st . st_size ); <nl> + gchar * filesize = g_strdup_printf ("% d ", ( gint ) st . st_size ); <nl>  <nl> rs_facebook_client_param_add_string ( param , " filename ", filename ); <nl> rs_facebook_client_param_add_string ( param , " length ", filesize ); <nl> rs_facebook_client_upload_image ( RSFacebookClient * facebook , const gchar * filenam <nl> facebook_client_request ( facebook , " facebook . photos . upload ", param , content , error ); <nl>  <nl> g_string_free ( content , TRUE ); <nl> + g_free ( filesize ); <nl>  <nl> return TRUE ; <nl> }
rs_image8_new ( const guint width , const guint height , const guint channels , const <nl> } <nl> else <nl> { <nl> + rsi -> image = NULL ; <nl> rsi -> rowstride = PITCH ( width ) * pixelsize ; <nl> rsi -> pixels = ( guchar *) g_malloc ( sizeof ( guchar )* rsi -> h * rsi -> rowstride ); <nl> rsi -> channels = channels ;
makernote_nikon ( RAWFILE * rawfile , guint offset , RSMetadata * meta ) <nl> || g_str_equal ( meta -> model_ascii , " NIKON 1 V1 ") <nl> || g_str_equal ( meta -> model_ascii , " NIKON 1 V2 ") <nl> || g_str_equal ( meta -> model_ascii , " NIKON D7000 ") <nl> + || g_str_equal ( meta -> model_ascii , " NIKON D7100 ") <nl> || g_str_equal ( meta -> model_ascii , " COOLPIX P7700 ")) <nl> { <nl> meta -> cam_mul [ 0 ] = get_rational ( rawfile , offset );
bool mp_image_params_equals ( const struct mp_image_params * p1 , <nl> p1 -> d_w == p2 -> d_w && p1 -> d_h == p2 -> d_h && <nl> p1 -> colorspace == p2 -> colorspace && <nl> p1 -> colorlevels == p2 -> colorlevels && <nl> + p1 -> outputlevels == p2 -> outputlevels && <nl> p1 -> chroma_location == p2 -> chroma_location ; <nl> } <nl> 
if ( auto_quality > 0 ){ <nl>  <nl> if ( mp_dvdnav_stream_has_changed ( mpctx -> stream )) { <nl> double ar = - 1 . 0 ; <nl> - if ( stream_control ( mpctx -> demuxer -> stream , <nl> + if ( mpctx -> sh_video && <nl> + stream_control ( mpctx -> demuxer -> stream , <nl> STREAM_CTRL_GET_ASPECT_RATIO , & ar ) <nl> != STREAM_UNSUPPORTED ) <nl> mpctx -> sh_video -> stream_aspect = ar ;
read_toc ( const char * dev ) { <nl> } <nl> for ( i = first ; i <= last ; i ++) { <nl> struct cdrom_tocentry tocentry ; <nl> - tocentry . cdte_track = ( i == last ) ? 0xAA : i ; <nl> + tocentry . cdte_track = ( i == last ) ? 0xAA : i + 1 ; <nl> tocentry . cdte_format = CDROM_MSF ; <nl> ioctl ( drive , CDROMREADTOCENTRY , & tocentry ); <nl> cdtoc [ i ]. min = tocentry . cdte_addr . msf . minute ; <nl> read_toc ( const char * dev ) { <nl> } <nl> for ( i = first ; i <= last ; i ++) { <nl> struct ioc_read_toc_single_entry tocentry ; <nl> - tocentry . track = ( i == last ) ? 0xAA : i ; <nl> + tocentry . track = ( i == last ) ? 0xAA : i + 1 ; <nl> tocentry . address_format = CD_MSF_FORMAT ; <nl> ioctl ( drive , CDIOREADTOCENTRY , & tocentry ); <nl> cdtoc [ i ]. min = tocentry . entry . addr . msf . minute ; <nl> read_toc ( const char * dev ) { <nl> for ( i = first ; i <= last ; i ++) { <nl> struct ioc_read_toc_entry tocentry ; <nl> struct cd_toc_entry toc_buffer ; <nl> - tocentry . starting_track = ( i == last ) ? 0xAA : i ; <nl> + tocentry . starting_track = ( i == last ) ? 0xAA : i + 1 ; <nl> tocentry . address_format = CD_MSF_FORMAT ; <nl> tocentry . data = & toc_buffer ; <nl> tocentry . data_len = sizeof ( toc_buffer );
int stream_enable_cache ( stream_t * stream , int size , int min , int prefill ){ <nl>  <nl> if (( stream -> cache_pid = fork ())){ <nl> // wait until cache is filled at least prefill_init % <nl> - printf (" CACHE_PRE_INIT : % d [% d ] % d pre :% d eof :% d \ n ", <nl> + mp_msg ( MSGT_CACHE , MSGL_V ," CACHE_PRE_INIT : % d [% d ] % d pre :% d eof :% d \ n ", <nl> s -> min_filepos , s -> read_filepos , s -> max_filepos , min , s -> eof ); <nl> while ( s -> read_filepos < s -> min_filepos || s -> max_filepos - s -> read_filepos < min ){ <nl> mp_msg ( MSGT_CACHE , MSGL_STATUS ,"\ rCache fill : % 5 . 2f %% (% d bytes ) ",
static int find_entrypoint ( int format , VAEntrypoint * ep , int num_ep ) <nl>  <nl> static int is_direct_mapping ( VADisplay display ) <nl> { <nl> - VADisplayAttribute attr ; <nl> + VADisplayAttribute attr = { 0 }; <nl> VAStatus status ; <nl>  <nl> # if VA_CHECK_VERSION ( 0 , 34 , 0 )
void demux_seek_mpg ( demuxer_t * demuxer , float rel_seek_secs , float audio_delay , in <nl> continue ; <nl> } <nl> } <nl> + if (! sh_video ) break ; <nl> i = sync_video_packet ( d_video ); <nl> if ( sh_video -> format == 0x10000004 ) { // mpeg4 <nl> if ( i == 0x1B6 ) { // vop ( frame ) startcode
static uint32_t get_image ( mp_image_t * mpi ) { <nl> if ( mpi -> flags & MP_IMGFLAG_READABLE ) return VO_FALSE ; <nl> if ( ati_hack ) { <nl> int s = 1 ; <nl> + // for unexplainable reasons , with width < 512 chroma tends to be messed up <nl> + // ( after ca . 2 / 3 the previous line repeats all over ) <nl> + if ( mpi -> width < 512 ) return VO_FALSE ; <nl> while ( s < mpi -> width ) s *= 2 ; <nl> mpi -> width = s ; <nl> }
int read_asf_header ( demuxer_t * demuxer , struct asf_priv * asf ){ <nl> goto err_out ; <nl> } <nl>  <nl> - if (( pos = find_asf_guid ( hdr , asf_ext_stream_audio , pos , hdr_len )) >= 0 ) <nl> + if (( pos = find_asf_guid ( hdr , asf_ext_stream_audio , 0 , hdr_len )) >= 0 ) <nl> { <nl> // Special case : found GUID for dvr - ms audio . <nl> // Now skip back to associated stream header .
static void adjust_sync ( struct MPContext * mpctx , double v_pts , double frame_time <nl> double av_delay = a_pts - v_pts ; <nl>  <nl> double change = av_delay * 0 . 1 ; <nl> + double factor = fabs ( av_delay ) < 0 . 3 ? 0 . 1 : 0 . 4 ; <nl> double max_change = opts -> default_max_pts_correction >= 0 ? <nl> - opts -> default_max_pts_correction : frame_time * 0 . 1 ; <nl> + opts -> default_max_pts_correction : frame_time * factor ; <nl> if ( change < - max_change ) <nl> change = - max_change ; <nl> else if ( change > max_change )
demux_mkv_open_video ( demuxer_t * demuxer , mkv_track_t * track , int vid ) <nl> uint32_t type2 ; <nl> unsigned int cnt ; <nl>  <nl> - src = track -> private_data + RVPROPERTIES_SIZE ; <nl> + src = ( uint8_t *) track -> private_data + RVPROPERTIES_SIZE ; <nl>  <nl> cnt = track -> private_size - RVPROPERTIES_SIZE ; <nl> bih = realloc ( bih , sizeof ( BITMAPINFOHEADER )+ 8 + cnt );
static HRESULT STDMETHODCALLTYPE DropTarget_Drop ( IDropTarget * This , <nl> } else if ( pDataObj -> lpVtbl -> GetData ( pDataObj , <nl> & fmtetc_url , & medium ) == S_OK ) { <nl> // get the URL encoded in US - ASCII <nl> - char * url = ( char *) GlobalLock ( medium . hGlobal ); <nl> - if ( url != NULL ) { <nl> + wchar_t * wurl = GlobalLock ( medium . hGlobal ); <nl> + if ( wurl != NULL ) { <nl> + char * url = mp_to_utf8 ( NULL , wurl ); <nl> if ( mp_event_drop_mime_data ( t -> w32 -> input_ctx , " text / uri - list ", <nl> bstr0 ( url ), action ) > 0 ) { <nl> MP_VERBOSE ( t -> w32 , " received dropped URL : % s \ n ", url ); <nl> static HRESULT STDMETHODCALLTYPE DropTarget_Drop ( IDropTarget * This , <nl> MP_ERR ( t -> w32 , " error getting dropped URL \ n "); <nl> } <nl>  <nl> + talloc_free ( url ); <nl> GlobalUnlock ( medium . hGlobal ); <nl> } <nl>  <nl> static void * gui_thread ( void * ptr ) <nl> if ( SUCCEEDED ( OleInitialize ( NULL ))) { <nl> ole_ok = true ; <nl>  <nl> - fmtetc_url . cfFormat = ( CLIPFORMAT ) RegisterClipboardFormat ( TEXT (" UniformResourceLocator ")); <nl> + fmtetc_url . cfFormat = ( CLIPFORMAT ) RegisterClipboardFormat ( TEXT (" UniformResourceLocatorW ")); <nl> DropTarget * dropTarget = talloc ( NULL , DropTarget ); <nl> DropTarget_Init ( dropTarget , w32 ); <nl> RegisterDragDrop ( w32 -> window , & dropTarget -> iface );
static struct mp_image * dxva2_retrieve_image ( struct lavc_ctx * s , <nl>  <nl> IDirect3DSurface9_GetDesc ( surface , & surfaceDesc ); <nl>  <nl> + if ( surfaceDesc . Width < img -> w || surfaceDesc . Height < img -> h ) <nl> + return img ; <nl> + <nl> struct mp_image * sw_img = <nl> - mp_image_pool_get ( ctx -> sw_pool , IMGFMT_NV12 , img -> w , img -> h ); <nl> + mp_image_pool_get ( ctx -> sw_pool , IMGFMT_NV12 , surfaceDesc . Width , surfaceDesc . Height ); <nl>  <nl> if (! sw_img ) <nl> return img ; <nl> static struct mp_image * dxva2_retrieve_image ( struct lavc_ctx * s , <nl> } <nl>  <nl> ctx -> copy_nv12 ( sw_img , LockedRect . pBits , LockedRect . Pitch , surfaceDesc . Height ); <nl> + mp_image_set_size ( sw_img , img -> w , img -> h ); <nl> mp_image_copy_attributes ( sw_img , img ); <nl>  <nl> IDirect3DSurface9_UnlockRect ( surface );
void mp_image_copy_attributes ( struct mp_image * dst , struct mp_image * src ) <nl> } <nl> mp_image_params_guess_csp (& dst -> params ); // ensure colorspace consistency <nl> if (( dst -> fmt . flags & MP_IMGFLAG_PAL ) && ( src -> fmt . flags & MP_IMGFLAG_PAL )) { <nl> - if ( dst -> planes [ 1 ] && src -> planes [ 1 ]) <nl> - memcpy ( dst -> planes [ 1 ], src -> planes [ 1 ], MP_PALETTE_SIZE ); <nl> + if ( dst -> planes [ 1 ] && src -> planes [ 1 ]) { <nl> + if ( mp_image_make_writeable ( dst )) <nl> + memcpy ( dst -> planes [ 1 ], src -> planes [ 1 ], MP_PALETTE_SIZE ); <nl> + } <nl> } <nl> } <nl> 
int asf_mmst_streaming_start ( stream_t * stream ) <nl> URL_t * url1 = stream -> streaming_ctrl -> url ; <nl> int s = stream -> fd ; <nl>  <nl> + if ( s > 0 ) { <nl> + close ( stream -> fd ); <nl> + stream -> fd = - 1 ; <nl> + } <nl> + <nl> /* parse url */ <nl> path = strchr ( url1 -> file ,'/') + 1 ; <nl>  <nl> url1 -> port = 1755 ; <nl> s = connect2Server ( url1 -> hostname , url1 -> port ); <nl> + if ( s < 0 ) { <nl> + return s ; <nl> + } <nl> printf (" connected \ n "); <nl>  <nl> /*
static int load_syms_windows ( char * path ) { <nl> if ( wrvyuv_custom_message && <nl> wrvyuv_free && <nl> wrvyuv_init && <nl> - wrvyuv_transform ) <nl> + wrvyuv_transform ) { <nl> + dll_type = 1 ; <nl> + rv_handle = handle ; <nl> return 1 ; <nl> + } <nl>  <nl> mp_msg ( MSGT_DECVIDEO , MSGL_WARN ," Error resolving symbols ! ( version incompatibility ?)\ n "); <nl> FreeLibrary ( handle );
static void update_prop ( void * p ) <nl> // outstanding property . <nl> static bool gen_property_change_event ( struct mpv_handle * ctx ) <nl> { <nl> + if (! ctx -> mpctx -> initialized ) <nl> + return false ; <nl> int start = ctx -> lowest_changed ; <nl> ctx -> lowest_changed = ctx -> num_properties ; <nl> for ( int n = start ; n < ctx -> num_properties ; n ++) {
static int vf_open ( vf_instance_t * vf , char * args ){ <nl> mux_v -> bih -> biCompression = mmioFOURCC (' D ', ' I ', ' V ', ' X '); <nl> else if (! strcasecmp ( lavc_param_vcodec , " msmpeg4 ")) <nl> mux_v -> bih -> biCompression = mmioFOURCC (' d ', ' i ', ' v ', ' 3 '); <nl> + else if (! strcasecmp ( lavc_param_vcodec , " msmpeg4v2 ")) <nl> + mux_v -> bih -> biCompression = mmioFOURCC (' M ', ' P ', ' 4 ', ' 2 '); <nl> else <nl> mux_v -> bih -> biCompression = mmioFOURCC ( lavc_param_vcodec [ 0 ], <nl> lavc_param_vcodec [ 1 ], lavc_param_vcodec [ 2 ], lavc_param_vcodec [ 3 ]); /* FIXME !!! */
static void vo_x11_putkey_ext ( int keysym ) <nl> { <nl> switch ( keysym ) <nl> { <nl> + case XF86XK_MenuKB : <nl> + mplayer_put_key ( KEY_MENU ); <nl> + break ; <nl> + case XF86XK_AudioPlay : <nl> + mplayer_put_key ( KEY_PLAY ); <nl> + break ; <nl> case XF86XK_AudioPause : <nl> mplayer_put_key ( KEY_PAUSE ); <nl> break ; <nl> static void vo_x11_putkey_ext ( int keysym ) <nl> case XF86XK_AudioNext : <nl> mplayer_put_key ( KEY_NEXT ); <nl> break ; <nl> + case XF86XK_AudioMute : <nl> + mplayer_put_key ( KEY_MUTE ); <nl> + break ; <nl> case XF86XK_AudioLowerVolume : <nl> mplayer_put_key ( KEY_VOLUME_DOWN ); <nl> break ;
static uint32_t get_image ( mp_image_t * mpi ){ <nl> mpi -> stride [ 1 ]= mpi -> stride [ 2 ]= image_width / 2 ; <nl> } else { <nl> mpi -> planes [ 0 ]= xvimage [ current_buf ]-> data ; <nl> - mpi -> stride [ 0 ]= image_width ; <nl> + mpi -> stride [ 0 ]= image_width *( mpi -> bpp >> 3 ); <nl> } <nl> mpi -> flags |= MP_IMGFLAG_DIRECT ; <nl> // printf (" mga : get_image () SUCCESS -> Direct Rendering ENABLED \ n ");
int init_audio_codec ( sh_audio_t * sh_audio ) <nl> sh_audio -> sample_format = AFMT_S16_LE ; <nl> # endif <nl> sh_audio -> samplerate = 0 ; <nl> + sh_audio -> channels = 0 ; <nl> sh_audio -> i_bps = 0 ; // input rate ( bytes / sec ) <nl> sh_audio -> o_bps = 0 ; // output rate ( bytes / sec ) <nl> 
static int init ( sh_audio_t * sh_audio ) <nl> if ( sh_audio -> wf ){ <nl> // If the decoder uses the wrong number of channels all is lost anyway . <nl> // sh_audio -> channels = sh_audio -> wf -> nChannels ; <nl> + if ( lavc_context -> codec_id == CODEC_ID_AAC && <nl> + sh_audio -> samplerate == 2 * sh_audio -> wf -> nSamplesPerSec ) { <nl> + mp_msg ( MSGT_DECAUDIO , MSGL_WARN , <nl> + " Ignoring broken container sample rate for ACC with SBR \ n "); <nl> + } else <nl> if ( sh_audio -> wf -> nSamplesPerSec ) <nl> sh_audio -> samplerate = sh_audio -> wf -> nSamplesPerSec ; <nl> if ( sh_audio -> wf -> nAvgBytesPerSec )
static WIN_BOOL WINAPI expWriteFile ( HANDLE h , LPCVOID pv , DWORD size , LPDWORD wr , LP <nl> static DWORD WINAPI expSetFilePointer ( HANDLE h , LONG val , LPLONG ext , DWORD whence ) <nl> { <nl> int wh ; <nl> - dbgprintf (" SetFilePointer (% d , 0x % x , 0x % x = % d , % d )\ n ", h , val , ext , * ext , whence ); <nl> + dbgprintf (" SetFilePointer (% d , 0x % x , 0x % x = % d , % d )\ n ", h , val , ext , ext ? * ext : NULL , whence ); <nl> // why would DLL want temporary file with > 2Gb size ? <nl> switch ( whence ) <nl> {
begin_bench : <nl> # endif <nl>  <nl> # ifdef HAVE_BFG_HOTPLUG <nl> - if ( opt_hotplug && ! opt_scrypt ) <nl> + if ( opt_hotplug ) <nl> hotplug_start (); <nl> # endif <nl> 
static void avalon_shutdown ( struct thr_info * thr ) <nl> } <nl>  <nl> struct device_drv avalon_drv = { <nl> + . drv_id = DRIVER_AVALON , <nl> . dname = " avalon ", <nl> . name = " AVA ", <nl> . drv_detect = avalon_detect ,
static inline void string_elist_del ( struct string_elist * item ) <nl> if ( item -> free_me ) <nl> free ( item -> string ); <nl> list_del (& item -> list ); <nl> + free ( item ); <nl> } <nl>  <nl> 
ACPI_STATUS <nl> OsGetGlobalLock ( void ) <nl> { <nl> UINT32 GlobalLockReg ; <nl> - ACPI_STATUS Status ; <nl> + ACPI_STATUS Status = AE_OK ; <nl>  <nl>  <nl> if ( FACS )
/****************************************************************************** <nl> * <nl> * Module Name : astable - Tables used for source conversion <nl> - * $ Revision : 1 . 18 $ <nl> + * $ Revision : 1 . 19 $ <nl> * <nl> *****************************************************************************/ <nl>  <nl> ACPI_STRING_TABLE StandardDataTypes [] = { <nl>  <nl> char LinuxHeader [] = <nl> "/*\ n " <nl> -" * Copyright ( C ) 2000 - 2007 , R . Byron Moore \ n " <nl> +" * Copyright ( C ) 2000 - 2008 , Intel Corp .\ n " <nl> " * All rights reserved .\ n " <nl> " *\ n " <nl> " * Redistribution and use in source and binary forms , with or without \ n " <nl> ACPI_CONVERSION_TABLE StatsConversionTable = { <nl> ACPI_STRING_TABLE CustomReplacements [] = { <nl>  <nl>  <nl> + {"( c ) 1999 - 2008 ", "( c ) 1999 - 2008 ", REPLACE_WHOLE_WORD }, <nl> # if 0 <nl> - {"( c ) 1999 - 2006 ", "( c ) 1999 - 2007 ", REPLACE_WHOLE_WORD }, <nl> {" AcpiTbSumTable ", " AcpiTbSumTable ", REPLACE_WHOLE_WORD }, <nl> {" ACPI_SIG_BOOT ", " ACPI_SIG_BOOT ", REPLACE_WHOLE_WORD }, <nl> {" ACPI_SIG_DBGP ", " ACPI_SIG_DBGP ", REPLACE_WHOLE_WORD },
/****************************************************************************** <nl> * <nl> * Name : actypes . h - Common data types for the entire ACPI subsystem <nl> - * $ Revision : 1 . 134 $ <nl> + * $ Revision : 1 . 135 $ <nl> * <nl> *****************************************************************************/ <nl>  <nl> typedef UINT8 OBJECT_TYPE_INTERNAL ; <nl> * This section contains object types that do not relate to the ACPI ObjectType operator . <nl> * They are used for various internal purposes only . If new predefined ACPI_TYPEs are <nl> * added ( via the ACPI specification ), these internal types must move upwards . <nl> - * Also , values exceeding the largest official ACPI ObjectType must not overlap with <nl> + * Also , values exceeding the largest official ACPI ObjectType must not overlap with <nl> * defined AML opcodes . <nl> */ <nl> # define INTERNAL_TYPE_BEGIN 17
AmlExecCreateField ( <nl> FieldDesc -> FieldUnit . UpdateRule = ( UINT8 ) UPDATE_Preserve ; <nl> FieldDesc -> FieldUnit . Length = BitCount ; <nl> FieldDesc -> FieldUnit . BitOffset = ( UINT8 ) ( BitOffset % 8 ); <nl> - FieldDesc -> FieldUnit . Offset = BitOffset / 8 ; <nl> + FieldDesc -> FieldUnit . Offset = DIV_8 ( BitOffset ); <nl> FieldDesc -> FieldUnit . Container = SrcDesc ; <nl> FieldDesc -> FieldUnit . Sequence = SrcDesc -> Buffer . Sequence ; <nl> 
/****************************************************************************** <nl> * <nl> * Module Name : aslglobal . h - Global variable definitions <nl> - * $ Revision : 1 . 15 $ <nl> + * $ Revision : 1 . 17 $ <nl> * <nl> *****************************************************************************/ <nl>  <nl> EXTERN ASL_PARSE_NODE INIT_GLOBAL (* Gbl_NodeCacheNext , NULL ); <nl> EXTERN ASL_PARSE_NODE INIT_GLOBAL (* Gbl_NodeCacheLast , NULL ); <nl> EXTERN NATIVE_CHAR INIT_GLOBAL (* Gbl_StringCacheNext , NULL ); <nl> EXTERN NATIVE_CHAR INIT_GLOBAL (* Gbl_StringCacheLast , NULL ); <nl> - <nl> + EXTERN UINT32 INIT_GLOBAL ( Gbl_TempCount , 0 ); <nl> + EXTERN ASL_PARSE_NODE * Gbl_FirstLevelInsertionNode ; <nl>  <nl>  <nl> EXTERN UINT32 INIT_GLOBAL ( Gbl_CurrentHexColumn , 0 ); <nl> EXTERN FILE * DebugFile ; /* Placeholder for oswinxf only */ <nl> EXTERN ASL_ANALYSIS_WALK_INFO AnalysisWalkInfo ; <nl> EXTERN ACPI_TABLE_HEADER TableHeader ; <nl> extern ASL_RESERVED_INFO ReservedMethods []; <nl> + EXTERN ASL_EVENT_INFO AslGbl_Events [ 20 ]; <nl>  <nl>  <nl> /* Scratch buffers */
main ( int argc , char * argv []) <nl> ( void ) sigaddset (& block_cld , SIGCHLD ); <nl> ( void ) sigprocmask ( SIG_BLOCK , & block_cld , NULL ); <nl>  <nl> + /* <nl> + * The parent only needs stderr after the fork , so close other fd ' s <nl> + * that we inherited from zoneadm so that the parent doesn ' t have those <nl> + * open while waiting . The child will close the rest after the fork . <nl> + */ <nl> + closefrom ( 3 ); <nl> + <nl> if (( ctfd = init_template ()) == - 1 ) { <nl> zerror ( zlogp , B_TRUE , " failed to create contract "); <nl> return ( 1 );
dmu_sendbackup ( objset_t * tosnap , objset_t * fromsnap , vnode_t * vp ) <nl> if ( err ) { <nl> if ( err == EINTR && ba . err ) <nl> err = ba . err ; <nl> + kmem_free ( drr , sizeof ( dmu_replay_record_t )); <nl> return ( err ); <nl> } <nl>  <nl> dmu_sendbackup ( objset_t * tosnap , objset_t * fromsnap , vnode_t * vp ) <nl> drr -> drr_type = DRR_END ; <nl> drr -> drr_u . drr_end . drr_checksum = ba . zc ; <nl>  <nl> - if ( dump_bytes (& ba , drr , sizeof ( dmu_replay_record_t ))) <nl> + if ( dump_bytes (& ba , drr , sizeof ( dmu_replay_record_t ))) { <nl> + kmem_free ( drr , sizeof ( dmu_replay_record_t )); <nl> return ( ba . err ); <nl> + } <nl>  <nl> kmem_free ( drr , sizeof ( dmu_replay_record_t )); <nl>  <nl> dmu_recvbackup ( char * tosnap , struct drr_begin * drrb , uint64_t * sizep , <nl> ds -> ds_prev -> ds_phys -> ds_guid != <nl> drrb -> drr_fromguid ) { <nl> dsl_dataset_close ( ds , DS_MODE_EXCLUSIVE , FTAG ); <nl> + kmem_free ( ra . buf , ra . bufsize ); <nl> return ( ENODEV ); <nl> } <nl> ( void ) dsl_dataset_rollback ( ds );
ahci_config_space_init ( ahci_ctl_t * ahci_ctlp ) <nl> ahci_ctlp -> ahcictl_cap |= AHCI_CAP_32BIT_DMA ; <nl> } <nl>  <nl> + /* ASUS M3N - HT ( NVidia 780a ) does not support MSI */ <nl> + if ( venid == 0x10de && devid == 0x0ad4 ) { <nl> + AHCIDBG0 ( AHCIDBG_INIT , ahci_ctlp , <nl> + " ASUS M3N - HT ( NVidia 780a ) does not support MSI " <nl> + " interrupts , so force it to use fixed interrupts ."); <nl> + ahci_msi_enabled = B_FALSE ; <nl> + } <nl> + <nl> /* <nl> * Check if capabilities list is supported and if so , <nl> * get initial capabilities pointer and clear bits 0 , 1 .
dtrace_action_ustack ( dtrace_mstate_t * mstate , dtrace_state_t * state , <nl> uint64_t * pcs = & buf [ 1 ], * fps ; <nl> char * str = ( char *)& pcs [ nframes ]; <nl> int size , offs = 0 , i , j ; <nl> + size_t rem ; <nl> uintptr_t old = mstate -> dtms_scratch_ptr , saved ; <nl> uint16_t * flags = & cpu_core [ CPU -> cpu_id ]. cpuc_dtrace_flags ; <nl> char * sym ; <nl> dtrace_action_ustack ( dtrace_mstate_t * mstate , dtrace_state_t * state , <nl> continue ; <nl> } <nl>  <nl> + if (! dtrace_strcanload (( uintptr_t ) sym , strsize , & rem , mstate , <nl> + &( state -> dts_vstate ))) { <nl> + str [ offs ++] = '\ 0 '; <nl> + continue ; <nl> + } <nl> + <nl> DTRACE_CPUFLAG_SET ( CPU_DTRACE_NOFAULT ); <nl>  <nl> /* <nl> * Now copy in the string that the helper returned to us . <nl> */ <nl> - for ( j = 0 ; offs + j < strsize ; j ++) { <nl> + for ( j = 0 ; offs + j < strsize && j < rem ; j ++) { <nl> if (( str [ offs + j ] = sym [ j ]) == '\ 0 ') <nl> break ; <nl> }
void ppce500_init ( PPCE500Params * params ) <nl>  <nl> /* Fixup Memory size on a alignment boundary */ <nl> ram_size &= ~( RAM_SIZES_ALIGN - 1 ); <nl> + params -> ram_size = ram_size ; <nl>  <nl> /* Register Memory */ <nl> memory_region_init_ram ( ram , " mpc8544ds . ram ", ram_size );
static int serial_post_load ( void * opaque , int version_id ) <nl> } <nl> /* Initialize fcr via setter to perform essential side - effects */ <nl> serial_ioport_write ( s , 0x02 , s -> fcr_vmstate ); <nl> + serial_update_parameters ( s ); <nl> return 0 ; <nl> } <nl> 
typedef struct PRePPCIState { <nl> PCIHostState parent_obj ; <nl>  <nl> MemoryRegion intack ; <nl> - qemu_irq irq [ 4 ]; <nl> + qemu_irq irq [ PCI_NUM_PINS ]; <nl> PCIBus pci_bus ; <nl> RavenPCIState pci_dev ; <nl> } PREPPCIState ; <nl> static void raven_pcihost_realizefn ( DeviceState * d , Error ** errp ) <nl>  <nl> isa_mem_base = 0xc0000000 ; <nl>  <nl> - for ( i = 0 ; i < 4 ; i ++) { <nl> + for ( i = 0 ; i < PCI_NUM_PINS ; i ++) { <nl> sysbus_init_irq ( dev , & s -> irq [ i ]); <nl> } <nl>  <nl> - pci_bus_irqs (& s -> pci_bus , prep_set_irq , prep_map_irq , s -> irq , 4 ); <nl> + pci_bus_irqs (& s -> pci_bus , prep_set_irq , prep_map_irq , s -> irq , PCI_NUM_PINS ); <nl>  <nl> memory_region_init_io (& h -> conf_mem , OBJECT ( h ), & pci_host_conf_be_ops , s , <nl> " pci - conf - idx ", 1 );
typedef struct { <nl>  <nl> static inline int num_effective_busses ( XilinxSPIPS * s ) <nl> { <nl> - return ( s -> regs [ R_LQSPI_STS ] & LQSPI_CFG_SEP_BUS && <nl> - s -> regs [ R_LQSPI_STS ] & LQSPI_CFG_TWO_MEM ) ? s -> num_busses : 1 ; <nl> + return ( s -> regs [ R_LQSPI_CFG ] & LQSPI_CFG_SEP_BUS && <nl> + s -> regs [ R_LQSPI_CFG ] & LQSPI_CFG_TWO_MEM ) ? s -> num_busses : 1 ; <nl> } <nl>  <nl> static void xilinx_spips_update_cs_lines ( XilinxSPIPS * s )
static int mode_sense_page ( SCSIDiskState * s , int page , uint8_t ** p_outbuf , <nl>  <nl> case MODE_PAGE_R_W_ERROR : <nl> length = 10 ; <nl> + if ( page_control == 1 ) { /* Changeable Values */ <nl> + break ; <nl> + } <nl> p [ 0 ] = 0x80 ; /* Automatic Write Reallocation Enabled */ <nl> if ( s -> qdev . type == TYPE_ROM ) { <nl> p [ 1 ] = 0x20 ; /* Read Retry Count */
static void qemu_tcg_init_cpu_signals ( void ) <nl> } <nl> # endif /* _WIN32 */ <nl>  <nl> - QemuMutex qemu_global_mutex ; <nl> + static QemuMutex qemu_global_mutex ; <nl> static QemuCond qemu_io_proceeded_cond ; <nl> static bool iothread_requesting_mutex ; <nl> 
BlockDriverAIOCB * paio_ioctl ( BlockDriverState * bs , int fd , <nl> acb -> aio_type = QEMU_AIO_IOCTL ; <nl> acb -> aio_fildes = fd ; <nl> acb -> ev_signo = SIGUSR2 ; <nl> + acb -> async_context_id = get_async_context_id (); <nl> acb -> aio_offset = 0 ; <nl> acb -> aio_ioctl_buf = buf ; <nl> acb -> aio_ioctl_cmd = req ;
void qmp_migrate ( const char * uri , bool has_blk , bool blk , <nl> error_setg ( errp , QERR_MIGRATION_ACTIVE ); <nl> return ; <nl> } <nl> - <nl> if ( runstate_check ( RUN_STATE_INMIGRATE )) { <nl> error_setg ( errp , " Guest is waiting for an incoming migration "); <nl> return ; <nl> void qmp_migrate ( const char * uri , bool has_blk , bool blk , <nl> return ; <nl> } <nl>  <nl> + /* We are starting a new migration , so we want to start in a clean <nl> + state . This change is only needed if previous migration <nl> + failed / was cancelled . We don ' t use migrate_set_state () because <nl> + we are setting the initial state , not changing it . */ <nl> + s -> state = MIGRATION_STATUS_NONE ; <nl> + <nl> s = migrate_init (& params ); <nl>  <nl> if ( strstart ( uri , " tcp :", & p )) {
static inline void cpu_get_tb_cpu_state ( CPUState * env , target_ulong * pc , <nl> * flags = env -> hflags & ( MIPS_HFLAG_TMASK | MIPS_HFLAG_BMASK ); <nl> } <nl>  <nl> + static inline void cpu_set_tls ( CPUState * env , target_ulong newtls ) <nl> +{ <nl> + env -> tls_value = newtls ; <nl> +} <nl> + <nl> # endif /* ! defined ( __MIPS_CPU_H__ ) */
static void spapr_populate_cpu_dt ( CPUState * cs , void * fdt , int offset , <nl> uint32_t cpufreq = kvm_enabled () ? kvmppc_get_clockfreq () : 1000000000 ; <nl> uint32_t page_sizes_prop [ 64 ]; <nl> size_t page_sizes_prop_size ; <nl> - QemuOpts * opts = qemu_opts_find ( qemu_find_opts (" smp - opts "), NULL ); <nl> - unsigned sockets = opts ? qemu_opt_get_number ( opts , " sockets ", 0 ) : 0 ; <nl> - uint32_t cpus_per_socket = sockets ? ( smp_cpus / sockets ) : 1 ; <nl> + uint32_t vcpus_per_socket = smp_threads * smp_cores ; <nl> uint32_t pft_size_prop [] = { 0 , cpu_to_be32 ( spapr -> htab_shift )}; <nl>  <nl> _FDT (( fdt_setprop_cell ( fdt , offset , " reg ", index ))); <nl> static void spapr_populate_cpu_dt ( CPUState * cs , void * fdt , int offset , <nl> } <nl>  <nl> _FDT (( fdt_setprop_cell ( fdt , offset , " ibm , chip - id ", <nl> - cs -> cpu_index / cpus_per_socket ))); <nl> + cs -> cpu_index / vcpus_per_socket ))); <nl>  <nl> _FDT (( fdt_setprop ( fdt , offset , " ibm , pft - size ", <nl> pft_size_prop , sizeof ( pft_size_prop ))));
static GSList * gd_vc_gfx_init ( GtkDisplayState * s , VirtualConsole * vc , <nl>  <nl> if ( dpy_ui_info_supported ( vc -> gfx . dcl . con )) { <nl> gtk_menu_item_activate ( GTK_MENU_ITEM ( s -> zoom_fit_item )); <nl> + s -> free_scale = true ; <nl> } <nl>  <nl> return group ;
static int bdrv_open_inherit ( BlockDriverState ** pbs , const char * filename , <nl> BlockDriverState * bs ; <nl> BlockDriver * drv = NULL ; <nl> const char * drvname ; <nl> + const char * backing ; <nl> Error * local_err = NULL ; <nl> int snapshot_flags = 0 ; <nl>  <nl> static int bdrv_open_inherit ( BlockDriverState ** pbs , const char * filename , <nl>  <nl> assert ( drvname || !( flags & BDRV_O_PROTOCOL )); <nl>  <nl> + backing = qdict_get_try_str ( options , " backing "); <nl> + if ( backing && * backing == '\ 0 ') { <nl> + flags |= BDRV_O_NO_BACKING ; <nl> + qdict_del ( options , " backing "); <nl> + } <nl> + <nl> bs -> open_flags = flags ; <nl> bs -> options = options ; <nl> options = qdict_clone_shallow ( options );
void virtio_cleanup ( VirtIODevice * vdev ) <nl> if ( vdev -> config ) <nl> qemu_free ( vdev -> config ); <nl> qemu_free ( vdev -> vq ); <nl> + qemu_free ( vdev ); <nl> } <nl>  <nl> static void virtio_vmstate_change ( void * opaque , int running , int reason )
static void kbd_write_mouse ( KBDState * s , int val ) <nl> s -> mouse_sample_rate = 100 ; <nl> s -> mouse_resolution = 2 ; <nl> s -> mouse_status = 0 ; <nl> + s -> mouse_type = 0 ; <nl> kbd_queue ( s , AUX_ACK , 1 ); <nl> kbd_queue ( s , 0xaa , 1 ); <nl> kbd_queue ( s , s -> mouse_type , 1 );
void qmp_migrate_set_cache_size ( int64_t value , Error ** errp ) <nl> return ; <nl> } <nl>  <nl> + /* Cache should not be larger than guest ram size */ <nl> + if ( value > ram_bytes_total ()) { <nl> + error_set ( errp , QERR_INVALID_PARAMETER_VALUE , " cache size ", <nl> + " exceeds guest ram size "); <nl> + return ; <nl> + } <nl> + <nl> new_size = xbzrle_cache_resize ( value ); <nl> if ( new_size < 0 ) { <nl> error_set ( errp , QERR_INVALID_PARAMETER_VALUE , " cache size ",
static void cirrus_init_common ( CirrusVGAState * s , int device_id , int is_pci ) <nl> s -> vga . cursor_draw_line = cirrus_cursor_draw_line ; <nl>  <nl> qemu_register_reset ( cirrus_reset , s ); <nl> - cirrus_reset ( s ); <nl> } <nl>  <nl> /***************************************
static TCGArg * tcg_constant_folding ( TCGContext * s , uint16_t * tcg_opc_ptr , <nl> /* Simplify LT / GE comparisons vs zero to a single compare <nl> vs the high word of the input . */ <nl> s -> gen_opc_buf [ op_index ] = INDEX_op_setcond_i32 ; <nl> + reset_temp ( args [ 0 ]); <nl> gen_args [ 0 ] = args [ 0 ]; <nl> gen_args [ 1 ] = args [ 2 ]; <nl> gen_args [ 2 ] = args [ 4 ];
static inline void tcg_out8 ( TCGContext * s , uint8_t v ) <nl> static inline void tcg_out16 ( TCGContext * s , uint16_t v ) <nl> { <nl> uint8_t * p = s -> code_ptr ; <nl> - *( uint16_t *) p = v ; <nl> + memcpy ( p , & v , sizeof ( v )); <nl> s -> code_ptr = p + 2 ; <nl> } <nl>  <nl> static inline void tcg_out32 ( TCGContext * s , uint32_t v ) <nl> { <nl> uint8_t * p = s -> code_ptr ; <nl> - *( uint32_t *) p = v ; <nl> + memcpy ( p , & v , sizeof ( v )); <nl> s -> code_ptr = p + 4 ; <nl> } <nl>  <nl> static inline void tcg_out64 ( TCGContext * s , uint64_t v ) <nl> { <nl> uint8_t * p = s -> code_ptr ; <nl> - *( uint64_t *) p = v ; <nl> + memcpy ( p , & v , sizeof ( v )); <nl> s -> code_ptr = p + 8 ; <nl> } <nl> 
void pc_hot_add_cpu ( const int64_t id , Error ** errp ) <nl> DeviceState * icc_bridge ; <nl> int64_t apic_id = x86_cpu_apic_id_from_index ( id ); <nl>  <nl> + if ( id < 0 ) { <nl> + error_setg ( errp , " Invalid CPU id : %" PRIi64 , id ); <nl> + return ; <nl> + } <nl> + <nl> if ( cpu_exists ( apic_id )) { <nl> error_setg ( errp , " Unable to add CPU : %" PRIi64 <nl> ", it already exists ", id );
static void ide_atapi_cmd ( IDEState * s ) <nl> break ; <nl> case GPCMD_START_STOP_UNIT : <nl> { <nl> - int start , eject , err = 0 ; <nl> + int start , eject , sense , err = 0 ; <nl> start = packet [ 4 ] & 1 ; <nl> eject = ( packet [ 4 ] >> 1 ) & 1 ; <nl>  <nl> static void ide_atapi_cmd ( IDEState * s ) <nl> ide_atapi_cmd_ok ( s ); <nl> break ; <nl> case - EBUSY : <nl> - ide_atapi_cmd_error ( s , SENSE_NOT_READY , <nl> + sense = SENSE_NOT_READY ; <nl> + if ( bdrv_is_inserted ( s -> bs )) { <nl> + sense = SENSE_ILLEGAL_REQUEST ; <nl> + } <nl> + ide_atapi_cmd_error ( s , sense , <nl> ASC_MEDIA_REMOVAL_PREVENTED ); <nl> break ; <nl> default :
static void usb_mtp_realize ( USBDevice * dev , Error ** errp ) <nl> usb_desc_init ( dev ); <nl> QTAILQ_INIT (& s -> objects ); <nl> if ( s -> desc == NULL ) { <nl> + if ( s -> root == NULL ) { <nl> + error_setg ( errp , " usb - mtp : x - root property must be configured "); <nl> + return ; <nl> + } <nl> s -> desc = strrchr ( s -> root , '/'); <nl> if ( s -> desc && s -> desc [ 0 ]) { <nl> s -> desc = g_strdup ( s -> desc + 1 );
static int kvm_sclp_service_call ( S390CPU * cpu , struct kvm_run * run , <nl> int r = 0 ; <nl>  <nl> cpu_synchronize_state ( CPU ( cpu )); <nl> + if ( env -> psw . mask & PSW_MASK_PSTATE ) { <nl> + enter_pgmcheck ( cpu , PGM_PRIVILEGED ); <nl> + return 0 ; <nl> + } <nl> sccb = env -> regs [ ipbh0 & 0xf ]; <nl> code = env -> regs [( ipbh0 & 0xf0 ) >> 4 ]; <nl> 
static void * cur_chip = NULL ; /* current chip point */ <nl> /* static OPLSAMPLE * bufL ,* bufR ; */ <nl> static OPL_CH * S_CH ; <nl> static OPL_CH * E_CH ; <nl> - OPL_SLOT * SLOT7_1 ,* SLOT7_2 ,* SLOT8_1 ,* SLOT8_2 ; <nl> + static OPL_SLOT * SLOT7_1 , * SLOT7_2 , * SLOT8_1 , * SLOT8_2 ; <nl>  <nl> static INT32 outd [ 1 ]; <nl> static INT32 ams ; <nl> static INT32 vib ; <nl> - INT32 * ams_table ; <nl> - INT32 * vib_table ; <nl> + static INT32 * ams_table ; <nl> + static INT32 * vib_table ; <nl> static INT32 amsIncr ; <nl> static INT32 vibIncr ; <nl> static INT32 feedback2 ; /* connect for SLOT 2 */
static int qcow2_save_vmstate ( BlockDriverState * bs , QEMUIOVector * qiov , <nl> int64_t pos ) <nl> { <nl> BDRVQcowState * s = bs -> opaque ; <nl> + int64_t total_sectors = bs -> total_sectors ; <nl> int growable = bs -> growable ; <nl> int ret ; <nl>  <nl> static int qcow2_save_vmstate ( BlockDriverState * bs , QEMUIOVector * qiov , <nl> ret = bdrv_pwritev ( bs , qcow2_vm_state_offset ( s ) + pos , qiov ); <nl> bs -> growable = growable ; <nl>  <nl> + /* bdrv_co_do_writev will have increased the total_sectors value to include <nl> + * the VM state - the VM state is however not an actual part of the block <nl> + * device , therefore , we need to restore the old value . */ <nl> + bs -> total_sectors = total_sectors ; <nl> + <nl> return ret ; <nl> } <nl> 
struct m_hdr { <nl> struct mbuf { <nl> struct m_hdr m_hdr ; <nl> Slirp * slirp ; <nl> + bool arp_requested ; <nl> + uint64_t expiration_date ; <nl> + /* start of dynamic buffer area , must be last element */ <nl> union M_dat { <nl> char m_dat_ [ 1 ]; /* ANSI don ' t like 0 sized arrays */ <nl> char * m_ext_ ; <nl> } M_dat ; <nl> - bool arp_requested ; <nl> - uint64_t expiration_date ; <nl> }; <nl>  <nl> # define m_next m_hdr . mh_next
void espdma_memory_read ( void * opaque , uint8_t * buf , int len ) <nl> DPRINTF (" DMA read , direction : % c , addr 0x % 8 . 8x \ n ", <nl> s -> dmaregs [ 0 ] & DMA_WRITE_MEM ? ' w ': ' r ', s -> dmaregs [ 1 ]); <nl> sparc_iommu_memory_read ( s -> iommu , s -> dmaregs [ 1 ], buf , len ); <nl> + DPRINTF (" Raise IRQ \ n "); <nl> s -> dmaregs [ 0 ] |= DMA_INTR ; <nl> s -> dmaregs [ 1 ] += len ; <nl> } <nl> void espdma_memory_write ( void * opaque , uint8_t * buf , int len ) <nl> DPRINTF (" DMA write , direction : % c , addr 0x % 8 . 8x \ n ", <nl> s -> dmaregs [ 0 ] & DMA_WRITE_MEM ? ' w ': ' r ', s -> dmaregs [ 1 ]); <nl> sparc_iommu_memory_write ( s -> iommu , s -> dmaregs [ 1 ], buf , len ); <nl> + DPRINTF (" Raise IRQ \ n "); <nl> s -> dmaregs [ 0 ] |= DMA_INTR ; <nl> s -> dmaregs [ 1 ] += len ; <nl> }
void qemu_cpu_kick ( void * _env ) <nl> CPUState * env = _env ; <nl>  <nl> qemu_cond_broadcast ( env -> halt_cond ); <nl> - if (! env -> thread_kicked ) { <nl> + if ( kvm_enabled () && ! env -> thread_kicked ) { <nl> qemu_cpu_kick_thread ( env ); <nl> env -> thread_kicked = true ; <nl> }
static void ppc_heathrow_init ( QEMUMachineInitArgs * args ) <nl> int linux_boot , i ; <nl> MemoryRegion * ram = g_new ( MemoryRegion , 1 ); <nl> MemoryRegion * bios = g_new ( MemoryRegion , 1 ); <nl> + MemoryRegion * isa = g_new ( MemoryRegion , 1 ); <nl> uint32_t kernel_base , initrd_base , cmdline_base = 0 ; <nl> int32_t kernel_size , initrd_size ; <nl> PCIBus * pci_bus ; <nl> static void ppc_heathrow_init ( QEMUMachineInitArgs * args ) <nl> } <nl>  <nl> /* Register 2 MB of ISA IO space */ <nl> - isa_mmio_init ( 0xfe000000 , 0x00200000 ); <nl> + memory_region_init_alias ( isa , NULL , " isa_mmio ", <nl> + get_system_io (), 0 , 0x00200000 ); <nl> + memory_region_add_subregion ( sysmem , 0xfe000000 , isa ); <nl>  <nl> /* XXX : we register only 1 output pin for heathrow PIC */ <nl> heathrow_irqs = g_malloc0 ( smp_cpus * sizeof ( qemu_irq *));
enum { <nl> # ifdef TARGET_SPARC64 <nl> # define DFPREG ( r ) ((( r & 1 ) << 6 ) | ( r & 0x1e )) <nl> # else <nl> -# define DFPREG ( r ) ( r ) <nl> +# define DFPREG ( r ) ( r & 0x1e ) <nl> # endif <nl>  <nl> # ifdef USE_DIRECT_JUMP
messageAddArguments ( message * m , const char * s ) <nl> ptr = strchr ( kcopy , ':'); <nl> if ( ptr == NULL ) { <nl> cli_dbgmsg (" Can ' t parse header \"% s \"\ n ", s ); <nl> + free ( kcopy ); <nl> return ; <nl> } <nl> }
static char * decodehexstr ( const char * hex , unsigned int * dlen ) <nl>  <nl> decoded = calloc ( len + 1 + wildcard * 32 , sizeof ( char )); <nl> if (! decoded ) { <nl> + free ( str16 ); <nl> mprintf ("! decodehexstr : Can ' t allocate memory for decoded \ n "); <nl> return NULL ; <nl> } <nl> static char * decodehexstr ( const char * hex , unsigned int * dlen ) <nl> default : <nl> mprintf ("! decodehexstr : Unknown wildcard ( 0x % x @% u )\ n ", str16 [ i ] & CLI_MATCH_WILDCARD , i ); <nl> free ( decoded ); <nl> + free ( str16 ); <nl> return NULL ; <nl> } <nl> } else { <nl> static char * decodehexstr ( const char * hex , unsigned int * dlen ) <nl>  <nl> if ( dlen ) <nl> * dlen = p ; <nl> - <nl> + free ( str16 ); <nl> return decoded ; <nl> } <nl> 
const char * cl_strerror ( int clerror ) <nl> return " Can ' t map file into memory "; <nl> case CL_EMEM : <nl> return " Can ' t allocate memory "; <nl> + case CL_ETIMEOUT : <nl> + return " Time limit reached "; <nl> /* internal ( needed for debug messages ) */ <nl> case CL_EMAXREC : <nl> return " CL_EMAXREC ";
int openioc_parse ( const char * fname , int fd , struct cl_engine * engine ) <nl> * vp -- = '\ 0 '; <nl> hashlen --; <nl> } <nl> - virusname = mpool_malloc ( engine -> mempool , ioclen + hashlen + 2 ); <nl> + virusname = mpool_malloc ( engine -> mempool , ioclen + hashlen + 13 ); <nl> if ( NULL == virusname ) { <nl> cli_dbgmsg (" openioc_parse : mpool_malloc for virname memory failed .\ n "); <nl> xmlTextReaderClose ( reader ); <nl> int openioc_parse ( const char * fname , int fd , struct cl_engine * engine ) <nl> * vp ++ = * sp ; <nl> } <nl> } <nl> - * vp = '\ 0 '; <nl> + strcpy ( vp , ". UNOFFICIAL "); <nl> rc = hm_addhash_str ( engine -> hm_hdb , hash , 0 , virusname ); <nl> if ( rc != CL_SUCCESS ) <nl> cli_dbgmsg (" openioc_parse : hm_addhash_str failed with % i hash len % i for % s .\ n ",
extern " C " { <nl>  <nl> # ifdef DEBUG <nl> # include < stdio . h > <nl> +# include < stdint . h > <nl>  <nl> + extern uint8_t cli_debug_flag ; <nl> /* Old GCCs don ' t have __func__ , but __FUNCTION__ : <nl> * http :// gcc . gnu . org / onlinedocs / gcc / Function - Names . html <nl> */ <nl> extern " C " { <nl> # endif <nl> # endif <nl> /* Adding custom clamav debug code . */ <nl> -# define D ( x ) do { printf (" LibClamAV debug : % s :% d (% s )", __FILE__ , __LINE__ , __func__ ); \ <nl> - printf x ; fputc ('\ n ', stdout ); fflush ( stdout );} while ( 0 ); <nl> +# define D ( x ) do { if ( cli_debug_flag ) { \ <nl> + printf (" LibClamAV debug : % s :% d (% s )", __FILE__ , __LINE__ , __func__ ); \ <nl> + printf x ; fputc ('\ n ', stdout ); fflush ( stdout ); \ <nl> + } \ <nl> + } while ( 0 ); <nl>  <nl> # else <nl> # define D ( x )
messageAddArgument ( message * m , const char * arg ) <nl> * FIXME : Bounce message handling is corrupting the in <nl> * core copies of headers <nl> */ <nl> - cli_dbgmsg (" Possible data corruption fixed \ n "); <nl> - p [ 8 ] = '='; <nl> + if ( strlen ( p ) > 8 ) { <nl> + cli_dbgmsg (" Possible data corruption fixed \ n "); <nl> + p [ 8 ] = '='; <nl> + } else { <nl> + cli_dbgmsg (" Possible data corruption not fixed \ n "); <nl> + } <nl> } else { <nl> if (* p ) <nl> cli_dbgmsg (" messageAddArgument , '% s ' contains no '='\ n ", p ); <nl> messageFindArgument ( const message * m , const char * variable ) <nl> cli_dbgmsg (" messageFindArgument : no '=' sign found in MIME header '% s ' (% s )\ n ", variable , messageGetArgument ( m , i )); <nl> return NULL ; <nl> } <nl> - if ((*++ ptr == '"') && ( strchr (& ptr [ 1 ], '"') != NULL )) { <nl> + if (( strlen ( ptr ) > 2 ) && (*++ ptr == '"') && ( strchr (& ptr [ 1 ], '"') != NULL )) { <nl> /* Remove any quote characters */ <nl> char * ret = cli_strdup (++ ptr ); <nl> char * p ;
bool Machine :: Code :: decoder :: validate_opcode ( const opcode opc , const byte * cons <nl> return false ; <nl> } <nl> const opcode_t & op = Machine :: getOpcodeTable ()[ opc ]; <nl> + if ( op . param_sz == VARARGS && bc >= _max . bytecode ) <nl> + { <nl> + failure ( arguments_exhausted ); <nl> + return false ; <nl> + } <nl> const size_t param_sz = op . param_sz == VARARGS ? bc [ 0 ] + 1 : op . param_sz ; <nl> if ( bc - 1 + param_sz >= _max . bytecode ) <nl> {
GlyphCache :: GlyphCache ( const Face & face , const uint32 face_options ) <nl> } <nl> delete _glyph_loader ; <nl> _glyph_loader = 0 ; <nl> + // coverity [ leaked_storage : FALSE ] - calling read_glyph on index 0 saved <nl> + // glyphs as _glyphs [ 0 ]. Setting _glyph_loader to nullptr here flags that <nl> + // the dtor needs to call delete [] on _glyphs [ 0 ] to release what was allocated <nl> + // as glyphs <nl> } <nl>  <nl> if ( _glyphs && glyph ( 0 ) == 0 )
do_adjustment ( struct adjtime * adjtime_p , <nl> adjtime_p -> dirty = TRUE ; <nl> } else if ( adjtime_p -> last_adj_time == 0 ) { <nl> if ( debug ) <nl> - printf ( _ <nl> - (" Not setting clock because last adjustment time is zero , " <nl> - " so history is bad .")); <nl> + printf ( _ (" Not setting clock because last adjustment time is zero , " <nl> + " so history is bad .\ n ")); <nl> } else if ( abs ( adjtime_p -> drift_factor ) > MAX_DRIFT ) { <nl> if ( debug ) <nl> - printf ( _ (" Not setting clock because drift factor % f is far too high .\ n "), <nl> - adjtime_p -> drift_factor ); <nl> + printf ( _ (" Not setting clock because drift factor % f is far too high .\ n "), <nl> + adjtime_p -> drift_factor ); <nl> } else { <nl> int adjustment ; <nl> /* Number of seconds we must insert in the Hardware Clock */
static void print_value ( int output , int num , const char * devname , <nl> print_udev_format ( name , value ); <nl>  <nl> } else if ( output & OUTPUT_EXPORT_LIST ) { <nl> + if ( num == 1 && devname ) <nl> + printf (" DEVNAME =% s \ n ", devname ); <nl> fputs ( name , stdout ); <nl> fputs ("=", stdout ); <nl> safe_print ( value , valsz );
# define SB_JOURNAL_BUCKETS 256U <nl>  <nl> # define node ( i , j ) (( i )-> d + ( j )) <nl> -# define end ( i ) node ( i , ( i )-> keys ) <nl> +# define end ( i ) node ( i , le16_to_cpu (( i )-> keys )) <nl>  <nl> static const char bcache_magic [] = { <nl> 0xc6 , 0x85 , 0x73 , 0xf6 , 0x4e , 0x1a , 0x45 , 0xca , <nl> static int probe_bcache ( blkid_probe pr , const struct blkid_idmag * mag ) <nl>  <nl> if ( le64_to_cpu ( bcs -> offset ) != BCACHE_SB_OFF / 512 ) <nl> return BLKID_PROBE_NONE ; <nl> + if ( le16_to_cpu ( bcs -> keys ) > SB_JOURNAL_BUCKETS ) <nl> + return BLKID_PROBE_NONE ; <nl> if (! blkid_probe_verify_csum ( pr , bcache_crc64 ( bcs ), le64_to_cpu ( bcs -> csum ))) <nl> return BLKID_PROBE_NONE ; <nl> 
int fdisk_assign_device ( struct fdisk_context * cxt , <nl>  <nl> fd = open ( fname , ( readonly ? O_RDONLY : O_RDWR ) | O_CLOEXEC ); <nl> if ( fd < 0 ) <nl> - return - errno ; <nl> + goto fail ; <nl>  <nl> - fstat ( fd , & cxt -> dev_st ); <nl> + if ( fstat ( fd , & cxt -> dev_st ) != 0 ) <nl> + goto fail ; <nl>  <nl> cxt -> readonly = readonly ; <nl> cxt -> dev_fd = fd ; <nl> int fdisk_assign_device ( struct fdisk_context * cxt , <nl> fname , readonly ? " READ - ONLY " : " READ - WRITE ")); <nl> return 0 ; <nl> fail : <nl> + if ( fd >= 0 ) <nl> + close ( fd ); <nl> DBG ( CXT , ul_debugobj ( cxt , " failed to assign device ")); <nl> return - errno ; <nl> }
readlink_to_namei ( struct namei * nm , const char * path ) <nl> err ( EXIT_FAILURE , _ (" out of memory ?")); <nl>  <nl> if (* sym != '/') { <nl> + /* create the absolute path from the relative symlink */ <nl> memcpy ( nm -> abslink , path , nm -> relstart ); <nl> *( nm -> abslink + nm -> relstart ) = '/'; <nl> nm -> relstart ++; <nl> - memcpy ( nm -> abslink + nm -> relstart , sym , sz ); <nl> + memcpy ( nm -> abslink + nm -> relstart , sym , sz - nm -> relstart ); <nl> } else <nl> memcpy ( nm -> abslink , sym , sz ); <nl> nm -> abslink [ sz ] = '\ 0 ';
int proc_next_tid ( struct proc_tasks * tasks , pid_t * tid ) <nl> struct dirent * d ; <nl> char * end ; <nl>  <nl> + if (! tasks || ! tid ) <nl> + return - 1 ; <nl> + <nl> * tid = 0 ; <nl> errno = 0 ; <nl> 
long old_style_option ( int * argc , char ** argv ) <nl> lines = strtol_or_err ( argv [ i ] + 1 , <nl> _ (" failed to parse number of lines ")); <nl> nargs --; <nl> - memmove ( argv + i , argv + i + 1 , sizeof ( char *) * nargs ); <nl> + if ( nargs - i ) <nl> + memmove ( argv + i , argv + i + 1 , <nl> + sizeof ( char *) * ( nargs - i )); <nl> } else <nl> i ++; <nl> }
wchar_t * buf ; <nl>  <nl> static void sig_handler ( int signo __attribute__ (( __unused__ ))) <nl> { <nl> - free ( buf ); <nl> _exit ( EXIT_SUCCESS ); <nl> } <nl> 
mount_one ( const char * spec , const char * node , const char * types , <nl> } <nl>  <nl> /* Handle possible LABEL = and UUID = forms of spec */ <nl> - if ( types == NULL || ( strncmp ( types , " nfs ", 3 ) && <nl> + if ( types == NULL || ( strncmp ( types , " 9p ", 2 ) && <nl> + strncmp ( types , " nfs ", 3 ) && <nl> strncmp ( types , " cifs ", 4 ) && <nl> strncmp ( types , " smbfs ", 5 ))) { <nl> nspec = spec_to_devname ( spec );
void Bittorrent :: saveFastResumeData () { <nl> if (! rd -> resume_data ) continue ; <nl> QDir torrentBackup ( misc :: qBittorrentPath () + " BT_backup "); <nl> QTorrentHandle h ( rd -> handle ); <nl> + if (! h . is_valid ()) continue ; <nl> // Remove old fastresume file if it exists <nl> QFile :: remove ( torrentBackup . path ()+ QDir :: separator ()+ h . hash () + ". fastresume "); <nl> QString file = h . hash ()+". fastresume ";
class about : public QDialog , private Ui :: AboutDlg { <nl> QString :: fromUtf8 ("<! DOCTYPE HTML PUBLIC \"-// W3C // DTD HTML 4 . 0 // EN \" \" http :// www . w3 . org / TR / REC - html40 / strict . dtd \">< html >< head >< meta name =\" qrichtext \" content =\" 1 \" />< style type =\" text / css \"> p , li { white - space : pre - wrap ; }</ style ></ head >< body style =\" font - size : 11pt ; font - weight : 400 ; font - style : normal ;\">< p style =\" margin - top : 0px ; margin - bottom : 0px ; margin - left : 0px ; margin - right : 0px ; - qt - block - indent : 0 ; text - indent : 0px ;\">") + <nl> tr (" An advanced BitTorrent client programmed in < nobr > C ++</ nobr >, based on Qt toolkit and libtorrent - rasterbar .") + <nl> QString :: fromUtf8 (" < br />< br />") + <nl> - trUtf8 (" Copyright % 1 2006 - 2015 The qBittorrent project "). arg ( C_COPYRIGHT ) + <nl> + trUtf8 (" Copyright % 1 2006 - 2015 The qBittorrent project "). arg ( QString :: fromUtf8 ( C_COPYRIGHT )) + <nl> QString :: fromUtf8 ("< br />< br />") + <nl> tr (" Home Page : ") + <nl> QString :: fromUtf8 ("< a href =\" http :// www . qbittorrent . org \">< span style =\" text - decoration : underline ; color :# 0000ff ;\"> http :// www . qbittorrent . org </ span ></ a ></ p >< p style =\" margin - top : 0px ; margin - bottom : 0px ; margin - left : 0px ; margin - right : 0px ; - qt - block - indent : 0 ; text - indent : 0px ;\">") +
void TorrentCreatorThread :: run () { <nl> t . add_url_seed ( seed . trimmed (). toStdString ()); <nl> } <nl> qint32 tier = 0 ; <nl> + bool newline = false ; <nl> foreach ( const QString & tracker , trackers ) { <nl> if ( tracker . isEmpty ()) { <nl> + if ( newline ) <nl> + continue ; <nl> ++ tier ; <nl> + newline = true ; <nl> continue ; <nl> } <nl> t . add_tracker ( tracker . trimmed (). toStdString (), tier ); <nl> + newline = false ; <nl> } <nl> if ( abort ) return ; <nl> // calculate the hash for all pieces
layer_resize ( int layer , int x_size , int y_size ) <nl> struct map_tile * tilemap ; <nl> struct map_trigger * trigger ; <nl> struct map_zone * zone ; <nl> + size_t tilemap_size ; <nl>  <nl> int x , y , i ; <nl>  <nl> layer_resize ( int layer , int x_size , int y_size ) <nl>  <nl> // allocate a new tilemap and copy the old layer tiles into it . we can ' t simply realloc <nl> // because the tilemap is a 2D array . <nl> - if (!( tilemap = malloc ( x_size * y_size * sizeof ( struct map_tile )))) <nl> + tilemap_size = x_size * y_size * sizeof ( struct map_tile ); <nl> + if ( x_size == 0 || tilemap_size / x_size / sizeof ( struct map_tile ) != y_size <nl> + || !( tilemap = malloc ( tilemap_size ))) <nl> return false ; <nl> for ( x = 0 ; x < x_size ; ++ x ) { <nl> for ( y = 0 ; y < y_size ; ++ y ) {
bool AudioOutput :: mix ( void * outbuff , unsigned int nsamp ) { <nl> if ( validListener && (( aop -> fPos [ 0 ] != 0 . 0f ) || ( aop -> fPos [ 1 ] != 0 . 0f ) || ( aop -> fPos [ 2 ] != 0 . 0f ))) { <nl> float dir [ 3 ] = { aop -> fPos [ 0 ] - g . p -> fPosition [ 0 ], aop -> fPos [ 1 ] - g . p -> fPosition [ 1 ], aop -> fPos [ 2 ] - g . p -> fPosition [ 2 ] }; <nl> float len = sqrtf ( dir [ 0 ] * dir [ 0 ] + dir [ 1 ] * dir [ 1 ] + dir [ 2 ] * dir [ 2 ]); <nl> - dir [ 0 ] /= len ; <nl> - dir [ 1 ] /= len ; <nl> - dir [ 2 ] /= len ; <nl> + if ( len > 0 . 0f ) <nl> + { <nl> + dir [ 0 ] /= len ; <nl> + dir [ 1 ] /= len ; <nl> + dir [ 2 ] /= len ; <nl> + } <nl> /* <nl> qWarning (" Voice pos : % f % f % f ", aop -> fPos [ 0 ], aop -> fPos [ 1 ], aop -> fPos [ 2 ]); <nl> qWarning (" Voice dir : % f % f % f ", dir [ 0 ], dir [ 1 ], dir [ 2 ]);
void MainWindow :: serverDisconnected ( QAbstractSocket :: SocketError err , QString re <nl> if (! Database :: getDigest ( host , port ). isNull ()) { <nl> basereason = tr ("< b > WARNING :</ b > The server presented a certificate that was different from the stored one ."); <nl> } else { <nl> - basereason = tr (" Sever presented a certificate which failed verification ."); <nl> + basereason = tr (" Server presented a certificate which failed verification ."); <nl> } <nl> QStringList qsl ; <nl> foreach ( QSslError e , g . sh -> qlErrors )
MumbleProto :: PermissionDenied mppd ; \ <nl> mppd . set_permission ( static_cast < int >( what )); \ <nl> mppd . set_channel_id ( where -> iId ); \ <nl> - mppd . set_actor_id ( who -> uiSession ); \ <nl> + mppd . set_session ( who -> uiSession ); \ <nl> sendMessage ( uSource , mppd ); \ <nl> log ( uSource , QString ("% 1 not allowed to % 2 in % 3 "). arg ( who -> qsName ). arg ( ChanACL :: permName ( what )). arg ( where -> qsName )); \ <nl> }
int BandwidthRecord :: bytesPerSec () { <nl>  <nl> void Server :: run () { <nl> qint32 len ; <nl> - char encrypted [ 65535 ]; <nl> - char buffer [ 65535 ]; <nl> + char encrypted [ 65536 ]; <nl> + char buffer [ 65536 ]; <nl>  <nl> quint32 msgType = 0 ; <nl> unsigned int uiSession = 0 ;
ViewCert :: ViewCert ( QList < QSslCertificate > cl , QWidget * p ) : QDialog ( p ) { <nl> QGroupBox * qcbChain , * qcbDetails ; <nl>  <nl> qcbChain = new QGroupBox ( tr (" Certificate chain ")); <nl> - qcbDetails = new QGroupBox ( tr (" Certifitcate details ")); <nl> + qcbDetails = new QGroupBox ( tr (" Certificate details ")); <nl>  <nl> h = new QHBoxLayout (); <nl> qlwChain = new QListWidget ();
int openDatabase ( char * prefix , char * dbpath , rpmdb * rpmdbp , int mode , <nl> int i ; <nl> struct flock lockinfo ; <nl>  <nl> + /* we should accept NULL as a valid prefix */ <nl> + if (! prefix ) prefix =""; <nl> + <nl> i = strlen ( dbpath ); <nl> if ( dbpath [ i - 1 ] != '/') { <nl> filename = alloca ( i + 2 );
int build ( rpmts ts , const char * arg , BTA_t ba , const char * rcfile ) <nl> char * target ; <nl> if (( te = strchr ( t , ',')) == NULL ) <nl> te = t + strlen ( t ); <nl> - target = alloca ( te - t + 1 ); <nl> + target = xmalloc ( te - t + 1 ); <nl> strncpy ( target , t , ( te - t )); <nl> target [ te - t ] = '\ 0 '; <nl> if (* te != '\ 0 ') <nl> int build ( rpmts ts , const char * arg , BTA_t ba , const char * rcfile ) <nl> rpmFreeMacros ( NULL ); <nl> rpmFreeRpmrc (); <nl> ( void ) rpmReadConfigFiles ( rcfile , target ); <nl> + free ( target ); <nl> rc = buildForTarget ( ts , arg , ba ); <nl> if ( rc ) <nl> break ;
static int doSign ( poptContext optCon ) <nl> } <nl>  <nl> exit : <nl> + free ( passPhrase ); <nl> free ( name ); <nl> return rc ; <nl> }
char * rpmGenPath ( const char * urlroot , const char * urlmdir , <nl> char * xfile = rpmGetPath ( urlfile , NULL ); <nl> const char * file = xfile ; <nl> char * result ; <nl> - const char * url = NULL ; <nl> + char * url = NULL ; <nl> int nurl = 0 ; <nl> int ut ; <nl>  <nl> char * rpmGenPath ( const char * urlroot , const char * urlmdir , <nl> xroot = _free ( xroot ); <nl> xmdir = _free ( xmdir ); <nl> xfile = _free ( xfile ); <nl> - _constfree ( url ); <nl> + free ( url ); <nl> return result ; <nl> } <nl> 
static int copyTdEntry ( const indexEntry entry , rpmtd td , headerGetFlags flags ) <nl> dataStart = ( unsigned char *) memcpy ( pe + ril , dataStart , rdl ); <nl>  <nl> rc = regionSwab ( NULL , ril , 0 , pe , dataStart , dataStart + rdl , 0 ); <nl> + /* don ' t return data on failure */ <nl> + if ( rc < 0 ) { <nl> + td -> data = _free ( td -> data ); <nl> + } <nl> /* XXX 1 on success . */ <nl> rc = ( rc < 0 ) ? 0 : 1 ; <nl> } else {
int rpmvercmp ( const char * a , const char * b ) <nl> while (* one && ! xisalnum (* one )) one ++; <nl> while (* two && ! xisalnum (* two )) two ++; <nl>  <nl> + /* If we ran to the end of either , we are finished with the loop */ <nl> + if (!(* one && * two )) break ; <nl> + <nl> str1 = one ; <nl> str2 = two ; <nl>  <nl> int rpmvercmp ( const char * a , const char * b ) <nl> * str2 = '\ 0 '; <nl> /*@= boundswrite @*/ <nl>  <nl> + /* this cannot happen , as we previously tested to make sure that */ <nl> + /* the first string has a non - null segment */ <nl> + if ( one == str1 ) return - 1 ; /* arbitrary */ <nl> + <nl> /* take care of the case where the two version segments are */ <nl> /* different types : one numeric , the other alpha ( i . e . empty ) */ <nl> - if ( one == str1 ) return - 1 ; /* arbitrary */ <nl> + /* numeric segments are always newer than alpha segments */ <nl> /* XXX See patch # 60884 ( and details ) from bugzilla # 50977 . */ <nl> if ( two == str2 ) return ( isnum ? 1 : - 1 ); <nl> 
int rpmVerifySignatures ( QVA_t qva , rpmts ts , FD_t fd , <nl> { int offset = 6 ; <nl> b = stpcpy ( b , "( MD5 ) ( PGP ) "); <nl> tempKey = strstr ( result , " ey ID "); <nl> - if ( tempKey == NULL ) { <nl> - tempKey = strstr ( result , " keyid :"); <nl> - offset = 9 ; <nl> - } <nl> if ( tempKey ) { <nl> char * kt = ( sigres == RPMRC_NOKEY ? m : u ); <nl> kt = stpcpy ( kt , " PGP #");
static int installArchive ( char * prefix , int fd , struct fileToInstall * files , <nl> kill ( SIGTERM , child ); <nl> } <nl>  <nl> - if ( write ( p [ 1 ], buf , bytesRead ) != bytesRead ) { <nl> + if ( bytesRead && write ( p [ 1 ], buf , bytesRead ) != bytesRead ) { <nl> cpioFailed = 1 ; <nl> childDead = 1 ; <nl> kill ( SIGTERM , child );
static void removeIndexEntry ( dbIndex * dbi , char * key , dbIndexRecord rec , <nl> case 2 : <nl> break ; /* error message already generated from dbindex . c */ <nl> } <nl> + <nl> + freeDBIndexRecord ( matches ); <nl> } <nl>  <nl> int rpmdbRemove ( rpmdb db , unsigned int offset , int tolerant ) { <nl> int rpmdbRemove ( rpmdb db , unsigned int offset , int tolerant ) { <nl>  <nl> unblockSignals (); <nl>  <nl> + freeHeader ( h ); <nl> + <nl> return 0 ; <nl> } <nl> 
/* seen_db . c -- implementation of seen database using per - user berkeley db <nl> - $ Id : seen_db . c , v 1 . 9 2000 / 04 / 28 22 : 01 : 26 leg Exp $ <nl> + $ Id : seen_db . c , v 1 . 10 2000 / 05 / 05 21 : 35 : 50 leg Exp $ <nl>  <nl> # Copyright 2000 Carnegie Mellon University <nl> # <nl> static int seen_readold ( struct seen * seendb , <nl> const char * base ; <nl> const char * buf = 0 , * p ; <nl> unsigned long len , linelen ; <nl> - unsigned long offset ; <nl> + unsigned long offset = 0 ; <nl>  <nl> strcpy ( fnamebuf , seendb -> path ); <nl> strcat ( fnamebuf , FNAME_SEEN ); <nl> static int seen_readold ( struct seen * seendb , <nl> /* no old - style seen file for this database */ <nl> linelen = 0 ; <nl> } else if ( fd == - 1 ) { <nl> - syslog (" error opening '% s ': % m ", fnamebuf ); <nl> + syslog ( LOG_ERR , " error opening '% s ': % m ", fnamebuf ); <nl> return IMAP_IOERROR ; <nl> } else { <nl> if ( fstat ( fd , & sbuf ) == - 1 ) {
static int find_cb ( void * rock , const char * key , size_t keylen , <nl>  <nl> newkeylen = make_key ( mboxname , uid , entry , userid , newkey , sizeof ( newkey )); <nl> if ( keylen != newkeylen || strncmp ( newkey , key , keylen )) { <nl> - syslog ( LOG_ERR , " find_cb : bogus key % d % s % s ", uid , entry , userid ); <nl> + syslog ( LOG_ERR , " find_cb : bogus key % s % d % s % s (% d % d )", mboxname , uid , entry , userid , ( int ) keylen , ( int ) newkeylen ); <nl> } <nl>  <nl> r = split_attribs ( data , datalen , & value );
/* util . h -- general utility functions <nl> - * $ Id : util . h , v 1 . 8 1999 / 03 / 02 01 : 29 : 42 tjs Exp $ <nl> + * $ Id : util . h , v 1 . 9 1999 / 03 / 02 01 : 46 : 03 tjs Exp $ <nl> * <nl> * Copyright 1998 by Carnegie Mellon University <nl> * <nl> extern const unsigned char convert_to_uppercase [ 256 ]; <nl> # define TOUPPER ( c ) ( charset_convert_to_uppercase [( unsigned char )( c )]) <nl> # define TOLOWER ( c ) ( convert_to_lowercase [( unsigned char )( c )]) <nl>  <nl> + typedef struct keyvalue { <nl> + char * key , * value ; <nl> +} keyvalue ; <nl> + <nl> /* convert string to all lower case <nl> */ <nl> extern char * lcase ( char * str );
static int callout_run_socket ( const char * callout , <nl>  <nl> memset (& mysun , 0 , sizeof ( mysun )); <nl> mysun . sun_family = AF_UNIX ; <nl> - strncpy ( mysun . sun_path , callout , sizeof ( mysun . sun_path )); <nl> + xstrncpy ( mysun . sun_path , callout , sizeof ( mysun . sun_path )); <nl> r = connect ( sock , ( struct sockaddr *)& mysun , sizeof ( mysun )); <nl> if ( r < 0 ) { <nl> syslog ( LOG_ERR , " cannot connect socket for callout : % m ");
EXPORTED int index_urlfetch ( struct index_state * state , uint32_t msgno , <nl> const char * data ; <nl> size_t size ; <nl> int32_t skip = 0 ; <nl> - int n , r = 0 ; <nl> + unsigned long n ; <nl> + int r = 0 ; <nl> char * decbuf = NULL ; <nl> struct index_record record ; <nl>  <nl> EXPORTED int index_urlfetch ( struct index_state * state , uint32_t msgno , <nl> start_octet = size ; <nl> n = 0 ; <nl> } <nl> - else if ( start_octet + n > size ) { <nl> + else if ( start_octet + n < start_octet || start_octet + n > size ) { <nl> n = size - start_octet ; <nl> } <nl>  <nl> EXPORTED int index_urlfetch ( struct index_state * state , uint32_t msgno , <nl>  <nl> if ( domain == DOMAIN_BINARY ) { <nl> /* Write size of literal8 */ <nl> - prot_printf ( pout , " ~{% u }\ r \ n ", n ); <nl> + prot_printf ( pout , " ~{% lu }\ r \ n ", n ); <nl> } else { <nl> /* Write size of literal */ <nl> - prot_printf ( pout , " {% u }\ r \ n ", n ); <nl> + prot_printf ( pout , " {% lu }\ r \ n ", n ); <nl> } <nl> } <nl> 
# include " parseaddr . h " <nl> # include " xmalloc . h " <nl>  <nl> + static char parseaddr_unspecified_domain [] = " unspecified - domain "; <nl> + <nl> static void parseaddr_append (); <nl> static int parseaddr_phrase (); <nl> static int parseaddr_domain (); <nl> char ** freemep ; <nl> newaddr -> mailbox = mailbox ; <nl>  <nl> if ( domain && !* domain ) { <nl> - domain = " unspecified - domain "; <nl> + domain = parseaddr_unspecified_domain ; <nl> } <nl> newaddr -> domain = domain ; <nl> 
static const char * callback_getdata ( sasl_conn_t * conn , <nl> switch ( cb -> id ) { <nl> case SASL_CB_USER : <nl> case SASL_CB_AUTHNAME : { <nl> - sasl_getsimple_t * simple_cb = ( mysasl_cb_ft *) cb -> proc ; <nl> + sasl_getsimple_t * simple_cb = ( void *) cb -> proc ; <nl> simple_cb ( cb -> context , cb -> id , & result , NULL ); <nl> break ; <nl> } <nl>  <nl> case SASL_CB_PASS : { <nl> sasl_secret_t * pass ; <nl> - sasl_getsecret_t * pass_cb = ( mysasl_cb_ft *) cb -> proc ; <nl> + sasl_getsecret_t * pass_cb = ( void *) cb -> proc ; <nl> pass_cb ( conn , cb -> context , cb -> id , & pass ); <nl> result = ( const char *) pass -> data ; <nl> break ;
# include < errno . h > <nl> # include < limits . h > <nl> # include < math . h > <nl> +# include < inttypes . h > <nl>  <nl> # ifndef INADDR_NONE <nl> # define INADDR_NONE 0xffffffff <nl> static void limit_fds ( rlim_t x ) <nl>  <nl> # ifdef HAVE_GETRLIMIT <nl> if (! getrlimit ( RLIMIT_NUMFDS , & rl )) { <nl> + if ( x != RLIM_INFINITY && rl . rlim_max != RLIM_INFINITY && x > rl . rlim_max ) { <nl> + syslog ( LOG_WARNING , <nl> + " limit_fds : requested %" PRIu64 ", but capped to %" PRIu64 , <nl> + ( uint64_t ) x , ( uint64_t ) rl . rlim_max ); <nl> + } <nl> rl . rlim_cur = ( x == RLIM_INFINITY || x > rl . rlim_max ) ? rl . rlim_max : x ; <nl> } <nl> else
int mailbox_rename_cleanup ( struct mailbox ** mailboxptr , int isinbox ) <nl> */ <nl> int mailbox_copyfile ( const char * from , const char * to , int nolink ) <nl> { <nl> - int flags = 0 ; <nl> + int flags = COPYFILE_MKDIR ; <nl> if ( nolink ) flags |= COPYFILE_NOLINK ; <nl> - return cyrus_copyfile ( from , to , flags ); <nl> + <nl> + if ( cyrus_copyfile ( from , to , flags )) <nl> + return IMAP_IOERROR ; <nl> + <nl> + return 0 ; <nl> } <nl>  <nl> /* ---------------------------------------------------------------------- */
static void cmdloop ( void ) <nl> snmp_increment ( SCAN_COUNT , 1 ); <nl> } <nl> else if (! strcmp ( cmd . s , " Syncapply ")) { <nl> + if (! imapd_userisadmin ) goto badcmd ; <nl> + <nl> struct dlist * kl = sync_parseline ( imapd_in ); <nl>  <nl> if ( kl ) { <nl> static void cmdloop ( void ) <nl> else goto extraargs ; <nl> } <nl> else if (! strcmp ( cmd . s , " Syncget ")) { <nl> + if (! imapd_userisadmin ) goto badcmd ; <nl> + <nl> struct dlist * kl = sync_parseline ( imapd_in ); <nl>  <nl> if ( kl ) { <nl> static void cmdloop ( void ) <nl> else goto extraargs ; <nl> } <nl> else if (! strcmp ( cmd . s , " Syncrestart ")) { <nl> + if (! imapd_userisadmin ) goto badcmd ; <nl> + <nl> if ( c == '\ r ') c = prot_getc ( imapd_in ); <nl> if ( c != '\ n ') goto extraargs ; <nl>  <nl> static void cmdloop ( void ) <nl> cmd_syncrestart ( tag . s , & reserve_list , 1 ); <nl> } <nl> else if (! strcmp ( cmd . s , " Syncrestore ")) { <nl> + if (! imapd_userisadmin ) goto badcmd ; <nl> + <nl> struct dlist * kl = sync_parseline ( imapd_in ); <nl>  <nl> if ( kl ) {
static int carddav_put ( struct transaction_t * txn , void * obj , <nl> { <nl> struct carddav_db * db = ( struct carddav_db *) destdb ; <nl> struct vparse_card * vcard = ( struct vparse_card *) obj ; <nl> + <nl> + if (!( vcard && vcard -> objects && <nl> + vparse_restriction_check ( vcard -> objects ))) { <nl> + txn -> error . precond = CARDDAV_VALID_DATA ; <nl> + return HTTP_FORBIDDEN ; <nl> + } <nl> + <nl> return store_resource ( txn , vcard , mailbox , resource , db , /* dupcheck */ 1 ); <nl> } <nl> 
struct buf { <nl> }; <nl> # define BUF_INITIALIZER { NULL , 0 , 0 , 0 } <nl>  <nl> -# define buf_new () xzmalloc ( sizeof ( struct buf )) <nl> +# define buf_new () (( struct buf *) xzmalloc ( sizeof ( struct buf ))) <nl> # define buf_destroy ( b ) do { buf_free (( b )); free (( b )); } while ( 0 ) <nl> # define buf_ensure ( b , n ) do { if (( b )-> alloc < ( b )-> len + ( n )) _buf_ensure (( b ), ( n )); } while ( 0 ) <nl> # define buf_putc ( b , c ) do { buf_ensure (( b ), 1 ); ( b )-> s [( b )-> len ++] = ( c ); } while ( 0 )
static void remove_lockitem ( struct mboxlocklist * remitem ) <nl> previtem -> next = item -> next ; <nl> else <nl> open_mboxlocks = item -> next ; <nl> - if ( item -> l . lock_fd != - 1 ) <nl> + if ( item -> l . lock_fd != - 1 ) { <nl> + if ( item -> l . locktype ) <nl> + lock_unlock ( item -> l . lock_fd , item -> l . name ); <nl> close ( item -> l . lock_fd ); <nl> + } <nl> free ( item -> l . name ); <nl> free ( item ); <nl> return ;
struct apply_rock { <nl> void * data ; <nl> char lastname [ MAX_MAILBOX_PATH + 1 ]; <nl> int sawuser ; <nl> + unsigned int nseen ; <nl> }; <nl>  <nl> static int apply_cb ( char * name , int matchlen , <nl> static int apply_cb ( char * name , int matchlen , <nl> goto out ; <nl>  <nl> r = arock -> proc ( state , arock -> data ); <nl> + arock -> nseen ++; <nl>  <nl> out : <nl> annotate_state_unset_scope ( state ); <nl> int annotate_apply_mailboxes ( annotate_state_t * state , <nl> state -> auth_state , <nl> apply_cb , & arock ); <nl>  <nl> + if (! r && ! arock . nseen ) <nl> + r = IMAP_MAILBOX_NONEXISTENT ; <nl> + <nl> return r ; <nl> } <nl> 
EXPORTED int mboxlist_renamemailbox ( const char * oldname , const char * newname , <nl>  <nl> /* log the rename */ <nl> sync_log_mailbox_double ( oldname , newname ); <nl> + /* and log an append so that squatter indexes it */ <nl> + sync_log_append ( newname ); <nl> } <nl>  <nl> /* free memory */
MsgData ** index_msgdata_load ( struct index_state * state , <nl> if ( found_anchor && record . uid == anchor ) <nl> * found_anchor = 1 ; <nl>  <nl> + /* useful for convupdates */ <nl> + cur -> modseq = record . modseq ; <nl> + <nl> did_cache = did_env = did_conv = 0 ; <nl> tmpenv = NULL ; <nl> conv = NULL ; /* XXX : use a hash to avoid re - reading ? */
EXPORTED void seqset_add ( struct seqset * seq , unsigned num , int ismember ) <nl> { <nl> if (! seq ) return ; <nl>  <nl> + /* there are some cases where we want to make sure something is added <nl> + * as an initial value and then re - add it again later , so if we get <nl> + * the same number multiple times , that ' s OK */ <nl> + if ( ismember && num == seq -> prev && seq -> len && seq -> set [ seq -> len - 1 ]. high == num ) <nl> + return ; <nl> + <nl> if ( num <= seq -> prev ) <nl> fatal (" numbers out of order ", EC_SOFTWARE ); <nl> 
* OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE . <nl> */ <nl>  <nl> -/* $ Id : proxyd . c , v 1 . 39 2000 / 06 / 20 18 : 10 : 36 leg Exp $ */ <nl> +/* $ Id : proxyd . c , v 1 . 40 2000 / 07 / 03 20 : 16 : 09 leg Exp $ */ <nl>  <nl> # include < config . h > <nl>  <nl> void cmd_find ( char * tag , char * namespace , char * pattern ) <nl>  <nl> if (! strcmp ( namespace , " mailboxes ")) { <nl> mboxlist_findsub ( pattern , proxyd_userisadmin , proxyd_userid , <nl> - proxyd_authstate , mailboxdata , NULL ); <nl> + proxyd_authstate , mailboxdata , NULL , 1 ); <nl> } else if (! strcmp ( namespace , " all . mailboxes ")) { <nl> mboxlist_findall ( pattern , proxyd_userisadmin , proxyd_userid , <nl> proxyd_authstate , mailboxdata , NULL );
static struct partial_caldata_t { <nl> struct partial_comp_t * comp ; <nl> } partial_caldata ; <nl>  <nl> - static int is_busytime ( struct freebusy_filter * calfilter , icalcomponent * comp ); <nl> + static int is_busytime ( icalcomponent * comp ); <nl>  <nl> static int meth_options_cal ( struct transaction_t * txn , void * params ); <nl> static int meth_get_head_cal ( struct transaction_t * txn , void * params ); <nl> static int add_freebusy_comp ( icalcomponent * comp , <nl> struct icaltimetype recurid ; <nl> icalparameter_fbtype fbtype ; <nl>  <nl> - if (! is_busytime ( calfilter , comp )) return 1 ; <nl> + if (! is_busytime ( comp )) return 1 ; <nl>  <nl> /* Set start and end times */ <nl> start = icaltime_convert_to_zone ( start , utc_zone ); <nl> static int add_freebusy_comp ( icalcomponent * comp , <nl> } <nl>  <nl>  <nl> - static int is_busytime ( struct freebusy_filter * calfilter , icalcomponent * comp ) <nl> + static int is_busytime ( icalcomponent * comp ) <nl> { <nl> /* Check TRANSP and STATUS per RFC 4791 , section 7 . 10 */ <nl> const icalproperty * prop ;
-/* $ Id : acconfig . h , v 1 . 31 2002 / 03 / 18 15 : 14 : 16 ken3 Exp $ */ <nl> +/* $ Id : acconfig . h , v 1 . 32 2002 / 04 / 05 19 : 12 : 54 rjs3 Exp $ */ <nl> /* <nl> * Copyright ( c ) 2000 Carnegie Mellon University . All rights reserved . <nl> * <nl> typedef int rlim_t ; <nl>  <nl> /* getaddrinfo things */ <nl> # include < netdb . h > <nl> +# include < sys / types . h > <nl> # include < sys / socket . h > <nl>  <nl> # ifndef HAVE_GETADDRINFO
int clientsArePaused ( void ) { <nl> while (( ln = listNext (& li )) != NULL ) { <nl> c = listNodeValue ( ln ); <nl>  <nl> - if ( c -> flags & REDIS_SLAVE ) continue ; <nl> + if ( c -> flags & ( REDIS_SLAVE | REDIS_BLOCKED )) continue ; <nl> listAddNodeTail ( server . unblocked_clients , c ); <nl> } <nl> }
int sdsTest ( int argc , char * argv []) { <nl> unsigned int oldfree ; <nl>  <nl> sdsfree ( x ); <nl> + sdsfree ( y ); <nl> x = sdsnew (" 0 "); <nl> sh = ( void *) ( x -( sizeof ( struct sdshdr ))); <nl> test_cond (" sdsnew () free / len buffers ", sh -> len == 1 && sh -> free == 0 ); <nl> int sdsTest ( int argc , char * argv []) { <nl> test_cond (" sdsIncrLen () -- content ", x [ 0 ] == ' 0 ' && x [ 1 ] == ' 1 '); <nl> test_cond (" sdsIncrLen () -- len ", sh -> len == 2 ); <nl> test_cond (" sdsIncrLen () -- free ", sh -> free == oldfree - 1 ); <nl> + <nl> + sdsfree ( x ); <nl> } <nl> } <nl> test_report ()
static void repl ( void ) { <nl> } else { <nl> long long start_time = mstime (), elapsed ; <nl> int repeat , skipargs = 0 ; <nl> + char * endptr ; <nl>  <nl> - repeat = atoi ( argv [ 0 ]); <nl> - if ( argc > 1 && repeat ) { <nl> + repeat = strtol ( argv [ 0 ], & endptr , 10 ); <nl> + if ( argc > 1 && * endptr == '\ 0 ' && repeat ) { <nl> skipargs = 1 ; <nl> } else { <nl> repeat = 1 ;
void msetnxCommand ( redisClient * c ) { <nl> } <nl>  <nl> void incrDecrCommand ( redisClient * c , long long incr ) { <nl> - long long value ; <nl> + long long value , oldvalue ; <nl> robj * o ; <nl>  <nl> o = lookupKeyWrite ( c -> db , c -> argv [ 1 ]); <nl> if ( o != NULL && checkType ( c , o , REDIS_STRING )) return ; <nl> if ( getLongLongFromObjectOrReply ( c , o ,& value , NULL ) != REDIS_OK ) return ; <nl>  <nl> + oldvalue = value ; <nl> value += incr ; <nl> + if (( incr < 0 && value > oldvalue ) || ( incr > 0 && value < oldvalue )) { <nl> + addReplyError ( c ," increment or decrement would overflow "); <nl> + return ; <nl> + } <nl> o = createStringObjectFromLongLong ( value ); <nl> dbReplace ( c -> db , c -> argv [ 1 ], o ); <nl> touchWatchedKey ( c -> db , c -> argv [ 1 ]);
int luaRedisGenericCommand ( lua_State * lua , int raise_error ) { <nl> luaSortArray ( lua ); <nl> } <nl> sdsfree ( reply ); <nl> + c -> reply_bytes = 0 ; <nl>  <nl> cleanup : <nl> /* Clean up . Command code may have changed argv / argc so we use the
robj ** moduleCreateArgvFromUserFormat ( const char * cmdname , const char * fmt , int <nl> /* A vector of strings */ <nl> robj ** v = va_arg ( ap , void *); <nl> size_t vlen = va_arg ( ap , size_t ); <nl> - <nl> - /* We need to grow argv to hold the vector ' s elements . <nl> + <nl> + /* We need to grow argv to hold the vector ' s elements . <nl> * We resize by vector_len - 1 elements , because we held <nl> * one element in argv for the vector already */ <nl> - argv_size += vlen - 1 ; <nl> + argv_size += vlen - 1 ; <nl> argv = zrealloc ( argv , sizeof ( robj *)* argv_size ); <nl>  <nl> - size_t i = 0 ; <nl> + size_t i = 0 ; <nl> for ( i = 0 ; i < vlen ; i ++) { <nl> incrRefCount ( v [ i ]); <nl> argv [ argc ++] = v [ i ];
static int b_unpack ( lua_State * L ) { <nl> const char * fmt = luaL_checkstring ( L , 1 ); <nl> size_t ld ; <nl> const char * data = luaL_checklstring ( L , 2 , & ld ); <nl> - size_t pos = luaL_optinteger ( L , 3 , 1 ) - 1 ; <nl> + size_t pos = luaL_optinteger ( L , 3 , 1 ); <nl> + luaL_argcheck ( L , pos > 0 , 3 , " offset must be 1 or greater "); <nl> + pos --; /* Lua indexes are 1 - based , but here we want 0 - based for C <nl> + * pointer math . */ <nl> int n = 0 ; /* number of results */ <nl> defaultoptions (& h ); <nl> while (* fmt ) { <nl> int opt = * fmt ++; <nl> size_t size = optsize ( L , opt , & fmt ); <nl> pos += gettoalign ( pos , & h , opt , size ); <nl> - luaL_argcheck ( L , pos + size <= ld , 2 , " data string too short "); <nl> + luaL_argcheck ( L , size <= ld && pos <= ld - size , <nl> + 2 , " data string too short "); <nl> /* stack space for item + next position */ <nl> luaL_checkstack ( L , 2 , " too many results "); <nl> switch ( opt ) {
static int clusterManagerCommandImport ( int argc , char ** argv ) { <nl>  <nl> clusterManagerNode * refnode = clusterManagerNewNode ( ip , port ); <nl> if (! clusterManagerLoadInfoFromNode ( refnode , 0 )) return 0 ; <nl> + if (! clusterManagerCheckCluster ( 0 )) return 0 ; <nl> char * reply_err = NULL ; <nl> redisReply * src_reply = NULL ; <nl> // Connect to the source node .
REDIS_STATIC void * _quicklistSaver ( unsigned char * data , unsigned int sz ) { <nl> unsigned char * vstr ; <nl> if ( data ) { <nl> vstr = zmalloc ( sz ); <nl> - memcpy ( data , vstr , sz ); <nl> + memcpy ( vstr , data , sz ); <nl> return vstr ; <nl> } <nl> return NULL ;
static int read_header ( ShortenContext * s ) <nl> s -> channels = get_uint ( s , CHANSIZE ); <nl> if ( s -> channels <= 0 || s -> channels > MAX_CHANNELS ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " too many channels : % d \ n ", s -> channels ); <nl> + s -> channels = 0 ; <nl> return - 1 ; <nl> } <nl> s -> avctx -> channels = s -> channels ;
static av_cold int g726_init ( AVCodecContext * avctx ) <nl> AVG726Context * c = ( AVG726Context *) avctx -> priv_data ; <nl> unsigned int index = ( avctx -> bit_rate + avctx -> sample_rate / 2 ) / avctx -> sample_rate - 2 ; <nl>  <nl> - if ( avctx -> channels != 1 || <nl> + if ( <nl> ( avctx -> bit_rate != 16000 && avctx -> bit_rate != 24000 && <nl> avctx -> bit_rate != 32000 && avctx -> bit_rate != 40000 )) { <nl> av_log ( avctx , AV_LOG_ERROR , " G726 : unsupported audio format \ n "); <nl> static av_cold int g726_init ( AVCodecContext * avctx ) <nl> av_log ( avctx , AV_LOG_ERROR , " G726 : unsupported audio format \ n "); <nl> return - 1 ; <nl> } <nl> + if ( avctx -> channels != 1 ){ <nl> + av_log ( avctx , AV_LOG_ERROR , " Only mono is supported \ n "); <nl> + return - 1 ; <nl> + } <nl> if ( index > 3 ){ <nl> av_log ( avctx , AV_LOG_ERROR , " Unsupported number of bits % d \ n ", index + 2 ); <nl> return - 1 ;
static int tgv_decode_frame ( AVCodecContext * avctx , <nl> s -> width = AV_RL16 (& buf [ 0 ]); <nl> s -> height = AV_RL16 (& buf [ 2 ]); <nl> if ( s -> avctx -> width != s -> width || s -> avctx -> height != s -> height ) { <nl> - avcodec_set_dimensions ( s -> avctx , s -> width , s -> height ); <nl> av_freep (& s -> frame_buffer ); <nl> av_frame_unref (& s -> last_frame ); <nl> + if (( ret = ff_set_dimensions ( s -> avctx , s -> width , s -> height )) < 0 ) <nl> + return ret ; <nl> } <nl>  <nl> pal_count = AV_RL16 (& buf [ 6 ]); <nl> static int tgv_decode_frame ( AVCodecContext * avctx , <nl> } <nl> } <nl>  <nl> - if (( ret = av_image_check_size ( s -> width , s -> height , 0 , avctx )) < 0 ) <nl> - return ret ; <nl> - <nl> if (( ret = ff_get_buffer ( avctx , frame , AV_GET_BUFFER_FLAG_REF )) < 0 ) <nl> return ret ; <nl> 
static int svq1_decode_block_intra ( GetBitContext * bitbuf , uint8_t * pixels , <nl> continue ; /* skip vector */ <nl> } <nl>  <nl> - if ( stages > 0 && level >= 4 ) { <nl> + if (( stages > 0 && level >= 4 ) || stages < 0 ) { <nl> av_dlog ( NULL , <nl> " Error ( svq1_decode_block_intra ): invalid vector : stages =% i level =% i \ n ", <nl> stages , level ); <nl> static int svq1_decode_block_non_intra ( GetBitContext * bitbuf , uint8_t * pixels , <nl> if ( stages == - 1 ) <nl> continue ; /* skip vector */ <nl>  <nl> - if (( stages > 0 ) && ( level >= 4 )) { <nl> + if (( stages > 0 && level >= 4 ) || stages < 0 ) { <nl> av_dlog ( NULL , <nl> " Error ( svq1_decode_block_non_intra ): invalid vector : stages =% i level =% i \ n ", <nl> stages , level );
DECLARE_ALIGNED ( 16 , static const uint16_t , dither )[ 8 ][ 8 ] = { <nl> void ff_gradfun_filter_line_c ( uint8_t * dst , uint8_t * src , uint16_t * dc , int width , int thresh , const uint16_t * dithers ) <nl> { <nl> int x ; <nl> - for ( x = 0 ; x < width ; x ++, dc += x & 1 ) { <nl> + for ( x = 0 ; x < width ; dc += x & 1 , x ++) { <nl> int pix = src [ x ] << 7 ; <nl> int delta = dc [ 0 ] - pix ; <nl> int m = abs ( delta ) * thresh >> 16 ;
static int ape_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> if ( ape -> currentframe > ape -> totalframes ) <nl> return AVERROR ( EIO ); <nl>  <nl> - avio_seek ( s -> pb , ape -> frames [ ape -> currentframe ]. pos , SEEK_SET ); <nl> + if ( avio_seek ( s -> pb , ape -> frames [ ape -> currentframe ]. pos , SEEK_SET ) < 0 ) <nl> + return AVERROR ( EIO ); <nl>  <nl> /* Calculate how many blocks there are in this frame */ <nl> if ( ape -> currentframe == ( ape -> totalframes - 1 ))
SwsContext * sws_getContext ( int srcW , int srcH , enum PixelFormat srcFormat , <nl> c -> chrMmx2FilterCode = av_malloc ( c -> chrMmx2FilterCodeSize ); <nl> # endif <nl>  <nl> + if (! c -> lumMmx2FilterCode || ! c -> chrMmx2FilterCode ) <nl> + goto fail ; <nl> FF_ALLOCZ_OR_GOTO ( c , c -> hLumFilter , ( dstW / 8 + 8 )* sizeof ( int16_t ), fail ); <nl> FF_ALLOCZ_OR_GOTO ( c , c -> hChrFilter , ( c -> chrDstW / 4 + 8 )* sizeof ( int16_t ), fail ); <nl> FF_ALLOCZ_OR_GOTO ( c , c -> hLumFilterPos , ( dstW / 2 / 8 + 8 )* sizeof ( int32_t ), fail );
static int mov_write_ilst_tag ( AVIOContext * pb , MOVMuxContext * mov , <nl> mov_write_string_metadata ( s , pb , "\ 251wrt ", " composer " , 1 ); <nl> mov_write_string_metadata ( s , pb , "\ 251alb ", " album " , 1 ); <nl> mov_write_string_metadata ( s , pb , "\ 251day ", " date " , 1 ); <nl> - mov_write_string_tag ( pb , "\ 251too ", LIBAVFORMAT_IDENT , 0 , 1 ); <nl> + if (! mov_write_string_metadata ( s , pb , "\ 251too ", " encoding_tool ", 1 )) <nl> + mov_write_string_tag ( pb , "\ 251too ", LIBAVFORMAT_IDENT , 0 , 1 ); <nl> mov_write_string_metadata ( s , pb , "\ 251cmt ", " comment " , 1 ); <nl> mov_write_string_metadata ( s , pb , "\ 251gen ", " genre " , 1 ); <nl> mov_write_string_metadata ( s , pb , "\ 251cpy ", " copyright ", 1 );
static void estimate_timings_from_bit_rate ( AVFormatContext * ic ) <nl> for ( i = 0 ; i < ic -> nb_streams ; i ++) { <nl> st = ic -> streams [ i ]; <nl> if ( st -> codec -> bit_rate > 0 ) { <nl> - if ( INT_MAX - st -> codec -> bit_rate > bit_rate ) { <nl> + if ( INT_MAX - st -> codec -> bit_rate < bit_rate ) { <nl> bit_rate = 0 ; <nl> break ; <nl> }
static void blend_subrect ( AVPicture * dst , const AVSubtitleRect * rect , int imgw , <nl> lum [ 0 ] = ALPHA_BLEND ( a , lum [ 0 ], y , 0 ); <nl> cb [ 0 ] = ALPHA_BLEND ( a >> 2 , cb [ 0 ], u , 0 ); <nl> cr [ 0 ] = ALPHA_BLEND ( a >> 2 , cr [ 0 ], v , 0 ); <nl> + p ++; <nl> + lum ++; <nl> } <nl> p += wrap3 + ( wrap3 - dstw * BPP ); <nl> lum += wrap + ( wrap - dstw - dstx );
static int decode_slice_header ( H264Context * h , H264Context * h0 ){ <nl> h -> slice_type_nos = slice_type & 3 ; <nl>  <nl> s -> pict_type = h -> slice_type ; // to make a few old functions happy , it ' s wrong though <nl> - if ( s -> pict_type == FF_B_TYPE && s0 -> last_picture_ptr == NULL ) { <nl> - av_log ( h -> s . avctx , AV_LOG_ERROR , <nl> - " B picture before any references , skipping \ n "); <nl> - return - 1 ; <nl> - } <nl>  <nl> pps_id = get_ue_golomb (& s -> gb ); <nl> if ( pps_id >= MAX_PPS_COUNT ){
decode_intra_mb : <nl> sl -> intra4x4_pred_mode_cache [ scan8 [ i ]] = decode_cabac_mb_intra4x4_pred_mode ( sl , pred ); <nl>  <nl> ff_dlog ( h -> avctx , " i4x4 pred =% d mode =% d \ n ", pred , <nl> - h -> intra4x4_pred_mode_cache [ scan8 [ i ]]); <nl> + sl -> intra4x4_pred_mode_cache [ scan8 [ i ]]); <nl> } <nl> } <nl> write_back_intra_pred_mode ( h , sl );
static int set_channel_layout ( AVCodecContext * avctx , int channels , int num_core_ <nl> s -> channel_order_tab = ff_dca_channel_reorder_nolfe [ s -> amode ]; <nl> } <nl>  <nl> + if ( channels < ff_dca_channels [ s -> amode ]) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> if ( channels > !! s -> lfe && <nl> s -> channel_order_tab [ channels - 1 - !! s -> lfe ] < 0 ) <nl> return AVERROR_INVALIDDATA ;
static int encode_thread ( AVCodecContext * c , void * arg ){ <nl> if ( qp < s -> avctx -> qmin || qp > s -> avctx -> qmax ) <nl> break ; <nl> backup_s . dquant = dquant ; <nl> - if ( s -> mb_intra ){ <nl> + if ( s -> mb_intra && s -> dc_val [ 0 ]){ <nl> for ( i = 0 ; i < 6 ; i ++){ <nl> dc [ i ]= s -> dc_val [ 0 ][ s -> block_index [ i ] ]; <nl> memcpy ( ac [ i ], s -> ac_val [ 0 ][ s -> block_index [ i ]], sizeof ( DCTELEM )* 16 ); <nl> static int encode_thread ( AVCodecContext * c , void * arg ){ <nl> encode_mb_hq ( s , & backup_s , & best_s , CANDIDATE_MB_TYPE_INTER /* wrong but unused */, pb , pb2 , tex_pb , <nl> & dmin , & next_block , s -> mv [ mvdir ][ 0 ][ 0 ], s -> mv [ mvdir ][ 0 ][ 1 ]); <nl> if ( best_s . qscale != qp ){ <nl> - if ( s -> mb_intra ){ <nl> + if ( s -> mb_intra && s -> dc_val [ 0 ]){ <nl> for ( i = 0 ; i < 6 ; i ++){ <nl> s -> dc_val [ 0 ][ s -> block_index [ i ] ]= dc [ i ]; <nl> memcpy ( s -> ac_val [ 0 ][ s -> block_index [ i ]], ac [ i ], sizeof ( DCTELEM )* 16 );
static void rtcp_send_sr ( AVFormatContext * s1 , int64_t ntp_time ) <nl> s -> last_rtcp_ntp_time = ntp_time ; <nl> rtp_ts = av_rescale_q ( ntp_time - s -> first_rtcp_ntp_time , ( AVRational ){ 1 , 1000000 }, <nl> s1 -> streams [ 0 ]-> time_base ) + s -> base_timestamp ; <nl> - avio_w8 ( s1 -> pb , ( RTP_VERSION << 6 )); <nl> + avio_w8 ( s1 -> pb , RTP_VERSION << 6 ); <nl> avio_w8 ( s1 -> pb , RTCP_SR ); <nl> avio_wb16 ( s1 -> pb , 6 ); /* length in words - 1 */ <nl> avio_wb32 ( s1 -> pb , s -> ssrc ); <nl> void ff_rtp_send_data ( AVFormatContext * s1 , const uint8_t * buf1 , int len , int m ) <nl> av_dlog ( s1 , " rtp_send_data size =% d \ n ", len ); <nl>  <nl> /* build the RTP header */ <nl> - avio_w8 ( s1 -> pb , ( RTP_VERSION << 6 )); <nl> + avio_w8 ( s1 -> pb , RTP_VERSION << 6 ); <nl> avio_w8 ( s1 -> pb , ( s -> payload_type & 0x7f ) | (( m & 0x01 ) << 7 )); <nl> avio_wb16 ( s1 -> pb , s -> seq ); <nl> avio_wb32 ( s1 -> pb , s -> timestamp );
static void decode_frame ( SiprContext * ctx , SiprParameters * params , <nl> memcpy ( ctx -> postfilter_syn5k0 , ctx -> postfilter_syn5k0 + frame_size , <nl> LP_FILTER_ORDER * sizeof ( float )); <nl> } <nl> - memcpy ( ctx -> excitation , excitation - PITCH_DELAY_MAX - L_INTERPOL , <nl> + memmove ( ctx -> excitation , excitation - PITCH_DELAY_MAX - L_INTERPOL , <nl> ( PITCH_DELAY_MAX + L_INTERPOL ) * sizeof ( float )); <nl>  <nl> ff_acelp_apply_order_2_transfer_function ( out_data , synth ,
static int xa_read_packet ( AVFormatContext * s , <nl> unsigned int packet_size ; <nl> int ret ; <nl>  <nl> - if ( xa -> sent_bytes > xa -> out_size ) <nl> - return AVERROR ( EIO ); <nl> + if ( xa -> sent_bytes >= xa -> out_size ) <nl> + return AVERROR_EOF ; <nl> /* 1 byte header and 14 bytes worth of samples * number channels per block */ <nl> packet_size = 15 * st -> codec -> channels ; <nl> 
static av_cold int adpcm_encode_init ( AVCodecContext * avctx ) <nl> } <nl>  <nl> avctx -> coded_frame = avcodec_alloc_frame (); <nl> - avctx -> coded_frame -> key_frame = 1 ; <nl>  <nl> return 0 ; <nl> error :
static int matroska_probe ( AVProbeData * p ) <nl> * Not fully fool - proof , but good enough . */ <nl> for ( i = 0 ; i < FF_ARRAY_ELEMS ( matroska_doctypes ); i ++) { <nl> int probelen = strlen ( matroska_doctypes [ i ]); <nl> + if ( total < probelen ) <nl> + continue ; <nl> for ( n = 4 + size ; n <= 4 + size + total - probelen ; n ++) <nl> if (! memcmp ( p -> buf + n , matroska_doctypes [ i ], probelen )) <nl> return AVPROBE_SCORE_MAX ;
static int handle_file ( struct Tracks * tracks , const char * file , int split ) <nl> track -> bitrate = st -> codec -> bit_rate ; <nl> track -> track_id = st -> id ; <nl> track -> timescale = st -> time_base . den ; <nl> - track -> duration = av_rescale_rnd ( ctx -> duration , track -> timescale , <nl> - AV_TIME_BASE , AV_ROUND_UP ); <nl> + track -> duration = st -> duration ; <nl> track -> is_audio = st -> codec -> codec_type == AVMEDIA_TYPE_AUDIO ; <nl> track -> is_video = st -> codec -> codec_type == AVMEDIA_TYPE_VIDEO ; <nl> 
typedef struct AVPanScan { <nl> * - encoding : Set by libavcodec .\ <nl> * - decoding : Set by libavcodec .\ <nl> */\ <nl> - void * thread_opaque ; <nl> + void * thread_opaque ;\ <nl>  <nl> # define FF_QSCALE_TYPE_MPEG1 0 <nl> # define FF_QSCALE_TYPE_MPEG2 1
static int mov_read_stsd ( MOVContext * c , ByteIOContext * pb , MOVAtom atom ) <nl> # endif <nl> /* no ifdef since parameters are always those */ <nl> case CODEC_ID_QCELP : <nl> + // force sample rate for qcelp when not stored in mov <nl> + if ( st -> codec -> codec_tag != MKTAG (' Q ',' c ',' l ',' p ')) <nl> + st -> codec -> sample_rate = 8000 ; <nl> st -> codec -> frame_size = 160 ; <nl> st -> codec -> channels = 1 ; /* really needed */ <nl> break ;
static int http_connect ( URLContext * h , const char * path , const char * hoststr , <nl> int post , err , ch ; <nl> char line [ 1024 ], * q ; <nl> char * auth_b64 ; <nl> - int auth_b64_len = strlen ( auth )* 4 / 3 + 12 ; <nl> + int auth_b64_len = ( strlen ( auth ) + 2 ) / 3 * 4 + 1 ; <nl> int64_t off = s -> off ; <nl>  <nl> 
void mpeg4_encode_mb ( MpegEncContext * s , <nl> cbpy ^= 0xf ; <nl> put_bits ( pb2 , cbpy_tab [ cbpy ][ 1 ], cbpy_tab [ cbpy ][ 0 ]); <nl>  <nl> + if (! s -> progressive_sequence ){ <nl> + if ( cbp ) <nl> + put_bits ( pb2 , 1 , s -> interlaced_dct ); <nl> + } <nl> + <nl> if ( interleaved_stats ){ <nl> bits = get_bit_count (& s -> pb ); <nl> s -> misc_bits += bits - s -> last_bits ;
static int pva_read_packet ( AVFormatContext * s , AVPacket * pkt ) { <nl> flags = get_byte ( pb ); <nl> length = get_be16 ( pb ); <nl>  <nl> - pts_flag = ( flags & 0x10 ) >> 4 ; <nl> + pts_flag = flags & 0x10 ; <nl>  <nl> if ( syncword != PVA_MAGIC ) { <nl> av_log ( s , AV_LOG_ERROR , " invalid syncword \ n ");
static int vp9_handle_packet ( AVFormatContext * ctx , PayloadContext * rtp_vp9_ctx , <nl> return 0 ; <nl> } <nl>  <nl> + static void vp9_close_context ( PayloadContext * vp9 ) <nl> +{ <nl> + ffio_free_dyn_buf (& vp9 -> buf ); <nl> +} <nl> + <nl> RTPDynamicProtocolHandler ff_vp9_dynamic_handler = { <nl> . enc_name = " VP9 ", <nl> . codec_type = AVMEDIA_TYPE_VIDEO , <nl> . codec_id = AV_CODEC_ID_VP9 , <nl> . priv_data_size = sizeof ( PayloadContext ), <nl> . init = vp9_init , <nl> + . close = vp9_close_context , <nl> . parse_packet = vp9_handle_packet <nl> };
static int request_frame ( AVFilterLink * outlink ) <nl> avfilter_start_frame ( outlink , outpicref ); <nl> avfilter_draw_slice ( outlink , 0 , outlink -> h , 1 ); <nl> avfilter_end_frame ( outlink ); <nl> + avfilter_unref_buffer ( movie -> picref ); <nl> + movie -> picref = NULL ; <nl>  <nl> return 0 ; <nl> }
int ff_rv34_decode_frame ( AVCodecContext * avctx , <nl> break ; <nl> } <nl>  <nl> - if ( last ){ <nl> + if ( last && s -> current_picture_ptr ){ <nl> if ( r -> loop_filter ) <nl> r -> loop_filter ( r , s -> mb_height - 1 ); <nl> ff_er_frame_end ( s );
int main ( int argc , char ** argv ) <nl> audio_st = add_audio_stream ( oc , fmt -> audio_codec ); <nl> } <nl>  <nl> - av_dump_format ( oc , 0 , filename , 1 ); <nl> - <nl> /* now that all the parameters are set , we can open the audio and <nl> video codecs and allocate the necessary encode buffers */ <nl> if ( video_st ) <nl> int main ( int argc , char ** argv ) <nl> if ( audio_st ) <nl> open_audio ( oc , audio_st ); <nl>  <nl> + av_dump_format ( oc , 0 , filename , 1 ); <nl> + <nl> /* open the output file , if needed */ <nl> if (!( fmt -> flags & AVFMT_NOFILE )) { <nl> if ( avio_open (& oc -> pb , filename , AVIO_FLAG_WRITE ) < 0 ) {
static int filter_frame ( AVFilterLink * inlink , AVFrame * in ) <nl> direct = 1 ; <nl> out = in ; <nl> } else { <nl> + direct = 0 ; <nl> out = ff_get_video_buffer ( outlink , outlink -> w , outlink -> h ); <nl> if (! out ) { <nl> av_frame_free (& in );
static int a64_write_header ( AVFormatContext * s ) <nl> 0x00 , // charset_lifetime ( multi only ) <nl> 0x00 // fps in 50 / fps ; <nl> }; <nl> + <nl> + if ( avctx -> extradata_size < 4 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Missing extradata \ n "); <nl> + return AVERROR ( EINVAL ); <nl> + } <nl> + <nl> switch ( avctx -> codec -> id ) { <nl> case AV_CODEC_ID_A64_MULTI : <nl> header [ 2 ] = 0x00 ;
static void unpack_alpha ( GetBitContext * gb , uint16_t * dst , int num_coeffs , <nl> dst [ idx ++] = alpha_val >> 6 ; <nl> else <nl> dst [ idx ++] = ( alpha_val << 2 ) | ( alpha_val >> 6 ); <nl> - if ( idx == num_coeffs - 1 ) <nl> + if ( idx >= num_coeffs - 1 ) <nl> break ; <nl> } while ( get_bits1 ( gb )); <nl> val = get_bits ( gb , 4 );
static int ac3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , <nl>  <nl> /* decode the audio blocks */ <nl> channel_map = ff_ac3_dec_channel_map [ s -> output_mode & ~ AC3_OUTPUT_LFEON ][ s -> lfe_on ]; <nl> - for ( ch = 0 ; ch < s -> out_channels ; ch ++) <nl> - output [ ch ] = s -> output [ channel_map [ ch ]]; <nl> + for ( ch = 0 ; ch < s -> out_channels ; ch ++) <nl> + output [ ch ] = s -> output [ channel_map [ ch ]]; <nl> for ( blk = 0 ; blk < s -> num_blocks ; blk ++) { <nl> if (! err && decode_audio_block ( s , blk )) { <nl> av_log ( avctx , AV_LOG_ERROR , " error decoding the audio block \ n ");
static int libopenjpeg_decode_frame ( AVCodecContext * avctx , <nl> adjust [ x ] = FFMAX ( image -> comps [ x ]. prec - 8 , 0 ); <nl> } <nl>  <nl> - for ( y = 0 ; y < height ; y ++) { <nl> - index = y * width ; <nl> + for ( y = 0 ; y < avctx -> height ; y ++) { <nl> + index = y * avctx -> width ; <nl> img_ptr = picture -> data [ 0 ] + y * picture -> linesize [ 0 ]; <nl> - for ( x = 0 ; x < width ; x ++, index ++) { <nl> + for ( x = 0 ; x < avctx -> width ; x ++, index ++) { <nl> * img_ptr ++ = image -> comps [ 0 ]. data [ index ] >> adjust [ 0 ]; <nl> if ( image -> numcomps > 2 && check_image_attributes ( image )) { <nl> * img_ptr ++ = image -> comps [ 1 ]. data [ index ] >> adjust [ 1 ];
static int decode_frame ( AVCodecContext * avctx , void * data , <nl> av_log ( f -> avctx , AV_LOG_ERROR , " cframe id mismatch % d % d \ n ", <nl> id , avctx -> frame_number ); <nl>  <nl> + if ( f -> version <= 1 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> cfrm -> size = cfrm -> id = 0 ; <nl> frame_4cc = AV_RL32 (" pfrm "); <nl> } else
 <nl> # include " config . h " <nl> # include " libavformat / avformat . h " <nl> -# include < unistd . h > <nl> -# include < fcntl . h > <nl> -# include < sys / ioctl . h > <nl> -# include < sys / time . h > <nl> -# define _LINUX_TIME_H 1 <nl> # include < time . h > <nl> # include < X11 / X . h > <nl> # include < X11 / Xlib . h > <nl> # include < X11 / Xlibint . h > <nl> # include < X11 / Xproto . h > <nl> # include < X11 / Xutil . h > <nl> -# include < sys / ipc . h > <nl> # include < sys / shm . h > <nl> # include < X11 / extensions / XShm . h > <nl> 
static const int tc0_table [ 52 * 3 ][ 3 ] = { <nl>  <nl> /* Cabac pre state table */ <nl>  <nl> - static const int cabac_context_init_I [ 460 ][ 2 ] = <nl> + static const int8_t cabac_context_init_I [ 460 ][ 2 ] = <nl> { <nl> /* 0 - 10 */ <nl> { 20 , - 15 }, { 2 , 54 }, { 3 , 74 }, { 20 , - 15 }, <nl> static const int cabac_context_init_I [ 460 ][ 2 ] = <nl> { 29 , 9 }, { 35 , 20 }, { 29 , 36 }, { 14 , 67 } <nl> }; <nl>  <nl> - static const int cabac_context_init_PB [ 3 ][ 460 ][ 2 ] = <nl> + static const int8_t cabac_context_init_PB [ 3 ][ 460 ][ 2 ] = <nl> { <nl> /* i_cabac_init_idc == 0 */ <nl> {
typedef struct HLSContext { <nl> int has_video ; <nl> int64_t start_pts ; <nl> int64_t end_pts ; <nl> + int nb_entries ; <nl> ListEntry * list ; <nl> ListEntry * end_list ; <nl> char * basename ; <nl> static int append_entry ( HLSContext * hls , uint64_t duration ) <nl>  <nl> hls -> end_list = en ; <nl>  <nl> - if ( hls -> number >= hls -> size ) { <nl> + if ( hls -> nb_entries >= hls -> size ) { <nl> en = hls -> list ; <nl> hls -> list = en -> next ; <nl> av_free ( en ); <nl> - } <nl> + } else <nl> + hls -> nb_entries ++; <nl>  <nl> return 0 ; <nl> }
static void sbr_make_f_tablelim ( SpectralBandReplication * sbr ) <nl> 1 . 18509277094158210129f , // 2 ^( 0 . 49 / 2 ) <nl> 1 . 11987160404675912501f }; // 2 ^( 0 . 49 / 3 ) <nl> const float lim_bands_per_octave_warped = bands_warped [ sbr -> bs_limiter_bands - 1 ]; <nl> - int16_t patch_borders [ 5 ]; <nl> + int16_t patch_borders [ 7 ]; <nl> uint16_t * in = sbr -> f_tablelim + 1 , * out = sbr -> f_tablelim ; <nl>  <nl> patch_borders [ 0 ] = sbr -> kx [ 1 ];
static int sol_read_packet ( AVFormatContext * s , <nl> if ( s -> pb -> eof_reached ) <nl> return AVERROR ( EIO ); <nl> ret = av_get_packet ( s -> pb , pkt , MAX_SIZE ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> pkt -> stream_index = 0 ; <nl>  <nl> /* note : we need to modify the packet size here to handle the last
static int config_input ( AVFilterLink * inlink ) <nl> PadContext * pad = ctx -> priv ; <nl> const AVPixFmtDescriptor * pix_desc = & av_pix_fmt_descriptors [ inlink -> format ]; <nl> uint8_t rgba_color [ 4 ]; <nl> - uint8_t rgba_map [ 4 ]; <nl> + uint8_t rgba_map [ 4 ] = { 0 }; <nl> int i , is_packed_rgb = 1 ; <nl>  <nl> switch ( inlink -> format ) {
static int decode_vol_header ( MpegEncContext * s , GetBitContext * gb ){ <nl>  <nl> s -> progressive_sequence = <nl> s -> progressive_frame = get_bits1 ( gb )^ 1 ; <nl> + s -> interlaced_dct = 0 ; <nl> if (! get_bits1 ( gb ) && ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )) <nl> av_log ( s -> avctx , AV_LOG_INFO , " MPEG4 OBMC not supported ( very likely buggy encoder )\ n "); /* OBMC Disable */ <nl> if ( vo_ver_id == 1 ) {
static int bit_alloc ( AC3EncodeContext * s , <nl> mant_cnt [ 1 ] = mant_cnt [ 2 ] = 2 ; <nl> mant_cnt [ 4 ] = 1 ; <nl> for ( ch = 0 ; ch < s -> channels ; ch ++) { <nl> + /* Currently the only bit allocation parameters which vary across <nl> + blocks within a frame are the exponent values . We can take <nl> + advantage of that by reusing the bit allocation pointers <nl> + whenever we reuse exponents . */ <nl> + if ( block -> exp_strategy [ ch ] == EXP_REUSE ) { <nl> + memcpy ( block -> bap [ ch ], s -> blocks [ blk - 1 ]. bap [ ch ], AC3_MAX_COEFS ); <nl> + } else { <nl> ff_ac3_bit_alloc_calc_bap ( block -> mask [ ch ], block -> psd [ ch ], 0 , <nl> s -> nb_coefs [ ch ], snr_offset , <nl> s -> bit_alloc . floor , ff_ac3_bap_tab , <nl> block -> bap [ ch ]); <nl> + } <nl> mantissa_bits += compute_mantissa_size ( mant_cnt , block -> bap [ ch ], s -> nb_coefs [ ch ]); <nl> } <nl> mantissa_bits += compute_mantissa_size_final ( mant_cnt );
static void do_output_subblock ( Real144_internal * glob , <nl> if ( a ) { <nl> a += HALFBLOCK - 1 ; <nl> rotate_block ( glob -> buffer_2 , buffer_a , a ); <nl> + m [ 0 ] = irms ( buffer_a , gval ) >> 12 ; <nl> + } else { <nl> + m [ 0 ] = 0 ; <nl> } <nl>  <nl> m [ 1 ] = (( ftable1 [ b ] >> 4 ) * gval ) >> 8 ; <nl> m [ 2 ] = (( ftable2 [ c ] >> 4 ) * gval ) >> 8 ; <nl>  <nl> - if ( a ) <nl> - m [ 0 ] = irms ( buffer_a , gval ) >> 12 ; <nl> - else <nl> - m [ 0 ] = 0 ; <nl> - <nl> memmove ( glob -> buffer_2 , glob -> buffer_2 + BLOCKSIZE , <nl> ( BUFFERSIZE - BLOCKSIZE ) * 2 ); <nl> 
static int wav_read_header ( AVFormatContext * s , <nl> avio_rl64 ( pb ); /* RIFF size */ <nl> data_size = avio_rl64 ( pb ); <nl> sample_count = avio_rl64 ( pb ); <nl> + if ( data_size < 0 || sample_count < 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " negative data_size and / or sample_count in " <nl> + " ds64 : data_size = %" PRId64 ", sample_count = %" PRId64 "\ n ", <nl> + data_size , sample_count ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> avio_skip ( pb , size - 16 ); /* skip rest of ds64 chunk */ <nl> } <nl> 
static int matroska_parse_tracks ( AVFormatContext * s ) <nl> track -> video . fourcc = AV_RL32 ( track -> codec_priv . data ); <nl> codec_id = ff_codec_get_id ( ff_codec_movvideo_tags , <nl> track -> video . fourcc ); <nl> + if ( codec_id == AV_CODEC_ID_NONE ) { <nl> + char buf [ 32 ]; <nl> + av_get_codec_tag_string ( buf , sizeof ( buf ), track -> video . fourcc ); <nl> + av_log ( matroska -> ctx , AV_LOG_ERROR , <nl> + " mov FourCC not found % s .\ n ", buf ); <nl> + } <nl> } else if ( codec_id == AV_CODEC_ID_PCM_S16BE ) { <nl> switch ( track -> audio . bitdepth ) { <nl> case 8 :
static int ac3_parse_audio_block ( AC3DecodeContext * ctx ) <nl> for ( i = 0 ; i < 5 ; i ++) <nl> ctx -> chcoeffs [ i ] = 2 . 0 ; <nl>  <nl> + ctx -> blksw = 0 ; <nl> for ( i = 0 ; i < nfchans ; i ++) /* block switch flag */ <nl> ctx -> blksw |= get_bits1 ( gb ) << i ; <nl>  <nl> + ctx -> dithflag = 0 ; <nl> for ( i = 0 ; i < nfchans ; i ++) /* dithering flag */ <nl> ctx -> dithflag |= get_bits1 ( gb ) << i ; <nl>  <nl> static int ac3_parse_audio_block ( AC3DecodeContext * ctx ) <nl> dump_floats (" channel transform coefficients ", 10 , ctx -> transform_coeffs [ i + 1 ], BLOCK_SIZE );*/ <nl>  <nl> /* recover coefficients if rematrixing is in use */ <nl> - if ( ctx -> rematstr ) <nl> + if ( ctx -> rematflg ) <nl> do_rematrixing ( ctx ); <nl>  <nl> do_imdct ( ctx );
static int cbs_h2645_write_nal_unit ( CodedBitstreamContext * ctx , <nl> // Overflow but we didn ' t notice . <nl> av_assert0 ( put_bits_count (& pbc ) <= 8 * priv -> write_buffer_size ); <nl>  <nl> + if ( err < 0 ) { <nl> + // Write failed for some other reason . <nl> + return err ; <nl> + } <nl> + <nl> if ( put_bits_count (& pbc ) % 8 ) <nl> unit -> data_bit_padding = 8 - put_bits_count (& pbc ) % 8 ; <nl> else
static int rpza_decode_frame ( AVCodecContext * avctx , <nl> s -> buf = buf ; <nl> s -> size = buf_size ; <nl>  <nl> + s -> frame . reference = 1 ; <nl> if ( avctx -> get_buffer ( avctx , & s -> frame )) { <nl> printf (" RPZA Video : get_buffer () failed \ n "); <nl> return - 1 ;
static int mpeg_decode_slice ( Mpeg1Context * s1 , int mb_y , <nl> s -> resync_mb_x = <nl> s -> resync_mb_y = - 1 ; <nl>  <nl> - if ( mb_y >= s -> mb_height ){ <nl> - av_log ( s -> avctx , AV_LOG_ERROR , " slice below image (% d >= % d )\ n ", mb_y , s -> mb_height ); <nl> - return - 1 ; <nl> - } <nl> + assert ( mb_y < s -> mb_height ); <nl>  <nl> init_get_bits (& s -> gb , * buf , buf_size * 8 ); <nl>  <nl> static int decode_chunks ( AVCodecContext * avctx , <nl> if ( s2 -> picture_structure == PICT_BOTTOM_FIELD ) <nl> mb_y ++; <nl>  <nl> + if ( mb_y >= s2 -> mb_height ){ <nl> + av_log ( s2 -> avctx , AV_LOG_ERROR , " slice below image (% d >= % d )\ n ", mb_y , s2 -> mb_height ); <nl> + return - 1 ; <nl> + } <nl> + <nl> if ( s2 -> last_picture_ptr == NULL ){ <nl> /* Skip B - frames if we do not have reference frames and gop is not closed */ <nl> if ( s2 -> pict_type == FF_B_TYPE ){
bool zmq :: session_t :: read (:: zmq_msg_t * msg_ ) <nl>  <nl> bool zmq :: session_t :: write (:: zmq_msg_t * msg_ ) <nl> { <nl> - if ( out_pipe -> write ( msg_ )) { <nl> + if ( out_pipe && out_pipe -> write ( msg_ )) { <nl> zmq_msg_init ( msg_ ); <nl> return true ; <nl> }
_enable_carbons_handler ( xmpp_conn_t * const conn , xmpp_stanza_t * const stanza , <nl> char * error_message = stanza_get_error_message ( stanza ); <nl> cons_show_error (" Server error enabling message carbons : % s ", error_message ); <nl> log_debug (" Error enabling carbons : % s ", error_message ); <nl> + free ( error_message ); <nl> } else { <nl> log_debug (" Message carbons enabled ."); <nl> } <nl> _disable_carbons_handler ( xmpp_conn_t * const conn , xmpp_stanza_t * const stanza , <nl> char * error_message = stanza_get_error_message ( stanza ); <nl> cons_show_error (" Server error disabling message carbons : % s ", error_message ); <nl> log_debug (" Error disabling carbons : % s ", error_message ); <nl> + free ( error_message ); <nl> } else { <nl> log_debug (" Message carbons disabled ."); <nl> }
# include < contact . h > <nl>  <nl> typedef struct _muc_room_t { <nl> - char * jid ; <nl> + char * room ; <nl> char * nick ; <nl> GHashTable * roster ; <nl> gboolean roster_received ; <nl> room_join ( const char * const jid , const char * const nick ) <nl> } <nl>  <nl> muc_room * new_room = malloc ( sizeof ( muc_room )); <nl> - new_room -> jid = strdup ( jid ); <nl> + new_room -> room = strdup ( jid ); <nl> new_room -> nick = strdup ( nick ); <nl> new_room -> roster = g_hash_table_new_full ( g_str_hash , g_str_equal , g_free , <nl> ( GDestroyNotify ) p_contact_free ); <nl> static void <nl> _room_free ( muc_room * room ) <nl> { <nl> if ( room != NULL ) { <nl> - if ( room -> jid != NULL ) { <nl> - g_free ( room -> jid ); <nl> - room -> jid = NULL ; <nl> + if ( room -> room != NULL ) { <nl> + g_free ( room -> room ); <nl> + room -> room = NULL ; <nl> } <nl> if ( room -> nick != NULL ) { <nl> g_free ( room -> nick );
static int eapmschapv2_compose ( EAP_HANDLER * handler , VALUE_PAIR * reply ) <nl> DEBUG2 (" MSCHAP Success \ n "); <nl> length = 46 ; <nl> eap_ds -> request -> type . data = malloc ( length ); <nl> - memset ( eap_ds -> request -> type . data , 0 , length ); <nl> /* <nl> * Allocate room for the EAP - MS - CHAPv2 data . <nl> */ <nl> static int eapmschapv2_compose ( EAP_HANDLER * handler , VALUE_PAIR * reply ) <nl> radlog ( L_ERR , " rlm_eap_mschapv2 : out of memory "); <nl> return 0 ; <nl> } <nl> + memset ( eap_ds -> request -> type . data , 0 , length ); <nl> eap_ds -> request -> type . length = length ; <nl>  <nl> eap_ds -> request -> type . data [ 0 ] = PW_EAP_MSCHAPV2_SUCCESS ; <nl> static int eapmschapv2_compose ( EAP_HANDLER * handler , VALUE_PAIR * reply ) <nl> DEBUG2 (" MSCHAP Failure \ n "); <nl> length = 4 + MSCHAPV2_FAILURE_MESSAGE_LEN ; <nl> eap_ds -> request -> type . data = malloc ( length ); <nl> - memset ( eap_ds -> request -> type . data , 0 , length ); <nl>  <nl> /* <nl> * Allocate room for the EAP - MS - CHAPv2 data . <nl> static int eapmschapv2_compose ( EAP_HANDLER * handler , VALUE_PAIR * reply ) <nl> radlog ( L_ERR , " rlm_eap_mschapv2 : out of memory "); <nl> return 0 ; <nl> } <nl> + memset ( eap_ds -> request -> type . data , 0 , length ); <nl> eap_ds -> request -> type . length = length ; <nl>  <nl> eap_ds -> request -> type . data [ 0 ] = PW_EAP_MSCHAPV2_FAILURE ;
static int sql_init_socket ( SQLSOCK * sqlsocket , SQL_CONFIG * config ) { <nl> pg_sock -> result = NULL ; <nl> pg_sock -> conn = PQconnectdb ( connstring ); <nl>  <nl> - if ( PQstatus ( sqlsocket -> conn ) == CONNECTION_BAD ) { <nl> + if ( PQstatus ( pg_sock -> conn ) == CONNECTION_BAD ) { <nl> radlog ( L_ERR , " rlm_sql_postgresql : Couldn ' t connect socket to PostgreSQL server % s @% s :% s ", config -> sql_login , config -> sql_server , config -> sql_db ); <nl> radlog ( L_ERR , " rlm_sql_postgresql : Postgresql error '% s '", PQerrorMessage ( pg_sock -> conn )); <nl> PQfinish ( pg_sock -> conn );
static int perl_instantiate ( CONF_SECTION * conf , void ** instance ) <nl> * fail . <nl> */ <nl> if ( cf_section_parse ( conf , inst , module_config ) < 0 ) { <nl> + free ( embed ); <nl> free ( inst ); <nl> return - 1 ; <nl> } <nl> static int perl_instantiate ( CONF_SECTION * conf , void ** instance ) <nl> # ifdef USE_ITHREADS <nl> if (( inst -> perl = perl_alloc ()) == NULL ) { <nl> radlog ( L_DBG , " rlm_perl : No memory for allocating new perl !"); <nl> + free ( embed ); <nl> + free ( inst ); <nl> return (- 1 ); <nl> } <nl>  <nl> static int perl_instantiate ( CONF_SECTION * conf , void ** instance ) <nl> # else <nl> if (( inst -> perl = perl_alloc ()) == NULL ) { <nl> radlog ( L_ERR , " rlm_perl : No memory for allocating new perl !"); <nl> + free ( embed ); <nl> + free ( inst ); <nl> return - 1 ; <nl> } <nl>  <nl> static int perl_instantiate ( CONF_SECTION * conf , void ** instance ) <nl> exitstatus = perl_run ( inst -> perl ); <nl> } else { <nl> radlog ( L_ERR ," rlm_perl : perl_parse failed : % s not found or has syntax errors . \ n ", inst -> module ); <nl> + free ( embed ); <nl> + free ( inst ); <nl> return (- 1 ); <nl> } <nl> 
VALUE_PAIR * pairparsevalue ( VALUE_PAIR * vp , const char * value ) <nl> c = '\''; <nl> cp ++; <nl> break ; <nl> + case '\\': <nl> + c = '\\'; <nl> + cp ++; <nl> + break ; <nl> case '`': <nl> c = '`'; <nl> cp ++;
static int ippool_postauth ( void * instance , REQUEST * request ) <nl> return RLM_MODULE_NOOP ; <nl> } <nl> vp -> lvalue = entry . ipaddr ; <nl> + ip_ntoa ( vp -> strvalue , vp -> lvalue ); <nl> pairadd (& request -> reply -> vps , vp ); <nl> } <nl> else {
static int sql_query ( SQLSOCK * sqlsocket , SQL_CONFIG * config , char * querystr ) { <nl> } <nl>  <nl> pg_sock -> result = PQexec ( pg_sock -> conn , querystr ); <nl> - /* Returns a PGresult pointer or possibly a NULL pointer . <nl> + /* Returns a result pointer or possibly a NULL pointer . <nl> * A non - NULL pointer will generally be returned except in <nl> * out - of - memory conditions or serious errors such as inability <nl> * to send the command to the backend . If a NULL is returned , <nl> static int sql_store_result ( SQLSOCK * sqlsocket , SQL_CONFIG * config ) { <nl> *************************************************************************/ <nl> static int sql_destroy_socket ( SQLSOCK * sqlsocket , SQL_CONFIG * config ) <nl> { <nl> + rlm_sql_postgres_sock * pg_sock = sqlsocket -> conn ; <nl>  <nl> - /* <nl> - * FIXME : Someone write the Postgres specific disconnect <nl> - * and free code !! <nl> - */ <nl> + free ( pg_sock ); <nl> return 0 ; <nl> } <nl> 
static int proxy_to_virtual_server ( REQUEST * request ) <nl>  <nl> } else { <nl> RDEBUG2 (" Unknown packet type % d ", request -> proxy -> code ); <nl> + request_free (& fake ); <nl> return 0 ; <nl> } <nl> 
static int ippool_postauth ( void * instance , REQUEST * request ) <nl> { <nl> /* Override supplied Framed - IP - Address */ <nl> RDEBUG (" override is set to yes . Override the existing Framed - IP - Address attribute ."); <nl> - pairdelete (& request -> reply -> vps , PW_FRAMED_IP_ADDRESS ); <nl> + pairdelete (& request -> reply -> vps , PW_FRAMED_IP_ADDRESS , 0 ); <nl> } else { <nl> /* Abort */ <nl> RDEBUG (" override is set to no . Return NOOP ."); <nl> static int ippool_postauth ( void * instance , REQUEST * request ) <nl>  <nl> RDEBUG (" Allocated ip % s to client key : % s ", ip_ntoa ( str , entry . ipaddr ), hex_str ); <nl> vp = radius_paircreate ( request , & request -> reply -> vps , <nl> - PW_FRAMED_IP_ADDRESS , PW_TYPE_IPADDR ); <nl> + PW_FRAMED_IP_ADDRESS , 0 , PW_TYPE_IPADDR ); <nl> vp -> vp_ipaddr = entry . ipaddr ; <nl>  <nl> /* <nl> static int ippool_postauth ( void * instance , REQUEST * request ) <nl> */ <nl> if ( pairfind ( request -> reply -> vps , PW_FRAMED_IP_NETMASK , 0 ) == NULL ) { <nl> vp = radius_paircreate ( request , & request -> reply -> vps , <nl> - PW_FRAMED_IP_NETMASK , <nl> + PW_FRAMED_IP_NETMASK , 0 , <nl> PW_TYPE_IPADDR ); <nl> vp -> vp_ipaddr = ntohl ( data -> netmask ); <nl> }
int jabber_si_handle_request ( struct im_connection * ic , struct xt_node * node , st <nl> requestok = FALSE ; <nl> } <nl>  <nl> - * s = '/'; <nl> + if ( s ) <nl> + * s = '/'; <nl> } <nl> - else <nl> + <nl> + if ( ! requestok ) <nl> { <nl> reply = jabber_make_error_packet ( node , " item - not - found ", " cancel ", NULL ); <nl> if (! jabber_write_packet ( ic , reply ))
static void register_mibs ( void ) { <nl> hf_register_info hf ; <nl>  <nl> hf . p_id = &( oid_data -> value_hfid ); <nl> - hf . hfinfo . name = oid_data -> name ; <nl> + hf . hfinfo . name = g_strdup ( oid_data -> name ); <nl> hf . hfinfo . abbrev = alnumerize ( oid_data -> name ); <nl> hf . hfinfo . type = typedata -> ft_type ; <nl> hf . hfinfo . display = typedata -> display ;
dissect_infiniband ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_transport_header_version , tvb , offset , 1 , FALSE ); offset += 1 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_partition_key , tvb , offset , 2 , FALSE ); offset += 2 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_reserved8 , tvb , offset , 1 , FALSE ); offset += 1 ; <nl> - proto_tree_add_item ( base_transport_header_tree , hf_infiniband_destination_qp , tvb , offset , 3 , FALSE ); offset += 3 ; <nl> + proto_tree_add_item ( base_transport_header_tree , hf_infiniband_destination_qp , tvb , offset , 3 , FALSE ); <nl> + dst_qp = tvb_get_ntoh24 ( tvb , offset ); offset += 3 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_acknowledge_request , tvb , offset , 1 , FALSE ); <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_reserved7 , tvb , offset , 1 , FALSE ); offset += 1 ; <nl> proto_tree_add_item ( base_transport_header_tree , hf_infiniband_packet_sequence_number , tvb , offset , 3 , FALSE ); offset += 3 ;
proto_reg_handoff_e100 ( void ) <nl> /* Check all UDP traffic , as the specific UDP port is configurable */ <nl> heur_dissector_add (" udp ", dissect_e100 , " E100 over UDP ", " e100_udp ", proto_e100 , HEURISTIC_ENABLE ); <nl> /* e100 traffic encapsulates traffic from the ethernet frame on */ <nl> - eth_handle = find_dissector (" eth "); <nl> + eth_handle = find_dissector (" eth_withoutfcs "); <nl> } <nl>  <nl> /*
static int <nl> dissect_dnp3_al ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> { <nl> guint8 al_ctl , al_seq , al_func , al_class = 0 , i ; <nl> - guint16 bytes , obj_type ; <nl> + guint16 bytes , obj_type = 0 ; <nl> guint data_len = 0 , offset = 0 ; <nl> proto_item * ti , * tc , * t_robj ; <nl> proto_tree * al_tree , * field_tree , * robj_tree ;
static void dissect_mqpcf ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , m <nl>  <nl> static gboolean dissect_mqpcf_heur ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data ) <nl> { <nl> - if ( tvb_length ( tvb ) >= 36 ) <nl> + if ( data && tvb_length ( tvb ) >= 36 ) <nl> { <nl> mq_parm_t * p_mq_parm = ( mq_parm_t *) data ; <nl> if ( strncmp (( const char *) p_mq_parm -> mq_format , MQ_MQFMT_ADMIN , 8 ) == 0
/* file . c <nl> * File I / O routines <nl> * <nl> - * $ Id : file . c , v 1 . 59 1999 / 08 / 10 04 : 13 : 36 guy Exp $ <nl> + * $ Id : file . c , v 1 . 60 1999 / 08 / 10 06 : 54 : 12 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> wtap_dispatch_cb ( u_char * user , const struct wtap_pkthdr * phdr , int offset , <nl> /* Allocate the next list entry , and add it to the list . */ <nl> fdata = ( frame_data *) g_malloc ( sizeof ( frame_data )); <nl>  <nl> + fdata -> next = NULL ; <nl> fdata -> pkt_len = phdr -> len ; <nl> fdata -> cap_len = phdr -> caplen ; <nl> fdata -> file_off = offset ;
static void * mqtt_message_decode_copy_cb ( void * dest , const void * orig , size_t le <nl> const mqtt_message_decode_t * o = ( const mqtt_message_decode_t *) orig ; <nl> mqtt_message_decode_t * d = ( mqtt_message_decode_t *) dest ; <nl>  <nl> + d -> match_criteria = o -> match_criteria ; <nl> d -> topic_pattern = g_strdup ( o -> topic_pattern ); <nl> d -> payload_proto_name = g_strdup ( o -> payload_proto_name ); <nl> 
color_global_cb ( GtkWidget * widget _U_ , gpointer data ) <nl>  <nl> gtk_file_chooser_select_filename ( GTK_FILE_CHOOSER ( fs_widget ), path ); <nl>  <nl> - g_free (( gchar *) path ); <nl> + g_free ( path ); <nl> } <nl>  <nl> /* Import color filters */
dissect_data_chunk ( tvbuff_t * chunk_tvb , <nl> */ <nl> if ( b_bit ) <nl> { <nl> - gboolean retval ; <nl> + gboolean retval = FALSE ; <nl>  <nl> /* <nl> * If this particular fragment happens to get a ReportedBoundsError
sync_pipe_start ( capture_options * capture_opts ) { <nl> execv ( argv [ 0 ], ( gpointer ) argv ); <nl> g_snprintf ( errmsg , sizeof errmsg , " Couldn ' t run % s in child process : % s ", <nl> argv [ 0 ], strerror ( errno )); <nl> - sync_pipe_errmsg_to_parent ( errmsg , ""); <nl> + sync_pipe_errmsg_to_parent ( 1 , errmsg , ""); <nl>  <nl> /* Exit with " _exit ()", so that we don ' t close the connection <nl> to the X server ( and cause stuff buffered up by our parent but <nl> sync_interface_stats_open ( int * read_fd , int * fork_child , gchar ** msg ) { <nl>  <nl> /* Close down the stats process */ <nl> int <nl> - sync_interface_stats_close ( int * read_fd , int * fork_child , gchar ** msg ) { <nl> + sync_interface_stats_close ( int * read_fd , int * fork_child <nl> +# ifndef _WIN32 <nl> + _U_ <nl> +# endif <nl> +, gchar ** msg ) { <nl> # ifdef _WIN32 <nl> return sync_pipe_close_command ( read_fd , fork_child , msg ); <nl> # else
capture_loop_dispatch ( capture_options * capture_opts _U_ , loop_data * ld , <nl> inpkts = pcap_dispatch ( ld -> pcap_h , 1 , capture_loop_packet_cb , <nl> ( u_char *) ld ); <nl> if ( inpkts < 0 ) { <nl> - ld -> pcap_err = TRUE ; <nl> + if ( inpkts == - 1 ) { <nl> + /* Error , rather than pcap_breakloop (). */ <nl> + ld -> pcap_err = TRUE ; <nl> + } <nl> ld -> go = FALSE ; /* error or pcap_breakloop () - stop capturing */ <nl> } <nl> } else {
fp_set_per_packet_inf_from_conv ( umts_fp_conversation_info_t * p_conv_data , <nl>  <nl> /* Peek at C / T , different RLC params for different logical channels */ <nl> /* C / T is 4 bits according to 3GPP TS 25 . 321 , paragraph 9 . 2 . 1 , from MAC header ( not FP )*/ <nl> - c_t = tvb_get_bits8 ( tvb , tb_bit_off /*( 2 + p_conv_data -> num_dch_in_flow )* 8 */, 4 ); /* c_t = tvb_get_guint8 ( tvb , offset );*/ <nl> - macinf -> lchid [ j + chan ] = c_t + 1 ; <nl> + c_t = ( tvb_get_bits8 ( tvb , tb_bit_off /*( 2 + p_conv_data -> num_dch_in_flow )* 8 */, 4 ) + 1 ) % 0xf ; /* c_t = tvb_get_guint8 ( tvb , offset );*/ <nl> + macinf -> lchid [ j + chan ] = c_t ; <nl>  <nl> - macinf -> content [ j + chan ] = lchId_type_table [ c_t + 1 ]; /* Base MAC content on logical channel id ( Table is in packet - nbap . h )*/ <nl> - rlcinf -> mode [ j + chan ] = lchId_rlc_map [ c_t + 1 ]; /* Based RLC mode on logical channel id */ <nl> + macinf -> content [ j + chan ] = lchId_type_table [ c_t ]; /* Base MAC content on logical channel id ( Table is in packet - nbap . h )*/ <nl> + rlcinf -> mode [ j + chan ] = lchId_rlc_map [ c_t ]; /* Based RLC mode on logical channel id */ <nl> } <nl> } else { <nl> fake_lchid = make_fake_lchid ( pinfo , p_conv_data -> dchs_in_flow_list [ chan ]);
/* packet - ip . c <nl> * Routines for IP and miscellaneous IP protocol packet disassembly <nl> * <nl> - * $ Id : packet - ip . c , v 1 . 66 1999 / 12 / 09 21 : 58 : 04 guy Exp $ <nl> + * $ Id : packet - ip . c , v 1 . 67 1999 / 12 / 13 05 : 09 : 05 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> dissect_ip_tcp_options ( const u_char * opd , int offset , guint length , <nl> option length . */ <nl> proto_tree_add_text ( opt_tree , offset , 2 , <nl> "% s ( with too - short option length = % u byte % s )", name , <nl> - plurality ( len , "", " s ")); <nl> + len , plurality ( len , "", " s ")); <nl> return ; <nl> } else if ( len - 2 > length ) { <nl> /* Bogus - option goes past the end of the header . */
static void dissect_attribute_value_pairs ( proto_tree * tree , packet_info * pinfo , <nl> last_eap = TRUE ; <nl> } <nl>  <nl> - if ( last_eap ) { <nl> + if ( last_eap && eap_buffer ) { <nl> gboolean save_writable ; <nl>  <nl> proto_item_append_text ( avp_item ,
dissect_ICBAPhysicalDevice_get_LogicalDevice_rqst ( tvbuff_t * tvb , int offset , <nl>  <nl> offset = dissect_dcom_dcerpc_pointer ( tvb , offset , pinfo , tree , di , drep , <nl> & u32Pointer ); <nl> + <nl> + szStr [ 0 ] ='\ 0 '; <nl> + <nl> if ( u32Pointer ) { <nl> offset = dissect_dcom_BSTR ( tvb , offset , pinfo , tree , di , drep , <nl> hf_cba_name , szStr , u32MaxStr );
dissect_ntlmssp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> col_append_sep_fstr ( pinfo -> cinfo , COL_INFO , ", ","% s ", <nl> val_to_str ( ntlmssph -> type , <nl> ntlmssp_message_types , <nl> - " Unknown message type ")); <nl> + " Unknown NTLMSSP message type ")); <nl>  <nl> /* Call the appropriate dissector based on the Message Type */ <nl> switch ( ntlmssph -> type ) {
dissect_icqv5Client ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> * bytes in the buffer . <nl> */ <nl> rounded_size = (((( capturedsize - ICQ5_CL_SESSIONID ) + 3 )/ 4 )* 4 ) + ICQ5_CL_SESSIONID ; <nl> - decr_pd = tvb_memdup ( tvb , 0 , capturedsize ); <nl> + /* rounded_size might exceed the tvb bounds so we can ' t just use tvb_memdup here . */ <nl> + decr_pd = g_malloc ( rounded_size ); <nl> + tvb_memcpy ( tvb , decr_pd , 0 , capturedsize ); <nl> decrypt_v5 ( decr_pd , rounded_size , key ); <nl>  <nl> /* Allocate a new tvbuff , referring to the decrypted data . */
gboolean ws_strtou64 ( const gchar * str , guint64 * cint ) <nl> gchar * endptr ; <nl> guint64 val ; <nl>  <nl> + if ( str [ 0 ] == '-' || str [ 0 ] == '+') { <nl> + /* <nl> + * Unsigned numbers don ' t have a sign . <nl> + */ <nl> + errno = EINVAL ; <nl> + return FALSE ; <nl> + } <nl> errno = 0 ; <nl> val = g_ascii_strtoull ( str , & endptr , 10 ); <nl> if (( val == 0 && endptr == str ) || (* endptr != 0 )) {
# include < epan / packet . h > <nl> # include " prefs . h " <nl>  <nl> - static int ISUP_thinTCPPort = 0 ; <nl> + static guint ISUP_thinTCPPort = 0 ; <nl>  <nl> /* Initialize the protocol and registered fields */ <nl> static int proto_isup_thin = - 1 ; <nl> dissect_isup_thin ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) <nl> void <nl> proto_reg_handoff_isup_thin ( void ) <nl> { <nl> - static int Initialized = FALSE ; <nl> + static gboolean Initialized = FALSE ; <nl> static dissector_handle_t isup_thin_handle ; <nl> - static int saved_tcp_port ; <nl> + static guint saved_tcp_port ; <nl>  <nl> if (! Initialized ) { <nl> isup_thin_handle = find_dissector (" isup_thin ");
dissect_sbus ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ <nl> } <nl> offset += 2 ; /* now at the end of the telegram */ <nl> } <nl> - return tvb_length ( tvb ); <nl> + return offset ; <nl> /* End of dissect_sbus */ <nl> } <nl> 
dissect_sigcomp_tcp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * _ <nl>  <nl> col_clear ( pinfo -> cinfo , COL_INFO ); <nl>  <nl> - length = tvb_captured_length_remaining ( tvb , offset ); <nl> + length = tvb_reported_length ( tvb ); <nl>  <nl> try_again : <nl> /* create display subtree for the protocol */
dissect_dcm_pdv_fragmented ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , <nl> pdv_body_len , <nl> !( pdv -> is_last_fragment )); <nl>  <nl> - if (( head && ( head -> next == NULL )) || pdv -> is_last_fragment ) { <nl> + if ( head && ( head -> next == NULL )) { <nl> /* Was not really fragmented , therefore use ' conventional ' decoding <nl> fragment_add_seq_next () won ' t add any items to the list , when last fragment only <nl> */
/* proto_draw . c <nl> * Routines for GTK + packet display <nl> * <nl> - * $ Id : proto_draw . c , v 1 . 24 2001 / 01 / 02 01 : 32 : 21 guy Exp $ <nl> + * $ Id : proto_draw . c , v 1 . 25 2001 / 01 / 11 05 : 51 : 10 gram Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ zing . org > <nl> packet_hex_print ( GtkText * bv , guint8 * pd , frame_data * fd , field_info * finfo ) <nl> if ( bstart > 0 ) { <nl> int lineheight , linenum ; <nl> float scrollval ; <nl> - linenum = bstart / BYTE_VIEW_WIDTH ; <nl>  <nl> - /* need to change to some way of getting that offset instead of + 4 */ <nl> - lineheight = gdk_string_height ( m_b_font , " 0 ") + 4 ; <nl> + linenum = bstart / BYTE_VIEW_WIDTH ; <nl> + /* This is the lineheight that the GtkText widget uses when drawing text . */ <nl> + lineheight = m_b_font -> ascent + m_b_font -> descent ; <nl> scrollval = MIN ( linenum * lineheight , bv -> vadj -> upper - bv -> vadj -> page_size ); <nl>  <nl> gtk_adjustment_set_value ( bv -> vadj , scrollval );
create_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) <nl> * doing a " stat ()" on it . If it ' s a drive letter , <nl> * or if the " stat ()" succeeds , we assume it exists . <nl> */ <nl> - pf_dir_path_copy = pf_dir_path ; <nl> + pf_dir_path_copy = g_strdup ( pf_dir_path ); <nl> pf_dir_parent_path = get_dirname ( pf_dir_path_copy ); <nl> pf_dir_parent_path_len = strlen ( pf_dir_parent_path ); <nl> if ( pf_dir_parent_path_len > 0 <nl> create_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) <nl> save_errno = errno ; <nl> * pf_dir_path_return = pf_dir_path ; <nl> errno = save_errno ; <nl> + g_free ( pf_dir_path_copy ); <nl> return - 1 ; <nl> } <nl> /* <nl> create_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) <nl> ret = ws_mkdir ( pf_dir_parent_path , 0755 ); <nl> if ( ret == - 1 ) { <nl> * pf_dir_path_return = pf_dir_parent_path ; <nl> + g_free ( pf_dir_path ); <nl> return - 1 ; <nl> } <nl> }
extcap_register_preferences_callback ( gpointer key , gpointer value _U_ , gpointer <nl>  <nl> void extcap_register_preferences ( void ) <nl> { <nl> + if ( prefs . capture_no_extcap ) <nl> + return ; <nl> + <nl> module_t * dev_module = prefs_find_module (" extcap "); <nl>  <nl> if (! dev_module ) <nl> extcap_load_interface_list ( void ) <nl> gchar * argv ; <nl> gchar * error ; <nl>  <nl> + if ( prefs . capture_no_extcap ) <nl> + return ; <nl> + <nl> if ( _toolbars ) <nl> { <nl> // Remove existing interface toolbars here instead of in extcap_clear_interfaces ()
dissect_spnego_supportedMech ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , <nl> proto_tree_add_text ( tree , tvb , offset , nbytes , " supportedMech : % s ", <nl> oid_string ); <nl>  <nl> - g_free ( oid_string ); <nl> - <nl> offset += nbytes ; <nl>  <nl> /* Should check for an unrecognized OID ... */
be_cell_id_aux ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len , gchar <nl>  <nl> case 0x01 : <nl> case 0x05 : <nl> - case 0x0a : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl> + case 0x0a : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl>  <nl> /* LAC */ <nl>  <nl> be_cell_id_aux ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len , gchar <nl> if ( add_string ) <nl> g_snprintf ( add_string , string_len , " - LAC ( 0x % 04x )", value ); <nl>  <nl> - case 0x09 : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl> + /* FALLTHRU */ <nl> + <nl> + case 0x09 : /* For intersystem handover from GSM to UMTS or cdma2000 : */ <nl>  <nl> if (( disc == 0x08 ) ||( disc == 0x09 ) || ( disc == 0x0a )){ <nl> /* RNC - ID */
static void gtk_vumeter_size_calculate ( GtkWidget * widget , GtkRequisition * requi <nl> PangoLayout * layout = gtk_widget_create_pango_layout ( widget , item -> label ); <nl> pango_layout_get_pixel_size ( layout , & layout_width , & layout_height ); <nl> /* XXX - memleak */ <nl> + } else { <nl> + layout_width = 0 ; <nl> + layout_height = 0 ; <nl> } <nl>  <nl> if ( vumeter -> vertical == TRUE ) {
static void uat_edit_dialog ( uat_t * uat , gint row , gboolean copy ) { <nl> if ( copy && row >= 0 ) { <nl> dd -> rec = g_malloc0 ( uat -> record_size ); <nl> if ( uat -> copy_cb ) { <nl> - uat -> copy_cb ( dd -> rec , UAT_INDEX_PTR ( uat , row ), uat -> record_size ); <nl> + uat -> copy_cb ( dd -> rec , UAT_INDEX_PTR ( uat , row ), ( unsigned int ) uat -> record_size ); <nl> } <nl> dd -> is_new = TRUE ; <nl> } else if ( row >= 0 ) {
/* main . c <nl> * <nl> - * $ Id : main . c , v 1 . 386 2004 / 02 / 01 20 : 28 : 11 ulfl Exp $ <nl> + * $ Id : main . c , v 1 . 387 2004 / 02 / 01 22 : 43 : 34 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> main_window_delete_event_cb ( GtkWidget * widget _U_ , GdkEvent * event _U_ , gpointer <nl> } <nl>  <nl> static void <nl> - main_load_window_geometry ( GtkWidget * widget ) <nl> + main_load_window_geometry ( GtkWidget * widget <nl> +# if GTK_MAJOR_VERSION < 2 <nl> + _U_ <nl> +# endif <nl> +) <nl> { <nl> /* as we now have the geometry from the recent file , set it */ <nl> if ( prefs . gui_geometry_save_position ) {
AirPDcapDecryptWPABroadcastKey ( const EAPOL_RSN_KEY * pEAPKey , guint8 * decryption_ <nl> } <nl> } <nl>  <nl> - if ( key_bytes_len < GROUP_KEY_MIN_LEN || key_bytes_len > eapol_len - sizeof ( EAPOL_RSN_KEY )) { <nl> + if (( key_bytes_len < GROUP_KEY_MIN_LEN ) || <nl> + ( eapol_len < sizeof ( EAPOL_RSN_KEY )) || <nl> + ( key_bytes_len > eapol_len - sizeof ( EAPOL_RSN_KEY ))) { <nl> return AIRPDCAP_RET_NO_VALID_HANDSHAKE ; <nl> } <nl> 
* Routines for MS Exchange MAPI <nl> * Copyright 2002 , Ronnie Sahlberg <nl> * <nl> - * $ Id : packet - dcerpc - mapi . c , v 1 . 5 2002 / 05 / 25 09 : 19 : 45 sahlberg Exp $ <nl> + * $ Id : packet - dcerpc - mapi . c , v 1 . 6 2002 / 05 / 25 10 : 25 : 27 guy Exp $ <nl> * <nl> * Ethereal - Network traffic analyzer <nl> * By Gerald Combs < gerald @ ethereal . com > <nl> mapi_decrypt_pdu ( tvbuff_t * tvb , int offset , <nl> proto_tree_add_item ( tr , hf_mapi_decrypted_data , mmd -> tvb , 2 , pdu_len , FALSE ); <nl>  <nl> proto_tree_add_item ( tr , hf_mapi_pdu_trailer , mmd -> tvb , pdu_len , 4 , FALSE ); <nl> - if ( len >( pdu_len + 4 )){ <nl> + if ( len >(( guint32 ) pdu_len + 4 )){ <nl> proto_tree_add_item ( tr , hf_mapi_pdu_extra_trailer , mmd -> tvb , pdu_len + 4 , len -( pdu_len + 4 ), FALSE ); <nl> } <nl> 
proto_tree_write_node_pdml ( proto_node * node , gpointer data ) <nl> label_ptr = ""; <nl> } <nl>  <nl> - fputs ("< field show =\"", pdata -> fh ); <nl> + /* Show empty name since it is a required field */ <nl> + fputs ("< field name =\"", pdata -> fh ); <nl> + fputs ("\" show =\"", pdata -> fh ); <nl> print_escaped_xml ( pdata -> fh , label_ptr ); <nl>  <nl> fprintf ( pdata -> fh , "\" size =\"% d ", fi -> length );
void MulticastStatisticsDialog :: updateMulticastParameters () <nl>  <nl> param = buffer_alarm_threshold_le_ -> text (). toInt (& ok ); <nl> if ( ok && param > 0 ) { <nl> - mcast_stream_trigger = param ; <nl> + mcast_stream_bufferalarm = param ; <nl> } <nl>  <nl> param = stream_empty_speed_le_ -> text (). toInt (& ok );
be_field_element_dissect ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint <nl> str = match_strval_idx (( guint32 ) oct , bssmap_field_element_ids , & idx ); <nl> ie_len = tvb_get_guint8 ( tvb , curr_offset ++); <nl>  <nl> + if (! str ) <nl> + str = " Unknown "; <nl> + <nl> /* <nl> * add Field Element name <nl> */
pcapng_read_section_header_block ( FILE_T fh , pcapng_block_header_t * bh , <nl> bytes_read = pcapng_read_option ( fh , pn , & oh , option_content , opt_cont_buf_len , to_read , err , err_info , " section_header "); <nl> if ( bytes_read <= 0 ) { <nl> pcapng_debug (" pcapng_read_section_header_block : failed to read option "); <nl> + g_free ( option_content ); <nl> return PCAPNG_BLOCK_ERROR ; <nl> } <nl> to_read -= bytes_read ;
int ieee80211_radiotap_iterator_init ( <nl>  <nl> /* find payload start allowing for extended bitmap ( s ) */ <nl> if ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> + if (! ITERATOR_VALID ( iterator , sizeof ( guint32 ))) <nl> + return - EINVAL ; <nl> while ( get_unaligned_le32 ( iterator -> _arg ) & <nl> ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> iterator -> _arg += sizeof ( guint32 );
int do_cli_server ( int argc , char ** argv TSRMLS_DC ) /* {{{ */ <nl> return 1 ; <nl> } <nl> } else { <nl> - document_root = "."; <nl> + char path [ MAXPATHLEN ]; <nl> + char * ret = NULL ; <nl> + <nl> +# if HAVE_GETCWD <nl> + ret = VCWD_GETCWD ( path , MAXPATHLEN ); <nl> +# elif HAVE_GETWD <nl> + ret = VCWD_GETWD ( path ); <nl> +# endif <nl> + document_root = ret ? path : "."; <nl> } <nl>  <nl> if ( argc > php_optind ) {
static int _php_ibase_def_trans ( ibase_db_link * ib_link , int trans_n ) <nl> { <nl> TSRMLS_FETCH (); <nl>  <nl> + if ( ib_link == NULL ) { <nl> + php_error_docref ( NULL TSRMLS_CC , E_WARNING , " Invalid database link "); <nl> + return FAILURE ; <nl> + } <nl> + <nl> if ( trans_n == 0 && ib_link -> trans [ 0 ] == NULL ) { <nl> if ( isc_start_transaction ( IB_STATUS , & ib_link -> trans [ 0 ], 1 , & ib_link -> link , 0 , NULL )) { <nl> _php_ibase_error ( TSRMLS_C ); <nl> static void _php_ibase_trans_end ( INTERNAL_FUNCTION_PARAMETERS , int commit ) <nl> break ; <nl> } <nl>  <nl> + if ( ib_link == NULL ) { <nl> + php_error_docref ( NULL TSRMLS_CC , E_WARNING , " Invalid database link "); <nl> + RETURN_FALSE ; <nl> + } <nl> + <nl> if ( ib_link -> trans [ trans_n ] == NULL ) { <nl> php_error_docref ( NULL TSRMLS_CC , E_WARNING , " Trying to commit or rollback an already handled transaction "); <nl> RETURN_FALSE ;
ZEND_API inline void zend_assign_to_variable_reference ( znode * result , zval ** var <nl> value_ptr = * value_ptr_ptr ; <nl> if ( variable_ptr == EG ( error_zval_ptr ) || value_ptr == EG ( error_zval_ptr )) { <nl> variable_ptr_ptr = & EG ( uninitialized_zval_ptr ); <nl> - } else if ( variable_ptr != value_ptr ) { <nl> + } else if ( variable_ptr ==& EG ( uninitialized_zval ) || variable_ptr != value_ptr ) { <nl> variable_ptr -> refcount --; <nl> if ( variable_ptr -> refcount == 0 ) { <nl> zendi_zval_dtor (* variable_ptr );
static char * zend_parse_arg_impl ( int arg_num , zval ** arg , va_list * va , char ** sp <nl> zend_fcall_info * fci = va_arg (* va , zend_fcall_info *); <nl> zend_fcall_info_cache * fcc = va_arg (* va , zend_fcall_info_cache *); <nl>  <nl> - if ( zend_fcall_info_init (* arg , fci , fcc TSRMLS_DC ) == SUCCESS ) { <nl> + if ( zend_fcall_info_init (* arg , fci , fcc TSRMLS_CC ) == SUCCESS ) { <nl> break ; <nl> } else if ( return_null ) { <nl> fci -> size = 0 ;
static php_stream * user_wrapper_opendir ( php_stream_wrapper * wrapper , char * filen <nl> us -> wrapper = uwrap ; <nl>  <nl> us -> object = user_stream_create_object ( uwrap , context TSRMLS_CC ); <nl> - if ( us == NULL ) { <nl> + if ( us -> object == NULL ) { <nl> FG ( user_stream_current_filename ) = NULL ; <nl> efree ( us ); <nl> return NULL ;
void zend_compile_try ( zend_ast * ast ) /* {{{ */ <nl> /* Pop FAST_CALL from unwind stack */ <nl> zend_stack_del_top (& CG ( loop_var_stack )); <nl>  <nl> + CG ( zend_lineno ) = finally_ast -> lineno ; <nl> + <nl> opline = zend_emit_op ( NULL , ZEND_FAST_CALL , NULL , NULL ); <nl> opline -> op1 . num = try_catch_offset ; <nl> opline -> result_type = IS_TMP_VAR ;
void php_var_serialize ( pval * buf , pval ** struc , HashTable * var_hash ) <nl> HashTable * myht ; <nl> BLS_FETCH (); <nl>  <nl> - if ( var_hash != NULL && php_add_var_hash ( var_hash ,* struc ,( void *)& var_already ) == FAILURE ) { <nl> + if ( var_hash != NULL && (* struc )-> is_ref && php_add_var_hash ( var_hash ,* struc ,( void *)& var_already ) == FAILURE ) { <nl> slen = sprintf ( s ," R :% ld ;",* var_already ); <nl> STR_CAT ( buf , s , slen ); <nl> return ;
static void zend_fetch_var_address ( zend_op * opline , temp_variable * Ts , int type <nl> zval ** retval ; <nl> zval tmp_varname ; <nl> HashTable * target_symbol_table ; <nl> + zend_bool free_tmp = 0 ; <nl>  <nl> if ( varname -> type != IS_STRING ) { <nl> tmp_varname = * varname ; <nl> zval_copy_ctor (& tmp_varname ); <nl> convert_to_string (& tmp_varname ); <nl> varname = & tmp_varname ; <nl> + free_tmp = 1 ; <nl> } <nl>  <nl> if ( opline -> op2 . u . EA . type == ZEND_FETCH_STATIC_MEMBER ) { <nl> static void zend_fetch_var_address ( zend_op * opline , temp_variable * Ts , int type <nl> } <nl>  <nl>  <nl> - if ( varname == & tmp_varname ) { <nl> + if ( free_tmp ) { <nl> zval_dtor ( varname ); <nl> } <nl> T ( opline -> result . u . var ). var . ptr_ptr = retval ;
static void _php_image_create_from ( INTERNAL_FUNCTION_PARAMETERS , int image_type , <nl>  <nl> io_ctx = gdNewDynamicCtxEx ( buff_size , buff , 0 ); <nl> if (! io_ctx ) { <nl> + pefree ( buff , 1 ); <nl> php_error_docref ( NULL TSRMLS_CC , E_WARNING ," Cannot allocate GD IO context "); <nl> goto out_err ; <nl> } <nl> static void _php_image_create_from ( INTERNAL_FUNCTION_PARAMETERS , int image_type , <nl> im = (* ioctx_func_p )( io_ctx ); <nl> } <nl> io_ctx -> gd_free ( io_ctx ); <nl> + pefree ( buff , 1 ); <nl> } else { <nl> /* try and force the stream to be FILE * */ <nl> if ( FAILURE == php_stream_cast ( stream , PHP_STREAM_AS_STDIO | PHP_STREAM_CAST_TRY_HARD , ( void **) & fp , REPORT_ERRORS )) {
-/* Generated by re2c 0 . 13 . 7 . 5 on Thu Dec 11 19 : 26 : 19 2014 */ <nl> +/* Generated by re2c 0 . 13 . 7 . 5 on Thu Jan 1 14 : 43 : 18 2015 */ <nl> # line 1 " ext / standard / var_unserializer . re " <nl> /* <nl> +----------------------------------------------------------------------+ <nl> static inline int process_nested_data ( UNSERIALIZE_PARAMETER , HashTable * ht , long <nl> } else { <nl> /* object properties should include no integers */ <nl> convert_to_string ( key ); <nl> - if ( zend_symtable_find ( ht , Z_STRVAL_P ( key ), Z_STRLEN_P ( key ) + 1 , ( void **)& old_data )== SUCCESS ) { <nl> + if ( zend_hash_find ( ht , Z_STRVAL_P ( key ), Z_STRLEN_P ( key ) + 1 , ( void **)& old_data )== SUCCESS ) { <nl> var_push_dtor ( var_hash , old_data ); <nl> } <nl> zend_hash_update ( ht , Z_STRVAL_P ( key ), Z_STRLEN_P ( key ) + 1 , & data ,
void zend_do_foreach_cont ( znode * value , znode * key , znode * as_token , znode * fore <nl> result_key = opline -> result ; <nl> } <nl>  <nl> - if ( 1 && assign_by_ref ) { <nl> + if ( assign_by_ref ) { <nl> zend_do_assign_ref (& dummy , value , & result_value TSRMLS_CC ); <nl> } else { <nl> zend_do_assign (& dummy , value , & result_value TSRMLS_CC );
ZEND_METHOD ( reflection_class , isSubclassOf ) <nl> case IS_UNICODE : <nl> if ( zend_u_lookup_class ( Z_TYPE_P ( class_name ), Z_UNIVAL_P ( class_name ), Z_UNILEN_P ( class_name ), & pce TSRMLS_CC ) == FAILURE ) { <nl> zend_throw_exception_ex ( reflection_exception_ptr , 0 TSRMLS_CC , <nl> - " Interface % R does not exist ", Z_TYPE_P ( class_name ), Z_UNIVAL_P ( class_name )); <nl> + " Class % R does not exist ", Z_TYPE_P ( class_name ), Z_UNIVAL_P ( class_name )); <nl> return ; <nl> } <nl> class_ce = * pce ;
int mysqlnd_local_infile_init ( void ** ptr , char * filename , void ** userdata TSRMLS <nl>  <nl> DBG_ENTER (" mysqlnd_local_infile_init "); <nl>  <nl> - * ptr = info = (( MYSQLND_INFILE_INFO *) mnd_ecalloc ( 1 , sizeof ( MYSQLND_INFILE_INFO ))); <nl> + info = (( MYSQLND_INFILE_INFO *) mnd_ecalloc ( 1 , sizeof ( MYSQLND_INFILE_INFO ))); <nl> + if (! info ) { <nl> + DBG_RETURN ( 1 ); <nl> + } <nl> + <nl> + * ptr = info ; <nl>  <nl> /* check open_basedir */ <nl> if ( PG ( open_basedir )) {
-/* Generated by re2c 0 . 13 . 5 on Wed Mar 27 23 : 52 : 29 2013 */ <nl> +/* Generated by re2c 0 . 13 . 5 on Mon May 20 00 : 45 : 38 2013 */ <nl> # line 1 " Zend / zend_language_scanner . l " <nl> /* <nl> +----------------------------------------------------------------------+ <nl> ZEND_API zend_op_array * compile_file ( zend_file_handle * file_handle , int type TSR <nl> compiler_result = zendparse ( TSRMLS_C ); <nl> zend_do_return (& retval_znode , 0 TSRMLS_CC ); <nl> CG ( in_compilation ) = original_in_compilation ; <nl> - if ( compiler_result == 1 ) { /* parser error */ <nl> + if ( compiler_result != 0 ) { /* parser error */ <nl> zend_bailout (); <nl> } <nl> compilation_successful = 1 ; <nl> zend_op_array * compile_string ( zval * source_string , char * filename TSRMLS_DC ) <nl> SCNG ( script_filtered ) = NULL ; <nl> } <nl>  <nl> - if ( compiler_result == 1 ) { <nl> + if ( compiler_result != 0 ) { <nl> CG ( active_op_array ) = original_active_op_array ; <nl> CG ( unclean_shutdown )= 1 ; <nl> destroy_op_array ( op_array TSRMLS_CC );
static PHPDBG_COMMAND ( print ) /* {{{ */ <nl> # else <nl> phpdbg_writeln (" Readline \ tno "); <nl> # endif <nl> + <nl> phpdbg_writeln (" Exec \ t \ t % s ", PHPDBG_G ( exec ) ? PHPDBG_G ( exec ) : " none "); <nl> phpdbg_writeln (" Compiled \ t % s ", PHPDBG_G ( ops ) ? " yes " : " no "); <nl> phpdbg_writeln (" Stepping \ t % s ", ( PHPDBG_G ( flags ) & PHPDBG_IS_STEPPING ) ? " on " : " off "); <nl> phpdbg_writeln (" Quietness \ t % s ", ( PHPDBG_G ( flags ) & PHPDBG_IS_QUIET ) ? " on " : " off "); <nl> + phpdbg_writeln (" Oplog \ t \ t % s ", PHPDBG_G ( oplog ) ? " on " : " off "); <nl>  <nl> if ( PHPDBG_G ( ops )) { <nl> phpdbg_writeln (" Opcodes \ t \ t % d ", PHPDBG_G ( ops )-> last ); <nl> static PHPDBG_COMMAND ( print ) /* {{{ */ <nl> phpdbg_writeln (" Variables \ tNone "); <nl> } <nl> } <nl> + <nl> phpdbg_writeln (" Executing \ t % s ", EG ( in_execution ) ? " yes " : " no "); <nl> if ( EG ( in_execution )) { <nl> phpdbg_writeln (" VM Return \ t % d ", PHPDBG_G ( vmret ));
zend_op_array * persistent_compile_file ( zend_file_handle * file_handle , int type ) <nl> /* In case this callback is called from include_once , require_once or it ' s <nl> * a main FastCGI request , the key must be already calculated , and cached <nl> * persistent script already found */ <nl> - if ( ZCG ( cache_persistent_script ) && ZCG ( key_len ) && <nl> + if (( ZCG ( cache_persistent_script ) && ZCG ( key_len ) && <nl> (! EG ( current_execute_data ) && <nl> file_handle -> filename == SG ( request_info ). path_translated && <nl> - ZCG ( cache_opline ) == NULL ) || <nl> + ZCG ( cache_opline ) == NULL )) || <nl> ( EG ( current_execute_data ) && <nl> EG ( current_execute_data )-> func && <nl> ZEND_USER_CODE ( EG ( current_execute_data )-> func -> common . type ) && <nl> static zend_string * persistent_zend_resolve_path ( const char * filename , int filen <nl> ! ZCSG ( restart_in_progress )) { <nl>  <nl> /* check if callback is called from include_once or it ' s a main request */ <nl> - if (! ZCG ( accel_directives ). revalidate_path && <nl> + if ((! ZCG ( accel_directives ). revalidate_path && <nl> (! EG ( current_execute_data ) && <nl> - filename == SG ( request_info ). path_translated ) || <nl> + filename == SG ( request_info ). path_translated )) || <nl> ( EG ( current_execute_data ) && <nl> EG ( current_execute_data )-> func && <nl> ZEND_USER_CODE ( EG ( current_execute_data )-> func -> common . type ) &&
PHPAPI int php_network_get_peer_name ( php_socket_t sock , <nl> { <nl> php_sockaddr_storage sa ; <nl> socklen_t sl = sizeof ( sa ); <nl> + memset (& sa , 0 , sizeof ( sa )); <nl>  <nl> if ( getpeername ( sock , ( struct sockaddr *)& sa , & sl ) == 0 ) { <nl> php_network_populate_name_from_sockaddr (( struct sockaddr *)& sa , sl , <nl> PHPAPI int php_network_get_sock_name ( php_socket_t sock , <nl> { <nl> php_sockaddr_storage sa ; <nl> socklen_t sl = sizeof ( sa ); <nl> + memset (& sa , 0 , sizeof ( sa )); <nl>  <nl> if ( getsockname ( sock , ( struct sockaddr *)& sa , & sl ) == 0 ) { <nl> php_network_populate_name_from_sockaddr (( struct sockaddr *)& sa , sl ,
static void _php_image_bw_convert ( gdImagePtr im_org , gdIOCtx * out , int threshold <nl> */ <nl> function_entry gd_functions [] = { <nl> PHP_FE ( imagearc , NULL ) <nl> - PHP_FE ( imageellipse , NULL ) <nl> PHP_FE ( imagechar , NULL ) <nl> PHP_FE ( imagecharup , NULL ) <nl> PHP_FE ( imagecolorallocate , NULL ) <nl> function_entry gd_functions [] = { <nl> PHP_FE ( imagecreatetruecolor , NULL ) <nl> PHP_FE ( imagetruecolortopalette , NULL ) <nl> PHP_FE ( imagesetthickness , NULL ) <nl> + PHP_FE ( imageellipse , NULL ) <nl> PHP_FE ( imagefilledarc , NULL ) <nl> PHP_FE ( imagefilledellipse , NULL ) <nl> PHP_FE ( imagealphablending , NULL )
void phpdbg_list_file ( const char * filename , long count , long offset ) /* {{{ */ <nl> unsigned int line = 0 , displayed = 0 ; <nl>  <nl> if (( fd = open ( filename , O_RDONLY )) == - 1 ) { <nl> - printf ("[ Failed to open file to list ]\ n "); <nl> + printf ("[ Failed to open file % s to list ]\ n ", filename ); <nl> return ; <nl> } <nl>  <nl> - fstat ( fd , & st ); <nl> + if ( fstat ( fd , & st ) == - 1 ) { <nl> + printf ("[ Failed to stat file % s ]\ n ", filename ); <nl> + goto out ; <nl> + } <nl>  <nl> last_pos = mem = mmap ( 0 , st . st_size , PROT_READ , MAP_SHARED , fd , 0 ); <nl> end_pos = mem + st . st_size ; <nl> void phpdbg_list_file ( const char * filename , long count , long offset ) /* {{{ */ <nl> } <nl>  <nl> munmap ( mem , st . st_size ); <nl> + out : <nl> close ( fd ); <nl> - <nl> } /* }}} */
static int _preg_do_eval ( char * eval_str , char * subject , int * offsets , <nl> convert_to_string (& retval ); <nl>  <nl> /* Save the return value and its length */ <nl> - * result = estrdup ( retval . value . str . val ); <nl> + * result = estrndup ( retval . value . str . val , retval . value . str . len ); <nl> result_len = retval . value . str . len ; <nl>  <nl> /* Clean up */ <nl> static char * _php_replace_in_subject ( zval * regex , zval * replace , zval ** subject ) <nl> /* If regex is an array */ <nl> if ( regex -> type == IS_ARRAY ) { <nl> /* Duplicating subject string for repeated replacement */ <nl> - subject_value = estrdup ((* subject )-> value . str . val ); <nl> + subject_value = estrndup ((* subject )-> value . str . val , (* subject )-> value . str . len ); <nl>  <nl> zend_hash_internal_pointer_reset ( regex -> value . ht ); <nl> 
PHP_FUNCTION ( sqlite_popen ) <nl> } <nl> if ( errmsg ) { <nl> zval_dtor ( errmsg ); <nl> + ZVAL_NULL ( errmsg ); <nl> } <nl>  <nl> if ( strncmp ( filename , ": memory :", sizeof (": memory :") - 1 )) { <nl> PHP_FUNCTION ( sqlite_open ) <nl> } <nl> if ( errmsg ) { <nl> zval_dtor ( errmsg ); <nl> + ZVAL_NULL ( errmsg ); <nl> } <nl>  <nl> if ( strncmp ( filename , ": memory :", sizeof (": memory :") - 1 )) { <nl> PHP_FUNCTION ( sqlite_factory ) <nl> } <nl> if ( errmsg ) { <nl> zval_dtor ( errmsg ); <nl> + ZVAL_NULL ( errmsg ); <nl> } <nl>  <nl> if ( strncmp ( filename , ": memory :", sizeof (": memory :") - 1 )) {
static ZIPARCHIVE_METHOD ( addFromString ) <nl> /* TODO : fix _zip_replace */ <nl> if ( cur_idx >= 0 ) { <nl> if ( zip_delete ( intern , cur_idx ) == - 1 ) { <nl> - RETURN_FALSE ; <nl> + goto fail ; <nl> } <nl> } <nl>  <nl> - if ( zip_add ( intern , name , zs ) == - 1 ) { <nl> - RETURN_FALSE ; <nl> - } else { <nl> + if ( zip_add ( intern , name , zs ) != - 1 ) { <nl> RETURN_TRUE ; <nl> } <nl> + fail : <nl> + zip_source_free ( zs ); <nl> + RETURN_FALSE ; <nl> } <nl> /* }}} */ <nl> 
MYSQLND_METHOD ( mysqlnd_res , store_result_fetch_data )( MYSQLND * const conn , MYSQL <nl> /* libmysql ' s documentation says it should be so for SELECT statements */ <nl> conn -> upsert_status . affected_rows = set -> row_count ; <nl> } <nl> - DBG_INF_FMT (" ret =% s row_count =% u warnings =% u server_status =% u ", ret == PASS ? " PASS ":" FAIL ", <nl> - set -> row_count , conn -> upsert_status . warning_count , conn -> upsert_status . server_status ); <nl> + DBG_INF_FMT (" ret =% s row_count =" MYSQLND_LLU_SPEC " warnings =% u server_status =% u ", <nl> + ret == PASS ? " PASS ":" FAIL ", ( uint ) set -> row_count , conn -> upsert_status . warning_count , conn -> upsert_status . server_status ); <nl> end : <nl> PACKET_FREE ( row_packet ); <nl> 
static size_t exif_convert_any_to_int ( void * value , int format , int motorola_inte <nl> if ( s_den == 0 ) { <nl> return 0 ; <nl> } else { <nl> - return php_ifd_get32s ( value , motorola_intel ) / s_den ; <nl> + return ( size_t )(( double ) php_ifd_get32s ( value , motorola_intel ) / s_den ); <nl> } <nl>  <nl> case TAG_FMT_SSHORT : return php_ifd_get16u ( value , motorola_intel );
static int phar_parse_pharfile ( php_stream * fp , char * fname , int fname_len , char <nl> /* if the alias is stored we enforce it ( implicit overrides explicit ) */ <nl> if ( alias && alias_len && ( alias_len != ( int ) tmp_len || strncmp ( alias , buffer , tmp_len ))) <nl> { <nl> - buffer [ tmp_len ] = '\ 0 '; <nl> php_stream_close ( fp ); <nl>  <nl> if ( signature ) { <nl> static int phar_parse_pharfile ( php_stream * fp , char * fname , int fname_len , char <nl> } <nl>  <nl> if ( error ) { <nl> - spprintf ( error , 0 , " cannot load phar \"% s \" with implicit alias \"% s \" under different alias \"% s \"", fname , buffer , alias ); <nl> + spprintf ( error , 0 , " cannot load phar \"% s \" with implicit alias \"%.* s \" under different alias \"% s \"", fname , tmp_len , buffer , alias ); <nl> } <nl>  <nl> efree ( savebuf );
static void php_search_array ( INTERNAL_FUNCTION_PARAMETERS , int behavior ) <nl> HashTable * target_hash ; /* array hashtable */ <nl> HashPosition pos ; /* hash iterator */ <nl> ulong num_key ; <nl> + uint str_key_len ; <nl> char * string_key ; <nl> int (* compare_func )( zval *, zval *, zval * TSRMLS_DC ) = is_equal_function ; <nl>  <nl> static void php_search_array ( INTERNAL_FUNCTION_PARAMETERS , int behavior ) <nl> RETURN_TRUE ; <nl> } else { <nl> /* Return current key */ <nl> - switch ( zend_hash_get_current_key_ex ( target_hash , & string_key , NULL , & num_key , 1 , & pos )) { <nl> + switch ( zend_hash_get_current_key_ex ( target_hash , & string_key , & str_key_len , & num_key , 0 , & pos )) { <nl> case HASH_KEY_IS_STRING : <nl> - RETVAL_STRING ( string_key , 0 ); <nl> + RETURN_STRINGL ( string_key , str_key_len - 1 , 1 ); <nl> break ; <nl> case HASH_KEY_IS_LONG : <nl> - RETVAL_LONG ( num_key ); <nl> + RETURN_LONG ( num_key ); <nl> break ; <nl> } <nl> }
PHP_FUNCTION ( imagetruecolortopalette ) <nl> RETURN_FALSE ; <nl> } <nl>  <nl> - if ( ncolors <= 0 ) { <nl> - php_error_docref ( NULL , E_WARNING , " Number of colors has to be greater than zero "); <nl> + if ( ncolors <= 0 || ZEND_LONG_INT_OVFL ( ncolors )) { <nl> + php_error_docref ( NULL , E_WARNING , " Number of colors has to be greater than zero and no more than % d ", INT_MAX ); <nl> RETURN_FALSE ; <nl> } <nl> - gdImageTrueColorToPalette ( im , dither , ncolors ); <nl> + gdImageTrueColorToPalette ( im , dither , ( int ) ncolors ); <nl>  <nl> RETURN_TRUE ; <nl> }
PHPAPI char * _php_stream_gets ( php_stream * stream , char * buf , size_t maxlen TSRML <nl> size_t toread = maxlen - 1 ; <nl> if ( toread > stream -> chunk_size ) <nl> toread = stream -> chunk_size ; <nl> + else if ( toread < stream -> chunk_size ) <nl> + stream -> chunk_size = toread ; <nl>  <nl> /* XXX : Should not the loop end , if the stream op fails ? */ <nl> php_stream_fill_read_buffer ( stream , toread TSRMLS_CC );
apprentice_map ( struct magic_set * ms , const char * fn ) <nl> if ( dbname == NULL ) <nl> goto error ; <nl>  <nl> - stream = php_stream_open_wrapper (( char *) fn , " rb ", REPORT_ERRORS , NULL ); <nl> + stream = php_stream_open_wrapper (( char *) fn , " rb ", REPORT_ERRORS , NULL ); <nl>  <nl> if (! stream ) { <nl> goto error ;
PHPAPI size_t php_strip_tags ( char * rbuf , int len , int * stateptr , char * allow , in <nl>  <nl> while ( i < len ) { <nl> switch ( c ) { <nl> + case '\ 0 ': <nl> + break ; <nl> case '<': <nl> if ( isspace (*( p + 1 ))) { <nl> goto reg_char ;
PHP_FUNCTION ( gettype ) <nl> WRONG_PARAM_COUNT ; <nl> } <nl> switch ( arg -> type ) { <nl> + case IS_BOOL : <nl> + RETVAL_STRING (" boolean ", 1 ); <nl> + break ; <nl> case IS_LONG : <nl> RETVAL_STRING (" integer ", 1 ); <nl> break ;
PHP_FUNCTION ( unserialize ) <nl> const unsigned char * p ; <nl> php_unserialize_data_t var_hash ; <nl> zval * options = NULL , * classes = NULL ; <nl> + zval * retval ; <nl> HashTable * class_hash = NULL ; <nl>  <nl> if ( zend_parse_parameters ( ZEND_NUM_ARGS (), " s | a ", & buf , & buf_len , & options ) == FAILURE ) { <nl> PHP_FUNCTION ( unserialize ) <nl> } <nl> } <nl>  <nl> - if (! php_var_unserialize_ex ( return_value , & p , p + buf_len , & var_hash , class_hash )) { <nl> + retval = var_tmp_var (& var_hash ); <nl> + if (! php_var_unserialize_ex ( retval , & p , p + buf_len , & var_hash , class_hash )) { <nl> PHP_VAR_UNSERIALIZE_DESTROY ( var_hash ); <nl> if ( class_hash ) { <nl> zend_hash_destroy ( class_hash ); <nl> FREE_HASHTABLE ( class_hash ); <nl> } <nl> - zval_ptr_dtor ( return_value ); <nl> if (! EG ( exception )) { <nl> php_error_docref ( NULL , E_NOTICE , " Error at offset " ZEND_LONG_FMT " of % zd bytes ", <nl> ( zend_long )(( char *) p - buf ), buf_len ); <nl> } <nl> RETURN_FALSE ; <nl> } <nl> - /* We should keep an reference to return_value to prevent it from being dtor <nl> - in case nesting calls to unserialize */ <nl> - var_push_dtor (& var_hash , return_value ); <nl> + <nl> + ZVAL_COPY ( return_value , retval ); <nl>  <nl> PHP_VAR_UNSERIALIZE_DESTROY ( var_hash ); <nl> if ( class_hash ) {
int main ( int argc , char * argv []) <nl> # if defined ( PHP_WIN32 ) && defined ( _DEBUG ) && defined ( PHP_WIN32_DEBUG_HEAP ) <nl> { <nl> int tmp_flag ; <nl> - <nl> + _CrtSetReportMode ( _CRT_WARN , _CRTDBG_MODE_FILE ); <nl> + _CrtSetReportFile ( _CRT_WARN , _CRTDBG_FILE_STDERR ); <nl> _CrtSetReportMode ( _CRT_ERROR , _CRTDBG_MODE_FILE ); <nl> _CrtSetReportFile ( _CRT_ERROR , _CRTDBG_FILE_STDERR ); <nl> - <nl> + _CrtSetReportMode ( _CRT_ASSERT , _CRTDBG_MODE_FILE ); <nl> + _CrtSetReportFile ( _CRT_ASSERT , _CRTDBG_FILE_STDERR ); <nl> tmp_flag = _CrtSetDbgFlag ( _CRTDBG_REPORT_FLAG ); <nl> tmp_flag |= _CRTDBG_DELAY_FREE_MEM_DF ; <nl> tmp_flag |= _CRTDBG_LEAK_CHECK_DF ;
PHPAPI extern const char php_sig_gif [ 3 ]; <nl> PHPAPI extern const char php_sig_jpg [ 3 ]; <nl> PHPAPI extern const char php_sig_png [ 3 ]; <nl> - PHPAPI const char php_sig_gd2 [ 3 ] = {' g ', ' d ', ' 2 '}; <nl> + PHPAPI extern const char php_sig_gd2 [ 3 ] = {' g ', ' d ', ' 2 '}; <nl>  <nl> extern zend_module_entry gd_module_entry ; <nl> # define phpext_gd_ptr & gd_module_entry
static MUTEX_T reentrant_locks [ NUMBER_OF_LOCKS ]; <nl>  <nl> PHPAPI char * php_ctime_r ( const time_t * clock , char * buf ) <nl> { <nl> - if ( ctime_r ( clock , buf , 26 ) == buf ) <nl> + if ( ctime_r ( clock , buf ) == buf ) <nl> return ( buf ); <nl> return ( NULL ); <nl> } <nl>  <nl> PHPAPI char * php_asctime_r ( const struct tm * tm , char * buf ) <nl> { <nl> - if ( asctime_r ( tm , buf , 26 ) == buf ) <nl> + if ( asctime_r ( tm , buf ) == buf ) <nl> return ( buf ); <nl> return ( NULL ); <nl> }
PHP_METHOD ( Phar , webPhar ) <nl> } <nl>  <nl> if (( strlen ( sapi_module . name ) == sizeof (" cgi - fcgi ")- 1 && ! strncmp ( sapi_module . name , " cgi - fcgi ", sizeof (" cgi - fcgi ")- 1 )) <nl> + || ( strlen ( sapi_module . name ) == sizeof (" fpm - fcgi ")- 1 && ! strncmp ( sapi_module . name , " fpm - fcgi ", sizeof (" fpm - fcgi ")- 1 )) <nl> || ( strlen ( sapi_module . name ) == sizeof (" cgi ")- 1 && ! strncmp ( sapi_module . name , " cgi ", sizeof (" cgi ")- 1 ))) { <nl>  <nl> if ( PG ( http_globals )[ TRACK_VARS_SERVER ]) {
static php_iconv_err_t _php_iconv_mime_decode ( smart_str * pretval , const char * st <nl>  <nl> case 3 : /* expecting a encoding scheme specifier */ <nl> switch (* p1 ) { <nl> + case ' b ': <nl> case ' B ': <nl> enc_scheme = PHP_ICONV_ENC_SCHEME_BASE64 ; <nl> scan_stat = 4 ; <nl> break ; <nl>  <nl> + case ' q ': <nl> case ' Q ': <nl> enc_scheme = PHP_ICONV_ENC_SCHEME_QPRINT ; <nl> scan_stat = 4 ;
static char * ps_files_path_create ( char * buf , size_t buflen , ps_files * data , cons <nl>  <nl> key_len = strlen ( key ); <nl> if ( key_len <= data -> dirdepth || <nl> - buflen < ( strlen ( data -> basedir ) + 2 * data -> dirdepth + key_len + 5 + sizeof ( FILE_PREFIX ))) { <nl> + buflen < ( data -> basedir_len + 2 * data -> dirdepth + key_len + 5 + sizeof ( FILE_PREFIX ))) { <nl> return NULL ; <nl> } <nl>  <nl> static void ps_files_open ( ps_files * data , const char * key ) <nl> ps_files_close ( data ); <nl>  <nl> if ( php_session_valid_key ( key ) == FAILURE ) { <nl> + if ( data -> basedir ) { <nl> + efree ( data -> basedir ); <nl> + data -> basedir = NULL ; <nl> + data -> basedir_len = 0 ; <nl> + } <nl> php_error_docref ( NULL , E_WARNING , " The session id is too long or contains illegal characters , valid characters are a - z , A - Z , 0 - 9 and '-,'"); <nl> return ; <nl> }
void zend_compile_params ( zend_ast * ast , zend_ast * return_type_ast ) /* {{{ */ <nl> opline -> op2 . num = - 1 ; <nl> } <nl> } <nl> - } <nl> + } else { <nl> + if ( opline -> opcode == ZEND_RECV_INIT ) { <nl> + Z_CACHE_SLOT ( op_array -> literals [ opline -> op2 . constant ]) = - 1 ; <nl> + } else { <nl> + opline -> op2 . num = - 1 ; <nl> + } <nl> + } <nl> } <nl>  <nl> /* These are assigned at the end to avoid unitialized memory in case of an error */
/* <nl> * The version of the OCI8 extension . <nl> */ <nl> -# define PHP_OCI8_VERSION " 1 . 4 . 0 Alpha " <nl> +# define PHP_OCI8_VERSION " 1 . 4 . 1 " <nl>  <nl> extern zend_module_entry oci8_module_entry ; <nl> # define phpext_oci8_ptr & oci8_module_entry
int phpdbg_call_register ( phpdbg_input_t * input TSRMLS_DC ) /* {{{ */ <nl> & PHPDBG_G ( registered ), function -> string , function -> length + 1 )) { <nl>  <nl> zval fname , * fretval ; <nl> - zend_fcall_info * fci = emalloc ( sizeof ( zend_fcall_info )); <nl> + zend_fcall_info * fci = ecalloc ( 1 , sizeof ( zend_fcall_info )); <nl>  <nl> ZVAL_STRINGL (& fname , function -> string , function -> length , 1 ); <nl> 
PHP_FUNCTION ( socket_recvfrom ) <nl> sin . sin_family = AF_INET ; <nl>  <nl> if ( arg6 == NULL ) { <nl> + efree ( recv_buf ); <nl> WRONG_PARAM_COUNT ; <nl> } <nl>  <nl> PHP_FUNCTION ( socket_recvfrom ) <nl> sin6 . sin6_family = AF_INET6 ; <nl>  <nl> if ( arg6 == NULL ) { <nl> + efree ( recv_buf ); <nl> WRONG_PARAM_COUNT ; <nl> } <nl> 
static PHP_INI_MH ( OnChangeMemoryLimit ) <nl> if ( new_value ) { <nl> new_limit = atoi ( new_value ); <nl> } else { <nl> - new_limit = 2 << 30 ; /* effectively , no limit */ <nl> + new_limit = 1 << 30 ; /* effectively , no limit */ <nl> } <nl> return zend_set_memory_limit ( new_limit ); <nl> }
PHP_FUNCTION ( php_uname ) <nl> Return comma - separated string of . ini files parsed from the additional ini dir */ <nl> PHP_FUNCTION ( php_ini_scanned_files ) <nl> { <nl> + if ( zend_parse_parameters_none () == FAILURE ) { <nl> + return ; <nl> + } <nl> + <nl> if ( strlen ( PHP_CONFIG_FILE_SCAN_DIR ) && php_ini_scanned_files ) { <nl> RETURN_STRING ( php_ini_scanned_files , 1 ); <nl> } else { <nl> PHP_FUNCTION ( php_ini_scanned_files ) <nl> Return the actual loaded ini filename */ <nl> PHP_FUNCTION ( php_ini_loaded_file ) <nl> { <nl> + if ( zend_parse_parameters_none () == FAILURE ) { <nl> + return ; <nl> + } <nl> + <nl> if ( php_ini_opened_path ) { <nl> RETURN_STRING ( php_ini_opened_path , 1 ); <nl> } else {
PHP_FUNCTION ( ibase_gen_id ) <nl> & inc , & link )) { <nl> RETURN_FALSE ; <nl> } <nl> + <nl> + if ( gen_len > 31 ) { <nl> + php_error_docref ( NULL TSRMLS_CC , E_WARNING , " Invalid generator name "); <nl> + RETURN_FALSE ; <nl> + } <nl>  <nl> PHP_IBASE_LINK_TRANS ( link , ib_link , trans ); <nl> 
SAPI_POST_HANDLER_FUNC ( fdf_post_handler ) <nl> err = FDFGetValue ( theFDF , name , value , value_len - 1 ,& nBytes ); <nl> if ( err == FDFErcOK && nBytes != 0 ) { <nl> for ( p = value ;* p ; p ++) if (* p =='\ r ') * p ='\ n '; <nl> + if ( lastfieldname ) efree ( lastfieldname ); <nl> lastfieldname = estrdup ( name ); <nl> php_register_variable ( name , value , array_ptr ELS_CC PLS_CC ); <nl> }
static u_char * php_parserr ( u_char * cp , querybuf * answer , int type_to_fetch , int <nl>  <nl> while ( ll < dlen ) { <nl> n = cp [ ll ]; <nl> + if (( ll + n ) >= dlen ) { <nl> + // Invalid chunk length , truncate <nl> + n = dlen - ( ll + 1 ); <nl> + } <nl> memcpy ( tp + ll , cp + ll + 1 , n ); <nl> add_next_index_stringl ( entries , cp + ll + 1 , n , 1 ); <nl> ll = ll + n + 1 ;
ZEND_FUNCTION ( set_error_handler ) <nl> Restores the previously defined error handler function */ <nl> ZEND_FUNCTION ( restore_error_handler ) <nl> { <nl> + if ( zend_parse_parameters_none () == FAILURE ) { <nl> + return ; <nl> + } <nl> + <nl> if ( Z_TYPE ( EG ( user_error_handler )) != IS_UNDEF ) { <nl> zval zeh ; <nl>  <nl> ZEND_FUNCTION ( set_exception_handler ) <nl> Restores the previously defined exception handler function */ <nl> ZEND_FUNCTION ( restore_exception_handler ) <nl> { <nl> + if ( zend_parse_parameters_none () == FAILURE ) { <nl> + return ; <nl> + } <nl> + <nl> if ( Z_TYPE ( EG ( user_exception_handler )) != IS_UNDEF ) { <nl> zval_ptr_dtor (& EG ( user_exception_handler )); <nl> }
fetch_token_in_cc ( OnigToken * tok , UChar ** src , UChar * end , ScanEnv * env ) <nl> PUNFETCH ; <nl> prev = p ; <nl> num = scan_unsigned_octal_number (& p , end , 3 , enc ); <nl> - if ( num < 0 ) return ONIGERR_TOO_BIG_NUMBER ; <nl> + if ( num < 0 || num >= 256 ) return ONIGERR_TOO_BIG_NUMBER ; <nl> if ( p == prev ) { /* can ' t read nothing . */ <nl> num = 0 ; /* but , it ' s not error */ <nl> } <nl> fetch_token ( OnigToken * tok , UChar ** src , UChar * end , ScanEnv * env ) <nl> if ( IS_SYNTAX_OP ( syn , ONIG_SYN_OP_ESC_OCTAL3 )) { <nl> prev = p ; <nl> num = scan_unsigned_octal_number (& p , end , ( c == ' 0 ' ? 2 : 3 ), enc ); <nl> - if ( num < 0 ) return ONIGERR_TOO_BIG_NUMBER ; <nl> + if ( num < 0 || num >= 256 ) return ONIGERR_TOO_BIG_NUMBER ; <nl> if ( p == prev ) { /* can ' t read nothing . */ <nl> num = 0 ; /* but , it ' s not error */ <nl> } <nl> next_state_val ( CClassNode * cc , OnigCodePoint * vs , OnigCodePoint v , <nl> switch (* state ) { <nl> case CCS_VALUE : <nl> if (* type == CCV_SB ) <nl> + { <nl> + if (* vs > 0xff ) <nl> + return ONIGERR_INVALID_CODE_POINT_VALUE ; <nl> BITSET_SET_BIT ( cc -> bs , ( int )(* vs )); <nl> + } <nl> else if (* type == CCV_CODE_POINT ) { <nl> r = add_code_range (&( cc -> mbuf ), env , * vs , * vs ); <nl> if ( r < 0 ) return r ;
static void php_var_serialize_class ( smart_str * buf , zval * struc , zval * retval_pt <nl> zend_mangle_property_name (& priv_name , & prop_name_length , ce -> name , ce -> name_length , Z_STRVAL_PP ( name ), Z_STRLEN_PP ( name ), ce -> type & ZEND_INTERNAL_CLASS ); <nl> if ( zend_hash_find ( Z_OBJPROP_P ( struc ), priv_name , prop_name_length + 1 , ( void *) & d ) == SUCCESS ) { <nl> php_var_serialize_string ( buf , priv_name , prop_name_length ); <nl> - efree ( priv_name ); <nl> + pefree ( priv_name , ce -> type & ZEND_INTERNAL_CLASS ); <nl> php_var_serialize_intern ( buf , * d , var_hash TSRMLS_CC ); <nl> break ; <nl> } <nl> - efree ( priv_name ); <nl> + pefree ( priv_name , ce -> type & ZEND_INTERNAL_CLASS ); <nl> zend_mangle_property_name (& prot_name , & prop_name_length , "*", 1 , Z_STRVAL_PP ( name ), Z_STRLEN_PP ( name ), ce -> type & ZEND_INTERNAL_CLASS ); <nl> if ( zend_hash_find ( Z_OBJPROP_P ( struc ), prot_name , prop_name_length + 1 , ( void *) & d ) == SUCCESS ) { <nl> php_var_serialize_string ( buf , prot_name , prop_name_length ); <nl> - efree ( prot_name ); <nl> + pefree ( prot_name , ce -> type & ZEND_INTERNAL_CLASS ); <nl> php_var_serialize_intern ( buf , * d , var_hash TSRMLS_CC ); <nl> break ; <nl> } <nl> - efree ( prot_name ); <nl> + pefree ( prot_name , ce -> type & ZEND_INTERNAL_CLASS ); <nl> php_error_docref ( NULL TSRMLS_CC , E_NOTICE , "\"% s \" returned as member variable from __sleep () but does not exist ", Z_STRVAL_PP ( name )); <nl> php_var_serialize_string ( buf , Z_STRVAL_PP ( name ), Z_STRLEN_PP ( name )); <nl> php_var_serialize_intern ( buf , nvalp , var_hash TSRMLS_CC );
function_entry mysqli_functions [] = { <nl> */ <nl> function_entry mysqli_link_methods [] = { <nl> PHP_FALIAS ( affected_rows , mysqli_affected_rows , NULL ) <nl> - PHP_FALIAS ( auto_commit , mysqli_autocommit , NULL ) <nl> + PHP_FALIAS ( autocommit , mysqli_autocommit , NULL ) <nl> PHP_FALIAS ( change_user , mysqli_change_user , NULL ) <nl> PHP_FALIAS ( character_set_name , mysqli_character_set_name , NULL ) <nl> PHP_FALIAS ( client_encoding , mysqli_character_set_name , NULL ) <nl> function_entry mysqli_link_methods [] = { <nl> */ <nl> function_entry mysqli_result_methods [] = { <nl> PHP_FALIAS ( close , mysqli_free_result , NULL ) <nl> + PHP_FALIAS ( free , mysqli_free_result , NULL ) <nl> PHP_FALIAS ( data_seek , mysqli_data_seek , NULL ) <nl> PHP_FALIAS ( fetch_field , mysqli_fetch_field , NULL ) <nl> PHP_FALIAS ( fetch_fields , mysqli_fetch_fields , NULL )
static const create_table_t create [] = { <nl> { FILE_TYPE_DIR , " self ", 0755 }, <nl> { FILE_TYPE_DIR , " run ", 0755 }, <nl> { FILE_TYPE_DIR , " run / dbus ", 0755 }, <nl> + { FILE_TYPE_DIR , " run / media ", 0755 }, <nl> { FILE_TYPE_DIR , " run / user ", 0755 }, <nl> { FILE_TYPE_DIR , " run / user /% 1 $ d ", 0700 , NULL }, <nl> { FILE_TYPE_DIR , " run / user /% 1 $ d / pulse ", 0700 , NULL }, <nl> main ( int argc , <nl> } <nl>  <nl> if ( mount_host_fs ) <nl> - mount_extra_root_dirs ( mount_host_fs_ro ); <nl> + { <nl> + mount_extra_root_dirs ( mount_host_fs_ro ); <nl> + bind_mount ("/ run / media ", " run / media ", BIND_RECURSIVE | ( mount_host_fs_ro ? BIND_READONLY : 0 )); <nl> + } <nl>  <nl> if (! mount_host_fs ) <nl> create_homedir ( mount_home , app_id );
flatpak_table_printer_print ( FlatpakTablePrinter * printer ) <nl> lwidths = g_new0 ( int , printer -> n_columns ); <nl> rwidths = g_new0 ( int , printer -> n_columns ); <nl>  <nl> - for ( i = 0 ; i < printer -> titles -> len ; i ++) <nl> + for ( i = 0 ; i < printer -> titles -> len && i < printer -> n_columns ; i ++) <nl> { <nl> char * title = g_ptr_array_index ( printer -> titles , i ); <nl>  <nl> flatpak_table_printer_print ( FlatpakTablePrinter * printer ) <nl> if ( flatpak_fancy_output () && printer -> titles -> len > 0 ) <nl> { <nl> g_print ( FLATPAK_ANSI_BOLD_ON ); <nl> - for ( i = 0 ; i < printer -> titles -> len ; i ++) <nl> + for ( i = 0 ; i < printer -> titles -> len && i < printer -> n_columns ; i ++) <nl> { <nl> char * title = g_ptr_array_index ( printer -> titles , i ); <nl> 
parse_ref_file ( GKeyFile * keyfile , <nl> g_autoptr ( GBytes ) gpg_data = NULL ; <nl> gboolean is_runtime = FALSE ; <nl> g_autofree char * collection_id = NULL ; <nl> - char * str ; <nl> + g_autofree char * str = NULL ; <nl>  <nl> * name_out = NULL ; <nl> * branch_out = NULL ; <nl> parse_ref_file ( GKeyFile * keyfile , <nl> FLATPAK_REF_GPGKEY_KEY , NULL ); <nl> if ( str != NULL ) <nl> { <nl> - guchar * decoded ; <nl> + g_autofree guchar * decoded = NULL ; <nl> gsize decoded_len ; <nl>  <nl> str = g_strstrip ( str ); <nl> parse_ref_file ( GKeyFile * keyfile , <nl> if ( decoded_len < 10 ) /* Check some minimal size so we don ' t get crap */ <nl> return flatpak_fail ( error , " Invalid file format , gpg key invalid "); <nl>  <nl> - gpg_data = g_bytes_new_take ( decoded , decoded_len ); <nl> + gpg_data = g_bytes_new_take ( g_steal_pointer (& decoded ), decoded_len ); <nl> } <nl>  <nl> collection_id = g_key_file_get_string ( keyfile , FLATPAK_REF_GROUP ,
flatpak_builtin_add_remote ( int argc , char ** argv , <nl> if ( opt_collection_id != NULL && <nl> ! ostree_validate_collection_id ( opt_collection_id , & local_error )) <nl> return flatpak_fail ( error , _ ("% s  is not a valid collection ID : % s "), opt_collection_id , local_error -> message ); <nl> + <nl> + if ( opt_collection_id != NULL && <nl> + ( opt_no_gpg_verify || opt_gpg_import == NULL || opt_gpg_import [ 0 ] == NULL )) <nl> + return flatpak_fail ( error , _ (" GPG verification is required if collections are enabled ")); <nl> # endif /* FLATPAK_ENABLE_P2P */ <nl>  <nl> remote_name = argv [ 1 ];
builder_source_git_extract ( BuilderSource * source , <nl> if (! git_extract_submodule ( url , dest , context , error )) <nl> return FALSE ; <nl>  <nl> + if (! git ( dest , NULL , error , <nl> + " config ", "-- local ", " remote . origin . url ", url , NULL )) <nl> + return FALSE ; <nl> + <nl> return TRUE ; <nl> } <nl> 
size_t cnt , n , max ; \ <nl> kmptype_t ** buf ; \ <nl> } kmp_ ## name ## _t ; \ <nl> - static inline kmp_ ## name ## _t * kmp_init_ ## name () { \ <nl> + static inline kmp_ ## name ## _t * kmp_init_ ## name ( void ) { \ <nl> return xcalloc ( 1 , sizeof ( kmp_ ## name ## _t )); \ <nl> } \ <nl> static inline void kmp_destroy_ ## name ( kmp_ ## name ## _t * mp ) { \ <nl> -- mp -> cnt ; \ <nl> if ( mp -> n == mp -> max ) { \ <nl> mp -> max = mp -> max ? mp -> max << 1 : 16 ; \ <nl> - mp -> buf = xrealloc ( mp -> buf , sizeof ( void *) * mp -> max ); \ <nl> + mp -> buf = xrealloc ( mp -> buf , sizeof ( kmptype_t *) * mp -> max ); \ <nl> } \ <nl> mp -> buf [ mp -> n ++] = p ; \ <nl> } <nl> kmp_ ## name ## _t * mp ; \ <nl> size_t size ; \ <nl> } kl_ ## name ## _t ; \ <nl> - static inline kl_ ## name ## _t * kl_init_ ## name () { \ <nl> + static inline kl_ ## name ## _t * kl_init_ ## name ( void ) { \ <nl> kl_ ## name ## _t * kl = xcalloc ( 1 , sizeof ( kl_ ## name ## _t )); \ <nl> kl -> mp = kmp_init ( name ); \ <nl> kl -> head = kl -> tail = kmp_alloc ( name , kl -> mp ); \
Integer nvim_buf_line_count ( Buffer buffer , Error * err ) <nl> return 0 ; <nl> } <nl>  <nl> + // return sentinel value if the buffer isn ' t loaded <nl> + if ( buf -> b_ml . ml_mfp == NULL ) { <nl> + return 0 ; <nl> + } <nl> + <nl> return buf -> b_ml . ml_line_count ; <nl> } <nl>  <nl> ArrayOf ( String ) nvim_buf_get_lines ( uint64_t channel_id , <nl> return rv ; <nl> } <nl>  <nl> + // return sentinel value if the buffer isn ' t loaded <nl> + if ( buf -> b_ml . ml_mfp == NULL ) { <nl> + return rv ; <nl> + } <nl> + <nl> bool oob = false ; <nl> start = normalize_index ( buf , start , & oob ); <nl> end = normalize_index ( buf , end , & oob );
int dvcman_create_channel ( IWTSVirtualChannelManager * pChannelMgr , UINT32 Channel <nl> { <nl> DEBUG_WARN (" channel rejected by plugin "); <nl>  <nl> - channel -> status = 1 ; <nl> - ArrayList_Add ( dvcman -> channels , channel ); <nl> + free ( channel ); <nl> return 1 ; <nl> } <nl> } <nl> } <nl>  <nl> - channel -> status = 1 ; <nl> - ArrayList_Add ( dvcman -> channels , channel ); <nl> - <nl> + free ( channel ); <nl> return 1 ; <nl> } <nl> 
BOOL certificate_read_server_x509_certificate_chain ( rdpCertificate * certificate , <nl> DEBUG_CERTIFICATE (" License Server Certificate "); <nl> ret = certificate_read_x509_certificate (& certificate -> x509_cert_chain -> array [ i ], & cert_info ); <nl> DEBUG_LICENSE (" modulus length :% d ", ( int ) cert_info . ModulusLength ); <nl> - if ( cert_info . Modulus ) <nl> + if ( cert_info . Modulus ) <nl> free ( cert_info . Modulus ); <nl> - if (! ret ) <nl> + if (! ret ) { <nl> + printf (" failed to read License Server , content follows :\ n "); <nl> + winpr_HexDump ( certificate -> x509_cert_chain -> array [ i ]. data , certificate -> x509_cert_chain -> array [ i ]. length ); <nl> return FALSE ; <nl> + } <nl> } <nl> else if ( numCertBlobs - i == 1 ) <nl> {
tfo_probe ( void ) <nl> int sock , backlog = 5 ; <nl>  <nl> if ( ( sock = socket ( SOCK_STREAM , AF_INET , 0 )) < 0 <nl> - && setsockopt ( sock , IPPROTO_TCP , TCP_FASTOPEN , <nl> - & connect_backlog , sizeof ( smtp_connect_backlog )) <nl> + && setsockopt ( sock , IPPROTO_TCP , TCP_FASTOPEN , & backlog , sizeof ( backlog )) <nl> ) <nl> tcp_fastopen_ok = TRUE ; <nl> close ( sock );
if ( tls_offered && ! suppress_tls && <nl> if (! smtp_read_response (& inblock , buffer2 , sizeof ( buffer2 ), ' 2 ', <nl> ob -> command_timeout )) <nl> { <nl> - Ustrncpy ( buffer , buffer2 , sizeof ( buffer )); <nl> if ( errno != 0 || buffer2 [ 0 ] == 0 || <nl> ( buffer2 [ 0 ] == ' 4 ' && ! ob -> tls_tempfail_tryclear )) <nl> + { <nl> + Ustrncpy ( buffer , buffer2 , sizeof ( buffer )); <nl> goto RESPONSE_FAILED ; <nl> + } <nl> } <nl>  <nl> /* STARTTLS accepted : try to negotiate a TLS session . */
bool SQLCache :: childMailboxesFresh ( const QString & mailbox ) const <nl>  <nl> void SQLCache :: setChildMailboxes ( const QString & mailbox , const QList < MailboxMetadata >& data ) <nl> { <nl> + TransactionHelper txn (& db ); <nl> QString myMailbox = mailbox . isEmpty () ? QString :: fromAscii ("") : mailbox ; <nl> QVariantList mailboxFields , parentFields , separatorFields , flagsFelds ; <nl> Q_FOREACH ( const MailboxMetadata & item , data ) { <nl> void SQLCache :: setChildMailboxes ( const QString & mailbox , const QList < MailboxMet <nl> emitError ( tr (" Query querySetChildMailboxesFresh failed "), querySetChildMailboxesFresh ); <nl> return ; <nl> } <nl> + txn . commit (); <nl> } <nl>  <nl> void SQLCache :: forgetChildMailboxes ( const QString & mailbox )
void Model :: parsersMightBeIdling () <nl>  <nl> void Model :: killParser ( Parser * parser ) <nl> { <nl> + Q_FOREACH ( ImapTask * task , _parsers [ parser ]. activeTasks ) { <nl> + task -> deleteLater (); <nl> + } <nl> + <nl> for ( QMap < CommandHandle , Task >:: const_iterator it = _parsers [ parser ]. commandMap . begin (); <nl> it != _parsers [ parser ]. commandMap . end (); ++ it ) { <nl> // FIXME : fail the command , perform cleanup ,...
int LLVMFuzzerTestOneInput ( const uint8_t * data , size_t size ) { <nl>  <nl> ll = l + strspn ( l , WHITESPACE ); <nl>  <nl> - if ( HAS_FEATURE_MEMORY_SANITIZER && startswith ( ll , " ListenNetlink =")) { <nl> + if ( HAS_FEATURE_MEMORY_SANITIZER && startswith ( ll , " ListenNetlink ")) { <nl> /* ListenNetlink causes a false positive in msan , <nl> * let ' s skip this for now . */ <nl> log_notice (" Skipping test because ListenNetlink = is present ");
# include < libaudit . h > <nl> # include < stdbool . h > <nl>  <nl> +# include " capability - util . h " <nl> # include " fd - util . h " <nl> # include " log . h " <nl> # include " util . h " <nl> static int audit_fd ; <nl> int get_audit_fd ( void ) { <nl>  <nl> if (! initialized ) { <nl> + if ( have_effective_cap ( CAP_AUDIT_WRITE ) == 0 ) { <nl> + audit_fd = - EPERM ; <nl> + initialized = true ; <nl> + <nl> + return audit_fd ; <nl> + } <nl> + <nl> audit_fd = audit_open (); <nl>  <nl> if ( audit_fd < 0 ) {
_public_ int sd_pid_notify_with_fds ( pid_t pid , int unset_environment , const char <nl> goto finish ; <nl> } <nl>  <nl> + if ( strlen ( e ) > sizeof ( sockaddr . un . sun_path )) { <nl> + r = - EINVAL ; <nl> + goto finish ; <nl> + } <nl> + <nl> fd = socket ( AF_UNIX , SOCK_DGRAM | SOCK_CLOEXEC , 0 ); <nl> if ( fd < 0 ) { <nl> r = - errno ;
static void job_print_status_message ( Unit * u , JobType t , JobResult result ) { <nl> switch ( result ) { <nl>  <nl> case JOB_DONE : <nl> - unit_status_printf ( u , ANSI_HIGHLIGHT_GREEN_ON " OK " ANSI_HIGHLIGHT_OFF , " Started % s ", unit_description ( u )); <nl> + if ( u -> condition_result ) <nl> + unit_status_printf ( u , ANSI_HIGHLIGHT_GREEN_ON " OK " ANSI_HIGHLIGHT_OFF , " Started % s ", unit_description ( u )); <nl> break ; <nl>  <nl> case JOB_FAILED :
static int create_item ( Item * i ) { <nl>  <nl> case CREATE_FILE : <nl> case TRUNCATE_FILE : <nl> + r = write_one_file ( i , i -> path ); <nl> + if ( r < 0 ) <nl> + return r ; <nl> + break ; <nl> case WRITE_FILE : <nl> r = glob_item ( i , write_one_file ); <nl> if ( r < 0 )
void strv_free ( char ** l ) { <nl> char ** strv_copy ( char ** l ) { <nl> char ** r , ** k ; <nl>  <nl> - if (!( r = new ( char *, strv_length ( l )+ 1 ))) <nl> + if (!( k = r = new ( char *, strv_length ( l )+ 1 ))) <nl> return NULL ; <nl>  <nl> if ( l ) <nl> - for ( k = r ; * l ; k ++, l ++) <nl> + for (; * l ; k ++, l ++) <nl> if (!(* k = strdup (* l ))) <nl> goto fail ; <nl> 
static int set_usb_mass_storage_ifsubtype ( char * to , const char * from , size_t len <nl> if ( eptr != from ) { <nl> switch ( type_num ) { <nl> case 2 : <nl> - type = " cd "; <nl> + type = " atapi "; <nl> break ; <nl> case 3 : <nl> type = " tape "; <nl> static int set_usb_mass_storage_ifsubtype ( char * to , const char * from , size_t len <nl> } <nl> } <nl> util_strlcpy ( to , type , len ); <nl> - <nl> return type_num ; <nl> } <nl>  <nl> static int usb_id ( struct udev_device * dev ) <nl> udev_device_get_sysname ( dev )); <nl> return 1 ; <nl> } <nl> + <nl> if_class_num = strtoul ( if_class , NULL , 16 ); <nl> if ( if_class_num == 8 ) { <nl> + /* mass storage */ <nl> if_subclass = udev_device_get_sysattr_value ( dev_interface , " bInterfaceSubClass "); <nl> if ( if_subclass != NULL ) <nl> protocol = set_usb_mass_storage_ifsubtype ( type_str , if_subclass , sizeof ( type_str )- 1 ); <nl> static int usb_id ( struct udev_device * dev ) <nl> return 1 ; <nl> } <nl>  <nl> - /* mass storage */ <nl> - if ( protocol == 6 && ! use_usb_info ) { <nl> + /* mass storage : SCSI or ATAPI */ <nl> + if (( protocol == 6 || protocol == 2 ) && ! use_usb_info ) { <nl> struct udev_device * dev_scsi ; <nl> const char * scsi_model , * scsi_vendor , * scsi_type , * scsi_rev ; <nl> int host , bus , target , lun ;
static void font_copy_to_all_vcs ( int fd ) { <nl> return ; <nl> } <nl>  <nl> - for ( i = 1 ; i <= 15 ; i ++) { <nl> + for ( i = 1 ; i <= 63 ; i ++) { <nl> char vcname [ strlen ("/ dev / vcs ") + DECIMAL_STR_MAX ( int )]; <nl> _cleanup_close_ int vcfd = - 1 ; <nl> struct console_font_op cfo = {};
static int subvol_remove_children ( int fd , const char * subvolume , uint64_t subvol <nl> struct btrfs_ioctl_vol_args vol_args = {}; <nl> _cleanup_close_ int subvol_fd = - 1 ; <nl> struct stat st ; <nl> + bool made_writable = false ; <nl> int r ; <nl>  <nl> assert ( fd >= 0 ); <nl> static int subvol_remove_children ( int fd , const char * subvolume , uint64_t subvol <nl> if ( ioctl ( fd , BTRFS_IOC_INO_LOOKUP , & ino_args ) < 0 ) <nl> return - errno ; <nl>  <nl> + if (! made_writable ) { <nl> + r = btrfs_subvol_set_read_only_fd ( subvol_fd , false ); <nl> + if ( r < 0 ) <nl> + return r ; <nl> + <nl> + made_writable = true ; <nl> + } <nl> + <nl> if ( isempty ( ino_args . name )) <nl> /* Subvolume is in the top - level <nl> * directory of the subvolume . */
static int address_label_handler ( sd_netlink * rtnl , sd_netlink_message * m , void * <nl> else if ( r >= 0 ) <nl> manager_rtnl_process_address ( rtnl , m , link -> manager ); <nl>  <nl> - if ( link -> link_messages == 0 ) { <nl> + if ( link -> link_messages == 0 ) <nl> log_link_debug ( link , " Addresses label set "); <nl> - link_enter_set_routes ( link ); <nl> - } <nl>  <nl> return 1 ; <nl> }
static int append_assignment ( DBusMessageIter * iter , const char * assignment ) { <nl>  <nl> static int set_property ( DBusConnection * bus , char ** args ) { <nl>  <nl> - _cleanup_free_ DBusMessage * m = NULL , * reply = NULL ; <nl> + _cleanup_dbus_message_unref_ DBusMessage * m = NULL , * reply = NULL ; <nl> + _cleanup_free_ char * n = NULL ; <nl> DBusMessageIter iter , sub ; <nl> dbus_bool_t runtime ; <nl> DBusError error ; <nl> static int set_property ( DBusConnection * bus , char ** args ) { <nl>  <nl> runtime = arg_runtime ; <nl>  <nl> - if (! dbus_message_iter_append_basic (& iter , DBUS_TYPE_STRING , & args [ 1 ]) || <nl> + n = unit_name_mangle ( args [ 1 ]); <nl> + if (! n ) <nl> + return log_oom (); <nl> + <nl> + if (! dbus_message_iter_append_basic (& iter , DBUS_TYPE_STRING , & n ) || <nl> ! dbus_message_iter_append_basic (& iter , DBUS_TYPE_BOOLEAN , & runtime ) || <nl> ! dbus_message_iter_open_container (& iter , DBUS_TYPE_ARRAY , "( sv )", & sub )) <nl> return log_oom ();
static int parse_line ( const char * fname , unsigned line , const char * buffer ) { <nl> unsigned n ; <nl>  <nl> for ( n = 0 ; n < existing -> count ; n ++) { <nl> - if (! item_compatible ( existing -> items + n , & i )) <nl> + if (! item_compatible ( existing -> items + n , & i )) { <nl> log_warning ("[% s :% u ] Duplicate line for path \"% s \", ignoring .", <nl> fname , line , i . path ); <nl> + return 0 ; <nl> + } <nl> } <nl> } else { <nl> existing = new0 ( ItemArray , 1 );
This file is part of systemd . <nl>  <nl> Copyright 2010 Kay Sievers <nl> + Copyright 2016 Michal Soltys < soltys @ ziu . info > <nl>  <nl> systemd is free software ; you can redistribute it and / or modify it <nl> under the terms of the GNU Lesser General Public License as published by
static int stdout_stream_line ( StdoutStream * s , char * p ) { <nl>  <nl> case STDOUT_STREAM_PRIORITY : <nl> r = safe_atoi ( p , & s -> priority ); <nl> - if ( r < 0 || s -> priority <= 0 || s -> priority >= 999 ) { <nl> + if ( r < 0 || s -> priority < 0 || s -> priority >= 999 ) { <nl> log_warning (" Failed to parse log priority line ."); <nl> return - EINVAL ; <nl> }
static void service_set_state ( Service * s , ServiceState state ) { <nl> /* For remain_after_exit services , let ' s see if we can " release " the <nl> * hold on the console , since unit_notify () only does that in case of <nl> * change of state */ <nl> - if ( state == SERVICE_EXITED && s -> remain_after_exit && <nl> + if ( state == SERVICE_EXITED && <nl> + s -> remain_after_exit && <nl> UNIT ( s )-> manager -> n_on_console > 0 ) { <nl> - ExecContext * ec = unit_get_exec_context ( UNIT ( s )); <nl> + <nl> + ExecContext * ec ; <nl> + <nl> + ec = unit_get_exec_context ( UNIT ( s )); <nl> if ( ec && exec_context_may_touch_console ( ec )) { <nl> Manager * m = UNIT ( s )-> manager ; <nl> 
int main ( int argc , char * argv []) { <nl> if ( need_umount || need_swapoff || need_loop_detach ) { <nl> retries --; <nl>  <nl> - if ( retries <= FINALIZE_CRITICAL_ATTEMPTS ) { <nl> + if ( retries == FINALIZE_CRITICAL_ATTEMPTS ) { <nl> log_warning (" Approaching critical level to finalize filesystem and devices , try to kill all processes ."); <nl> rescue_send_signal ( SIGTERM ); <nl> rescue_send_signal ( SIGKILL ); <nl> } <nl>  <nl> if ( retries > 0 ) <nl> - log_info (" Action still required , % d tries left ", retries ); <nl> + log_info (" Action still required , % d tries left .", retries ); <nl> else { <nl> - log_error (" Tried enough but still action required need_umount =% d , need_swapoff =% d , need_loop_detach =% d ", need_umount , need_swapoff , need_loop_detach ); <nl> - r = - EBUSY ; <nl> - goto error ; <nl> + log_error (" Giving up . Actions left : Umount =% s , Swap off =% s , Loop detach =% s ", <nl> + yes_no ( need_umount ), yes_no ( need_swapoff ), yes_no ( need_loop_detach )); <nl> + break ; <nl> } <nl> } <nl> }
int dns_zone_put ( DnsZone * z , DnsScope * s , DnsResourceRecord * rr , bool probe ) { <nl> if ( established ) <nl> i -> state = DNS_ZONE_ITEM_ESTABLISHED ; <nl> else { <nl> + i -> state = DNS_ZONE_ITEM_PROBING ; <nl> + <nl> r = dns_zone_item_probe_start ( i ); <nl> if ( r < 0 ) { <nl> dns_zone_item_remove_and_free ( z , i ); <nl> i = NULL ; <nl> return r ; <nl> } <nl> - <nl> - i -> state = DNS_ZONE_ITEM_PROBING ; <nl> } <nl> } else <nl> i -> state = DNS_ZONE_ITEM_ESTABLISHED ;
int main ( int argc , char * argv []) { <nl> finish : <nl> pager_close (); <nl>  <nl> + strv_free ( arg_file ); <nl> + <nl> return r < 0 ? EXIT_FAILURE : EXIT_SUCCESS ; <nl> }
static int automount_start_expire ( Automount * a ) { <nl>  <nl> assert ( a ); <nl>  <nl> - timeout = now ( CLOCK_MONOTONIC ) + MAX ( a -> timeout_idle_usec / 10 , USEC_PER_SEC ); <nl> + timeout = now ( CLOCK_MONOTONIC ) + MAX ( a -> timeout_idle_usec / 3 , USEC_PER_SEC ); <nl>  <nl> if ( a -> expire_event_source ) { <nl> r = sd_event_source_set_time ( a -> expire_event_source , timeout );
int main ( int argc , char * argv []) { <nl> goto finish ; <nl> } <nl>  <nl> - r = cg_split_spec (* name , & c , & p ); <nl> - if ( r < 0 ) { <nl> - log_error_errno ( r , " Failed to split argument % s : % m ", * name ); <nl> + q = cg_split_spec (* name , & c , & p ); <nl> + if ( q < 0 ) { <nl> + log_error_errno ( q , " Failed to split argument % s : % m ", * name ); <nl> goto failed ; <nl> } <nl> 
int config_parse_exec_selinux_context ( <nl> } else <nl> ignore = false ; <nl>  <nl> - r = unit_name_printf ( u , rvalue , & k ); <nl> + r = unit_full_printf ( u , rvalue , & k ); <nl> if ( r < 0 ) { <nl> log_syntax ( unit , LOG_ERR , filename , line , r , " Failed to resolve specifiers , ignoring : % m "); <nl> return 0 ; <nl> int config_parse_exec_apparmor_profile ( <nl> } else <nl> ignore = false ; <nl>  <nl> - r = unit_name_printf ( u , rvalue , & k ); <nl> + r = unit_full_printf ( u , rvalue , & k ); <nl> if ( r < 0 ) { <nl> log_syntax ( unit , LOG_ERR , filename , line , r , " Failed to resolve specifiers , ignoring : % m "); <nl> return 0 ; <nl> int config_parse_exec_smack_process_label ( <nl> } else <nl> ignore = false ; <nl>  <nl> - r = unit_name_printf ( u , rvalue , & k ); <nl> + r = unit_full_printf ( u , rvalue , & k ); <nl> if ( r < 0 ) { <nl> log_syntax ( unit , LOG_ERR , filename , line , r , " Failed to resolve specifiers , ignoring : % m "); <nl> return 0 ; <nl> int config_parse_fdname ( <nl> return 0 ; <nl> } <nl>  <nl> - r = unit_name_printf ( UNIT ( s ), rvalue , & p ); <nl> + r = unit_full_printf ( UNIT ( s ), rvalue , & p ); <nl> if ( r < 0 ) { <nl> log_syntax ( unit , LOG_ERR , filename , line , r , " Failed to resolve specifiers , ignoring : % s ", rvalue ); <nl> return 0 ; <nl> int config_parse_runtime_directory ( <nl> return 0 ; <nl> } <nl>  <nl> - r = unit_name_printf ( u , word , & k ); <nl> + r = unit_full_printf ( u , word , & k ); <nl> if ( r < 0 ) { <nl> log_syntax ( unit , LOG_ERR , filename , line , r , <nl> " Failed to resolve specifiers in \"% s \", ignoring : % m ", word );
int base_filesystem_create ( const char * root ) { <nl> const char * target = NULL ; <nl> const char * s ; <nl>  <nl> + if ( faccessat ( fd , table [ i ]. dir , F_OK , AT_SYMLINK_NOFOLLOW ) >= 0 ) <nl> + continue ; <nl> + <nl> /* check if one of the targets exists */ <nl> NULSTR_FOREACH ( s , table [ i ]. target ) { <nl> if ( faccessat ( fd , s , F_OK , AT_SYMLINK_NOFOLLOW ) < 0 )
int message_append_basic ( sd_bus_message * m , char type , const void * p , const void <nl> void * a ; <nl> char * e = NULL ; <nl> int fd = - 1 ; <nl> - uint32_t fdi ; <nl> + uint32_t fdi = 0 ; <nl> int r ; <nl>  <nl> if (! m )
void dual_timestamp_serialize ( FILE * f , const char * name , dual_timestamp * t ) { <nl> } <nl>  <nl> int dual_timestamp_deserialize ( const char * value , dual_timestamp * t ) { <nl> - unsigned long long a , b ; <nl> + uint64_t a , b ; <nl>  <nl> assert ( value ); <nl> assert ( t ); <nl>  <nl> - if ( sscanf ( value , "% llu % llu ", & a , & b ) != 2 ) { <nl> + if ( sscanf ( value , "%" PRIu64 "%" PRIu64 , & a , & b ) != 2 ) { <nl> log_debug (" Failed to parse dual timestamp value \"% s \": % m ", value ); <nl> return - EINVAL ; <nl> }
int sd_rtnl_call ( sd_rtnl * rtnl , <nl> r = rtnl_poll ( rtnl , true , left ); <nl> if ( r < 0 ) <nl> return r ; <nl> + else if ( r == 0 ) <nl> + return - ETIMEDOUT ; <nl>  <nl> r = dispatch_wqueue ( rtnl ); <nl> if ( r < 0 )
Manager * manager_free ( Manager * m ) { <nl> free ( m -> switch_root_init ); <nl>  <nl> for ( i = 0 ; i < _RLIMIT_MAX ; i ++) <nl> - free ( m -> rlimit [ i ]); <nl> + m -> rlimit [ i ] = mfree ( m -> rlimit [ i ]); <nl>  <nl> assert ( hashmap_isempty ( m -> units_requiring_mounts_for )); <nl> hashmap_free ( m -> units_requiring_mounts_for ); <nl> int manager_set_default_rlimits ( Manager * m , struct rlimit ** default_rlimit ) { <nl> assert ( m ); <nl>  <nl> for ( i = 0 ; i < _RLIMIT_MAX ; i ++) { <nl> + m -> rlimit [ i ] = mfree ( m -> rlimit [ i ]); <nl> + <nl> if (! default_rlimit [ i ]) <nl> continue ; <nl> 
int config_parse_ipv6_route_preference ( const char * unit , <nl> _cleanup_route_free_ Route * n = NULL ; <nl> int r ; <nl>  <nl> + r = route_new_static ( network , filename , section_line , & n ); <nl> + if ( r < 0 ) <nl> + return r ; <nl> + <nl> if ( streq ( rvalue , " low ")) <nl> n -> pref = ICMPV6_ROUTER_PREF_LOW ; <nl> else if ( streq ( rvalue , " medium "))
finish : <nl>  <nl> dbus_shutdown (); <nl>  <nl> + if ( getpid () == 1 ) <nl> + freeze (); <nl> + <nl> return retval ; <nl> }
static int signal_name_owner_changed ( sd_bus_message * message , void * userdata , sd <nl> return 0 ; <nl> } <nl>  <nl> + old_owner = isempty ( old_owner ) ? NULL : old_owner ; <nl> + new_owner = isempty ( new_owner ) ? NULL : new_owner ; <nl> + <nl> if ( UNIT_VTABLE ( u )-> bus_name_owner_change ) <nl> UNIT_VTABLE ( u )-> bus_name_owner_change ( u , name , old_owner , new_owner ); <nl> 
Client_Key_Exchange :: Client_Key_Exchange ( Handshake_IO & io , <nl>  <nl> DL_Group group ( p , g ); <nl>  <nl> - if (! group . verify_group ( rng , true )) <nl> - throw Internal_Error (" DH group failed validation , possible attack "); <nl> + if (! group . verify_group ( rng , false )) <nl> + throw TLS_Exception ( Alert :: INSUFFICIENT_SECURITY , <nl> + " DH group validation failed "); <nl>  <nl> DH_PublicKey counterparty_key ( group , Y ); <nl> 
class Compress final : public Command <nl>  <nl> const std :: string out_file = output_filename ( in_file , comp_type ); <nl> std :: ofstream out ( out_file , std :: ios :: binary ); <nl> - if (! in . good ()) <nl> + if (! out . good ()) <nl> { <nl> throw CLI_IO_Error (" writing ", out_file ); <nl> }
krb5_get_init_creds_opt_init ( krb5_get_init_creds_opt * opt ) <nl> } <nl>  <nl> krb5_error_code <nl> - krb5_get_init_creds_opt_alloc ( krb5_get_init_creds_opt ** opt ) <nl> + krb5_get_init_creds_opt_alloc ( krb5_context context , <nl> + krb5_get_init_creds_opt ** opt ) <nl> { <nl> krb5_get_init_creds_opt * o ; <nl>  <nl> * opt = NULL ; <nl> o = calloc ( 1 , sizeof (* o )); <nl> - if ( o == NULL ) <nl> + if ( o == NULL ) { <nl> + krb5_set_error_string ( context , " out of memory "); <nl> return ENOMEM ; <nl> + } <nl> krb5_get_init_creds_opt_init ( o ); <nl> o -> private = calloc ( 1 , sizeof (* o -> private )); <nl> if ( o -> private == NULL ) { <nl> + krb5_set_error_string ( context , " out of memory "); <nl> free ( o ); <nl> return ENOMEM ; <nl> }
krb5_cc_next_cred ( krb5_context context , <nl> if ( id -> type != 1 ) <nl> abort (); <nl>  <nl> - krb5_storage_from_fd ( cursor -> fd ); <nl> - err = krb5_cc_read_cred ( sp , creds ); <nl> + sp = krb5_storage_from_fd ( cursor -> fd ); <nl> + err = krb5_cc_read_cred ( cursor -> fd , creds ); <nl> krb5_storage_free ( sp ); <nl> + return err ; <nl> } <nl>  <nl> krb5_error_code
copy_stream ( FILE * from , FILE * to ) <nl> return 0 ; <nl> off = 0 ; <nl> while ( off != st . st_size ) { <nl> - size_t len = BLOCKSIZE ; <nl> + size_t len ; <nl> ssize_t res ; <nl>  <nl> - if ( off + len > st . st_size ) <nl> - len = st . st_size - off ; <nl> + len = st . st_size - off ; <nl> + if ( len > BLOCKSIZE ) <nl> + len = BLOCKSIZE ; <nl>  <nl> chunk = mmap ( 0 , len , PROT_READ , MAP_SHARED , fileno ( from ), off ); <nl> if ( chunk == ( void *) MAP_FAILED ) {
find_all_addresses ( krb5_context context , krb5_addresses * res , int flags ) <nl> { <nl> struct sockaddr sa_zero ; <nl> struct ifaddrs * ifa0 , * ifa ; <nl> - krb5_error_code ret ; <nl> + krb5_error_code ret = ENXIO ; <nl> int num , idx ; <nl>  <nl> res -> val = NULL ;
KRB5_LIB_FUNCTION krb5_error_code KRB5_LIB_CALL <nl> krb5_ret_int16 ( krb5_storage * sp , <nl> int16_t * value ) <nl> { <nl> - int32_t v ; <nl> + int32_t v = 0 ; <nl> int ret ; <nl> ret = krb5_ret_int ( sp , & v , 2 ); <nl> if ( ret )
krb5_addlog_dest ( krb5_context context , krb5_log_facility * f , const char * orig ) <nl> ret = open_file ( context , f , min , max , NULL , NULL , stderr , 1 ); <nl> } else if ( strcmp ( p , " CONSOLE ") == 0 ){ <nl> ret = open_file ( context , f , min , max , "/ dev / console ", " w ", NULL , 0 ); <nl> - } else if ( strncmp ( p , " FILE :", 4 ) == 0 && ( p [ 4 ] == ':' || p [ 4 ] == '=')){ <nl> + } else if ( strncmp ( p , " FILE ", 4 ) == 0 && ( p [ 4 ] == ':' || p [ 4 ] == '=')){ <nl> char * fn ; <nl> FILE * file = NULL ; <nl> int keep_open = 0 ; <nl> krb5_addlog_dest ( krb5_context context , krb5_log_facility * f , const char * orig ) <nl> keep_open = 1 ; <nl> } <nl> ret = open_file ( context , f , min , max , fn , " a ", file , keep_open ); <nl> - } else if ( strncmp ( p , " DEVICE =", 6 ) == 0 ){ <nl> + } else if ( strncmp ( p , " DEVICE ", 6 ) == 0 && ( p [ 6 ] == ':' || p [ 6 ] == '=')){ <nl> ret = open_file ( context , f , min , max , strdup ( p + 7 ), " w ", NULL , 0 ); <nl> } else if ( strncmp ( p , " SYSLOG ", 6 ) == 0 && ( p [ 6 ] == '\ 0 ' || p [ 6 ] == ':')){ <nl> char severity [ 128 ] = "";
imath_rsa_public_decrypt ( int flen , const unsigned char * from , <nl> mp_int_clear (& us ); <nl>  <nl> /* head zero was skipped by mp_int_to_unsigned */ <nl> + if (* p == 0 ) <nl> + return - 7 ; <nl> if (* p != 1 ) <nl> return - 6 ; <nl> size --; p ++;
proto ( int sock , const char * service ) <nl> ( char *)( remotename . data ), ccname ); <nl> out : <nl> if ( status ) { <nl> - strcpy ( ret_string , " no "); <nl> + strlcpy ( ret_string , " no ", sizeof ( ret_string )); <nl> krb5_warnx ( context , " failed "); <nl> } else { <nl> - strcpy ( ret_string , " ok "); <nl> + strlcpy ( ret_string , " ok ", sizeof ( ret_string )); <nl> } <nl>  <nl> krb5_data_free (& tk_file );
add_enc_ts_padata ( krb5_context context , <nl> if ( salt == NULL ) { <nl> /* default to standard salt */ <nl> ret = krb5_get_pw_salt ( context , client , & salt2 ); <nl> + if ( ret ) <nl> + return ret ; <nl> salt = & salt2 ; <nl> } <nl> if (! enctypes ) {
hx509_crypto_available ( hx509_context context , <nl> continue ; <nl> if ( sig_algs [ i ]-> sig_alg == NULL ) <nl> continue ; <nl> - if ( keytype && der_heim_oid_cmp ((* sig_algs [ i ]-> key_oid )(), keytype )) <nl> + if ( keytype && sig_algs [ i ]-> key_oid && <nl> + der_heim_oid_cmp ((* sig_algs [ i ]-> key_oid )(), keytype )) <nl> continue ; <nl>  <nl> ptr = realloc (* val , sizeof (** val ) * ( len + 1 ));
retrieve ( char * cmd , char * name ) <nl> struct cmds * p ; <nl> for ( p = cmds ; p -> ext ; p ++){ <nl> char * tail = name + strlen ( name ) - strlen ( p -> ext ); <nl> + char c = * tail ; <nl>  <nl> - if ( strcmp ( tail , p -> ext ) == 0 ){ <nl> - char c = * tail ; <nl> - * tail = 0 ; <nl> + if ( strcmp ( tail , p -> ext ) == 0 && <nl> + (* tail = 0 ) == 0 && <nl> + access ( name , R_OK ) == 0 ){ <nl> snprintf ( line , sizeof ( line ), p -> cmd , name ); <nl> * tail = c ; <nl> break ; <nl> } <nl> + * tail = c ; <nl> } <nl> if ( p -> ext ){ <nl> fin = ftpd_popen ( line , " r ", 0 , 0 );
hdb_free_key ( Key * key ) <nl> krb5_error_code <nl> hdb_lock ( int fd , int operation ) <nl> { <nl> - int i , code ; <nl> + int i , code = 0 ; <nl> + <nl> for ( i = 0 ; i < 3 ; i ++){ <nl> code = flock ( fd , ( operation == HDB_RLOCK ? LOCK_SH : LOCK_EX ) | LOCK_NB ); <nl> if ( code == 0 || errno != EWOULDBLOCK )
proto ( int s , int errsock , <nl> return 1 ; <nl> } <nl>  <nl> - if ( net_read ( s , & reply , 1 ) != 1 ) { <nl> + ret = net_read ( s , & reply , 1 ); <nl> + if ( ret < 0 ) { <nl> warn (" read "); <nl> close ( errsock2 ); <nl> return 1 ; <nl> + } else if ( ret == 0 ) { <nl> + warnx (" unexpected EOF from % s ", hostname ); <nl> + close ( errsock2 ); <nl> + return 1 ; <nl> } <nl> if ( reply != 0 ) { <nl> 
realm_of_cell ( kafs_data * data , const char * cell , char ** realm ) <nl> } <nl> fclose ( F ); <nl> } <nl> - if (* realm == NULL && dns_find_cell ( cell , buf , sizeof ( buf )) == 0 ) <nl> + if (* realm == NULL && dns_find_cell ( cell , buf , sizeof ( buf )) == 0 ) { <nl> * realm = strdup ( krb_realmofhost ( buf )); <nl> + if (* realm != NULL ) <nl> + ret = 0 ; <nl> + } <nl> return ret ; <nl> } <nl> 
find_auth_cookie ( FILE * f ) <nl> Xauth * ret = NULL ; <nl> char local_hostname [ MaxHostNameLen ]; <nl> char * display = getenv (" DISPLAY "); <nl> + char d [ MaxHostNameLen + 4 ]; <nl> char * colon ; <nl> struct addrinfo * ai ; <nl> struct addrinfo hints ; <nl> int disp ; <nl> int error ; <nl>  <nl> - if ( display == NULL ) <nl> + if ( display == NULL ) <nl> display = ": 0 "; <nl> + strlcpy ( d , display , sizeof ( d )); <nl> + display = d ; <nl> colon = strchr ( display , ':'); <nl> if ( colon == NULL ) <nl> disp = 0 ;
krb5_get_error_message ( krb5_context context , krb5_error_code code ) <nl> void KRB5_LIB_FUNCTION <nl> krb5_free_error_message ( krb5_context context , const char * msg ) <nl> { <nl> - free ( msg ); <nl> + free ( rk_UNCONST ( msg )); <nl> }
HANDLE FindFirstFileA ( LPCSTR lpFileName , LPWIN32_FIND_DATAA lpFindFileData ) <nl> } <nl> } <nl>  <nl> + free ( pFileSearch ); <nl> return INVALID_HANDLE_VALUE ; <nl> } <nl> 
void update_free ( rdpUpdate * update ) <nl>  <nl> xfree ( update -> bitmap_update . rectangles ); <nl> xfree ( update -> pointer ); <nl> + xfree ( update -> primary -> polyline . points ); <nl> + xfree ( update -> primary -> polygon_sc . points ); <nl> xfree ( update -> primary ); <nl> xfree ( update -> secondary ); <nl> xfree ( update -> altsec );
uint8 * freerdp_icon_convert ( uint8 * srcData , uint8 * dstData , uint8 * mask , int wid <nl>  <nl> for ( bit = 0 ; bit < 8 ; bit ++) <nl> if (( bmask & ( 0x80 >> bit )) == 0 ) <nl> - *( icon + ( height - y ) * width + x + bit ) |= 0xFF000000 ; <nl> + *( icon + ( height - y - 1 ) * width + x + bit ) |= 0xFF000000 ; <nl> } <nl>  <nl> if (( width % 8 ) != 0 ) <nl> uint8 * freerdp_icon_convert ( uint8 * srcData , uint8 * dstData , uint8 * mask , int wid <nl>  <nl> for ( bit = 0 ; bit < width % 8 ; bit ++) <nl> if (( bmask & ( 0x80 >> bit )) == 0 ) <nl> - *( icon + ( height - y ) * width + x + bit ) |= 0xFF000000 ; <nl> + *( icon + ( height - y - 1 ) * width + x + bit ) |= 0xFF000000 ; <nl> } <nl>  <nl> /* Skip padding */ <nl> uint8 * freerdp_icon_convert ( uint8 * srcData , uint8 * dstData , uint8 * mask , int wid <nl> } <nl> } <nl>  <nl> - free ( mask ); <nl> - <nl> return dstData ; <nl> } <nl> 
BOOL drive_file_set_information ( DRIVE_FILE * file , UINT32 FsInformationClass , UIN <nl> if (! fullpath ) <nl> { <nl> WLog_ERR ( TAG , " drive_file_combine_fullpath failed !"); <nl> + free ( s ); <nl> return FALSE ; <nl> } <nl> free ( s );
boolean security_establish_keys ( uint8 * client_random , rdpRdp * rdp ) <nl>  <nl> memcpy ( rdp -> decrypt_update_key , rdp -> decrypt_key , 16 ); <nl> memcpy ( rdp -> encrypt_update_key , rdp -> encrypt_key , 16 ); <nl> + rdp -> decrypt_use_count = 0 ; <nl> + rdp -> decrypt_checksum_use_count = 0 ; <nl> + rdp -> encrypt_use_count = 0 ; <nl> + rdp -> encrypt_checksum_use_count = 0 ; <nl>  <nl> return true ; <nl> }
# include " config . h " <nl> # endif <nl>  <nl> +# include < assert . h > <nl> + <nl> # include " ntlm . h " <nl> # include "../ sspi . h " <nl>  <nl> NTLM_AV_PAIR * ntlm_av_pair_add ( NTLM_AV_PAIR * pAvPairList , NTLM_AV_ID AvId , PBYTE <nl> if (! pAvPair ) <nl> return NULL ; <nl>  <nl> + assert ( Value != NULL ); <nl> pAvPair -> AvId = AvId ; <nl> pAvPair -> AvLen = AvLen ; <nl> CopyMemory ( ntlm_av_pair_get_value_pointer ( pAvPair ), Value , AvLen );
void update_read_polyline_order ( STREAM * s , ORDER_INFO * orderInfo , POLYLINE_ORDER <nl> if ( orderInfo -> fieldFlags & ORDER_FIELD_07 ) <nl> { <nl> stream_read_uint8 ( s , polyline -> cbData ); <nl> - fprintf ( stderr , " TONG % d % d % d \ n ", sizeof ( DELTA_POINT *), polyline -> cbData , polyline -> numPoints ); <nl> + <nl> if ( polyline -> points == NULL ) <nl> - polyline -> points = ( DELTA_POINT *) xmalloc ( sizeof ( DELTA_POINT ) * polyline -> numPoints ); <nl> + polyline -> points = ( DELTA_POINT *) xmalloc ( sizeof ( DELTA_POINT ) * polyline -> cbData ); <nl> else <nl> - polyline -> points = ( DELTA_POINT *) xrealloc ( polyline -> points , sizeof ( DELTA_POINT ) * polyline -> numPoints ); <nl> + polyline -> points = ( DELTA_POINT *) xrealloc ( polyline -> points , sizeof ( DELTA_POINT ) * polyline -> cbData ); <nl>  <nl> update_read_delta_points ( s , polyline -> points , polyline -> numPoints , polyline -> xStart , polyline -> yStart ); <nl> }
HANDLE CreateNamedPipeA ( LPCSTR lpName , DWORD dwOpenMode , DWORD dwPipeMode , DWORD <nl>  <nl> WINPR_HANDLE_SET_TYPE ( pNamedPipe , HANDLE_TYPE_NAMED_PIPE ); <nl>  <nl> + pNamedPipe -> serverfd = - 1 ; <nl> + pNamedPipe -> clientfd = - 1 ; <nl> if (!( pNamedPipe -> name = _strdup ( lpName ))) <nl> goto out ; <nl> 
BOOL security_fips_decrypt ( BYTE * data , size_t length , rdpRdp * rdp ) <nl> { <nl> size_t olen ; <nl>  <nl> + if (! rdp || ! rdp -> fips_decrypt ) <nl> + return FALSE ; <nl> + <nl> if (! winpr_Cipher_Update ( rdp -> fips_decrypt , data , length , data , & olen )) <nl> return FALSE ; <nl> 
static BOOL rdp_print_input_capability_set ( wStream * s , UINT16 length ) <nl> static BOOL rdp_read_font_capability_set ( wStream * s , UINT16 length , rdpSettings * settings ) <nl> { <nl> WINPR_UNUSED ( settings ); <nl> - if ( length > 4 ) <nl> + if ( length > 5 ) <nl> Stream_Seek_UINT16 ( s ); /* fontSupportFlags ( 2 bytes ) */ <nl>  <nl> - if ( length > 6 ) <nl> + if ( length > 7 ) <nl> Stream_Seek_UINT16 ( s ); /* pad2Octets ( 2 bytes ) */ <nl>  <nl> return TRUE ;
rdpSettings * freerdp_settings_new ( DWORD flags ) <nl> settings -> NoBitmapCompressionHeader = TRUE ; <nl> settings -> RefreshRect = TRUE ; <nl> settings -> SuppressOutput = TRUE ; <nl> - settings -> GlyphSupportLevel = GLYPH_SUPPORT_FULL ; <nl> + settings -> GlyphSupportLevel = GLYPH_SUPPORT_NONE ; <nl> settings -> GlyphCache = malloc ( sizeof ( GLYPH_CACHE_DEFINITION ) * 10 ); <nl>  <nl> if (! settings -> GlyphCache )
NSC_CONTEXT * nsc_context_new ( void ) <nl> NSC_CONTEXT * nsc_context ; <nl> UINT8 i ; <nl>  <nl> - nsc_context = ( NSC_CONTEXT *) malloc ( sizeof ( NSC_CONTEXT )); <nl> - nsc_context -> priv = ( NSC_CONTEXT_PRIV *) malloc ( sizeof ( NSC_CONTEXT_PRIV )); <nl> + nsc_context = ( NSC_CONTEXT *) calloc ( 1 , sizeof ( NSC_CONTEXT )); <nl> + nsc_context -> priv = ( NSC_CONTEXT_PRIV *) calloc ( 1 , sizeof ( NSC_CONTEXT_PRIV )); <nl> for ( i = 0 ; i < 5 ; ++ i ) <nl> { <nl> nsc_context -> priv -> plane_buf [ i ] = NULL ;
static UINT handle_hotplug ( rdpdrPlugin * rdpdr ) <nl> dev_array [ size ]. path = word ; <nl> dev_array [ size ++]. to_add = TRUE ; <nl> } <nl> + else <nl> + free ( word ); <nl> } <nl> free ( line ); <nl> } <nl> static UINT handle_hotplug ( rdpdrPlugin * rdpdr ) <nl>  <nl> cleanup : <nl> for ( i = 0 ; i < size ; i ++) <nl> - free ( dev_array [ size ]. path ); <nl> + free ( dev_array [ i ]. path ); <nl>  <nl> return error ? error : rdpdr_send_device_list_announce_request ( rdpdr , TRUE ); <nl> }
BGD_DECLARE ( gdImagePtr ) gdImageCreateFromXpm ( char * filename ) <nl> return 0 ; <nl>  <nl> number = image . ncolors ; <nl> + if ( overflow2 ( sizeof ( int ), number )) { <nl> + return 0 ; <nl> + } <nl> colors = ( int *) gdMalloc ( sizeof ( int ) * number ); <nl> if ( colors == NULL ) <nl> return ( 0 );
using namespace mongoutils ; <nl>  <nl> namespace mongo { <nl>  <nl> + extern string dbpath ; <nl> void ensureParentDirCreated ( const boost :: filesystem :: path & p ){ <nl> const boost :: filesystem :: path parent = p . parent_path (); <nl>  <nl> if (! boost :: filesystem :: exists ( parent )){ <nl> + massert ( 13624 , " dbpath doesn ' t exist ", parent != dbpath ); <nl> ensureParentDirCreated ( parent ); <nl> log () << " creating directory " << parent . string () << endl ; <nl> boost :: filesystem :: create_directory ( parent );
namespace mongo { <nl> lastExtentSize = 0 ; <nl> nIndexes = 0 ; <nl> _isCapped = capped ; <nl> - _maxDocsInCapped = - 1 ; // no limit <nl> + _maxDocsInCapped = 0x7fffffff ; // no limit ( value is for pre - v2 . 3 . 2 compatability ) <nl> _paddingFactor = 1 . 0 ; <nl> _systemFlags = 0 ; <nl> _userFlags = 0 ; <nl> namespace mongo { <nl> bool NamespaceDetails :: validMaxCappedDocs ( long long * max ) { <nl> if ( * max <= 0 || <nl> * max == numeric_limits < long long >:: max () ) { <nl> - * max = - 1 ; <nl> + * max = 0x7fffffff ; <nl> return true ; <nl> } <nl>  <nl> namespace mongo { <nl>  <nl> long long NamespaceDetails :: maxCappedDocs () const { <nl> verify ( isCapped () ); <nl> - if ( _maxDocsInCapped == - 1 ) <nl> + if ( _maxDocsInCapped == 0x7fffffff ) <nl> return numeric_limits < long long >:: max (); <nl> return _maxDocsInCapped ; <nl> }
bool isBalanced ( string code ){ <nl> i ++; <nl> while ( i < code . size () && code [ i ] != '\'' ) i ++; <nl> break ; <nl> + case '\\': <nl> + if ( i + 1 < code . size () && code [ i + 1 ] == '/') i ++; <nl> + continue ; <nl> } <nl> } <nl>  <nl> public : <nl> assert ( isBalanced ( "// {" ) ); <nl> assert ( ! isBalanced ( "// \ n {" ) ); <nl> assert ( ! isBalanced ( "\"//\" {" ) ); <nl> + assert ( isBalanced ( "{ x :/ x \\//}" ) ); <nl> + assert ( ! isBalanced ( "{ \\/// }" ) ); <nl>  <nl> } <nl> } balnaced_test ;
namespace mongo { <nl> struct sigaction current ; <nl> sigaction ( SIGTRAP , NULL , & current ); <nl> if ( current . sa_handler == SIG_DFL ){ <nl> - cout << "######## 3setting up SIGTRAP handler " << endl ; <nl> signal ( SIGTRAP , SIG_IGN ); <nl> - cout << " DONE " << endl ; <nl> } <nl> } <nl> 
namespace mongo { <nl> else if ( rootNode -> getType () == STAGE_IXSCAN ) { <nl> ixScan = static_cast < IndexScanNode *>( rootNode ); <nl> } <nl> - verify ( ixScan ); <nl>  <nl> - node -> bounds = ixScan -> bounds ; <nl> - node -> hasBounds = true ; <nl> + if ( ixScan ) { <nl> + node -> bounds = ixScan -> bounds ; <nl> + node -> hasBounds = true ; <nl> + } <nl> } <nl>  <nl> for ( size_t i = 0 ; i < solns . size (); ++ i ) {
namespace mongo { <nl> double fivePct = free * 0 . 05 ; <nl> if ( fivePct > sz ) <nl> sz = fivePct ; <nl> + // we use 5 % of free space up to 50GB ( 1TB free ) <nl> + if ( fivePct > 50 . 0 * 1024 * 1024 * 1024 ) <nl> + sz = 50 . 0 * 1024 * 1024 * 1024 ; <nl> # endif <nl> } <nl> }
namespace mongo { <nl> OID lastID ; <nl> lastID . clear (); <nl> int secsToSleep = 0 ; <nl> - while ( Shard :: isMember ( _addr ) ){ <nl> + while ( ! inShutdown () && Shard :: isMember ( _addr ) ){ <nl>  <nl> if ( lastID . isSet () ){ <nl> scoped_lock lk ( _seenWritebacksLock ); <nl> namespace mongo { <nl> continue ; <nl> } <nl> catch ( std :: exception e ){ <nl> - log () << " WriteBackListener exception : " << e . what () << endl ; <nl>  <nl> + if ( inShutdown () ){ <nl> + // we ' re shutting down , so just clean up <nl> + return ; <nl> + } <nl> + <nl> + log () << " WriteBackListener exception : " << e . what () << endl ; <nl> + <nl> // It ' s possible this shard was removed <nl> Shard :: reloadShardInfo (); <nl> }
namespace mongo { <nl> } <nl>  <nl> inline bool BSONObj :: isValid (){ <nl> - return objsize () > 0 && objsize () <= 1024 * 1024 * 16 ; <nl> + return objsize () > 0 && objsize () <= 1024 * 1024 * 8 ; <nl> } <nl>  <nl> inline bool BSONObj :: getObjectID ( BSONElement & e ) {
namespace mongo { <nl> DBClientConnection * DBClientReplicaSet :: checkMaster () { <nl> HostAndPort h = _monitor -> getMaster (); <nl>  <nl> - if ( h == _masterHost ) { <nl> + if ( h == _masterHost && _master ) { <nl> // a master is selected . let ' s just make sure connection didn ' t die <nl> if ( ! _master -> isFailed () ) <nl> return _master . get (); <nl> namespace mongo { <nl> DBClientConnection * DBClientReplicaSet :: checkSlave () { <nl> HostAndPort h = _monitor -> getSlave ( _slaveHost ); <nl>  <nl> - if ( h == _slaveHost ) { <nl> + if ( h == _slaveHost && _slave ) { <nl> if ( ! _slave -> isFailed () ) <nl> return _slave . get (); <nl> _monitor -> notifySlaveFailure ( _slaveHost );
cling :: InvocationOptions :: CreateFromArgs ( int argc , const char * const argv [], <nl> void cling :: InvocationOptions :: PrintHelp () { <nl> llvm :: OwningPtr < OptTable > Opts ( CreateClingOptTable ()); <nl>  <nl> - // We need stream that doesn ' t close its file descriptor , thus we are not <nl> - // using llvm :: outs . Keeping file descriptor open we will be able to use <nl> - // the results in pipes ( Savannah # 99234 ). <nl> - Opts -> PrintHelp ( llvm :: errs (), " cling ", <nl> + Opts -> PrintHelp ( llvm :: outs (), " cling ", <nl> " cling : LLVM / clang C ++ Interpreter : http :// cern . ch / cling "); <nl>  <nl> llvm :: OwningPtr < OptTable > OptsC1 ( clang :: driver :: createDriverOptTable ()); <nl> - OptsC1 -> PrintHelp ( llvm :: errs (), " clang - cc1 ", <nl> + OptsC1 -> PrintHelp ( llvm :: outs (), " clang - cc1 ", <nl> " LLVM ' Clang ' Compiler : http :// clang . llvm . org "); <nl>  <nl> }
namespace ROOT { <nl>  <nl>  <nl> /** <nl> - Provide to the solver the function and an initial estimate of the Root , <nl> + Provide to the solver the function and an initial estimate of the root , <nl> for algorithms using derivatives . <nl> The templated function f must be of a type implementing the \ a operator () <nl> and the \ a Gradient () methods . <nl> namespace ROOT { <nl> Returns non zero if starting point is not valid <nl> */ <nl>  <nl> - int SetFunction ( const IGradFunction & f , double Root ) { <nl> - return fSolver -> SetFunction ( f , Root ); <nl> + int SetFunction ( const IGradFunction & f , double xstart ) { <nl> + return fSolver -> SetFunction ( f , xstart ); <nl> } <nl>  <nl> /**
namespace cling { <nl> ///\ param [ in ] file1 - A file to diff <nl> ///\ param [ in ] file2 - A file to diff <nl> ///\ param [ in ] differences - The differences if any between file1 and file2 <nl> + ///\ param [ in ] ignores - A list of differences to ignore . <nl> ///\ returns true if there is difference in the contents . <nl> /// <nl> bool differentContent ( const std :: string & file1 , const std :: string & file2 ,
-// @(#) root / win32 :$ Name : $:$ Id : TGWin32 . h , v 1 . 5 2000 / 10 / 19 10 : 42 : 31 rdm Exp $ <nl> +// @(#) root / win32 :$ Name : $:$ Id : TGWin32 . h , v 1 . 6 2001 / 04 / 03 10 : 34 : 28 rdm Exp $ <nl> // Author : Valery Fine 28 / 11 / 94 <nl>  <nl> /************************************************************************* <nl> public : <nl> virtual Window_t CreateWindow ( Window_t parent , Int_t x , Int_t y , <nl> UInt_t w , UInt_t h , UInt_t border , <nl> Int_t depth , UInt_t clss , <nl> - void * visual , SetWindowAttributes_t * attr <nl> + void * visual , SetWindowAttributes_t * attr , <nl> UInt_t wtype ); <nl> virtual Int_t OpenDisplay ( const char * dpyName ); <nl> virtual void CloseDisplay () { }
namespace cling { <nl> llvm :: StringRef RelativePath , <nl> const clang :: Module * Imported ) { <nl>  <nl> + if (! File ) <nl> + return ; <nl> auto iterator = m_Map . find ( File -> getUID ()); <nl> if ( iterator == m_Map . end ()) <nl> return ; // nothing to do , file not referred in any annotation
public : <nl> void SetParam ( Long64_t ll ); <nl> void SetParam ( ULong64_t ull ); <nl>  <nl> + template < typename ... T > void SetParams ( const T &... params ) { <nl> + if (! fFunc ) return ; <nl> + gInterpreter -> CallFunc_SetArguments ( fFunc , params ...); <nl> + } <nl> + <nl> void Execute ( void * object ); <nl> void Execute ( void * object , const char * params ); <nl> void Execute ( void * object , Long_t & retLong );
void ff_MPV_frame_end ( MpegEncContext * s ) <nl> s -> avctx -> coded_frame = & s -> current_picture_ptr -> f ; <nl>  <nl> if ( s -> codec_id != CODEC_ID_H264 && s -> current_picture . f . reference ) { <nl> - ff_thread_report_progress (& s -> current_picture_ptr -> f , <nl> - s -> mb_height - 1 , 0 ); <nl> + ff_thread_report_progress (& s -> current_picture_ptr -> f , INT_MAX , 0 ); <nl> } <nl> } <nl> 
int ff_mov_write_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> else <nl> samples_in_chunk = 1 ; <nl>  <nl> + if ( samples_in_chunk < 1 ) { <nl> + av_log ( s , AV_LOG_ERROR , " fatal error , input packet contains no samples \ n "); <nl> + return AVERROR_PATCHWELCOME ; <nl> + } <nl> + <nl> /* copy extradata if it exists */ <nl> if ( trk -> vos_len == 0 && par -> extradata_size > 0 && <nl> ! TAG_IS_AVCI ( trk -> tag ) &&
# include " avformat . h " <nl> # include " internal . h " <nl>  <nl> -# include " libavutil / avassert . h " <nl> # include " libavutil / log . h " <nl> # include " libavutil / opt . h " <nl> # include " libavutil / avstring . h " <nl> static int parse_times ( void * log_ctx , int64_t ** times , int * nb_times , <nl> for ( i = 0 ; i < * nb_times ; i ++) { <nl> int64_t t ; <nl> char * tstr = av_strtok ( p , ",", & saveptr ); <nl> - av_assert0 ( tstr ); <nl> p = NULL ; <nl>  <nl> + if (! tstr || ! tstr [ 0 ]) { <nl> + av_log ( log_ctx , AV_LOG_ERROR , " Empty time specification in times list % s \ n ", <nl> + times_str ); <nl> + FAIL ( AVERROR ( EINVAL )); <nl> + } <nl> + <nl> ret = av_parse_time (& t , tstr , 1 ); <nl> if ( ret < 0 ) { <nl> av_log ( log_ctx , AV_LOG_ERROR , <nl> - " Invalid time duration specification in % s \ n ", p ); <nl> + " Invalid time duration specification '% s ' in times list % s \ n ", tstr , times_str ); <nl> FAIL ( AVERROR ( EINVAL )); <nl> } <nl> (* times )[ i ] = t ;
static int read_var_block_data ( ALSDecContext * ctx , ALSBlockData * bd ) <nl> for ( k = 1 ; k < sub_blocks ; k ++) <nl> s [ k ] = s [ k - 1 ] + decode_rice ( gb , 0 ); <nl> } <nl> + for ( k = 1 ; k < sub_blocks ; k ++) <nl> + if ( s [ k ] > 32 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " k invalid for rice code .\ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl>  <nl> if ( get_bits1 ( gb )) <nl> * bd -> shift_lsbs = get_bits ( gb , 4 ) + 1 ;
static int mpeg_decode_slice ( Mpeg1Context * s1 , int mb_y , <nl> break ; <nl> } <nl> } <nl> + if ( s -> mb_x >= ( unsigned ) s -> mb_width ){ <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " initial skip overflow \ n "); <nl> + return - 1 ; <nl> + } <nl>  <nl> s -> resync_mb_x = s -> mb_x ; <nl> s -> resync_mb_y = s -> mb_y = mb_y ;
decode_intra_mb : <nl>  <nl> // We assume these blocks are very rare so we do not optimize it . <nl> h -> intra_pcm_ptr = align_get_bits (& h -> gb ); <nl> + if ( get_bits_left (& h -> gb ) < mb_size ) { <nl> + av_log ( h -> avctx , AV_LOG_ERROR , " Not enough data for an intra PCM block .\ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> skip_bits_long (& h -> gb , mb_size ); <nl>  <nl> // In deblocking , the quantizer is 0
static int process_audio_header_elements ( AVFormatContext * s ) <nl> } <nl>  <nl> switch ( compression_type ) { <nl> + case 0 : ea -> audio_codec = CODEC_ID_PCM_S16LE ; break ; <nl> case 7 : ea -> audio_codec = CODEC_ID_ADPCM_EA ; break ; <nl> default : <nl> av_log ( s , AV_LOG_ERROR , " unsupported stream type ; compression_type =% i \ n ", compression_type );
static void video_audio_display ( VideoState * s ) <nl> { <nl> int i , i_start , x , y1 , y , ys , delay , n , nb_display_channels ; <nl> int ch , channels , h , h2 , bgcolor , fgcolor ; <nl> - int16_t time_diff ; <nl> + int64_t time_diff ; <nl> int rdft_bits , nb_freq ; <nl>  <nl> for ( rdft_bits = 1 ; ( 1 << rdft_bits ) < 2 * s -> height ; rdft_bits ++)
static int has_codec_parameters ( AVCodecContext * enc ) <nl> val = enc -> sample_rate && enc -> channels && enc -> sample_fmt != SAMPLE_FMT_NONE ; <nl> if (! enc -> frame_size && <nl> ( enc -> codec_id == CODEC_ID_VORBIS || <nl> - enc -> codec_id == CODEC_ID_AAC )) <nl> + enc -> codec_id == CODEC_ID_AAC || <nl> + enc -> codec_id == CODEC_ID_SPEEX )) <nl> return 0 ; <nl> break ; <nl> case CODEC_TYPE_VIDEO :
static int yuv4_read_header ( AVFormatContext * s ) <nl> enum AVPixelFormat pix_fmt = AV_PIX_FMT_NONE , alt_pix_fmt = AV_PIX_FMT_NONE ; <nl> enum AVChromaLocation chroma_sample_location = AVCHROMA_LOC_UNSPECIFIED ; <nl> AVStream * st ; <nl> - enum AVFieldOrder field_order ; <nl> + enum AVFieldOrder field_order = AV_FIELD_UNKNOWN ; <nl>  <nl> for ( i = 0 ; i < MAX_YUV4_HEADER ; i ++) { <nl> header [ i ] = avio_r8 ( pb );
static int decode_frame ( AVCodecContext * avctx , void * data , <nl> out : <nl>  <nl> s -> current_picture_ptr = NULL ; <nl> + s -> first_field = 0 ; <nl>  <nl> // FIXME factorize this with the output code below <nl> out = h -> delayed_pic [ 0 ];
static int r3d_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> case MKTAG (' R ',' E ',' D ',' A '): <nl> if (! r3d -> audio_channels ) <nl> return - 1 ; <nl> - if ( s -> streams [ 1 ]-> discard == AVDISCARD_ALL ) <nl> + if ( s -> nb_streams >= 2 && s -> streams [ 1 ]-> discard == AVDISCARD_ALL ) <nl> goto skip ; <nl> if (!( err = r3d_read_reda ( s , pkt , & atom ))) <nl> return 0 ;
again : <nl> av_log ( h -> avctx , AV_LOG_ERROR , " decode_slice_header error \ n "); <nl> sl -> ref_count [ 0 ] = sl -> ref_count [ 1 ] = sl -> list_count = 0 ; <nl> } else if ( err == SLICE_SINGLETHREAD ) { <nl> - ret = ff_h264_execute_decode_slices ( h , context_count ); <nl> - if ( ret < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE )) <nl> - goto end ; <nl> - context_count = 0 ; <nl> + if ( context_count > 0 ) { <nl> + ret = ff_h264_execute_decode_slices ( h , context_count ); <nl> + if ( ret < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE )) <nl> + goto end ; <nl> + context_count = 0 ; <nl> + } <nl> /* Slice could not be decoded in parallel mode , restart . Note <nl> * that rbsp_buffer is not transferred , but since we no longer <nl> * run in parallel mode this should not be an issue . */
av_cold int ff_yuv2rgb_c_init_tables ( SwsContext * c , const int inv_table [ 4 ], <nl> cgu = (( cgu << 16 ) + 0x8000 ) / cy ; <nl> cgv = (( cgv << 16 ) + 0x8000 ) / cy ; <nl>  <nl> - av_free ( c -> yuvTable ); <nl> + av_freep (& c -> yuvTable ); <nl>  <nl> switch ( bpp ) { <nl> case 1 : <nl> av_cold int ff_yuv2rgb_c_init_tables ( SwsContext * c , const int inv_table [ 4 ], <nl> fill_gv_table ( c -> table_gV , 4 , cgv ); <nl> break ; <nl> default : <nl> - c -> yuvTable = NULL ; <nl> if (! isPlanar ( c -> dstFormat ) || bpp <= 24 ) <nl> av_log ( c , AV_LOG_ERROR , "% ibpp not supported by yuv2rgb \ n ", bpp ); <nl> return - 1 ;
static void alloc_picture ( void * opaque ) <nl> vp -> bmp = SDL_CreateYUVOverlay ( vp -> width , vp -> height , <nl> SDL_YV12_OVERLAY , <nl> screen ); <nl> + if (! vp -> bmp || vp -> bmp -> pitches [ 0 ] < vp -> width ) { <nl> + /* SDL allocates a buffer smaller than requested if the video <nl> + * overlay hardware is unable to support the requested size . */ <nl> + fprintf ( stderr , " Error : the video system does not support an image \ n " <nl> + " size of % dx % d pixels . Try using - vf \" scale = w : h \"\ n " <nl> + " to reduce the image size .\ n ", vp -> width , vp -> height ); <nl> + do_exit (); <nl> + } <nl>  <nl> SDL_LockMutex ( is -> pictq_mutex ); <nl> vp -> allocated = 1 ;
static void copy_cell ( Indeo3DecodeContext * ctx , Plane * plane , Cell * cell ) <nl> /* setup output and reference pointers */ <nl> offset_dst = ( cell -> ypos << 2 ) * plane -> pitch + ( cell -> xpos << 2 ); <nl> dst = plane -> pixels [ ctx -> buf_sel ] + offset_dst ; <nl> + if ( cell -> mv_ptr ){ <nl> mv_y = cell -> mv_ptr [ 0 ]; <nl> mv_x = cell -> mv_ptr [ 1 ]; <nl> + } else <nl> + mv_x = mv_y = 0 ; <nl> offset = offset_dst + mv_y * plane -> pitch + mv_x ; <nl> src = plane -> pixels [ ctx -> buf_sel ^ 1 ] + offset ; <nl> 
void ff_frame_thread_free ( AVCodecContext * avctx , int thread_count ) <nl> av_freep (& p -> avctx -> slice_offset ); <nl> } <nl>  <nl> + av_buffer_unref (& p -> avctx -> hw_frames_ctx ); <nl> + <nl> av_freep (& p -> avctx -> internal ); <nl> av_freep (& p -> avctx ); <nl> }
void avfilter_destroy ( AVFilterContext * filter ) <nl>  <nl> for ( i = 0 ; i < filter -> input_count ; i ++) { <nl> if ( filter -> inputs [ i ]) { <nl> + if ( filter -> inputs [ i ]-> src ) <nl> filter -> inputs [ i ]-> src -> outputs [ filter -> inputs [ i ]-> srcpad ] = NULL ; <nl> avfilter_formats_unref (& filter -> inputs [ i ]-> in_formats ); <nl> avfilter_formats_unref (& filter -> inputs [ i ]-> out_formats ); <nl> void avfilter_destroy ( AVFilterContext * filter ) <nl> } <nl> for ( i = 0 ; i < filter -> output_count ; i ++) { <nl> if ( filter -> outputs [ i ]) { <nl> + if ( filter -> outputs [ i ]-> dst ) <nl> filter -> outputs [ i ]-> dst -> inputs [ filter -> outputs [ i ]-> dstpad ] = NULL ; <nl> avfilter_formats_unref (& filter -> outputs [ i ]-> in_formats ); <nl> avfilter_formats_unref (& filter -> outputs [ i ]-> out_formats );
static int decode_frame ( NUTContext * nut , AVPacket * pkt , int frame_code ) <nl> if ( ret != size ) { <nl> if ( ret < 0 ) <nl> return ret ; <nl> - av_shrink_packet ( pkt , nut -> header_len [ header_idx ] + size ); <nl> } <nl> + av_shrink_packet ( pkt , nut -> header_len [ header_idx ] + ret ); <nl>  <nl> pkt -> stream_index = stream_id ; <nl> if ( stc -> last_flags & FLAG_KEY )
void checkasm_stack_clobber ( uint64_t clobber , ...); <nl> }\ <nl> } while ( 0 ) <nl> # else <nl> -# define bench_new (...) <nl> +# define bench_new (...) while ( 0 ) <nl> # endif <nl>  <nl> # endif
static int asf_read_frame_header ( AVFormatContext * s , AVIOContext * pb ){ <nl> } <nl> if ( asf -> packet_flags & 0x01 ) { <nl> DO_2BITS ( asf -> packet_segsizetype >> 6 , asf -> packet_frag_size , 0 ); // 0 is illegal <nl> - if ( asf -> packet_frag_size > asf -> packet_size_left - rsize ){ <nl> + if ( rsize > asf -> packet_size_left ) { <nl> + av_log ( s , AV_LOG_ERROR , " packet_replic_size is invalid \ n "); <nl> + return - 1 ; <nl> + } else if ( asf -> packet_frag_size > asf -> packet_size_left - rsize ){ <nl> if ( asf -> packet_frag_size > asf -> packet_size_left - rsize + asf -> packet_padsize ) { <nl> av_log ( s , AV_LOG_ERROR , " packet_frag_size is invalid (% d -% d )\ n ", asf -> packet_size_left , rsize ); <nl> return - 1 ;
static int add_candidate_ref ( HEVCContext * s , RefPicList * list , <nl> { <nl> HEVCFrame * ref = find_ref_idx ( s , poc ); <nl>  <nl> - if ( ref == s -> ref ) <nl> + if ( ref == s -> ref || list -> nb_refs >= HEVC_MAX_REFS ) <nl> return AVERROR_INVALIDDATA ; <nl>  <nl> if (! ref ) {
typedef struct SPS { <nl> int mb_aff ; ///< mb_adaptive_frame_field_flag <nl> int direct_8x8_inference_flag ; <nl> int crop ; ///< frame_cropping_flag <nl> - int crop_left ; ///< frame_cropping_rect_left_offset <nl> - int crop_right ; ///< frame_cropping_rect_right_offset <nl> - int crop_top ; ///< frame_cropping_rect_top_offset <nl> - int crop_bottom ; ///< frame_cropping_rect_bottom_offset <nl> + unsigned int crop_left ; ///< frame_cropping_rect_left_offset <nl> + unsigned int crop_right ; ///< frame_cropping_rect_right_offset <nl> + unsigned int crop_top ; ///< frame_cropping_rect_top_offset <nl> + unsigned int crop_bottom ; ///< frame_cropping_rect_bottom_offset <nl> int vui_parameters_present_flag ; <nl> AVRational sar ; <nl> int timing_info_present_flag ;
static void free_tables ( H264Context * h ){ <nl> av_freep (& h -> mb2b_xy ); <nl> av_freep (& h -> mb2b8_xy ); <nl>  <nl> - for ( i = 0 ; i < h -> s . avctx -> thread_count ; i ++) { <nl> + for ( i = 0 ; i < MAX_THREADS ; i ++) { <nl> hx = h -> thread_context [ i ]; <nl> if (! hx ) continue ; <nl> av_freep (& hx -> top_borders [ 1 ]);
int update_dimensions ( VP8Context * s , int width , int height , int is_vp7 ) <nl> s -> mb_height = ( s -> avctx -> coded_height + 15 ) / 16 ; <nl>  <nl> s -> mb_layout = is_vp7 || avctx -> active_thread_type == FF_THREAD_SLICE && <nl> - FFMIN ( s -> num_coeff_partitions , avctx -> thread_count ) > 1 ; <nl> + avctx -> thread_count > 1 ; <nl> if (! s -> mb_layout ) { // Frame threading and one thread <nl> s -> macroblocks_base = av_mallocz (( s -> mb_width + s -> mb_height * 2 + 1 ) * <nl> sizeof (* s -> macroblocks ));
static int mov_read_chpl ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl> return 0 ; <nl> } <nl>  <nl> +# define MIN_DATA_ENTRY_BOX_SIZE 12 <nl> static int mov_read_dref ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl> { <nl> AVStream * st ; <nl> static int mov_read_dref ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl>  <nl> avio_rb32 ( pb ); // version + flags <nl> entries = avio_rb32 ( pb ); <nl> - if ( entries >= UINT_MAX / sizeof (* sc -> drefs )) <nl> + if ( entries > ( atom . size - 1 ) / MIN_DATA_ENTRY_BOX_SIZE + 1 || <nl> + entries >= UINT_MAX / sizeof (* sc -> drefs )) <nl> return AVERROR_INVALIDDATA ; <nl> av_free ( sc -> drefs ); <nl> sc -> drefs = av_mallocz ( entries * sizeof (* sc -> drefs ));
static int dca_parse_audio_coding_header ( DCAContext * s , int base_channel , <nl> if ( get_bits1 (& s -> gb )) { <nl> embedded_downmix = get_bits1 (& s -> gb ); <nl> coeff = get_bits (& s -> gb , 6 ); <nl> + <nl> + if ( coeff < 1 || coeff > 61 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " 6bit coeff % d is out of range \ n ", coeff ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> scale_factor = - 1 . 0f / dca_dmix_code (( coeff << 2 )- 3 ); <nl>  <nl> s -> xxch_dmix_sf [ s -> xxch_chset ] = scale_factor ; <nl> static int dca_parse_audio_coding_header ( DCAContext * s , int base_channel , <nl>  <nl> coeff = get_bits (& s -> gb , 7 ); <nl> ichan = dca_xxch2index ( s , 1 << i ); <nl> + if (( coeff & 63 )< 1 || ( coeff & 63 )> 61 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " 7bit coeff % d is out of range \ n ", coeff ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> s -> xxch_dmix_coeff [ j ][ ichan ] = dca_dmix_code (( coeff << 2 )- 3 ); <nl> } <nl> }
static int frame_thread_init ( AVCodecContext * avctx ) <nl> FrameThreadContext * fctx ; <nl> int i , err = 0 ; <nl>  <nl> + if ( thread_count <= 1 ) { <nl> + avctx -> active_thread_type = 0 ; <nl> + return 0 ; <nl> + } <nl> + <nl> avctx -> thread_opaque = fctx = av_mallocz ( sizeof ( FrameThreadContext )); <nl>  <nl> fctx -> threads = av_mallocz ( sizeof ( PerThreadContext ) * thread_count ); <nl> int ff_thread_init ( AVCodecContext * avctx , int thread_count ) <nl> return - 1 ; <nl> } <nl>  <nl> - avctx -> thread_count = FFMAX ( 1 , thread_count ); <nl> - <nl> if ( avctx -> codec ) { <nl> validate_thread_parameters ( avctx ); <nl> 
int ff_get_wav_header ( AVIOContext * pb , AVCodecContext * codec , int size ) <nl> if ( size > 0 ) <nl> avio_skip ( pb , size ); <nl> } <nl> + if ( codec -> sample_rate <= 0 ) { <nl> + av_log ( NULL , AV_LOG_ERROR , <nl> + " Invalid sample rate : % d \ n ", codec -> sample_rate ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> if ( codec -> codec_id == AV_CODEC_ID_AAC_LATM ) { <nl> /* Channels and sample_rate values are those prior to applying SBR <nl> * and / or PS . */
static void update_stream_timings ( AVFormatContext * ic ) <nl> end_time1 = av_rescale_q_rnd ( st -> duration , st -> time_base , <nl> AV_TIME_BASE_Q , <nl> AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX ); <nl> - if ( end_time1 != AV_NOPTS_VALUE ) { <nl> + if ( end_time1 != AV_NOPTS_VALUE && start_time1 <= INT64_MAX - end_time1 ) { <nl> end_time1 += start_time1 ; <nl> end_time = FFMAX ( end_time , end_time1 ); <nl> }
static int parse_video_info ( AVIOContext * pb , AVStream * st ) <nl> st -> codecpar -> codec_id = ff_codec_get_id ( ff_codec_bmp_tags , tag ); <nl> size_bmp = FFMAX ( size_asf , size_bmp ); <nl>  <nl> - if ( size_bmp > BMP_HEADER_SIZE ) { <nl> + if ( size_bmp > BMP_HEADER_SIZE && <nl> + size_bmp < INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE ) { <nl> int ret ; <nl> st -> codecpar -> extradata_size = size_bmp - BMP_HEADER_SIZE ; <nl> if (!( st -> codecpar -> extradata = av_malloc ( st -> codecpar -> extradata_size +
static float wv_get_value_float ( WavpackFrameContext * s , uint32_t * crc , int S ) <nl> } <nl>  <nl> if ( S ) { <nl> - S <<= s -> float_shift ; <nl> + S *= 1 << s -> float_shift ; <nl> sign = S < 0 ; <nl> if ( sign ) <nl> S = - S ;
int ff_h264_frame_start ( H264Context * h ) <nl>  <nl> if (( ret = alloc_picture ( h , pic )) < 0 ) <nl> return ret ; <nl> - if (! h -> sync && ! h -> avctx -> hwaccel ) <nl> + if (! h -> sync && ! h -> avctx -> hwaccel && <nl> + !( h -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU )) <nl> avpriv_color_frame (& pic -> f , c ); <nl>  <nl> h -> cur_pic_ptr = pic ;
static av_always_inline float quantize_and_encode_band_cost_template ( <nl> if ( BT_ESC ) { <nl> for ( j = 0 ; j < 2 ; j ++) { <nl> if ( ff_aac_codebook_vectors [ cb - 1 ][ curidx * 2 + j ] == 64 . 0f ) { <nl> - int coef = av_clip_uintp2 ( quant ( fabsf ( in [ i + j ]), Q , ROUNDING ), 13 ); <nl> + int coef = av_clip ( quant ( fabsf ( in [ i + j ]), Q , ROUNDING ), 0 , ( 1 << 13 ) - 1 ); <nl> int len = av_log2 ( coef ); <nl>  <nl> put_bits ( pb , len - 4 + 1 , ( 1 << ( len - 4 + 1 )) - 2 );
int ff_h263_decode_picture_header ( MpegEncContext * s ) <nl> } <nl>  <nl> ff_h263_show_pict_info ( s ); <nl> - if ( s -> pict_type == AV_PICTURE_TYPE_I && s -> codec_tag == AV_RL32 (" ZYGO ")){ <nl> + if ( s -> pict_type == AV_PICTURE_TYPE_I && s -> codec_tag == AV_RL32 (" ZYGO ") && get_bits_left (& s -> gb ) >= 85 + 13 * 3 * 16 + 50 ){ <nl> int i , j ; <nl> for ( i = 0 ; i < 85 ; i ++) av_log ( s -> avctx , AV_LOG_DEBUG , "% d ", get_bits1 (& s -> gb )); <nl> av_log ( s -> avctx , AV_LOG_DEBUG , "\ n ");
static int unpack_modes ( Vp3DecodeContext * s , GetBitContext * gb ) <nl> */ <nl> static int unpack_vectors ( Vp3DecodeContext * s , GetBitContext * gb ) <nl> { <nl> - int i , j , k ; <nl> + int i , j , k , l ; <nl> int coding_mode ; <nl> int motion_x [ 6 ]; <nl> int motion_y [ 6 ]; <nl> static int unpack_vectors ( Vp3DecodeContext * s , GetBitContext * gb ) <nl> * Y fragment , then average for the C fragment vectors */ <nl> motion_x [ 4 ] = motion_y [ 4 ] = 0 ; <nl> for ( k = 0 ; k < 4 ; k ++) { <nl> + for ( l = 0 ; l < s -> coded_fragment_list_index ; l ++) <nl> + if ( s -> coded_fragment_list [ l ] == s -> macroblock_fragments [ 6 * current_macroblock + k ]) <nl> + break ; <nl> + if ( l < s -> coded_fragment_list_index ) { <nl> if ( coding_mode == 0 ) { <nl> motion_x [ k ] = motion_vector_table [ get_vlc2 ( gb , s -> motion_vector_vlc . table , 6 , 2 )]; <nl> motion_y [ k ] = motion_vector_table [ get_vlc2 ( gb , s -> motion_vector_vlc . table , 6 , 2 )]; <nl> static int unpack_vectors ( Vp3DecodeContext * s , GetBitContext * gb ) <nl> } <nl> last_motion_x = motion_x [ k ]; <nl> last_motion_y = motion_y [ k ]; <nl> + } else { <nl> + motion_x [ k ] = 0 ; <nl> + motion_y [ k ] = 0 ; <nl> + } <nl> motion_x [ 4 ] += motion_x [ k ]; <nl> motion_y [ 4 ] += motion_y [ k ]; <nl> }
int ff_hevc_parse_sps ( HEVCSPS * sps , GetBitContext * gb , unsigned int * sps_id , <nl> sps -> temporal_layer [ i ]. max_dec_pic_buffering = get_ue_golomb_long ( gb ) + 1 ; <nl> sps -> temporal_layer [ i ]. num_reorder_pics = get_ue_golomb_long ( gb ); <nl> sps -> temporal_layer [ i ]. max_latency_increase = get_ue_golomb_long ( gb ) - 1 ; <nl> - if ( sps -> temporal_layer [ i ]. max_dec_pic_buffering > HEVC_MAX_DPB_SIZE ) { <nl> + if ( sps -> temporal_layer [ i ]. max_dec_pic_buffering > ( unsigned ) HEVC_MAX_DPB_SIZE ) { <nl> av_log ( avctx , AV_LOG_ERROR , " sps_max_dec_pic_buffering_minus1 out of range : % d \ n ", <nl> - sps -> temporal_layer [ i ]. max_dec_pic_buffering - 1 ); <nl> + sps -> temporal_layer [ i ]. max_dec_pic_buffering - 1U ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> if ( sps -> temporal_layer [ i ]. num_reorder_pics > sps -> temporal_layer [ i ]. max_dec_pic_buffering - 1 ) {
static int encode_block ( SVQ1Context * s , uint8_t * src , uint8_t * ref , uint8_t * dec <nl> } <nl>  <nl> best_count = 0 ; <nl> - best_score -= (( block_sum [ 0 ]* block_sum [ 0 ])>>( level + 3 )); <nl> + best_score -= ( int )((( unsigned ) block_sum [ 0 ]* block_sum [ 0 ])>>( level + 3 )); <nl> best_mean = ( block_sum [ 0 ] + ( size >> 1 )) >> ( level + 3 ); <nl>  <nl> if ( level < 4 ){
static int vorbis_parse ( AVCodecParserContext * s1 , AVCodecContext * avctx , <nl>  <nl> if (! s -> vp && avctx -> extradata && avctx -> extradata_size ) { <nl> s -> vp = av_vorbis_parse_init ( avctx -> extradata , avctx -> extradata_size ); <nl> - if (! s -> vp ) <nl> - goto end ; <nl> } <nl> + if (! s -> vp ) <nl> + goto end ; <nl>  <nl> if (( duration = av_vorbis_parse_frame ( s -> vp , buf , buf_size )) >= 0 ) <nl> s1 -> duration = duration ;
retry : <nl> " Skipping flv packet : type % d , size % d , flags % d .\ n ", <nl> type , size , flags ); <nl> skip : <nl> - avio_seek ( s -> pb , next , SEEK_SET ); <nl> + if ( avio_seek ( s -> pb , next , SEEK_SET ) != next ) { <nl> + // This can happen if flv_read_metabody above read past <nl> + // next , on a non - seekable input , and the preceding data has <nl> + // been flushed out from the IO buffer . <nl> + av_log ( s , AV_LOG_ERROR , " Unable to seek to the next packet \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> ret = FFERROR_REDO ; <nl> goto leave ; <nl> }
static double bessel ( double x ){ <nl> lastv = v ; <nl> t *= x * inv [ i ]; <nl> v += t ; <nl> + av_assert2 ( i < 99 ); <nl> } <nl> return v ; <nl> }
redo_frame : <nl> || !( height >>( s -> chroma_v_shift + s -> spatial_decomposition_count ))) <nl> s -> spatial_decomposition_count --; <nl>  <nl> + if ( s -> spatial_decomposition_count <= 0 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Resolution too low \ n "); <nl> + return AVERROR ( EINVAL ); <nl> + } <nl> + <nl> s -> m . pict_type = pic -> pict_type ; <nl> s -> qbias = pic -> pict_type == AV_PICTURE_TYPE_P ? 2 : 0 ; <nl> 
static int get_last_needed_nal ( H264Context * h ) <nl> int nals_needed = 0 ; <nl> int first_slice = 0 ; <nl> int i ; <nl> + int ret ; <nl>  <nl> for ( i = 0 ; i < h -> pkt . nb_nals ; i ++) { <nl> H2645NAL * nal = & h -> pkt . nals [ i ]; <nl> static int get_last_needed_nal ( H264Context * h ) <nl> case NAL_DPA : <nl> case NAL_IDR_SLICE : <nl> case NAL_SLICE : <nl> - init_get_bits8 (& gb , nal -> data + 1 , ( nal -> size - 1 )); <nl> + ret = init_get_bits8 (& gb , nal -> data + 1 , ( nal -> size - 1 )); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> if (! get_ue_golomb_long (& gb ) || // first_mb_in_slice <nl> ! first_slice || <nl> first_slice != nal -> type ) <nl> static int decode_nal_units ( H264Context * h , const uint8_t * buf , int buf_size , <nl>  <nl> if ( avctx -> active_thread_type & FF_THREAD_FRAME ) <nl> nals_needed = get_last_needed_nal ( h ); <nl> + if ( nals_needed < 0 ) <nl> + return nals_needed ; <nl>  <nl> for ( i = 0 ; i < h -> pkt . nb_nals ; i ++) { <nl> H2645NAL * nal = & h -> pkt . nals [ i ];
static int read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> p -> current_frame_block ++; <nl> } <nl>  <nl> - size = p -> video_size - p -> frames_offset_table [ p -> current_frame ]; <nl> - if ( size < 1 ) <nl> + if ( p -> frames_offset_table [ p -> current_frame ] >= p -> video_size ) <nl> return AVERROR_INVALIDDATA ; <nl>  <nl> + size = p -> video_size - p -> frames_offset_table [ p -> current_frame ]; <nl> + <nl> if ( av_new_packet ( pkt , size ) < 0 ) <nl> return AVERROR ( ENOMEM ); <nl> 
static inline int get16 ( const uint8_t ** pp , const uint8_t * p_end ) <nl> int c ; <nl>  <nl> p = * pp ; <nl> - if (( p + 1 ) >= p_end ) <nl> + if ( 1 >= p_end - p ) <nl> return AVERROR_INVALIDDATA ; <nl> c = AV_RB16 ( p ); <nl> p += 2 ; <nl> static char * getstr8 ( const uint8_t ** pp , const uint8_t * p_end ) <nl> len = get8 (& p , p_end ); <nl> if ( len < 0 ) <nl> return NULL ; <nl> - if (( p + len ) > p_end ) <nl> + if ( len > p_end - p ) <nl> return NULL ; <nl> str = av_malloc ( len + 1 ); <nl> if (! str ) <nl> static int handle_packet ( MpegTSContext * ts , const uint8_t * packet ) <nl> if ( is_start ) { <nl> /* pointer field present */ <nl> len = * p ++; <nl> - if ( p + len > p_end ) <nl> + if ( len > p_end - p ) <nl> return 0 ; <nl> if ( len && cc_ok ) { <nl> /* write remaining section bytes */
static uint_fast8_t vorbis_floor0_decode ( vorbis_context * vc , <nl> float two_cos_w = 2 . 0f * cos ( wstep * iter_cond ); // needed all times <nl>  <nl> /* similar part for the q and p products */ <nl> - for ( j = 0 ; j < order ; j += 2 ) { <nl> + for ( j = 0 ; j + 1 < order ; j += 2 ) { <nl> q *= lsp [ j ] - two_cos_w ; <nl> p *= lsp [ j + 1 ]- two_cos_w ; <nl> }
static void generate_offset_lut ( DiracGolombLUT * lut , int off ) <nl> INIT_RESIDUE ( res ); <nl> SET_RESIDUE ( res , idx , LUT_BITS ); <nl>  <nl> - l -> preamble = CONVERT_TO_RESIDUE ( res >> ( RSIZE_BITS - off ), off ); <nl> l -> preamble_bits = off ; <nl> - l -> sign = (( l -> preamble >> ( RSIZE_BITS - l -> preamble_bits )) & 1 ) ? - 1 : + 1 ; <nl> + if ( off ) { <nl> + l -> preamble = CONVERT_TO_RESIDUE ( res >> ( RSIZE_BITS - off ), off ); <nl> + l -> sign = (( l -> preamble >> ( RSIZE_BITS - l -> preamble_bits )) & 1 ) ? - 1 : + 1 ; <nl> + } else { <nl> + l -> preamble = 0 ; <nl> + l -> sign = 1 ; <nl> + } <nl>  <nl> search_for_golomb ( l , res << off , LUT_BITS - off ); <nl> }
static inline int mdec_decode_block_intra ( MDECContext * a , int16_t * block , int n ) <nl> if ( diff >= 0xffff ) <nl> return AVERROR_INVALIDDATA ; <nl> a -> last_dc [ component ] += diff ; <nl> - block [ 0 ] = a -> last_dc [ component ] << 3 ; <nl> + block [ 0 ] = a -> last_dc [ component ] * ( 1 << 3 ); <nl> } <nl>  <nl> i = 0 ;
static int matroska_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> ret = matroska_parse_cluster ( matroska ); <nl> } <nl>  <nl> - if ( ret == AVERROR_INVALIDDATA ) { <nl> + if ( ret == AVERROR_INVALIDDATA && pkt -> data ) { <nl> pkt -> flags |= AV_PKT_FLAG_CORRUPT ; <nl> return 0 ; <nl> }
static av_cold int bktr_init ( const char * video_device , int width , int height , <nl> long ioctl_frequency ; <nl> char * arg ; <nl> int c ; <nl> - struct sigaction act = { 0 }, old ; <nl> + struct sigaction act = { { 0 } }, old ; <nl>  <nl> if ( idev < 0 || idev > 4 ) <nl> {
static int rm_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> // If there are queued audio packet return them first <nl> st = s -> streams [ rm -> audio_stream_num ]; <nl> ff_rm_retrieve_cache ( s , s -> pb , st , st -> priv_data , pkt ); <nl> + flags = 0 ; <nl> } else { <nl> if ( rm -> old_format ) { <nl> RMStream * ast ;
static void mov_parse_stsd_audio ( MOVContext * c , AVIOContext * pb , <nl>  <nl> static void mov_parse_stsd_subtitle ( MOVContext * c , AVIOContext * pb , <nl> AVStream * st , MOVStreamContext * sc , <nl> - int size ) <nl> + int64_t size ) <nl> { <nl> // ttxt stsd contains display flags , justification , background <nl> // color , fonts , and default styles , so fake an atom to read it <nl> static int mov_rewrite_dvd_sub_extradata ( AVStream * st ) <nl>  <nl> static int mov_parse_stsd_data ( MOVContext * c , AVIOContext * pb , <nl> AVStream * st , MOVStreamContext * sc , <nl> - int size ) <nl> + int64_t size ) <nl> { <nl> if ( st -> codec -> codec_tag == MKTAG (' t ',' m ',' c ',' d ')) { <nl> - if ( ff_get_extradata ( st -> codec , pb , size ) < 0 ) <nl> + if (( int ) size != size || ff_get_extradata ( st -> codec , pb , size ) < 0 ) <nl> return AVERROR ( ENOMEM ); <nl> if ( size > 16 ) { <nl> MOVStreamContext * tmcd_ctx = st -> priv_data ;
typedef struct ThreadContext { <nl> pthread_cond_t last_job_cond ; <nl> pthread_cond_t current_job_cond ; <nl> pthread_mutex_t current_job_lock ; <nl> + unsigned current_execute ; <nl> int current_job ; <nl> int done ; <nl> } ThreadContext ; <nl> static void * attribute_align_arg worker ( void * v ) <nl> { <nl> AVCodecContext * avctx = v ; <nl> ThreadContext * c = avctx -> thread_opaque ; <nl> + unsigned last_execute = 0 ; <nl> int our_job = c -> job_count ; <nl> int thread_count = avctx -> thread_count ; <nl> int self_id ; <nl> static void * attribute_align_arg worker ( void * v ) <nl> if ( c -> current_job == thread_count + c -> job_count ) <nl> pthread_cond_signal (& c -> last_job_cond ); <nl>  <nl> - if (! c -> done ) <nl> + while ( last_execute == c -> current_execute && ! c -> done ) <nl> pthread_cond_wait (& c -> current_job_cond , & c -> current_job_lock ); <nl> + last_execute = c -> current_execute ; <nl> our_job = self_id ; <nl>  <nl> if ( c -> done ) { <nl> static void * attribute_align_arg worker ( void * v ) <nl>  <nl> static av_always_inline void avcodec_thread_park_workers ( ThreadContext * c , int thread_count ) <nl> { <nl> - pthread_cond_wait (& c -> last_job_cond , & c -> current_job_lock ); <nl> + while ( c -> current_job != thread_count + c -> job_count ) <nl> + pthread_cond_wait (& c -> last_job_cond , & c -> current_job_lock ); <nl> pthread_mutex_unlock (& c -> current_job_lock ); <nl> } <nl>  <nl> static int avcodec_thread_execute ( AVCodecContext * avctx , action_func * func , void <nl> c -> rets = & dummy_ret ; <nl> c -> rets_count = 1 ; <nl> } <nl> + c -> current_execute ++; <nl> pthread_cond_broadcast (& c -> current_job_cond ); <nl>  <nl> avcodec_thread_park_workers ( c , avctx -> thread_count );
int ff_read_riff_info ( AVFormatContext * s , int64_t size ) <nl> AV_WL32 ( key , chunk_code ); <nl>  <nl> if ( avio_read ( pb , value , chunk_size ) != chunk_size ) { <nl> - av_freep ( key ); <nl> - av_freep ( value ); <nl> + av_free ( value ); <nl> av_log ( s , AV_LOG_ERROR , " premature end of file while reading INFO tag \ n "); <nl> return AVERROR_INVALIDDATA ; <nl> }
int av_samples_get_buffer_size ( int * linesize , int nb_channels , int nb_samples , <nl>  <nl> /* auto - select alignment if not specified */ <nl> if (! align ) { <nl> + if ( nb_samples > INT_MAX - 31 ) <nl> + return AVERROR ( EINVAL ); <nl> align = 1 ; <nl> nb_samples = FFALIGN ( nb_samples , 32 ); <nl> }
int ff_xvmc_field_start ( MpegEncContext * s , AVCodecContext * avctx ) <nl> render -> picture_structure = s -> picture_structure ; <nl> render -> flags = s -> first_field ? 0 : XVMC_SECOND_FIELD ; <nl>  <nl> - if ( render -> filled_mv_blocks_num ){ <nl> + if ( render -> filled_mv_blocks_num ) { <nl> av_log ( avctx , AV_LOG_ERROR , <nl> - " Rendering surface contains % i unprocessed blocks \ n ", <nl> - render -> filled_mv_blocks_num ); <nl> + " Rendering surface contains % i unprocessed blocks \ n ", <nl> + render -> filled_mv_blocks_num ); <nl> assert ( 0 ); <nl> } <nl>  <nl> void ff_xvmc_decode_mb ( MpegEncContext * s ) <nl> assert ( render -> filled_mv_blocks_num <= render -> total_number_of_mv_blocks ); <nl> assert ( render -> next_free_data_block_num <= render -> total_number_of_data_blocks ); <nl> /* The above conditions should not be able to fail as long as this function is used <nl> - and following if () automatically call callback to free blocks . */ <nl> + and following ' if ()' automatically call callback to free blocks . */ <nl>  <nl>  <nl> if ( render -> filled_mv_blocks_num >= render -> total_number_of_mv_blocks )
static ResampleContext * resample_init ( ResampleContext * c , int out_rate , int in_r <nl> av_assert0 ( 0 ); <nl> } <nl>  <nl> + if ( filter_size / factor > INT32_MAX / 256 ) { <nl> + av_log ( NULL , AV_LOG_ERROR , " Filter length too large \ n "); <nl> + goto error ; <nl> + } <nl> + <nl> c -> phase_shift = phase_shift ; <nl> c -> phase_mask = phase_count - 1 ; <nl> c -> linear = linear ;
static int huffman_decode ( MPADecodeContext * s , GranuleDef * g , <nl> part . We must go back into the data */ <nl> s_index -= 4 ; <nl> skip_bits_long (& s -> gb , last_pos - pos ); <nl> - av_log ( NULL , AV_LOG_ERROR , " overread , skip % d \ n ", last_pos & 7 ); <nl> + av_log ( NULL , AV_LOG_DEBUG , " overread , skip % d \ n ", last_pos - pos ); <nl> } <nl> if ( pos >= end_pos ) <nl> break ;
char * av_base64_encode ( char * buf , int buf_len , const uint8_t * src , int len ) <nl> # ifdef TEST_BASE64 <nl> # include " avutil . h " <nl>  <nl> - int b64test () <nl> + int b64test ( void ) <nl> { <nl> int numerr = 0 ; <nl> int len ;
static int mov_read_stts ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl> av_dlog ( c -> fc , " track [% i ]. stts . entries = % i \ n ", <nl> c -> fc -> nb_streams - 1 , entries ); <nl>  <nl> - if ( entries >= UINT_MAX / sizeof (* sc -> stts_data )) <nl> - return - 1 ; <nl> + if (! entries || entries >= UINT_MAX / sizeof (* sc -> stts_data )) <nl> + return AVERROR ( EINVAL ); <nl>  <nl> sc -> stts_data = av_malloc ( entries * sizeof (* sc -> stts_data )); <nl> if (! sc -> stts_data )
static void mp_decode_frame_helper ( MotionPixelsContext * mp , GetBitContext * gb ) <nl> YuvPixel p ; <nl> int y , y0 ; <nl>  <nl> + av_assert1 ( mp -> changes_map [ 0 ]); <nl> + <nl> for ( y = 0 ; y < mp -> avctx -> height ; ++ y ) { <nl> if ( mp -> changes_map [ y * mp -> avctx -> width ] != 0 ) { <nl> memset ( mp -> gradient_scale , 1 , sizeof ( mp -> gradient_scale ));
static int mov_read_close ( AVFormatContext * s ) <nl> av_freep (& sc -> rap_group ); <nl> av_freep (& sc -> display_matrix ); <nl>  <nl> - for ( j = 0 ; j < sc -> stsd_count ; j ++) <nl> - av_free ( sc -> extradata [ j ]); <nl> + if ( sc -> extradata ) <nl> + for ( j = 0 ; j < sc -> stsd_count ; j ++) <nl> + av_free ( sc -> extradata [ j ]); <nl> av_freep (& sc -> extradata ); <nl> av_freep (& sc -> extradata_size ); <nl> 
static int create_filtergraph ( AVFilterContext * ctx , <nl> s -> yuv_offset [ 1 ][ n ] = off ; <nl> fill_rgb2yuv_table ( s -> out_lumacoef , rgb2yuv ); <nl> bits = 1 << ( 29 - out_desc -> comp [ 0 ]. depth ); <nl> - for ( n = 0 ; n < 3 ; n ++) { <nl> - for ( out_rng = s -> out_y_rng , m = 0 ; m < 3 ; m ++, out_rng = s -> out_uv_rng ) { <nl> + for ( out_rng = s -> out_y_rng , n = 0 ; n < 3 ; n ++, out_rng = s -> out_uv_rng ) { <nl> + for ( m = 0 ; m < 3 ; m ++) { <nl> s -> rgb2yuv_coeffs [ n ][ m ][ 0 ] = lrint ( bits * out_rng * rgb2yuv [ n ][ m ] / 28672 ); <nl> for ( o = 1 ; o < 8 ; o ++) <nl> s -> rgb2yuv_coeffs [ n ][ m ][ o ] = s -> rgb2yuv_coeffs [ n ][ m ][ 0 ];
static int avi_read_seek ( AVFormatContext * s , int stream_index , <nl> continue ; <nl>  <nl> // av_assert1 ( st2 -> codecpar -> block_align ); <nl> - av_assert0 ( fabs ( av_q2d ( st2 -> time_base ) - ast2 -> scale / ( double ) ast2 -> rate ) < av_q2d ( st2 -> time_base ) * 0 . 00000001 ); <nl> index = av_index_search_timestamp ( st2 , <nl> av_rescale_q ( timestamp , <nl> st -> time_base ,
static void use_high_update_speed ( WmallDecodeCtx * s , int ich ) <nl> { <nl> int ilms , recent , icoef ; <nl> s -> update_speed [ ich ] = 16 ; <nl> - for ( ilms = s -> cdlms_ttl [ ich ]; ilms >= 0 ; ilms --) { <nl> + for ( ilms = s -> cdlms_ttl [ ich ] - 1 ; ilms >= 0 ; ilms --) { <nl> recent = s -> cdlms [ ich ][ ilms ]. recent ; <nl> if ( s -> bV3RTM ) { <nl> for ( icoef = 0 ; icoef < s -> cdlms [ ich ][ ilms ]. order ; icoef ++) <nl> static void use_normal_update_speed ( WmallDecodeCtx * s , int ich ) <nl> { <nl> int ilms , recent , icoef ; <nl> s -> update_speed [ ich ] = 8 ; <nl> - for ( ilms = s -> cdlms_ttl [ ich ]; ilms >= 0 ; ilms --) { <nl> + for ( ilms = s -> cdlms_ttl [ ich ] - 1 ; ilms >= 0 ; ilms --) { <nl> recent = s -> cdlms [ ich ][ ilms ]. recent ; <nl> if ( s -> bV3RTM ) { <nl> for ( icoef = 0 ; icoef < s -> cdlms [ ich ][ ilms ]. order ; icoef ++) <nl> static void revert_cdlms ( WmallDecodeCtx * s , int tile_size ) <nl> s -> transient [ ich ] = 1 ; <nl> use_high_update_speed ( s , ich ); <nl> } <nl> - for ( ilms = num_lms ; ilms >= 0 ; ilms --) { <nl> + for ( ilms = num_lms - 1 ; ilms >= 0 ; ilms --) { <nl> pred = lms_predict ( s , ich , ilms ); <nl> channel_coeff += pred ; <nl> lms_update ( s , ich , ilms , channel_coeff , pred );
static int asf_read_frame_header ( AVFormatContext * s , AVIOContext * pb ){ <nl> case 0x54 : <nl> aspect . num = avio_r8 ( pb ); <nl> aspect . den = avio_r8 ( pb ); <nl> - if ( aspect . num > 0 && aspect . den > 0 ) { <nl> + if ( aspect . num > 0 && aspect . den > 0 && asf -> stream_index >= 0 ) { <nl> s -> streams [ asf -> stream_index ]-> sample_aspect_ratio = aspect ; <nl> } <nl> break ;
static void sbr_gain_calc ( AACContext * ac , SpectralBandReplication * sbr , <nl> (( 1 . 0f + sbr -> e_curr [ e ][ m ]) * <nl> ( 1 . 0f + sbr -> q_mapped [ e ][ m ]))); <nl> } <nl> + sbr -> gain [ e ][ m ] += FLT_MIN ; <nl> } <nl> for ( m = sbr -> f_tablelim [ k ] - sbr -> kx [ 1 ]; m < sbr -> f_tablelim [ k + 1 ] - sbr -> kx [ 1 ]; m ++) { <nl> sum [ 0 ] += sbr -> e_origmapped [ e ][ m ];
static void pmt_cb ( MpegTSFilter * filter , const uint8_t * section , int section_len <nl> pes = ts -> pids [ pid ]-> u . pes_filter . opaque ; <nl> if (! pes -> st ) { <nl> pes -> st = avformat_new_stream ( pes -> stream , NULL ); <nl> + if (! pes -> st ) <nl> + goto out ; <nl> pes -> st -> id = pes -> pid ; <nl> } <nl> st = pes -> st ; <nl> static void pmt_cb ( MpegTSFilter * filter , const uint8_t * section , int section_len <nl> pes = add_pes_stream ( ts , pid , pcr_pid ); <nl> if ( pes ) { <nl> st = avformat_new_stream ( pes -> stream , NULL ); <nl> + if (! st ) <nl> + goto out ; <nl> st -> id = pes -> pid ; <nl> } <nl> } else { <nl> static void pmt_cb ( MpegTSFilter * filter , const uint8_t * section , int section_len <nl> st = ts -> stream -> streams [ idx ]; <nl> } else { <nl> st = avformat_new_stream ( ts -> stream , NULL ); <nl> + if (! st ) <nl> + goto out ; <nl> st -> id = pid ; <nl> st -> codec -> codec_type = AVMEDIA_TYPE_DATA ; <nl> }
static int libopenjpeg_decode_frame ( AVCodecContext * avctx , <nl>  <nl> if ( ff_thread_get_buffer ( avctx , picture ) < 0 ){ <nl> av_log ( avctx , AV_LOG_ERROR , " ff_thread_get_buffer () failed \ n "); <nl> - return - 1 ; <nl> + goto done ; <nl> } <nl>  <nl> ctx -> dec_params . cp_limit_decoding = NO_LIMITATION ; <nl> static int libopenjpeg_decode_frame ( AVCodecContext * avctx , <nl> stream = opj_cio_open (( opj_common_ptr ) dec , buf , buf_size ); <nl> if (! stream ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Codestream could not be opened for reading .\ n "); <nl> - opj_destroy_decompress ( dec ); <nl> - return - 1 ; <nl> + goto done ; <nl> } <nl>  <nl> + opj_image_destroy ( image ); <nl> // Decode the codestream <nl> image = opj_decode_with_info ( dec , stream , NULL ); <nl> opj_cio_close ( stream ); <nl> if (! image ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Error decoding codestream .\ n "); <nl> - opj_destroy_decompress ( dec ); <nl> - return - 1 ; <nl> + goto done ; <nl> } <nl>  <nl> pixel_size = av_pix_fmt_descriptors [ avctx -> pix_fmt ]. comp [ 0 ]. step_minus1 + 1 ;
int ff_j2k_init_component ( J2kComponent * comp , J2kCodingStyle * codsty , J2kQuantSt <nl> band -> cblknx = ff_j2k_ceildiv ( band -> cblknx , dx ); <nl> band -> cblkny = ff_j2k_ceildiv ( band -> cblkny , dy ); <nl>  <nl> - band -> cblk = av_malloc ( band -> cblknx * band -> cblkny * sizeof ( J2kCblk )); <nl> + band -> cblk = av_malloc ( sizeof ( J2kCblk ) * band -> cblknx * band -> cblkny ); <nl> if (! band -> cblk ) <nl> return AVERROR ( ENOMEM ); <nl> band -> prec = av_malloc ( reslevel -> num_precincts_x * reslevel -> num_precincts_y * sizeof ( J2kPrec ));
int ff_get_cpu_flags_arm ( void ) <nl> trickle down . */ <nl> if ( flags & ( AV_CPU_FLAG_VFPV3 | AV_CPU_FLAG_NEON )) <nl> flags |= AV_CPU_FLAG_ARMV6T2 ; <nl> - else <nl> + else if ( flags & ( AV_CPU_FLAG_ARMV6T2 | AV_CPU_FLAG_ARMV6 )) <nl> /* Some functions use the ' setend ' instruction which is deprecated on ARMv8 <nl> * and serializing on some ARMv7 cores . This ensures such functions <nl> * are only enabled on ARMv6 . */
int ff_dca_convert_bitstream ( const uint8_t * src , int src_size , uint8_t * dst , <nl> { <nl> uint32_t mrk ; <nl> int i , tmp ; <nl> - const uint16_t * ssrc = ( const uint16_t *) src ; <nl> - uint16_t * sdst = ( uint16_t *) dst ; <nl> PutBitContext pb ; <nl>  <nl> if (( unsigned ) src_size > ( unsigned ) max_size ) <nl> int ff_dca_convert_bitstream ( const uint8_t * src , int src_size , uint8_t * dst , <nl> memcpy ( dst , src , src_size ); <nl> return src_size ; <nl> case DCA_SYNCWORD_CORE_LE : <nl> - for ( i = 0 ; i < ( src_size + 1 ) >> 1 ; i ++) <nl> - * sdst ++ = av_bswap16 (* ssrc ++); <nl> + for ( i = 0 ; i < ( src_size + 1 ) >> 1 ; i ++) { <nl> + AV_WB16 ( dst , AV_RL16 ( src )); <nl> + src += 2 ; <nl> + dst += 2 ; <nl> + } <nl> return src_size ; <nl> case DCA_SYNCWORD_CORE_14B_BE : <nl> case DCA_SYNCWORD_CORE_14B_LE :
const AVOption * av_set_string ( void * obj , const char * name , const char * val ){ <nl> return NULL ; <nl> } <nl>  <nl> - memcpy ((( uint8_t *) obj ) + o -> offset , val , sizeof ( val )); <nl> + memcpy ((( uint8_t *) obj ) + o -> offset , & val , sizeof ( val )); <nl> return o ; <nl> } <nl>  <nl> const char * av_get_string ( void * obj , const char * name , const AVOption ** o_out , c <nl> if ( o_out ) * o_out = o ; <nl>  <nl> if ( o -> type == FF_OPT_TYPE_STRING ) <nl> - return dst ; <nl> + return *( void **) dst ; <nl>  <nl> switch ( o -> type ){ <nl> case FF_OPT_TYPE_FLAGS : snprintf ( buf , buf_len , " 0x % 08X ",*( int *) dst ); break ;
static void flush_dpb ( AVCodecContext * avctx ){ <nl> if ( h -> s . current_picture_ptr ) <nl> h -> s . current_picture_ptr -> reference = 0 ; <nl> h -> s . first_field = 0 ; <nl> + ff_mpeg_flush ( avctx ); <nl> } <nl>  <nl> /**
int av_packet_ref ( AVPacket * dst , const AVPacket * src ) <nl> if ( ret < 0 ) <nl> goto fail ; <nl> memcpy ( dst -> buf -> data , src -> data , src -> size ); <nl> - } else <nl> + } else { <nl> dst -> buf = av_buffer_ref ( src -> buf ); <nl> + if (! dst -> buf ) <nl> + goto fail ; <nl> + } <nl>  <nl> dst -> size = src -> size ; <nl> dst -> data = dst -> buf -> data ;
static int init ( AVFilterContext * ctx , const char * args ) <nl> eval -> class = & aevalsrc_class ; <nl> av_opt_set_defaults ( eval ); <nl>  <nl> + if (! args1 ) { <nl> + av_log ( ctx , AV_LOG_ERROR , " Argument is empty \ n "); <nl> + ret = args ? AVERROR ( ENOMEM ) : AVERROR ( EINVAL ); <nl> + goto end ; <nl> + } <nl> + <nl> /* parse expressions */ <nl> buf = args1 ; <nl> i = 0 ;
static int cinepak_decode_strip ( CinepakContext * s , <nl> while (( data + 4 ) <= eod ) { <nl> chunk_id = BE_16 (& data [ 0 ]); <nl> chunk_size = BE_16 (& data [ 2 ]) - 4 ; <nl> + if ( chunk_size < 0 ) <nl> + return - 1 ; <nl> + <nl> data += 4 ; <nl> chunk_size = (( data + chunk_size ) > eod ) ? ( eod - data ) : chunk_size ; <nl> 
static int avisynth_read_packet_video ( AVFormatContext * s , AVPacket * pkt , int dis <nl> AVS_VideoFrame * frame ; <nl> unsigned char * dst_p ; <nl> const unsigned char * src_p ; <nl> - int i , plane , rowsize , planeheight , pitch , bits ; <nl> + int n , i , plane , rowsize , planeheight , pitch , bits ; <nl> const char * error ; <nl>  <nl> if ( avs -> curr_frame >= avs -> vi -> num_frames ) <nl> return AVERROR_EOF ; <nl>  <nl> // This must happen even if the stream is discarded to prevent desync . <nl> - avs -> curr_frame ++; <nl> + n = avs -> curr_frame ++; <nl> if ( discard ) <nl> return 0 ; <nl>  <nl> static int avisynth_read_packet_video ( AVFormatContext * s , AVPacket * pkt , int dis <nl> if (! pkt -> data ) <nl> return AVERROR_UNKNOWN ; <nl>  <nl> - frame = avs_library -> avs_get_frame ( avs -> clip , avs -> curr_frame ); <nl> + frame = avs_library -> avs_get_frame ( avs -> clip , n ); <nl> error = avs_library -> avs_clip_get_error ( avs -> clip ); <nl> if ( error ) { <nl> av_log ( s , AV_LOG_ERROR , "% s \ n ", error ); <nl> static int avisynth_read_packet_audio ( AVFormatContext * s , AVPacket * pkt , int dis <nl> AviSynthContext * avs = s -> priv_data ; <nl> AVRational fps , samplerate ; <nl> int samples ; <nl> + int64_t n ; <nl> const char * error ; <nl>  <nl> if ( avs -> curr_sample >= avs -> vi -> num_audio_samples ) <nl> static int avisynth_read_packet_audio ( AVFormatContext * s , AVPacket * pkt , int dis <nl> samples = avs -> vi -> num_audio_samples - avs -> curr_sample ; <nl>  <nl> // This must happen even if the stream is discarded to prevent desync . <nl> + n = avs -> curr_sample ; <nl> avs -> curr_sample += samples ; <nl> if ( discard ) <nl> return 0 ; <nl> static int avisynth_read_packet_audio ( AVFormatContext * s , AVPacket * pkt , int dis <nl> if (! pkt -> data ) <nl> return AVERROR_UNKNOWN ; <nl>  <nl> - avs_library -> avs_get_audio ( avs -> clip , pkt -> data , avs -> curr_sample , samples ); <nl> + avs_library -> avs_get_audio ( avs -> clip , pkt -> data , n , samples ); <nl> error = avs_library -> avs_clip_get_error ( avs -> clip ); <nl> if ( error ) { <nl> av_log ( s , AV_LOG_ERROR , "% s \ n ", error );
AVFormatContext * avformat_alloc_context ( void ) <nl> return NULL ; <nl> } <nl> ic -> internal -> offset = AV_NOPTS_VALUE ; <nl> + ic -> internal -> raw_packet_buffer_remaining_size = RAW_PACKET_BUFFER_SIZE ; <nl>  <nl> return ic ; <nl> }
static av_cold int encode_init ( AVCodecContext * avctx ) <nl> ff_dsputil_init (& s -> dsp , avctx ); <nl>  <nl> /* Generate overlap window */ <nl> - ff_sine_window_init ( ff_sine_128 , 128 ); <nl> + ff_init_ff_sine_windows ( 7 ); <nl> for ( i = 0 ; i < POW_TABLE_SIZE ; i ++) <nl> pow_table [ i ] = - pow ( 2 , - i / 2048 . 0 - 3 . 0 + POW_TABLE_OFFSET ); <nl> 
int ff_mlz_decompression ( MLZ * mlz , GetBitContext * gb , int size , unsigned char * b <nl> } <nl> output_chars += ret ; <nl> set_new_entry_dict ( dict , mlz -> next_code , last_string_code , char_code ); <nl> + if ( mlz -> next_code >= TABLE_SIZE - 1 ) { <nl> + av_log ( mlz -> context , AV_LOG_ERROR , " Too many MLZ codes \ n "); <nl> + return output_chars ; <nl> + } <nl> mlz -> next_code ++; <nl> } else { <nl> int ret = decode_string ( mlz , & buff [ output_chars ], string_code , & char_code , size - output_chars ); <nl> int ff_mlz_decompression ( MLZ * mlz , GetBitContext * gb , int size , unsigned char * b <nl> if ( output_chars <= size && ! mlz -> freeze_flag ) { <nl> if ( last_string_code != - 1 ) { <nl> set_new_entry_dict ( dict , mlz -> next_code , last_string_code , char_code ); <nl> + if ( mlz -> next_code >= TABLE_SIZE - 1 ) { <nl> + av_log ( mlz -> context , AV_LOG_ERROR , " Too many MLZ codes \ n "); <nl> + return output_chars ; <nl> + } <nl> mlz -> next_code ++; <nl> } <nl> } else {
static int g2m_init_buffers ( G2MContext * c ) <nl> if (! c -> synth_tile || ! c -> jpeg_tile || <nl> c -> old_tile_w < c -> tile_width || <nl> c -> old_tile_h < c -> tile_height ) { <nl> - c -> tile_stride = FFALIGN ( c -> tile_width * 3 , 16 ); <nl> + c -> tile_stride = FFALIGN ( c -> tile_width , 16 ) * 3 ; <nl> aligned_height = FFALIGN ( c -> tile_height , 16 ); <nl> av_free ( c -> synth_tile ); <nl> av_free ( c -> jpeg_tile );
void ff_MPV_frame_end ( MpegEncContext * s ) <nl> s -> unrestricted_mv && <nl> s -> current_picture . f . reference && <nl> ! s -> intra_only && <nl> - !( s -> flags & CODEC_FLAG_EMU_EDGE )) { <nl> + !( s -> flags & CODEC_FLAG_EMU_EDGE ) && <nl> + ! s -> avctx -> lowres <nl> + ) { <nl> int hshift = av_pix_fmt_descriptors [ s -> avctx -> pix_fmt ]. log2_chroma_w ; <nl> int vshift = av_pix_fmt_descriptors [ s -> avctx -> pix_fmt ]. log2_chroma_h ; <nl> s -> dsp . draw_edges ( s -> current_picture . f . data [ 0 ], s -> current_picture . f . linesize [ 0 ],
static int oma_read_seek ( struct AVFormatContext * s , <nl> int stream_index , int64_t timestamp , int flags ) <nl> { <nl> OMAContext * oc = s -> priv_data ; <nl> - int err = ff_pcm_read_seek ( s , stream_index , timestamp , flags ); <nl> + int64_t err = ff_pcm_read_seek ( s , stream_index , timestamp , flags ); <nl>  <nl> if (! oc -> encrypted ) <nl> return err ;
static int mov_write_audio_tag ( AVFormatContext * s , AVIOContext * pb , MOVMuxContex <nl> uint32_t tag = track -> tag ; <nl>  <nl> if ( track -> mode == MODE_MOV ) { <nl> - if ( track -> timescale > UINT16_MAX ) { <nl> + if ( track -> timescale > UINT16_MAX || ! track -> par -> channels ) { <nl> if ( mov_get_lpcm_flags ( track -> par -> codec_id )) <nl> tag = AV_RL32 (" lpcm "); <nl> version = 2 ;
int ff_rtp_get_payload_type ( AVFormatContext * fmt , <nl> /* static payload type */ <nl> for ( i = 0 ; rtp_payload_types [ i ]. pt >= 0 ; ++ i ) <nl> if ( rtp_payload_types [ i ]. codec_id == codec -> codec_id ) { <nl> - if ( codec -> codec_id == AV_CODEC_ID_H263 && (! fmt || <nl> + if ( codec -> codec_id == AV_CODEC_ID_H263 && (! fmt || ! fmt -> oformat || <nl> ! fmt -> oformat -> priv_class || ! fmt -> priv_data || <nl> ! av_opt_flag_is_set ( fmt -> priv_data , " rtpflags ", " rfc2190 "))) <nl> continue ;
int ff_mjpeg_decode_sof ( MJpegDecodeContext * s ) <nl> s -> first_picture = 0 ; <nl> } <nl>  <nl> - if ( s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity )) <nl> + if ( s -> interlaced && ( s -> bottom_field == ! s -> interlace_polarity )) { <nl> + if ( s -> progressive ) { <nl> + av_log_ask_for_sample ( s -> avctx , " progressively coded interlaced pictures not supported \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> return 0 ; <nl> + } <nl>  <nl> /* XXX : not complete test ! */ <nl> pix_fmt_id = ( s -> h_count [ 0 ] << 28 ) | ( s -> v_count [ 0 ] << 24 ) |
static av_cold int encode_init ( AVCodecContext * avctx ) <nl> if ( av_image_check_size ( avctx -> width , avctx -> height , 0 , avctx ) < 0 ) { <nl> return - 1 ; <nl> } <nl> + if (( avctx -> width & 3 ) || ( avctx -> height & 3 )){ <nl> + av_log ( avctx , AV_LOG_ERROR , " width and height must be multiplies of 4 \ n "); <nl> + return - 1 ; <nl> + } <nl>  <nl> avcodec_get_frame_defaults (& c -> pic ); <nl> avctx -> coded_frame = ( AVFrame *)& c -> pic ;
static int mpeg_decode_slice ( MpegEncContext * s , int mb_y , <nl> } <nl> } <nl> eos : // end of slice <nl> + if ( get_bits_left (& s -> gb ) < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> * buf += ( get_bits_count (& s -> gb )- 1 )/ 8 ; <nl> av_dlog ( s , " y % d % d % d % d \ n ", s -> resync_mb_x , s -> resync_mb_y , s -> mb_x , s -> mb_y ); <nl> return 0 ;
int put_wav_header ( ByteIOContext * pb , AVCodecContext * enc ) <nl> } else if ( enc -> codec_id == CODEC_ID_ADPCM_IMA_WAV || enc -> codec_id == CODEC_ID_ADPCM_MS || enc -> codec_id == CODEC_ID_ADPCM_G726 || enc -> codec_id == CODEC_ID_ADPCM_YAMAHA ) { // <nl> bps = 4 ; <nl> } else { <nl> - bps = av_get_bits_per_sample ( enc -> codec_id ); <nl> + if (!( bps = av_get_bits_per_sample ( enc -> codec_id ))) <nl> + bps = 16 ; // default to 16 <nl> } <nl> if ( bps != enc -> bits_per_sample && enc -> bits_per_sample ){ <nl> av_log ( enc , AV_LOG_WARNING , " requested bits_per_sample (% d ) and actually stored (% d ) differ \ n ", enc -> bits_per_sample , bps );
enum AVCodecID av_guess_codec ( AVOutputFormat * fmt , const char * short_name , <nl> enum AVMediaType type ) <nl> { <nl> if ( av_match_name (" segment ", fmt -> name ) || av_match_name (" ssegment ", fmt -> name )) { <nl> - fmt = av_guess_format ( NULL , filename , NULL ); <nl> + AVOutputFormat * fmt2 = av_guess_format ( NULL , filename , NULL ); <nl> + if ( fmt2 ) <nl> + fmt = fmt2 ; <nl> } <nl>  <nl> if ( type == AVMEDIA_TYPE_VIDEO ) {
static inline void tm2_apply_deltas ( TM2Context * ctx , int * Y , int stride , int * de <nl> } <nl> } <nl>  <nl> - static inline void tm2_high_chroma ( int * data , int stride , int * last , int * CD , int * deltas ) <nl> + static inline void tm2_high_chroma ( int * data , int stride , int * last , unsigned * CD , int * deltas ) <nl> { <nl> int i , j ; <nl> for ( j = 0 ; j < 2 ; j ++) {
static int mpegts_write_end ( AVFormatContext * s ) <nl> } <nl> av_free ( ts -> services ); <nl>  <nl> - for ( i = 0 ; i < s -> nb_streams ; i ++) { <nl> - st = s -> streams [ i ]; <nl> - av_free ( st -> priv_data ); <nl> - } <nl> return 0 ; <nl> } <nl> 
static int vdpau_vc1_start_frame ( AVCodecContext * avctx , <nl> else <nl> info -> picture_type = s -> pict_type - 1 + s -> pict_type / 3 ; <nl>  <nl> - info -> frame_coding_mode = v -> fcm ; <nl> + info -> frame_coding_mode = v -> fcm ? v -> fcm + 1 : 0 ; <nl> info -> postprocflag = v -> postprocflag ; <nl> info -> pulldown = v -> broadcast ; <nl> info -> interlace = v -> interlace ;
static void FUNC ( put_hevc_epel_bi_w_hv )( uint8_t * _dst , ptrdiff_t _dststride , uin <nl> for ( y = 0 ; y < height ; y ++) { <nl> for ( x = 0 ; x < width ; x ++) <nl> dst [ x ] = av_clip_pixel ((( EPEL_FILTER ( tmp , MAX_PB_SIZE ) >> 6 ) * wx1 + src2 [ x ] * wx0 + <nl> - (( ox0 + ox1 + 1 ) << log2Wd )) >> ( log2Wd + 1 )); <nl> + (( ox0 + ox1 + 1 ) * ( 1 << log2Wd ))) >> ( log2Wd + 1 )); <nl> tmp += MAX_PB_SIZE ; <nl> dst += dststride ; <nl> src2 += MAX_PB_SIZE ;
static int rv20_decode_picture_header ( RVDecContext * rv ) <nl> return - 1 ; <nl> } <nl>  <nl> + if ( s -> low_delay && s -> pict_type == AV_PICTURE_TYPE_B ){ <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " low delay B \ n "); <nl> + return - 1 ; <nl> + } <nl> if ( s -> last_picture_ptr == NULL && s -> pict_type == AV_PICTURE_TYPE_B ){ <nl> av_log ( s -> avctx , AV_LOG_ERROR , " early B pix \ n "); <nl> return - 1 ;
static int bink_decode_plane ( BinkContext * c , GetBitContext * gb , int plane_idx , <nl> for ( i = 0 ; i < BINK_NB_SRC ; i ++) <nl> read_bundle ( gb , c , i ); <nl>  <nl> - ref_start = c -> last . data [ plane_idx ]; <nl> - ref_end = c -> last . data [ plane_idx ] <nl> + ref_start = c -> last . data [ plane_idx ] ? c -> last . data [ plane_idx ] <nl> + : c -> pic . data [ plane_idx ]; <nl> + ref_end = ref_start <nl> + ( bw - 1 + c -> last . linesize [ plane_idx ] * ( bh - 1 )) * 8 ; <nl>  <nl> for ( i = 0 ; i < 64 ; i ++) <nl> static int bink_decode_plane ( BinkContext * c , GetBitContext * gb , int plane_idx , <nl> if ( by == bh ) <nl> break ; <nl> dst = c -> pic . data [ plane_idx ] + 8 * by * stride ; <nl> - prev = c -> last . data [ plane_idx ] + 8 * by * stride ; <nl> + prev = ( c -> last . data [ plane_idx ] ? c -> last . data [ plane_idx ] <nl> + : c -> pic . data [ plane_idx ]) + 8 * by * stride ; <nl> for ( bx = 0 ; bx < bw ; bx ++, dst += 8 , prev += 8 ) { <nl> blk = get_value ( c , BINK_SRC_BLOCK_TYPES ); <nl> // 16x16 block type on odd line means part of the already decoded block , so skip it
static int jpeg2000_decode_tile ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile , <nl> if ( s -> precision <= 8 ) { <nl> for ( compno = 0 ; compno < s -> ncomponents ; compno ++) { <nl> Jpeg2000Component * comp = tile -> comp + compno ; <nl> + Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; <nl> float * datap = comp -> f_data ; <nl> int32_t * i_datap = comp -> i_data ; <nl> int cbps = s -> cbps [ compno ]; <nl> static int jpeg2000_decode_tile ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile , <nl> x = tile -> comp [ compno ]. coord [ 0 ][ 0 ] - s -> image_offset_x ; <nl> dst = line + x * s -> ncomponents + compno ; <nl>  <nl> - if ( tile -> codsty -> transform == FF_DWT97 ) { <nl> + if ( codsty -> transform == FF_DWT97 ) { <nl> for (; x < w ; x += s -> cdx [ compno ]) { <nl> int val = lrintf (* datap ) + ( 1 << ( cbps - 1 )); <nl> /* DC level shift and clip see ISO 15444 - 1 : 2002 G . 1 . 2 */ <nl> static int jpeg2000_decode_tile ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile , <nl> } else { <nl> for ( compno = 0 ; compno < s -> ncomponents ; compno ++) { <nl> Jpeg2000Component * comp = tile -> comp + compno ; <nl> + Jpeg2000CodingStyle * codsty = tile -> codsty + compno ; <nl> float * datap = comp -> f_data ; <nl> int32_t * i_datap = comp -> i_data ; <nl> uint16_t * linel ; <nl> static int jpeg2000_decode_tile ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile , <nl> uint16_t * dst ; <nl> x = tile -> comp [ compno ]. coord [ 0 ][ 0 ] - s -> image_offset_x ; <nl> dst = linel + ( x * s -> ncomponents + compno ); <nl> - if ( tile -> codsty -> transform == FF_DWT97 ) { <nl> + if ( codsty -> transform == FF_DWT97 ) { <nl> for (; x < w ; x += s -> cdx [ compno ]) { <nl> int val = lrintf (* datap ) + ( 1 << ( cbps - 1 )); <nl> /* DC level shift and clip see ISO 15444 - 1 : 2002 G . 1 . 2 */
int ff_hevc_output_frame ( HEVCContext * s , AVFrame * out , int flush ) <nl> if (( frame -> flags & HEVC_FRAME_FLAG_OUTPUT ) && <nl> frame -> sequence == s -> seq_output ) { <nl> nb_output ++; <nl> - if ( frame -> poc < min_poc ) { <nl> + if ( frame -> poc < min_poc || nb_output == 1 ) { <nl> min_poc = frame -> poc ; <nl> min_idx = i ; <nl> }
static int flv_set_video_codec ( AVFormatContext * s , AVStream * vstream , int flv_co <nl> vcodec -> codec_id = CODEC_ID_VP6A ; <nl> if ( vcodec -> extradata_size != 1 ) { <nl> vcodec -> extradata_size = 1 ; <nl> - vcodec -> extradata = av_malloc ( 1 ); <nl> + vcodec -> extradata = av_malloc ( 1 + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> } <nl> vcodec -> extradata [ 0 ] = avio_r8 ( s -> pb ); <nl> return 1 ; // 1 byte body size adjustment for flv_read_packet ()
static int matroska_deliver_packet ( MatroskaDemuxContext * matroska , <nl> */ <nl> static void matroska_clear_queue ( MatroskaDemuxContext * matroska ) <nl> { <nl> + matroska -> prev_pkt = NULL ; <nl> if ( matroska -> packets ) { <nl> int n ; <nl> for ( n = 0 ; n < matroska -> num_packets ; n ++) { <nl> static int matroska_read_seek ( AVFormatContext * s , int stream_index , <nl> avio_seek ( s -> pb , st -> index_entries [ st -> nb_index_entries - 1 ]. pos , SEEK_SET ); <nl> matroska -> current_id = 0 ; <nl> while (( index = av_index_search_timestamp ( st , timestamp , flags )) < 0 ) { <nl> - matroska -> prev_pkt = NULL ; <nl> matroska_clear_queue ( matroska ); <nl> if ( matroska_parse_cluster ( matroska ) < 0 ) <nl> break ;
static int truemotion2rt_decode_frame ( AVCodecContext * avctx , void * data , <nl> if ( ret < 0 ) <nl> return ret ; <nl>  <nl> + if ( avctx -> width / s -> hscale * avctx -> height * s -> delta_size > avpkt -> size * 8LL * 4 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> ret = init_get_bits8 ( gb , avpkt -> data + ret , avpkt -> size - ret ); <nl> if ( ret < 0 ) <nl> return ret ;
static int encode_superframe ( AVCodecContext * avctx , <nl> } <nl> } <nl>  <nl> + if ( buf_size < 2 * MAX_CODED_SUPERFRAME_SIZE ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " output buffer size is too small \ n "); <nl> + return AVERROR ( EINVAL ); <nl> + } <nl> + <nl> # if 1 <nl> total_gain = 128 ; <nl> for ( i = 64 ; i ; i >>= 1 ){
static int usage ( const char * argv0 , int ret ) <nl> struct MoofOffset { <nl> int64_t time ; <nl> int64_t offset ; <nl> - int duration ; <nl> + int64_t duration ; <nl> }; <nl>  <nl> struct Track { <nl> static void print_track_chunks ( FILE * out , struct Tracks * tracks , int main , <nl> fprintf ( stderr , " Mismatched duration of % s chunk % d in % s and % s \ n ", <nl> type , i , track -> name , tracks -> tracks [ j ]-> name ); <nl> } <nl> - fprintf ( out , "\ t \ t < c n =\"% d \" d =\"% d \" />\ n ", <nl> + fprintf ( out , "\ t \ t < c n =\"% d \" d =\"%" PRId64 "\" />\ n ", <nl> i , track -> offsets [ i ]. duration ); <nl> } <nl> }
int ff_h263_decode_mb ( MpegEncContext * s , <nl> } <nl>  <nl> if ( IS_DIRECT ( mb_type )){ <nl> + if (! s -> pp_time ) <nl> + return AVERROR_INVALIDDATA ; <nl> s -> mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT ; <nl> mb_type |= ff_mpeg4_set_direct_mv ( s , 0 , 0 ); <nl> } else {
unk_pixfmt : <nl> av_freep (& s -> last_nnz [ i ]); <nl> s -> blocks [ i ] = av_malloc ( size * sizeof (** s -> blocks )); <nl> s -> last_nnz [ i ] = av_mallocz ( size * sizeof (** s -> last_nnz )); <nl> + if (! s -> blocks [ i ] || ! s -> last_nnz [ i ]) <nl> + return AVERROR ( ENOMEM ); <nl> s -> block_stride [ i ] = bw * s -> h_count [ i ]; <nl> } <nl> memset ( s -> coefs_finished , 0 , sizeof ( s -> coefs_finished ));
static int set_hwframe_ctx ( AVCodecContext * ctx , AVBufferRef * hw_device_ctx ) <nl> if (( err = av_hwframe_ctx_init ( hw_frames_ref )) < 0 ) { <nl> fprintf ( stderr , " Failed to initialize VAAPI frame context ." <nl> " Error code : % s \ n ", av_err2str ( err )); <nl> + av_buffer_unref (& hw_frames_ref ); <nl> return err ; <nl> } <nl> ctx -> hw_frames_ctx = av_buffer_ref ( hw_frames_ref );
static int flashsv2_prime ( FlashSVContext * s , uint8_t * src , int size ) <nl> z_stream zs ; <nl> int zret ; // Zlib return code <nl>  <nl> + if (! src ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> zs . zalloc = NULL ; <nl> zs . zfree = NULL ; <nl> zs . opaque = NULL ;
static int oma_read_header ( AVFormatContext * s ) <nl> st -> codecpar -> channels = 2 ; <nl> st -> codecpar -> channel_layout = AV_CH_LAYOUT_STEREO ; <nl> st -> codecpar -> sample_rate = samplerate ; <nl> - st -> codecpar -> bit_rate = st -> codecpar -> sample_rate * framesize * 8 / 1024 ; <nl> + st -> codecpar -> bit_rate = st -> codecpar -> sample_rate * framesize / ( 1024 / 8 ); <nl>  <nl> /* fake the ATRAC3 extradata <nl> * ( wav format , makes stream copy to wav work ) */ <nl> static int oma_read_header ( AVFormatContext * s ) <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> st -> codecpar -> sample_rate = samplerate ; <nl> - st -> codecpar -> bit_rate = samplerate * framesize * 8 / 2048 ; <nl> + st -> codecpar -> bit_rate = samplerate * framesize / ( 2048 / 8 ); <nl> avpriv_set_pts_info ( st , 64 , 1 , samplerate ); <nl> break ; <nl> case OMA_CODECID_MP3 :
static int au_read_header ( AVFormatContext * s ) <nl> return AVERROR_INVALIDDATA ; <nl> } <nl>  <nl> + if ( channels <= 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Invalid number of channels % d \ n ", channels ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> if ( size >= 24 ) { <nl> /* skip unused data */ <nl> avio_skip ( pb , size - 24 );
static av_always_inline int dnxhd_decode_dct_block ( const DNXHDContext * ctx , <nl>  <nl> UPDATE_CACHE ( bs , & row -> gb ); <nl> GET_VLC ( len , bs , & row -> gb , ctx -> dc_vlc . table , DNXHD_DC_VLC_BITS , 1 ); <nl> + if ( len < 0 ) { <nl> + ret = len ; <nl> + goto error ; <nl> + } <nl> if ( len ) { <nl> level = GET_CACHE ( bs , & row -> gb ); <nl> LAST_SKIP_BITS ( bs , & row -> gb , len ); <nl> static av_always_inline int dnxhd_decode_dct_block ( const DNXHDContext * ctx , <nl> GET_VLC ( index1 , bs , & row -> gb , ctx -> ac_vlc . table , <nl> DNXHD_VLC_BITS , 2 ); <nl> } <nl> - <nl> + error : <nl> CLOSE_READER ( bs , & row -> gb ); <nl> return ret ; <nl> }
static void adpcm_compress_trellis ( AVCodecContext * avctx , <nl> uint8_t * h ;\ <nl> dec_sample = av_clip_int16 ( dec_sample );\ <nl> d = sample - dec_sample ;\ <nl> - ssd = nodes [ j ]-> ssd + d * d ;\ <nl> + ssd = nodes [ j ]-> ssd + d *( unsigned ) d ;\ <nl> /* Check for wraparound , skip such samples completely . \ <nl> * Note , changing ssd to a 64 bit variable would be \ <nl> * simpler , avoiding this check , but it ' s slower on \
static int flic_read_header ( AVFormatContext * s ) <nl> } <nl>  <nl> /* send over the whole 128 - byte FLIC header */ <nl> - st -> codec -> extradata_size = FLIC_HEADER_SIZE ; <nl> st -> codec -> extradata = av_malloc ( FLIC_HEADER_SIZE ); <nl> + if (! st -> codec -> extradata ) <nl> + return AVERROR ( ENOMEM ); <nl> + st -> codec -> extradata_size = FLIC_HEADER_SIZE ; <nl> memcpy ( st -> codec -> extradata , header , FLIC_HEADER_SIZE ); <nl>  <nl> /* peek at the preamble to detect TFTD videos - they seem to always start with an audio chunk */ <nl> static int flic_read_header ( AVFormatContext * s ) <nl>  <nl> /* send over abbreviated FLIC header chunk */ <nl> av_free ( st -> codec -> extradata ); <nl> - st -> codec -> extradata_size = 12 ; <nl> st -> codec -> extradata = av_malloc ( 12 ); <nl> + if (! st -> codec -> extradata ) <nl> + return AVERROR ( ENOMEM ); <nl> + st -> codec -> extradata_size = 12 ; <nl> memcpy ( st -> codec -> extradata , header , 12 ); <nl>  <nl> } else if ( magic_number == FLIC_FILE_MAGIC_1 ) {
static inline int decode_vui_parameters ( H264Context * h , SPS * sps ){ <nl> sps -> num_reorder_frames = get_ue_golomb (& s -> gb ); <nl> get_ue_golomb (& s -> gb ); /* max_dec_frame_buffering */ <nl>  <nl> + if ( s -> gb . size_in_bits < get_bits_count (& s -> gb )){ <nl> + av_log ( h -> s . avctx , AV_LOG_ERROR , " Overread VUI by % d bits \ n ", get_bits_count (& s -> gb ) - s -> gb . size_in_bits ); <nl> + sps -> num_reorder_frames = 0 ; <nl> + sps -> bitstream_restriction_flag = 0 ; <nl> + } <nl> + <nl> if ( sps -> num_reorder_frames > 16U /* max_dec_frame_buffering || max_dec_frame_buffering > 16 */){ <nl> av_log ( h -> s . avctx , AV_LOG_ERROR , " illegal num_reorder_frames % d \ n ", sps -> num_reorder_frames ); <nl> return - 1 ;
static int decompress_i ( AVCodecContext * avctx , uint32_t * dst , int linesize ) <nl>  <nl> if ( avctx -> bits_per_coded_sample == 16 ) { <nl> cx1 = ( clr & 0x3F00 ) >> 2 ; <nl> - cx = ( clr & 0xFFFFFF ) >> 16 ; <nl> + cx = ( clr & 0x3FFFFF ) >> 16 ; <nl> } else { <nl> cx1 = ( clr & 0xFC00 ) >> 4 ; <nl> cx = ( clr & 0xFFFFFF ) >> 18 ; <nl> static int decompress_p ( AVCodecContext * avctx , <nl>  <nl> if ( avctx -> bits_per_coded_sample == 16 ) { <nl> cx1 = ( clr & 0x3F00 ) >> 2 ; <nl> - cx = ( clr & 0xFFFFFF ) >> 16 ; <nl> + cx = ( clr & 0x3FFFFF ) >> 16 ; <nl> } else { <nl> cx1 = ( clr & 0xFC00 ) >> 4 ; <nl> cx = ( clr & 0xFFFFFF ) >> 18 ;
static int encode_thread ( AVCodecContext * c , void * arg ){ <nl> int16_t ac [ 6 ][ 16 ]; <nl> const int mvdir = ( best_s . mv_dir & MV_DIR_BACKWARD ) ? 1 : 0 ; <nl> static const int dquant_tab [ 4 ]={- 1 , 1 ,- 2 , 2 }; <nl> + int storecoefs = s -> mb_intra && s -> dc_val [ 0 ]; <nl>  <nl> av_assert2 ( backup_s . dquant == 0 ); <nl>  <nl> static int encode_thread ( AVCodecContext * c , void * arg ){ <nl> if ( qp < s -> avctx -> qmin || qp > s -> avctx -> qmax ) <nl> continue ; <nl> backup_s . dquant = dquant ; <nl> - if ( s -> mb_intra && s -> dc_val [ 0 ]){ <nl> + if ( storecoefs ){ <nl> for ( i = 0 ; i < 6 ; i ++){ <nl> dc [ i ]= s -> dc_val [ 0 ][ s -> block_index [ i ] ]; <nl> memcpy ( ac [ i ], s -> ac_val [ 0 ][ s -> block_index [ i ]], sizeof ( int16_t )* 16 ); <nl> static int encode_thread ( AVCodecContext * c , void * arg ){ <nl> encode_mb_hq ( s , & backup_s , & best_s , CANDIDATE_MB_TYPE_INTER /* wrong but unused */, pb , pb2 , tex_pb , <nl> & dmin , & next_block , s -> mv [ mvdir ][ 0 ][ 0 ], s -> mv [ mvdir ][ 0 ][ 1 ]); <nl> if ( best_s . qscale != qp ){ <nl> - if ( s -> mb_intra && s -> dc_val [ 0 ]){ <nl> + if ( storecoefs ){ <nl> for ( i = 0 ; i < 6 ; i ++){ <nl> s -> dc_val [ 0 ][ s -> block_index [ i ] ]= dc [ i ]; <nl> memcpy ( s -> ac_val [ 0 ][ s -> block_index [ i ]], ac [ i ], sizeof ( int16_t )* 16 );
static int add_file ( AVFormatContext * avf , char * filename , ConcatFile ** rfile , <nl>  <nl> if ( cat -> nb_files >= * nb_files_alloc ) { <nl> unsigned n = FFMAX (* nb_files_alloc * 2 , 16 ); <nl> - if ( n <= cat -> nb_files || <nl> - !( cat -> files = av_realloc_f ( cat -> files , n , sizeof (* cat -> files )))) <nl> + ConcatFile * new_files ; <nl> + if ( n <= cat -> nb_files || n > SIZE_MAX / sizeof (* cat -> files ) || <nl> + !( new_files = av_realloc ( cat -> files , n * sizeof (* cat -> files )))) <nl> return AVERROR ( ENOMEM ); <nl> + cat -> files = new_files ; <nl> * nb_files_alloc = n ; <nl> } <nl> 
static av_cold int libwebp_anim_encode_init ( AVCodecContext * avctx ) <nl> int ret = ff_libwebp_encode_init_common ( avctx ); <nl> if (! ret ) { <nl> LibWebPAnimContext * s = avctx -> priv_data ; <nl> - WebPAnimEncoderOptions enc_options ; <nl> + WebPAnimEncoderOptions enc_options = { 0 }; <nl> WebPAnimEncoderOptionsInit (& enc_options ); <nl> // TODO ( urvang ): Expose some options on command - line perhaps . <nl> s -> enc = WebPAnimEncoderNew ( avctx -> width , avctx -> height , & enc_options );
static int aiff_read_packet ( AVFormatContext * s , <nl> if ( max_size <= 0 ) <nl> return AVERROR_EOF ; <nl>  <nl> + if (! st -> codecpar -> block_align ) { <nl> + av_log ( s , AV_LOG_ERROR , " block_align not set \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> /* Now for that packet */ <nl> switch ( st -> codecpar -> codec_id ) { <nl> case AV_CODEC_ID_ADPCM_IMA_QT :
static int compute_mask ( int step , uint32_t * mask ) <nl> ret = AVERROR ( ENOMEM ); <nl> goto end ; <nl> } <nl> - counter = av_mallocz ( counter_size ); <nl> + counter = av_mallocz ( sizeof ( uint32_t *) * ( 2 * step + 1 )); <nl> if (! counter ) { <nl> ret = AVERROR ( ENOMEM ); <nl> goto end ;
static int rm_assemble_video_frame ( AVFormatContext * s , AVIOContext * pb , <nl> AVPacket * pkt , int len , int * pseq , <nl> int64_t * timestamp ) <nl> { <nl> - int hdr , seq , pic_num , len2 , pos ; <nl> + int hdr ; <nl> + int seq = 0 , pic_num = 0 , len2 = 0 , pos = 0 ; // init to silcense compiler warning <nl> int type ; <nl>  <nl> hdr = avio_r8 ( pb ); len --; <nl> ff_rm_retrieve_cache ( AVFormatContext * s , AVIOContext * pb , <nl> static int rm_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> { <nl> RMDemuxContext * rm = s -> priv_data ; <nl> - AVStream * st ; <nl> + AVStream * st = NULL ; // init to silence compiler warning <nl> int i , len , res , seq = 1 ; <nl> int64_t timestamp , pos ; <nl> int flags ;
static void mdct512 ( int32_t * out , int16_t * in ) <nl> /* shift to simplify computations */ <nl> for ( i = 0 ; i < MDCT_SAMPLES / 4 ; i ++) <nl> rot [ i ] = - in [ i + 3 * MDCT_SAMPLES / 4 ]; <nl> - for (; i < MDCT_SAMPLES ; i ++) <nl> - rot [ i ] = in [ i - MDCT_SAMPLES / 4 ]; <nl> + memcpy (& rot [ MDCT_SAMPLES / 4 ], & in [ 0 ], 3 * MDCT_SAMPLES / 4 * sizeof (* in )); <nl>  <nl> /* pre rotation */ <nl> for ( i = 0 ; i < MDCT_SAMPLES / 4 ; i ++) {
AVStream * video_st , * audio_st ; <nl> int64_t audio_dts , video_dts ; <nl>  <nl> int bframes ; <nl> - int duration ; <nl> - int audio_duration ; <nl> + int64_t duration ; <nl> + int64_t audio_duration ; <nl> int frames ; <nl> int gop_size ; <nl> int64_t next_p_pts ; <nl> static void init_fps ( int bf , int audio_preroll , int fps ) <nl> frames = 0 ; <nl> gop_size = 30 ; <nl> duration = video_st -> time_base . den / fps ; <nl> - audio_duration = 1024 * audio_st -> time_base . den / audio_st -> codec -> sample_rate ; <nl> + audio_duration = 1024LL * audio_st -> time_base . den / audio_st -> codec -> sample_rate ; <nl> if ( audio_preroll ) <nl> - audio_preroll = 2048 * audio_st -> time_base . den / audio_st -> codec -> sample_rate ; <nl> + audio_preroll = 2048LL * audio_st -> time_base . den / audio_st -> codec -> sample_rate ; <nl>  <nl> bframes = bf ; <nl> video_dts = bframes ? - duration : 0 ;
# endif <nl>  <nl> typedef struct UDPContext { <nl> + const AVClass * class ; <nl> int udp_fd ; <nl> int ttl ; <nl> int buffer_size ; <nl> static int udp_socket_create ( UDPContext * s , struct sockaddr_storage * addr , <nl>  <nl> if ((( struct sockaddr *) & s -> dest_addr )-> sa_family ) <nl> family = (( struct sockaddr *) & s -> dest_addr )-> sa_family ; <nl> - res0 = udp_resolve_host ( localaddr [ 0 ] ? localaddr : NULL , s -> local_port , <nl> + res0 = udp_resolve_host (( localaddr && localaddr [ 0 ]) ? localaddr : NULL , s -> local_port , <nl> SOCK_DGRAM , family , AI_PASSIVE ); <nl> if ( res0 == 0 ) <nl> goto fail ;
static int gsm_decode_frame ( AVCodecContext * avctx , void * data , <nl> return avctx -> block_align ; <nl> } <nl>  <nl> + static void gsm_flush ( AVCodecContext * avctx ) <nl> +{ <nl> + GSMContext * s = avctx -> priv_data ; <nl> + memset ( s , 0 , sizeof (* s )); <nl> +} <nl> + <nl> AVCodec ff_gsm_decoder = { <nl> . name = " gsm ", <nl> . type = AVMEDIA_TYPE_AUDIO , <nl> AVCodec ff_gsm_decoder = { <nl> . priv_data_size = sizeof ( GSMContext ), <nl> . init = gsm_init , <nl> . decode = gsm_decode_frame , <nl> + . flush = gsm_flush , <nl> . long_name = NULL_IF_CONFIG_SMALL (" GSM "), <nl> }; <nl>  <nl> AVCodec ff_gsm_ms_decoder = { <nl> . priv_data_size = sizeof ( GSMContext ), <nl> . init = gsm_init , <nl> . decode = gsm_decode_frame , <nl> + . flush = gsm_flush , <nl> . long_name = NULL_IF_CONFIG_SMALL (" GSM Microsoft variant "), <nl> };
static int decode_cell_data ( Cell * cell , uint8_t * block , uint8_t * ref_block , <nl> blk_row_offset = ( row_offset << ( 2 + v_zoom )) - ( cell -> width << 2 ); <nl> line_offset = v_zoom ? row_offset : 0 ; <nl>  <nl> - for ( y = 0 ; y < cell -> height ; is_first_row = 0 , y += 1 + v_zoom ) { <nl> - for ( x = 0 ; x < cell -> width ; x += 1 + h_zoom ) { <nl> + for ( y = 0 ; y + v_zoom < cell -> height ; is_first_row = 0 , y += 1 + v_zoom ) { <nl> + for ( x = 0 ; x + h_zoom < cell -> width ; x += 1 + h_zoom ) { <nl> ref = ref_block ; <nl> dst = block ; <nl> 
static void d3d11va_frames_uninit ( AVHWFramesContext * ctx ) <nl>  <nl> if ( frames_hwctx -> texture ) <nl> ID3D11Texture2D_Release ( frames_hwctx -> texture ); <nl> + frames_hwctx -> texture = NULL ; <nl>  <nl> if ( s -> staging_texture ) <nl> ID3D11Texture2D_Release ( s -> staging_texture ); <nl> + s -> staging_texture = NULL ; <nl> } <nl>  <nl> static void free_texture ( void * opaque , uint8_t * data )
static inline void codeblock ( DiracContext * s , SubBand * b , <nl> } <nl>  <nl> if ( s -> codeblock_mode && !( s -> old_delta_quant && blockcnt_one )) { <nl> - int quant = b -> quant ; <nl> + int quant ; <nl> if ( is_arith ) <nl> - quant += dirac_get_arith_int ( c , CTX_DELTA_Q_F , CTX_DELTA_Q_DATA ); <nl> + quant = dirac_get_arith_int ( c , CTX_DELTA_Q_F , CTX_DELTA_Q_DATA ); <nl> else <nl> - quant += dirac_get_se_golomb ( gb ); <nl> - if ( quant < 0 ) { <nl> + quant = dirac_get_se_golomb ( gb ); <nl> + if ( quant > INT_MAX - b -> quant || b -> quant + quant < 0 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " Invalid quant \ n "); <nl> return ; <nl> } <nl> - b -> quant = quant ; <nl> + b -> quant += quant ; <nl> } <nl>  <nl> if ( b -> quant > ( DIRAC_MAX_QUANT_INDEX - 1 )) {
FF_ENABLE_DEPRECATION_WARNINGS <nl>  <nl> if ( mxg -> soi_ptr - mxg -> buffer > mxg -> cache_size ) { <nl> if ( mxg -> cache_size > 0 ) { <nl> - memcpy ( mxg -> buffer , mxg -> buffer_ptr , mxg -> cache_size ); <nl> + memmove ( mxg -> buffer , mxg -> buffer_ptr , mxg -> cache_size ); <nl> } <nl>  <nl> mxg -> buffer_ptr = mxg -> buffer ;
static int vaapi_encode_h264_write_extra_header ( AVCodecContext * avctx , <nl>  <nl> if ( priv -> sei_needed ) { <nl> if ( priv -> aud_needed ) { <nl> - vaapi_encode_h264_add_nal ( avctx , au , & priv -> aud ); <nl> + err = vaapi_encode_h264_add_nal ( avctx , au , & priv -> aud ); <nl> + if ( err < 0 ) <nl> + goto fail ; <nl> priv -> aud_needed = 0 ; <nl> } <nl> 
static int config_input ( AVFilterLink * inlink ) <nl>  <nl> s -> depth = ( desc -> comp [ 0 ]. depth_minus1 + 1 ) >> 3 ; <nl> s -> step = av_get_padded_bits_per_pixel ( desc ) >> 3 ; <nl> - s -> is_packed = !( desc -> flags & AV_PIX_FMT_FLAG_PLANAR ); <nl> + s -> is_packed = !( desc -> flags & AV_PIX_FMT_FLAG_PLANAR ) && <nl> + ( desc -> nb_components > 1 ); <nl> if ( desc -> flags & AV_PIX_FMT_FLAG_RGB ) { <nl> ff_fill_rgba_map ( rgba_map , inlink -> format ); <nl> for ( i = 0 ; i < 4 ; i ++)
static void selfTest ( uint8_t * ref [ 4 ], int refStride [ 4 ], int w , int h ) <nl> enum PixelFormat srcFormat , dstFormat ; <nl>  <nl> for ( srcFormat = 0 ; srcFormat < PIX_FMT_NB ; srcFormat ++) { <nl> + if (! sws_isSupportedInput ( srcFormat )) <nl> + continue ; <nl> + <nl> for ( dstFormat = 0 ; dstFormat < PIX_FMT_NB ; dstFormat ++) { <nl> int i , j , k ; <nl> int res = 0 ; <nl>  <nl> + if (! sws_isSupportedOutput ( dstFormat )) <nl> + continue ; <nl> + <nl> printf ("% s -> % s \ n ", <nl> sws_format_name ( srcFormat ), <nl> sws_format_name ( dstFormat ));
int avformat_find_stream_info ( AVFormatContext * ic , AVDictionary ** options ) <nl> t = FFMAX ( t , av_rescale_q ( st -> codec_info_nb_frames , av_inv_q ( st -> avg_frame_rate ), AV_TIME_BASE_Q )); <nl>  <nl> if ( t == 0 <nl> - && st -> codec_info_nb_frames > 15 <nl> - && st -> codec -> codec_type == AVMEDIA_TYPE_VIDEO <nl> - && ( ! strcmp ( ic -> iformat -> name , " mpeg ") // this breaks some flvs thus use only for mpegps / ts for now ( for ts we have a sample that needs it ) <nl> - || ! strcmp ( ic -> iformat -> name , " mpegts ")) <nl> + && st -> codec_info_nb_frames > 30 <nl> && st -> info -> fps_first_dts != AV_NOPTS_VALUE <nl> && st -> info -> fps_last_dts != AV_NOPTS_VALUE ) <nl> t = FFMAX ( t , av_rescale_q ( st -> info -> fps_last_dts - st -> info -> fps_first_dts , st -> time_base , AV_TIME_BASE_Q ));
static void vc1_decode_ac_coeff ( VC1Context * v , int * last , int * skip , int * value , <nl> if ( index != vc1_ac_sizes [ codingset ] - 1 ) { <nl> run = vc1_index_decode_table [ codingset ][ index ][ 0 ]; <nl> level = vc1_index_decode_table [ codingset ][ index ][ 1 ]; <nl> - lst = index >= vc1_last_decode_table [ codingset ]; <nl> + lst = index >= vc1_last_decode_table [ codingset ] || get_bits_left ( gb ) < 0 ; <nl> if ( get_bits1 ( gb )) <nl> level = - level ; <nl> } else {
int av_frame_copy ( AVFrame * dst , const AVFrame * src ) <nl>  <nl> if ( dst -> width > 0 && dst -> height > 0 ) <nl> return frame_copy_video ( dst , src ); <nl> - else if ( dst -> nb_samples > 0 && dst -> channel_layout ) <nl> + else if ( dst -> nb_samples > 0 && dst -> channels > 0 ) <nl> return frame_copy_audio ( dst , src ); <nl>  <nl> return AVERROR ( EINVAL );
static int fic_decode_frame ( AVCodecContext * avctx , void * data , <nl> } <nl>  <nl> for ( slice = 0 ; slice < nslices ; slice ++) { <nl> - int slice_off = AV_RB32 ( src + tsize + FIC_HEADER_SIZE + slice * 4 ); <nl> - int slice_size ; <nl> + unsigned slice_off = AV_RB32 ( src + tsize + FIC_HEADER_SIZE + slice * 4 ); <nl> + unsigned slice_size ; <nl> int y_off = ctx -> slice_h * slice ; <nl> int slice_h = ctx -> slice_h ; <nl>  <nl> static int fic_decode_frame ( AVCodecContext * avctx , void * data , <nl> slice_size = AV_RB32 ( src + tsize + FIC_HEADER_SIZE + slice * 4 + 4 ); <nl> } <nl>  <nl> - slice_size -= slice_off ; <nl> - <nl> - if ( slice_off > msize || slice_off + slice_size > msize ) <nl> + if ( slice_size < slice_off || slice_size > msize ) <nl> continue ; <nl>  <nl> + slice_size -= slice_off ; <nl> + <nl> ctx -> slice_data [ slice ]. src = sdata + slice_off ; <nl> ctx -> slice_data [ slice ]. src_size = slice_size ; <nl> ctx -> slice_data [ slice ]. slice_h = slice_h ;
static int ogg_restore ( AVFormatContext * s ) <nl>  <nl> ogg -> state = ost -> next ; <nl>  <nl> - for ( i = 0 ; i < ogg -> nstreams ; i ++) <nl> + for ( i = 0 ; i < ogg -> nstreams ; i ++) { <nl> av_freep (& ogg -> streams [ i ]. buf ); <nl> + if ( i >= ost -> nstreams || ! ost -> streams [ i ]. private ) { <nl> + free_stream ( s , i ); <nl> + } <nl> + } <nl>  <nl> avio_seek ( bc , ost -> pos , SEEK_SET ); <nl> ogg -> page_pos = - 1 ;
static int decode_mb_info ( IVI5DecContext * ctx , IVIBandDesc * band , <nl> } <nl>  <nl> mb -> mv_x = mb -> mv_y = 0 ; /* no motion vector coded */ <nl> - if ( band -> inherit_mv ){ <nl> + if ( band -> inherit_mv && ref_mb ){ <nl> /* motion vector inheritance */ <nl> if ( mv_scale ) { <nl> mb -> mv_x = ivi_scale_mv ( ref_mb -> mv_x , mv_scale ); <nl> static int decode_mb_info ( IVI5DecContext * ctx , IVIBandDesc * band , <nl> } <nl> } <nl> } else { <nl> - if ( band -> inherit_mv ) { <nl> + if ( band -> inherit_mv && ref_mb ) { <nl> mb -> type = ref_mb -> type ; /* copy mb_type from corresponding reference mb */ <nl> } else if ( ctx -> frame_type == FRAMETYPE_INTRA ) { <nl> mb -> type = 0 ; /* mb_type is always INTRA for intra - frames */ <nl> static int decode_mb_info ( IVI5DecContext * ctx , IVIBandDesc * band , <nl> if (! mb -> type ) { <nl> mb -> mv_x = mb -> mv_y = 0 ; /* there is no motion vector in intra - macroblocks */ <nl> } else { <nl> - if ( band -> inherit_mv ){ <nl> + if ( band -> inherit_mv && ref_mb ){ <nl> /* motion vector inheritance */ <nl> if ( mv_scale ) { <nl> mb -> mv_x = ivi_scale_mv ( ref_mb -> mv_x , mv_scale );
static int read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> codec -> codec_id == AV_CODEC_ID_ADPCM_THP_LE ) { <nl> uint8_t * dst ; <nl>  <nl> + if ( size > ( INT_MAX - 32 - 4 ) || <nl> + ( 32 + 4 + size ) > ( INT_MAX / codec -> channels ) || <nl> + ( 32 + 4 + size ) * codec -> channels > INT_MAX - 8 ) <nl> + return AVERROR_INVALIDDATA ; <nl> if ( av_new_packet ( pkt , 8 + ( 32 + 4 + size ) * codec -> channels ) < 0 ) <nl> return AVERROR ( ENOMEM ); <nl> dst = pkt -> data ;
static int ff_asf_get_packet ( AVFormatContext * s , AVIOContext * pb ) <nl> asf -> packet_segments = 1 ; <nl> asf -> packet_segsizetype = 0x80 ; <nl> } <nl> + if ( rsize > packet_length - padsize ) { <nl> + asf -> packet_size_left = 0 ; <nl> + av_log ( s , AV_LOG_ERROR , <nl> + " invalid packet header length % d for pktlen % d -% d at %" PRId64 "\ n ", <nl> + rsize , packet_length , padsize , avio_tell ( pb )); <nl> + return - 1 ; <nl> + } <nl> asf -> packet_size_left = packet_length - padsize - rsize ; <nl> if ( packet_length < asf -> hdr . min_pktsize ) <nl> padsize += asf -> hdr . min_pktsize - packet_length ;
static av_cold int common_init ( AVCodecContext * avctx ){ <nl> s -> avctx = avctx ; <nl> s -> flags = avctx -> flags ; <nl>  <nl> + avcodec_get_frame_defaults (& s -> picture ); <nl> + <nl> dsputil_init (& s -> dsp , avctx ); <nl>  <nl> s -> width = avctx -> width ;
static int latm_decode_extradata ( LATMContext * ctx , uint8_t * buf , int size ) <nl> if ( ctx -> off < 0 ) <nl> return ctx -> off ; <nl>  <nl> + if ( ctx -> object_type == AOT_ALS && ( ctx -> off & 7 )) { <nl> + // as long as avpriv_mpeg4audio_get_config works correctly this is impossible <nl> + av_log ( ctx , AV_LOG_ERROR , " BUG : ALS offset is not byte - aligned \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> /* FIXME : are any formats not allowed in LATM ? */ <nl>  <nl> if ( m4ac . object_type > AOT_SBR && m4ac . object_type != AOT_ALS ) { <nl> static void latm_write_frame_header ( AVFormatContext * s , PutBitContext * bs ) <nl>  <nl> /* AudioSpecificConfig */ <nl> if ( ctx -> object_type == AOT_ALS ) { <nl> - header_size = avctx -> extradata_size -( ctx -> off + 7 ) >> 3 ; <nl> - avpriv_copy_bits ( bs , & avctx -> extradata [ ctx -> off ], header_size ); <nl> + header_size = avctx -> extradata_size -( ctx -> off >> 3 ); <nl> + avpriv_copy_bits ( bs , & avctx -> extradata [ ctx -> off >> 3 ], header_size ); <nl> } else { <nl> avpriv_copy_bits ( bs , avctx -> extradata , ctx -> off + 3 ); <nl> 
static int video_open ( VideoState * is ){ <nl> if ( screen && is -> width == screen -> w && screen -> w == w <nl> && is -> height == screen -> h && screen -> h == h ) <nl> return 0 ; <nl> - <nl> -# ifndef __APPLE__ <nl> screen = SDL_SetVideoMode ( w , h , 0 , flags ); <nl> -# else <nl> - /* setting bits_per_pixel = 0 or 32 causes blank video on OS X */ <nl> - screen = SDL_SetVideoMode ( w , h , 24 , flags ); <nl> -# endif <nl> if (! screen ) { <nl> fprintf ( stderr , " SDL : could not set video mode - exiting \ n "); <nl> do_exit ( is );
static int twolame_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , <nl> if ( ret < 0 ) // twolame error <nl> return AVERROR_UNKNOWN ; <nl>  <nl> - avpkt -> duration = ff_samples_to_time_base ( avctx , frame -> nb_samples ); <nl> if ( frame ) { <nl> + avpkt -> duration = ff_samples_to_time_base ( avctx , frame -> nb_samples ); <nl> if ( frame -> pts != AV_NOPTS_VALUE ) <nl> avpkt -> pts = frame -> pts - ff_samples_to_time_base ( avctx , avctx -> initial_padding ); <nl> } else {
static int decode_nal_units ( H264Context * h , const uint8_t * buf , int buf_size ){ <nl> switch ( hx -> nal_unit_type ) { <nl> case NAL_SPS : <nl> case NAL_PPS : <nl> + case NAL_IDR_SLICE : <nl> + case NAL_SLICE : <nl> nals_needed = nal_index ; <nl> } <nl> continue ;
static inline int wmv2_decode_inter_block ( Wmv2Context * w , DCTELEM * block , int n , <nl> static void wmv2_add_block ( Wmv2Context * w , DCTELEM * block1 , uint8_t * dst , int stride , int n ){ <nl> MpegEncContext * const s = & w -> s ; <nl>  <nl> + if ( s -> block_last_index [ n ] >= 0 ) { <nl> switch ( w -> abt_type_table [ n ]){ <nl> case 0 : <nl> - if ( s -> block_last_index [ n ] >= 0 ) { <nl> - s -> dsp . idct_add ( dst , stride , block1 ); <nl> - } <nl> + s -> dsp . idct_add ( dst , stride , block1 ); <nl> break ; <nl> case 1 : <nl> simple_idct84_add ( dst , stride , block1 ); <nl> static void wmv2_add_block ( Wmv2Context * w , DCTELEM * block1 , uint8_t * dst , int st <nl> default : <nl> av_log ( s -> avctx , AV_LOG_ERROR , " internal error in WMV2 abt \ n "); <nl> } <nl> + } <nl> } <nl>  <nl> void ff_wmv2_add_mb ( MpegEncContext * s , DCTELEM block1 [ 6 ][ 64 ], uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr ){
int ff_jpegls_decode_picture ( MJpegDecodeContext * s , int near , <nl> else <nl> shift = point_transform + ( 16 - s -> bits ); <nl>  <nl> + if ( shift >= 16 ) { <nl> + ret = AVERROR_INVALIDDATA ; <nl> + goto end ; <nl> + } <nl> + <nl> if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO ) { <nl> av_log ( s -> avctx , AV_LOG_DEBUG , <nl> " JPEG - LS params : % ix % i NEAR =% i MV =% i T (% i ,% i ,% i ) "
static void echo_samples_ ## name ## p ( AudioEchoContext * ctx , \ <nl> const double in_gain = ctx -> in_gain ; \ <nl> const int nb_echoes = ctx -> nb_echoes ; \ <nl> const int max_samples = ctx -> max_samples ; \ <nl> - int i , j , chan , index ; \ <nl> + int i , j , chan , av_uninit ( index ); \ <nl> + \ <nl> + av_assert1 ( channels > 0 ); /* would corrupt delay_index */ \ <nl> \ <nl> for ( chan = 0 ; chan < channels ; chan ++) { \ <nl> const type * s = ( type *) src [ chan ]; \
static int aac_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , <nl> tag = s -> chan_map [ i + 1 ]; <nl> chans = tag == TYPE_CPE ? 2 : 1 ; <nl> cpe = & s -> cpe [ i ]; <nl> + cpe -> common_window = 0 ; <nl> memset ( cpe -> is_mask , 0 , sizeof ( cpe -> is_mask )); <nl> memset ( cpe -> ms_mask , 0 , sizeof ( cpe -> ms_mask )); <nl> put_bits (& s -> pb , 3 , tag ); <nl> static int aac_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , <nl> s -> cur_channel = start_ch + ch ; <nl> s -> coder -> search_for_quantizers ( avctx , s , & cpe -> ch [ ch ], s -> lambda ); <nl> } <nl> - cpe -> common_window = 0 ; <nl> if ( chans > 1 <nl> && wi [ 0 ]. window_type [ 0 ] == wi [ 1 ]. window_type [ 0 ] <nl> && wi [ 0 ]. window_shape == wi [ 1 ]. window_shape ) {
static inline int get_ur_golomb_jpegls ( GetBitContext * gb , int k , int limit , int <nl> } else { <nl> int i ; <nl> for ( i = 0 ; SHOW_UBITS ( re , gb , 1 ) == 0 ; i ++){ <nl> + if ( get_bits_left ( gb )<= 0 ) <nl> + return - 1 ; <nl> LAST_SKIP_BITS ( re , gb , 1 ); <nl> UPDATE_CACHE ( re , gb ); <nl> }
static int adpcm_decode_frame ( AVCodecContext * avctx , void * data , <nl> /* Each EA ADPCM frame has a 12 - byte header followed by 30 - byte pieces , <nl> each coding 28 stereo samples . */ <nl>  <nl> + if ( avctx -> channels != 2 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> src += 4 ; // skip sample count ( already read ) <nl>  <nl> current_left_sample = ( int16_t ) bytestream_get_le16 (& src );
static char * value_string ( char * buf , int buf_size , struct unit_value uv ) <nl> const char * prefix_string = ""; <nl> int l ; <nl>  <nl> - if ( use_value_prefix ) { <nl> + if ( use_value_prefix && vald > 1 ) { <nl> long long int index ; <nl>  <nl> if ( uv . unit == unit_byte_str && use_byte_value_binary_prefix ) {
static int mpc_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> { <nl> MPCContext * c = s -> priv_data ; <nl> int ret , size , size2 , curbits , cur = c -> curframe ; <nl> - int64_t tmp , pos ; <nl> + unsigned tmp ; <nl> + int64_t pos ; <nl>  <nl> if ( c -> curframe >= c -> fcount && c -> fcount ) <nl> return - 1 ; <nl> static int mpc_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> if ( curbits <= 12 ){ <nl> size2 = ( tmp >> ( 12 - curbits )) & 0xFFFFF ; <nl> } else { <nl> - tmp = ( tmp << 32 ) | avio_rl32 ( s -> pb ); <nl> - size2 = ( tmp >> ( 44 - curbits )) & 0xFFFFF ; <nl> + size2 = ( tmp << ( curbits - 12 ) | avio_rl32 ( s -> pb ) >> ( 44 - curbits )) & 0xFFFFF ; <nl> } <nl> curbits += 20 ; <nl> avio_seek ( s -> pb , pos , SEEK_SET );
static void swap_channel_layouts_on_filter ( AVFilterContext * filter ) <nl>  <nl> for ( i = 0 ; i < filter -> nb_outputs ; i ++) { <nl> AVFilterLink * outlink = filter -> outputs [ i ]; <nl> - int best_idx , best_score = INT_MIN , best_count_diff = INT_MAX ; <nl> + int best_idx = - 1 , best_score = INT_MIN , best_count_diff = INT_MAX ; <nl>  <nl> if ( outlink -> type != AVMEDIA_TYPE_AUDIO || <nl> outlink -> in_channel_layouts -> nb_channel_layouts < 2 ) <nl> static void swap_channel_layouts_on_filter ( AVFilterContext * filter ) <nl> best_count_diff = count_diff ; <nl> } <nl> } <nl> + av_assert1 ( best_idx >= 0 ); <nl> FFSWAP ( uint64_t , outlink -> in_channel_layouts -> channel_layouts [ 0 ], <nl> outlink -> in_channel_layouts -> channel_layouts [ best_idx ]); <nl> }
static const char * ass_split_section ( ASSSplitContext * ctx , const char * buf ) <nl> } <nl> } <nl> } <nl> - buf += strcspn ( buf , "\ n ") + 1 ; <nl> + buf += strcspn ( buf , "\ n "); <nl> + buf += !!* buf ; <nl> } <nl> return buf ; <nl> }
static inline int parse_nal_units ( AVCodecParserContext * s , const uint8_t * buf , <nl>  <nl> for (;;) { <nl> int src_length , consumed ; <nl> + int ret ; <nl> buf = avpriv_find_start_code ( buf , buf_end , & state ); <nl> if (-- buf + 2 >= buf_end ) <nl> break ; <nl> static inline int parse_nal_units ( AVCodecParserContext * s , const uint8_t * buf , <nl> if ( consumed < 0 ) <nl> return consumed ; <nl>  <nl> - init_get_bits8 ( gb , nal -> data + 2 , nal -> size ); <nl> + ret = init_get_bits8 ( gb , nal -> data + 2 , nal -> size ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> + <nl> switch ( h -> nal_unit_type ) { <nl> case NAL_VPS : <nl> ff_hevc_decode_nal_vps ( gb , avctx , ps );
static int cdxl_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> av_free_packet ( pkt ); <nl> return ret ; <nl> } <nl> + av_shrink_packet ( pkt , CDXL_HEADER_SIZE + ret ); <nl> pkt -> stream_index = cdxl -> video_stream_index ; <nl> pkt -> flags |= AV_PKT_FLAG_KEY ; <nl> pkt -> pos = pos ;
# include " avformat . h " <nl> # include " rawenc . h " <nl>  <nl> +# define MAX_EXTRADATA_SIZE 1024 <nl> + <nl> typedef struct { <nl> AVClass * av_class ; <nl> int off ; <nl> static int latm_decode_extradata ( LATMContext * ctx , uint8_t * buf , int size ) <nl> { <nl> MPEG4AudioConfig m4ac ; <nl>  <nl> + if ( size > MAX_EXTRADATA_SIZE ) { <nl> + av_log ( ctx , AV_LOG_ERROR , " Extradata is larger than currently supported .\ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> ctx -> off = avpriv_mpeg4audio_get_config (& m4ac , buf , size * 8 , 1 ); <nl> if ( ctx -> off < 0 ) <nl> return ctx -> off ; <nl> static int latm_write_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> if ( pkt -> size > 0x1fff ) <nl> goto too_large ; <nl>  <nl> - buf = av_malloc ( pkt -> size + 1024 ); <nl> + buf = av_malloc ( pkt -> size + 1024 + MAX_EXTRADATA_SIZE ); <nl> if (! buf ) <nl> return AVERROR ( ENOMEM ); <nl>  <nl> - init_put_bits (& bs , buf , pkt -> size + 1024 ); <nl> + init_put_bits (& bs , buf , pkt -> size + 1024 + MAX_EXTRADATA_SIZE ); <nl>  <nl> latm_write_frame_header ( s , & bs ); <nl> 
static int mov_create_timecode_track ( AVFormatContext * s , int index , int src_inde <nl>  <nl> /* encode context : tmcd data stream */ <nl> track -> enc = avcodec_alloc_context3 ( NULL ); <nl> + if (! track -> enc ) <nl> + return AVERROR ( ENOMEM ); <nl> track -> enc -> codec_type = AVMEDIA_TYPE_DATA ; <nl> track -> enc -> codec_tag = track -> tag ; <nl> track -> enc -> time_base = av_inv_q ( rate ); <nl>  <nl> /* the tmcd track just contains one packet with the frame number */ <nl> pkt . data = av_malloc ( pkt . size ); <nl> + if (! pkt . data ) <nl> + return AVERROR ( ENOMEM ); <nl> AV_WB32 ( pkt . data , tc . start ); <nl> ret = ff_mov_write_packet ( s , & pkt ); <nl> av_free ( pkt . data );
static void encode_frame ( MpegAudioContext * s , <nl> else <nl> q1 = sample >> shift ; <nl> q1 = ( q1 * mult ) >> P ; <nl> - q [ m ] = (( q1 + ( 1 << P )) * steps ) >> ( P + 1 ); <nl> - if ( q [ m ] < 0 ) <nl> - q [ m ] = 0 ; <nl> + q1 += 1 << P ; <nl> + if ( q1 < 0 ) <nl> + q1 = 0 ; <nl> + q [ m ] = ( unsigned )( q1 * steps ) >> ( P + 1 ); <nl> } <nl> # endif <nl> if ( q [ m ] >= steps )
static av_cold int svq3_decode_init ( AVCodecContext * avctx ) <nl> int offset = ( get_bits_count (& gb )+ 7 )>> 3 ; <nl> uint8_t * buf ; <nl>  <nl> - if (( uint64_t ) watermark_width * 4 > UINT_MAX / watermark_height ) <nl> + if ( watermark_height <= 0 || ( uint64_t ) watermark_width * 4 > UINT_MAX / watermark_height ) <nl> return - 1 ; <nl>  <nl> buf = av_malloc ( buf_len );
static void ac3_output_frame_header ( AC3EncodeContext * s ) <nl> */ <nl> static void output_audio_block ( AC3EncodeContext * s , int blk ) <nl> { <nl> - int ch , i , baie , bnd , got_cpl , ch0 ; <nl> + int ch , i , baie , bnd , got_cpl , av_uninit ( ch0 ); <nl> AC3Block * block = & s -> blocks [ blk ]; <nl>  <nl> /* block switching */ <nl> static av_cold int validate_options ( AC3EncodeContext * s ) <nl> */ <nl> static av_cold void set_bandwidth ( AC3EncodeContext * s ) <nl> { <nl> - int blk , ch , cpl_start ; <nl> + int blk , ch , av_uninit ( cpl_start ); <nl>  <nl> if ( s -> cutoff ) { <nl> /* calculate bandwidth based on user - specified cutoff frequency */
static void destroy_buffers ( SANMVideoContext * ctx ) <nl>  <nl> static av_cold int init_buffers ( SANMVideoContext * ctx ) <nl> { <nl> - av_fast_padded_malloc (& ctx -> frm0 , & ctx -> frm0_size , ctx -> buf_size ); <nl> - av_fast_padded_malloc (& ctx -> frm1 , & ctx -> frm1_size , ctx -> buf_size ); <nl> - av_fast_padded_malloc (& ctx -> frm2 , & ctx -> frm2_size , ctx -> buf_size ); <nl> + av_fast_padded_mallocz (& ctx -> frm0 , & ctx -> frm0_size , ctx -> buf_size ); <nl> + av_fast_padded_mallocz (& ctx -> frm1 , & ctx -> frm1_size , ctx -> buf_size ); <nl> + av_fast_padded_mallocz (& ctx -> frm2 , & ctx -> frm2_size , ctx -> buf_size ); <nl> if (! ctx -> version ) <nl> - av_fast_padded_malloc (& ctx -> stored_frame , <nl> + av_fast_padded_mallocz (& ctx -> stored_frame , <nl> & ctx -> stored_frame_size , ctx -> buf_size ); <nl>  <nl> if (! ctx -> frm0 || ! ctx -> frm1 || ! ctx -> frm2 ||
int ff_get_wav_header ( AVFormatContext * s , AVIOContext * pb , <nl> id = avio_rl16 ( pb ); <nl> codec -> channels = avio_rl16 ( pb ); <nl> codec -> sample_rate = avio_rl32 ( pb ); <nl> - bitrate = avio_rl32 ( pb ) * 8 ; <nl> + bitrate = avio_rl32 ( pb ) * 8LL ; <nl> codec -> block_align = avio_rl16 ( pb ); <nl> } else { <nl> id = avio_rb16 ( pb ); <nl> codec -> channels = avio_rb16 ( pb ); <nl> codec -> sample_rate = avio_rb32 ( pb ); <nl> - bitrate = avio_rb32 ( pb ) * 8 ; <nl> + bitrate = avio_rb32 ( pb ) * 8LL ; <nl> codec -> block_align = avio_rb16 ( pb ); <nl> } <nl> if ( size == 14 ) { /* We ' re dealing with plain vanilla WAVEFORMAT */
static int libx265_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , <nl>  <nl> x265pic . pts = pic -> pts ; <nl> x265pic . bitDepth = av_pix_fmt_desc_get ( avctx -> pix_fmt )-> comp [ 0 ]. depth_minus1 + 1 ; <nl> + <nl> + x265pic . sliceType = pic -> pict_type == AV_PICTURE_TYPE_I ? X265_TYPE_I : <nl> + pic -> pict_type == AV_PICTURE_TYPE_P ? X265_TYPE_P : <nl> + pic -> pict_type == AV_PICTURE_TYPE_B ? X265_TYPE_B : <nl> + X265_TYPE_AUTO ; <nl> } <nl>  <nl> ret = x265_encoder_encode ( ctx -> encoder , & nal , & nnal ,
av_cold void ff_cavsdsp_init_x86 ( CAVSDSPContext * c , AVCodecContext * avctx ) <nl> { <nl> av_unused int cpu_flags = av_get_cpu_flags (); <nl>  <nl> - cavsdsp_init_mmx ( c , avctx ); <nl> + if ( X86_MMX ( cpu_flags )) <nl> + cavsdsp_init_mmx ( c , avctx ); <nl> + <nl> # if HAVE_AMD3DNOW_INLINE <nl> if ( INLINE_AMD3DNOW ( cpu_flags )) <nl> cavsdsp_init_3dnow ( c , avctx );
static av_cold int smvjpeg_decode_init ( AVCodecContext * avctx ) <nl> s -> avctx = avcodec_alloc_context3 ( codec ); <nl>  <nl> av_dict_set (& thread_opt , " threads ", " 1 ", 0 ); <nl> + s -> avctx -> refcounted_frames = 1 ; <nl> s -> avctx -> flags = avctx -> flags ; <nl> s -> avctx -> idct_algo = avctx -> idct_algo ; <nl> if ( ff_codec_open2_recursive ( s -> avctx , codec , & thread_opt ) < 0 ) { <nl> static int smvjpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_siz <nl> cur_frame = avpkt -> pts % s -> frames_per_jpeg ; <nl>  <nl> /* Are we at the start of a block ? */ <nl> - if (! cur_frame ) <nl> + if (! cur_frame ) { <nl> + av_frame_unref ( mjpeg_data ); <nl> ret = avcodec_decode_video2 ( s -> avctx , mjpeg_data , & s -> mjpeg_data_size , avpkt ); <nl> - else if (! s -> mjpeg_data_size ) <nl> + } else if (! s -> mjpeg_data_size ) <nl> return AVERROR ( EINVAL ); <nl>  <nl> desc = av_pix_fmt_desc_get ( s -> avctx -> pix_fmt ); <nl> static av_cold int smvjpeg_decode_end ( AVCodecContext * avctx ) <nl> MJpegDecodeContext * jpg = & s -> jpg ; <nl>  <nl> jpg -> picture_ptr = NULL ; <nl> + av_frame_free (& s -> picture [ 0 ]); <nl> av_frame_free (& s -> picture [ 1 ]); <nl> ff_codec_close_recursive ( s -> avctx ); <nl> av_freep (& s -> avctx );
static void list_fmts ( void (* get_fmt_string )( char * buf , int buf_size , int fmt ), <nl>  <nl> static void opt_frame_pix_fmt ( const char * arg ) <nl> { <nl> - if ( strcmp ( arg , " list ")) <nl> + if ( strcmp ( arg , " list ")) { <nl> frame_pix_fmt = avcodec_get_pix_fmt ( arg ); <nl> - else { <nl> + if ( frame_pix_fmt == PIX_FMT_NONE ) { <nl> + fprintf ( stderr , " Unknown pixel format requested : % s \ n ", arg ); <nl> + av_exit ( 1 ); <nl> + } <nl> + } else { <nl> list_fmts ( avcodec_pix_fmt_string , PIX_FMT_NB ); <nl> av_exit ( 0 ); <nl> }
static void mpegvideo_extract_headers ( AVCodecParserContext * s , <nl> { <nl> ParseContext1 * pc = s -> priv_data ; <nl> const uint8_t * buf_end ; <nl> + const uint8_t * buf_start = buf ; <nl> uint32_t start_code ; <nl> int frame_rate_index , ext_type , bytes_left ; <nl> int frame_rate_ext_n , frame_rate_ext_d ; <nl> static void mpegvideo_extract_headers ( AVCodecParserContext * s , <nl> bytes_left = buf_end - buf ; <nl> switch ( start_code ) { <nl> case PICTURE_START_CODE : <nl> + ff_fetch_timestamp ( s , buf - buf_start - 4 , 1 ); <nl> + <nl> if ( bytes_left >= 2 ) { <nl> s -> pict_type = ( buf [ 1 ] >> 3 ) & 7 ; <nl> }
static int mxf_parse_physical_source_package ( MXFContext * mxf , MXFTrack * source_t <nl> continue ; <nl> } <nl>  <nl> + if ( physical_track -> edit_rate . num <= 0 || <nl> + physical_track -> edit_rate . den <= 0 ) { <nl> + av_log ( mxf -> fc , AV_LOG_WARNING , <nl> + " Invalid edit rate (% d /% d ) found on structural " <nl> + " component #% d , defaulting to 25 / 1 \ n ", <nl> + physical_track -> edit_rate . num , <nl> + physical_track -> edit_rate . den , i ); <nl> + physical_track -> edit_rate = ( AVRational ){ 25 , 1 }; <nl> + } <nl> + <nl> for ( k = 0 ; k < physical_track -> sequence -> structural_components_count ; k ++) { <nl> if (!( mxf_tc = mxf_resolve_timecode_component ( mxf , & physical_track -> sequence -> structural_components_refs [ k ]))) <nl> continue ;
static void get_tree_codes ( uint32_t * bits , int16_t * lens , uint8_t * xlat , <nl>  <nl> s = nodes [ node ]. sym ; <nl> if ( s != - 1 ) { <nl> - bits [* pos ] = (~ pfx ) & (( 1 << FFMAX ( pl , 1 )) - 1 ); <nl> + bits [* pos ] = (~ pfx ) & (( 1U << FFMAX ( pl , 1 )) - 1 ); <nl> lens [* pos ] = FFMAX ( pl , 1 ); <nl> xlat [* pos ] = s + ( pl == 0 ); <nl> (* pos )++;
static void mpc8_parse_seektable ( AVFormatContext * s , int64_t off ) <nl> av_log ( s , AV_LOG_ERROR , " No seek table at given position \ n "); <nl> return ; <nl> } <nl> + if ( size > INT_MAX / 10 || size <= 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Seek table size is invalid \ n "); <nl> + return ; <nl> + } <nl> if (!( buf = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ))) <nl> return ; <nl> avio_read ( s -> pb , buf , size );
int attribute_align_arg sws_scale ( struct SwsContext * c , <nl> src2 [ 0 ] = base ; <nl> } <nl>  <nl> - if (! srcSliceY && ( c -> flags & SWS_BITEXACT ) && ( c -> flags & SWS_ERROR_DIFFUSION )) <nl> + if (! srcSliceY && ( c -> flags & SWS_BITEXACT ) && ( c -> flags & SWS_ERROR_DIFFUSION ) && c -> dither_error [ 0 ]) <nl> for ( i = 0 ; i < 4 ; i ++) <nl> memset ( c -> dither_error [ i ], 0 , sizeof ( c -> dither_error [ 0 ][ 0 ]) * ( c -> dstW + 2 )); <nl> 
ogm_header ( AVFormatContext * s , int idx ) <nl> size -= 52 ; <nl> if ( bytestream2_get_bytes_left (& p ) < size ) <nl> return AVERROR_INVALIDDATA ; <nl> - ff_alloc_extradata ( st -> codecpar , size ); <nl> + if ( ff_alloc_extradata ( st -> codecpar , size ) < 0 ) <nl> + return AVERROR ( ENOMEM ); <nl> bytestream2_get_buffer (& p , st -> codecpar -> extradata , st -> codecpar -> extradata_size ); <nl> } <nl> }
static av_cold int init ( AVFilterContext * ctx , const char * args ) <nl> if (! scale -> h_expr ) <nl> av_opt_set ( scale , " h ", " ih ", 0 ); <nl>  <nl> - av_log ( ctx , AV_LOG_VERBOSE , " w :% s h :% s flags :% s interl :% d \ n ", <nl> - scale -> w_expr , scale -> h_expr , scale -> flags_str , scale -> interlaced ); <nl> + av_log ( ctx , AV_LOG_VERBOSE , " w :% s h :% s flags :'% s ' interl :% d \ n ", <nl> + scale -> w_expr , scale -> h_expr , ( char *) av_x_if_null ( scale -> flags_str , ""), scale -> interlaced ); <nl>  <nl> scale -> flags = SWS_BILINEAR ; <nl> if ( scale -> flags_str ) {
static int64_t mkv_write_seekhead ( AVIOContext * pb , mkv_seekhead * seekhead ) <nl>  <nl> currentpos = avio_tell ( pb ); <nl>  <nl> - if ( seekhead -> reserved_size > 0 ) <nl> - if ( avio_seek ( pb , seekhead -> filepos , SEEK_SET ) < 0 ) <nl> - return - 1 ; <nl> + if ( seekhead -> reserved_size > 0 ) { <nl> + if ( avio_seek ( pb , seekhead -> filepos , SEEK_SET ) < 0 ) { <nl> + currentpos = - 1 ; <nl> + goto fail ; <nl> + } <nl> + } <nl>  <nl> metaseek = start_ebml_master ( pb , MATROSKA_ID_SEEKHEAD , seekhead -> reserved_size ); <nl> for ( i = 0 ; i < seekhead -> num_entries ; i ++) { <nl> static int64_t mkv_write_seekhead ( AVIOContext * pb , mkv_seekhead * seekhead ) <nl>  <nl> currentpos = seekhead -> filepos ; <nl> } <nl> + fail : <nl> av_free ( seekhead -> entries ); <nl> av_free ( seekhead ); <nl> 
static void matroska_clear_queue ( MatroskaDemuxContext * matroska ) <nl> } <nl>  <nl> static int matroska_parse_laces ( MatroskaDemuxContext * matroska , uint8_t ** buf , <nl> - int size , int type , <nl> + int * buf_size , int type , <nl> uint32_t ** lace_buf , int * laces ) <nl> { <nl> - int res = 0 , n ; <nl> + int res = 0 , n , size = * buf_size ; <nl> uint8_t * data = * buf ; <nl> uint32_t * lace_size ; <nl>  <nl> static int matroska_parse_laces ( MatroskaDemuxContext * matroska , uint8_t ** buf , <nl>  <nl> * buf = data ; <nl> * lace_buf = lace_size ; <nl> + * buf_size = size ; <nl>  <nl> return res ; <nl> } <nl> static int matroska_parse_block ( MatroskaDemuxContext * matroska , uint8_t * data , <nl> matroska -> skip_to_keyframe = 0 ; <nl> } <nl>  <nl> - res = matroska_parse_laces ( matroska , & data , size , ( flags & 0x06 ) >> 1 , <nl> + res = matroska_parse_laces ( matroska , & data , & size , ( flags & 0x06 ) >> 1 , <nl> & lace_size , & laces ); <nl>  <nl> if ( res )
int ff_lpc_calc_coefs ( LPCContext * s , <nl>  <nl> if ( pass ){ <nl> double eval , inv , rinv ; <nl> - eval = m [( pass - 1 )& 1 ]. evaluate_lls (& m [( pass - 1 )& 1 ], var + 1 , max_order - 1 ); <nl> + eval = m [ pass & 1 ]. evaluate_lls (& m [( pass - 1 )& 1 ], var + 1 , max_order - 1 ); <nl> eval = ( 512 >> pass ) + fabs ( eval - var [ 0 ]); <nl> inv = 1 / eval ; <nl> rinv = sqrt ( inv );
static void idr ( H264Context * h ){ <nl> static void flush_dpb ( AVCodecContext * avctx ){ <nl> H264Context * h = avctx -> priv_data ; <nl> int i ; <nl> - for ( i = 0 ; i < 16 ; i ++) <nl> + for ( i = 0 ; i < 16 ; i ++) { <nl> + if ( h -> delayed_pic [ i ]) <nl> + h -> delayed_pic [ i ]-> reference = 0 ; <nl> h -> delayed_pic [ i ]= NULL ; <nl> + } <nl> + if ( h -> delayed_output_pic ) <nl> + h -> delayed_output_pic -> reference = 0 ; <nl> h -> delayed_output_pic = NULL ; <nl> idr ( h ); <nl> if ( h -> s . current_picture_ptr )
static int read_filter_params ( MLPDecodeContext * m , GetBitContext * gbp , <nl> /* TODO : Check validity of state data . */ <nl>  <nl> for ( i = 0 ; i < order ; i ++) <nl> - fp -> state [ i ] = state_bits ? get_sbits ( gbp , state_bits ) << state_shift : 0 ; <nl> + fp -> state [ i ] = state_bits ? get_sbits ( gbp , state_bits ) * ( 1 << state_shift ) : 0 ; <nl> } <nl> } <nl> 
static int device_open ( AVFormatContext * ctx ) <nl> if ( fd < 0 ) { <nl> err = errno ; <nl>  <nl> - av_log ( ctx , AV_LOG_ERROR , " Cannot open video device % s : % s \ n ", <nl> + av_log ( ctx , AV_LOG_ERROR , " Cannot open video device % s : % s \ n ", <nl> ctx -> filename , strerror ( err )); <nl>  <nl> return AVERROR ( err ); <nl> static int device_open ( AVFormatContext * ctx ) <nl> goto fail ; <nl> } <nl>  <nl> - av_log ( ctx , AV_LOG_VERBOSE , "[% d ] Capabilities : % x \ n ", <nl> + av_log ( ctx , AV_LOG_VERBOSE , " fd :% d capabilities :% x \ n ", <nl> fd , cap . capabilities ); <nl>  <nl> if (!( cap . capabilities & V4L2_CAP_VIDEO_CAPTURE )) { <nl> static void list_formats ( AVFormatContext * ctx , int fd , int type ) <nl> if (!( vfd . flags & V4L2_FMT_FLAG_COMPRESSED ) && <nl> type & V4L_RAWFORMATS ) { <nl> const char * fmt_name = av_get_pix_fmt_name ( pix_fmt ); <nl> - av_log ( ctx , AV_LOG_INFO , " R : % 9s : % 20s :", <nl> + av_log ( ctx , AV_LOG_INFO , " Raw : % 9s : % 20s :", <nl> fmt_name ? fmt_name : " Unsupported ", <nl> vfd . description ); <nl> } else if ( vfd . flags & V4L2_FMT_FLAG_COMPRESSED && <nl> type & V4L_COMPFORMATS ) { <nl> AVCodec * codec = avcodec_find_encoder ( codec_id ); <nl> - av_log ( ctx , AV_LOG_INFO , " C : % 9s : % 20s :", <nl> + av_log ( ctx , AV_LOG_INFO , " Compressed : % 9s : % 20s :", <nl> codec ? codec -> name : " Unsupported ", <nl> vfd . description ); <nl> } else {
int av_image_check_sar ( unsigned int w , unsigned int h , AVRational sar ) <nl> { <nl> int64_t scaled_dim ; <nl>  <nl> - if (! sar . den ) <nl> + if ( sar . den <= 0 || sar . num < 0 ) <nl> return AVERROR ( EINVAL ); <nl>  <nl> if (! sar . num || sar . num == sar . den )
static int vpx_decode ( AVCodecContext * avctx , <nl> ( img_alpha = vpx_codec_get_frame (& ctx -> decoder_alpha , & iter_alpha )))) { <nl> uint8_t * planes [ 4 ]; <nl> int linesizes [ 4 ]; <nl> + <nl> + if ( img -> d_w > img -> w || img -> d_h > img -> h ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Display dimensions % dx % d exceed storage % dx % d \ n ", <nl> + img -> d_w , img -> d_h , img -> w , img -> h ); <nl> + return AVERROR_EXTERNAL ; <nl> + } <nl> + <nl> if (( ret = set_pix_fmt ( avctx , img , ctx -> has_alpha_channel )) < 0 ) { <nl> # ifdef VPX_IMG_FMT_HIGHBITDEPTH <nl> av_log ( avctx , AV_LOG_ERROR , " Unsupported output colorspace (% d ) / bit_depth (% d )\ n ",
static int rtcp_parse_packet ( RTPDemuxContext * s , const unsigned char * buf , int l <nl> while ( len >= 2 ) { <nl> switch ( buf [ 1 ]) { <nl> case RTCP_SR : <nl> - if ( len < 16 ) { <nl> + if ( len < 20 ) { <nl> av_log ( NULL , AV_LOG_ERROR , " Invalid length for RTCP SR packet \ n "); <nl> return AVERROR_INVALIDDATA ; <nl> }
static inline int vertClassify_altivec ( uint8_t src [], int stride , PPContext * c ) <nl> vector by assuming ( stride % 16 ) == 0 , unfortunately <nl> this is not always true . <nl> */ <nl> + short data_0 = (( c -> nonBQP * c -> ppMode . baseDcDiff )>> 8 ) + 1 ; <nl> DECLARE_ALIGNED ( 16 , short , data )[ 8 ] = <nl> { <nl> - (( c -> nonBQP * c -> ppMode . baseDcDiff )>> 8 ) + 1 , <nl> - data [ 0 ] * 2 + 1 , <nl> + data_0 , <nl> + data_0 * 2 + 1 , <nl> c -> QP * 2 , <nl> c -> QP * 4 <nl> };
void ff_frame_thread_free ( AVCodecContext * avctx , int thread_count ) <nl> pthread_join ( p -> thread , NULL ); <nl> p -> thread_init = 0 ; <nl>  <nl> - if ( codec -> close ) <nl> + if ( codec -> close && p -> avctx ) <nl> codec -> close ( p -> avctx ); <nl>  <nl> release_delayed_buffers ( p ); <nl> void ff_frame_thread_free ( AVCodecContext * avctx , int thread_count ) <nl> av_packet_unref (& p -> avpkt ); <nl> av_freep (& p -> released_buffers ); <nl>  <nl> - if ( i ) { <nl> + if ( i && p -> avctx ) { <nl> av_freep (& p -> avctx -> priv_data ); <nl> av_freep (& p -> avctx -> slice_offset ); <nl> } <nl>  <nl> - av_freep (& p -> avctx -> internal ); <nl> + if ( p -> avctx ) <nl> + av_freep (& p -> avctx -> internal ); <nl> av_freep (& p -> avctx ); <nl> } <nl> 
static inline int l3_unscale ( int value , int exponent ) <nl> # endif <nl> if ( e > ( SUINT ) 31 ) <nl> return 0 ; <nl> - m = ( m + ( 1 << ( e - 1 ))) >> e ; <nl> + m = ( m + (( 1U << e )>> 1 )) >> e ; <nl>  <nl> return m ; <nl> }
static int mov_read_keys ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl>  <nl> avio_skip ( pb , 4 ); <nl> count = avio_rb32 ( pb ); <nl> - if ( count > UINT_MAX / sizeof (* c -> meta_keys )) { <nl> + if ( count > UINT_MAX / sizeof (* c -> meta_keys ) - 1 ) { <nl> av_log ( c -> fc , AV_LOG_ERROR , <nl> " The ' keys ' atom with the invalid key count : % d \ n ", count ); <nl> return AVERROR_INVALIDDATA ;
static int vorbis_parse_setup_hdr_floors ( vorbis_context * vc ) { <nl> } <nl>  <nl> for ( k = 0 ; k <( 1 << floor_setup -> data . t1 . class_subclasses [ j ]);++ k ) { <nl> - floor_setup -> data . t1 . subclass_books [ j ][ k ]= get_bits ( gb , 8 )- 1 ; <nl> + floor_setup -> data . t1 . subclass_books [ j ][ k ]=( int16_t ) get_bits ( gb , 8 )- 1 ; <nl>  <nl> AV_DEBUG (" book % d . : % d \ n ", k , floor_setup -> data . t1 . subclass_books [ j ][ k ]); <nl> }
simple_round : <nl>  <nl> int64_t av_add_stable ( AVRational ts_tb , int64_t ts , AVRational inc_tb , int64_t inc ) <nl> { <nl> + int64_t m , d ; <nl> + <nl> if ( inc != 1 ) <nl> inc_tb = av_mul_q ( inc_tb , ( AVRational ) { inc , 1 }); <nl>  <nl> + m = inc_tb . num * ( int64_t ) ts_tb . den ; <nl> + d = inc_tb . den * ( int64_t ) ts_tb . num ; <nl> + <nl> + if ( m % d == 0 ) <nl> + return ts + m / d ; <nl> + <nl> if ( av_cmp_q ( inc_tb , ts_tb ) < 0 ) { <nl> // increase step is too small for even 1 step to be representable <nl> return ts ;
av_cold int ffv1_init_slice_contexts ( FFV1Context * f ) <nl> int sxe = f -> avctx -> width * ( sx + 1 ) / f -> num_h_slices ; <nl> int sys = f -> avctx -> height * sy / f -> num_v_slices ; <nl> int sye = f -> avctx -> height * ( sy + 1 ) / f -> num_v_slices ; <nl> + <nl> + if (! fs ) <nl> + return AVERROR ( ENOMEM ); <nl> + <nl> f -> slice_context [ i ] = fs ; <nl> memcpy ( fs , f , sizeof (* fs )); <nl> memset ( fs -> rc_stat2 , 0 , sizeof ( fs -> rc_stat2 ));
static void start_children ( FFServerStream * feed ) <nl> feed -> pid = fork (); <nl> if ( feed -> pid < 0 ) { <nl> http_log (" Unable to create children : % s \ n ", strerror ( errno )); <nl> + av_free ( pathname ); <nl> exit ( EXIT_FAILURE ); <nl> } <nl> 
static inline int l1_unscale ( int n , int mant , int scale_factor ) <nl> shift = scale_factor_modshift [ scale_factor ]; <nl> mod = shift & 3 ; <nl> shift >>= 2 ; <nl> - val = MUL64 ( mant + (- 1 << n ) + 1 , scale_factor_mult [ n - 1 ][ mod ]); <nl> + val = MUL64 (( int )( mant + (- 1U << n ) + 1 ), scale_factor_mult [ n - 1 ][ mod ]); <nl> shift += n ; <nl> /* NOTE : at this point , 1 <= shift >= 21 + 15 */ <nl> return ( int )(( val + ( 1LL << ( shift - 1 ))) >> shift );
int ff_combine_frame ( ParseContext * pc , int next , const uint8_t ** buf , int * buf_s <nl> if ( next == END_NOT_FOUND ){ <nl> void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , (* buf_size ) + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ); <nl>  <nl> - if (! new_buffer ) <nl> + if (! new_buffer ) { <nl> + pc -> index = 0 ; <nl> return AVERROR ( ENOMEM ); <nl> + } <nl> pc -> buffer = new_buffer ; <nl> memcpy (& pc -> buffer [ pc -> index ], * buf , * buf_size ); <nl> pc -> index += * buf_size ; <nl> int ff_combine_frame ( ParseContext * pc , int next , const uint8_t ** buf , int * buf_s <nl> /* append to buffer */ <nl> if ( pc -> index ){ <nl> void * new_buffer = av_fast_realloc ( pc -> buffer , & pc -> buffer_size , next + pc -> index + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> - <nl> - if (! new_buffer ) <nl> + if (! new_buffer ) { <nl> + pc -> overread_index = <nl> + pc -> index = 0 ; <nl> return AVERROR ( ENOMEM ); <nl> + } <nl> pc -> buffer = new_buffer ; <nl> if ( next > - FF_INPUT_BUFFER_PADDING_SIZE ) <nl> memcpy (& pc -> buffer [ pc -> index ], * buf ,
uint32_t av_crc ( const AVCRC * ctx , uint32_t crc , const uint8_t * buffer , size_t le <nl> const uint8_t * end = buffer + length ; <nl>  <nl> # if ! CONFIG_SMALL <nl> - if (! ctx [ 256 ]) <nl> + if (! ctx [ 256 ]) { <nl> + while ((( intptr_t ) buffer & 3 ) && buffer < end ) <nl> + crc = ctx [(( uint8_t ) crc ) ^ * buffer ++] ^ ( crc >> 8 ); <nl> + <nl> while ( buffer < end - 3 ){ <nl> crc ^= le2me_32 (*( const uint32_t *) buffer ); buffer += 4 ; <nl> crc = ctx [ 3 * 256 + ( crc & 0xFF )] <nl> uint32_t av_crc ( const AVCRC * ctx , uint32_t crc , const uint8_t * buffer , size_t le <nl> ^ ctx [ 1 * 256 + (( crc >> 16 )& 0xFF )] <nl> ^ ctx [ 0 * 256 + (( crc >> 24 ) )]; <nl> } <nl> + } <nl> # endif <nl> while ( buffer < end ) <nl> crc = ctx [(( uint8_t ) crc ) ^ * buffer ++] ^ ( crc >> 8 );
static ChannelElement * get_che ( AACContext * ac , int type , int elem_id ) <nl> int layout_map_tags ; <nl> push_output_configuration ( ac ); <nl>  <nl> + av_log ( ac -> avctx , AV_LOG_DEBUG , " mono with CPE \ n "); <nl> + <nl> if ( set_default_channel_config ( ac -> avctx , layout_map , & layout_map_tags , <nl> 2 ) < 0 ) <nl> return NULL ; <nl> static ChannelElement * get_che ( AACContext * ac , int type , int elem_id ) <nl> int layout_map_tags ; <nl> push_output_configuration ( ac ); <nl>  <nl> + av_log ( ac -> avctx , AV_LOG_DEBUG , " stereo with SCE \ n "); <nl> + <nl> if ( set_default_channel_config ( ac -> avctx , layout_map , & layout_map_tags , <nl> 1 ) < 0 ) <nl> return NULL ;
static int kempf_decode_tile ( G2MContext * c , int tile_x , int tile_y , <nl> return 0 ; <nl> zsize = ( src [ 0 ] << 8 ) | src [ 1 ]; src += 2 ; <nl>  <nl> - if ( src_end - src < zsize ) <nl> + if ( src_end - src < zsize + ( sub_type != 2 )) <nl> return AVERROR_INVALIDDATA ; <nl>  <nl> ret = uncompress ( c -> kempf_buf , & dlen , src , zsize ); <nl> static int kempf_decode_tile ( G2MContext * c , int tile_x , int tile_y , <nl> for ( i = 0 ; i < ( FFALIGN ( height , 16 ) >> 4 ); i ++) { <nl> for ( j = 0 ; j < ( FFALIGN ( width , 16 ) >> 4 ); j ++) { <nl> if (! bits ) { <nl> + if ( src >= src_end ) <nl> + return AVERROR_INVALIDDATA ; <nl> bitbuf = * src ++; <nl> bits = 8 ; <nl> }
static int read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> bytestream_put_le16 (& buf , 0 ); <nl> bytestream_put_le32 (& buf , 0 ); <nl>  <nl> - if (( ret = avio_read ( pb , buf , image -> size )) < 0 ) <nl> + if (( ret = avio_read ( pb , buf , image -> size )) < 0 ) { <nl> + av_packet_unref ( pkt ); <nl> return ret ; <nl> + } <nl>  <nl> st -> codecpar -> bits_per_coded_sample = AV_RL16 ( buf + 14 ); <nl> 
static int vmdaudio_decode_frame ( AVCodecContext * avctx , <nl>  <nl> silent_chunks = 0 ; <nl> if ( block_type == BLOCK_TYPE_INITIAL ) { <nl> - uint32_t flags = AV_RB32 ( buf ); <nl> + uint32_t flags ; <nl> + if ( buf_size < 4 ) <nl> + return - 1 ; <nl> + flags = AV_RB32 ( buf ); <nl> silent_chunks = av_popcount ( flags ); <nl> buf += 4 ; <nl> buf_size -= 4 ;
static av_cold int rl2_decode_end ( AVCodecContext * avctx ) <nl> { <nl> Rl2Context * s = avctx -> priv_data ; <nl>  <nl> - av_free ( s -> back_frame ); <nl> + av_freep (& s -> back_frame ); <nl>  <nl> return 0 ; <nl> }
int ff_socket ( int af , int type , int proto ) <nl> { <nl> fd = socket ( af , type , proto ); <nl> # if HAVE_FCNTL <nl> - if ( fd != - 1 ) <nl> - fcntl ( fd , F_SETFD , FD_CLOEXEC ); <nl> + if ( fd != - 1 ) { <nl> + if ( fcntl ( fd , F_SETFD , FD_CLOEXEC ) == - 1 ) <nl> + av_log ( NULL , AV_LOG_DEBUG , " Failed to set close on exec \ n "); <nl> + } <nl> # endif <nl> } <nl> return fd ;
static int mpeg4video_probe ( AVProbeData * probe_packet ) <nl>  <nl> for ( i = 0 ; i < probe_packet -> buf_size ; i ++){ <nl> temp_buffer = ( temp_buffer << 8 ) + probe_packet -> buf [ i ]; <nl> - if (( temp_buffer & 0xffffff00 ) != 0x100 ) <nl> + if ( temp_buffer & 0xfffffe00 ) <nl> + continue ; <nl> + if ( temp_buffer < 2 ) <nl> continue ; <nl>  <nl> if ( temp_buffer == VOP_START_CODE ) VOP ++; <nl> else if ( temp_buffer == VISUAL_OBJECT_START_CODE ) VISO ++; <nl> - else if ( temp_buffer < 0x120 ) VO ++; <nl> - else if ( temp_buffer < 0x130 ) VOL ++; <nl> + else if ( temp_buffer >= 0x100 && temp_buffer < 0x120 ) VO ++; <nl> + else if ( temp_buffer >= 0x120 && temp_buffer < 0x130 ) VOL ++; <nl> else if ( !( 0x1AF < temp_buffer && temp_buffer < 0x1B7 ) <nl> && !( 0x1B9 < temp_buffer && temp_buffer < 0x1C4 )) res ++; <nl> }
int LLVMFuzzerTestOneInput ( const uint8_t * data , size_t size ) { <nl>  <nl> int res = avcodec_open2 ( ctx , c , NULL ); <nl> if ( res < 0 ) <nl> - return res ; <nl> + return 0 ; // Failure of avcodec_open2 () does not imply that a issue was found <nl>  <nl> FDBCreate (& buffer ); <nl> int got_frame ;
void ff_aac_search_for_ltp ( AACEncContext * s , SingleChannelElement * sce , <nl>  <nl> if ( sce -> ics . window_sequence [ 0 ] == EIGHT_SHORT_SEQUENCE ) { <nl> if ( sce -> ics . ltp . lag ) { <nl> - memset (& sce -> lcoeffs [ 0 ], 0 . 0f , 3072 * sizeof ( sce -> lcoeffs [ 0 ])); <nl> + memset (& sce -> ltp_state [ 0 ], 0 , 3072 * sizeof ( sce -> ltp_state [ 0 ])); <nl> memset (& sce -> ics . ltp , 0 , sizeof ( LongTermPrediction )); <nl> } <nl> return ;
static int mpeg_decode_mb ( MpegEncContext * s , int16_t block [ 12 ][ 64 ]) <nl> dmy = get_dmv ( s ); <nl>  <nl>  <nl> - s -> last_mv [ i ][ 0 ][ 1 ] = my << my_shift ; <nl> - s -> last_mv [ i ][ 1 ][ 1 ] = my << my_shift ; <nl> + s -> last_mv [ i ][ 0 ][ 1 ] = my * ( 1 << my_shift ); <nl> + s -> last_mv [ i ][ 1 ][ 1 ] = my * ( 1 << my_shift ); <nl>  <nl> s -> mv [ i ][ 0 ][ 0 ] = mx ; <nl> s -> mv [ i ][ 0 ][ 1 ] = my ;
static int video_thread ( void * arg ) <nl> frame -> opaque = picref ; <nl> } <nl>  <nl> - if ( av_cmp_q ( tb , is -> video_st -> time_base )) { <nl> + if ( ret >= 0 && av_cmp_q ( tb , is -> video_st -> time_base )) { <nl> av_unused int64_t pts1 = pts_int ; <nl> pts_int = av_rescale_q ( pts_int , tb , is -> video_st -> time_base ); <nl> av_dlog ( NULL , " video_thread (): "
static int huff_build10 ( VLC * vlc , uint8_t * len ) <nl> for ( i = 0 ; i < 1024 ; i ++) { <nl> he [ i ]. sym = 1023 - i ; <nl> he [ i ]. len = len [ i ]; <nl> + if ( len [ i ] == 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> } <nl> AV_QSORT ( he , 1024 , HuffEntry , huff_cmp_len10 ); <nl>  <nl> static int huff_build ( VLC * vlc , uint8_t * len ) <nl> for ( i = 0 ; i < 256 ; i ++) { <nl> he [ i ]. sym = 255 - i ; <nl> he [ i ]. len = len [ i ]; <nl> + if ( len [ i ] == 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> } <nl> AV_QSORT ( he , 256 , HuffEntry , huff_cmp_len ); <nl> 
static double get_f64l ( uint8_t * p ) <nl>  <nl> int main ( int argc , char * argv []) <nl> { <nl> - int i , j ; <nl> + uint64_t i , j ; <nl> uint64_t sse = 0 ; <nl> double sse_d = 0 . 0 ; <nl> FILE * f [ 2 ]; <nl> int main ( int argc , char * argv []) <nl> int64_t max ; <nl> int shift = argc < 5 ? 0 : atoi ( argv [ 4 ]); <nl> int skip_bytes = argc < 6 ? 0 : atoi ( argv [ 5 ]); <nl> - int size0 = 0 ; <nl> - int size1 = 0 ; <nl> + uint64_t size0 = 0 ; <nl> + uint64_t size1 = 0 ; <nl> uint64_t maxdist = 0 ; <nl> double maxdist_d = 0 . 0 ; <nl>  <nl> int main ( int argc , char * argv []) <nl> else <nl> psnr = 1000 * F - 1 ; // floating point free infinity :) <nl>  <nl> - printf (" stddev :% 5d .% 02d PSNR :% 3d .% 02d MAXDIFF :% 5 " PRIu64 " bytes :% 9d /% 9d \ n ", <nl> + printf (" stddev :% 5d .% 02d PSNR :% 3d .% 02d MAXDIFF :% 5 " PRIu64 " bytes :% 9 " PRIu64 "/% 9 " PRIu64 "\ n ", <nl> ( int )( dev / F ), ( int )( dev % F ), <nl> ( int )( psnr / F ), ( int )( psnr % F ), <nl> maxdist , size0 , size1 ); <nl> int main ( int argc , char * argv []) <nl>  <nl> maxdist = maxdist_d * scale ; <nl>  <nl> - printf (" stddev :% 10 . 2f PSNR :% s MAXDIFF :% 10 " PRIu64 " bytes :% 9d /% 9d \ n ", <nl> + printf (" stddev :% 10 . 2f PSNR :% s MAXDIFF :% 10 " PRIu64 " bytes :% 9 " PRIu64 "/% 9 " PRIu64 "\ n ", <nl> dev * scale , psnr_str , maxdist , size0 , size1 ); <nl> break ; <nl> }
static int img_read_header ( AVFormatContext * s1 ) <nl> s -> img_last = last_index ; <nl> s -> img_number = first_index ; <nl> /* compute duration */ <nl> - st -> start_time = 0 ; <nl> - st -> duration = last_index - first_index + 1 ; <nl> + if (! s -> ts_from_file ) { <nl> + st -> start_time = 0 ; <nl> + st -> duration = last_index - first_index + 1 ; <nl> + } <nl> } <nl>  <nl> if ( s1 -> video_codec_id ) {
skip : <nl> // sign extension <nl> int32_t cts = ( avio_rb24 ( s -> pb ) + 0xff800000 ) ^ 0xff800000 ; <nl> pts = dts + cts ; <nl> - if ( cts < 0 ) { // dts are wrong <nl> + if ( cts < 0 && ! flv -> wrong_dts ) { // dts might be wrong <nl> flv -> wrong_dts = 1 ; <nl> av_log ( s , AV_LOG_WARNING , <nl> " Negative cts , previous timestamps might be wrong .\ n ");
*/ <nl>  <nl> # include " libavutil / intreadwrite . h " <nl> +# include " libavcodec / internal . h " <nl> # include " avformat . h " <nl> # include " internal . h " <nl>  <nl> static int genh_read_header ( AVFormatContext * s ) <nl>  <nl> st -> codecpar -> codec_type = AVMEDIA_TYPE_AUDIO ; <nl> st -> codecpar -> channels = avio_rl32 ( s -> pb ); <nl> - if ( st -> codecpar -> channels <= 0 ) <nl> + if ( st -> codecpar -> channels <= 0 || st -> codecpar -> channels > FF_SANE_NB_CHANNELS ) <nl> return AVERROR_INVALIDDATA ; <nl> if ( st -> codecpar -> channels == 1 ) <nl> st -> codecpar -> channel_layout = AV_CH_LAYOUT_MONO ;
static void mov_build_index ( MOVContext * mov , AVStream * st ) <nl> int rescaled = sc -> time_offset < 0 ? av_rescale ( sc -> time_offset , sc -> time_scale , mov -> time_scale ) : sc -> time_offset ; <nl> current_dts = - rescaled ; <nl> if ( sc -> ctts_data && sc -> stts_data && <nl> - sc -> ctts_data [ 0 ]. duration / sc -> stts_data [ 0 ]. duration > 16 ) { <nl> + sc -> ctts_data [ 0 ]. duration / FFMAX ( sc -> stts_data [ 0 ]. duration , 1 ) > 16 ) { <nl> /* more than 16 frames delay , dts are likely wrong <nl> this happens with files created by iMovie */ <nl> sc -> wrong_dts = 1 ;
static inline void copy ( LZOContext * c , int cnt ) <nl> */ <nl> static inline void copy_backptr ( LZOContext * c , int back , int cnt ) <nl> { <nl> - register const uint8_t * src = & c -> out [- back ]; <nl> register uint8_t * dst = c -> out ; <nl> - if ( src < c -> out_start || src > dst ) { <nl> + if ( dst - c -> out_start < back ) { <nl> c -> error |= AV_LZO_INVALID_BACKPTR ; <nl> return ; <nl> }
static int opus_decode_packet ( AVCodecContext * avctx , void * data , <nl> int coded_samples = 0 ; <nl> int decoded_samples = 0 ; <nl> int i , ret ; <nl> + int delayed_samples = 0 ; <nl>  <nl> for ( i = 0 ; i < c -> nb_streams ; i ++) { <nl> OpusStreamContext * s = & c -> streams [ i ]; <nl> s -> out [ 0 ] = <nl> s -> out [ 1 ] = NULL ; <nl> + delayed_samples = FFMAX ( delayed_samples , s -> delayed_samples ); <nl> } <nl>  <nl> /* decode the header of the first sub - packet to find out the sample count */ <nl> static int opus_decode_packet ( AVCodecContext * avctx , void * data , <nl> c -> streams [ 0 ]. silk_samplerate = get_silk_samplerate ( pkt -> config ); <nl> } <nl>  <nl> - frame -> nb_samples = coded_samples + c -> streams [ 0 ]. delayed_samples ; <nl> + frame -> nb_samples = coded_samples + delayed_samples ; <nl>  <nl> /* no input or buffered data => nothing to do */ <nl> if (! frame -> nb_samples ) {
static int twolame_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , <nl> if ( ret < 0 ) // twolame error <nl> return AVERROR_UNKNOWN ; <nl>  <nl> - avpkt -> duration = ff_samples_to_time_base ( avctx , frame -> nb_samples ); <nl> if ( frame ) { <nl> + avpkt -> duration = ff_samples_to_time_base ( avctx , frame -> nb_samples ); <nl> if ( frame -> pts != AV_NOPTS_VALUE ) <nl> avpkt -> pts = frame -> pts - ff_samples_to_time_base ( avctx , avctx -> delay ); <nl> } else {
# ifndef AVUTIL_MEM_INTERNAL_H <nl> # define AVUTIL_MEM_INTERNAL_H <nl>  <nl> +# include " avassert . h " <nl> +# include " mem . h " <nl> + <nl> static inline int ff_fast_malloc ( void * ptr , unsigned int * size , size_t min_size , int zero_realloc ) <nl> { <nl> void * val ;
static int http_read_stream ( URLContext * h , uint8_t * buf , int size ) <nl>  <nl> av_log ( NULL , AV_LOG_TRACE , " Chunked encoding data size : %" PRId64 "'\ n ", <nl> s -> chunksize ); <nl> - <nl> - if (! s -> chunksize ) <nl> + if ( s -> chunksize < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + else if (! s -> chunksize ) <nl> return 0 ; <nl> break ; <nl> }
static int ism_write_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> SmoothStreamingContext * c = s -> priv_data ; <nl> AVStream * st = s -> streams [ pkt -> stream_index ]; <nl> OutputStream * os = & c -> streams [ pkt -> stream_index ]; <nl> - int64_t end_dts = ( c -> nb_fragments + 1 ) * c -> min_frag_duration ; <nl> + int64_t end_dts = ( c -> nb_fragments + 1LL ) * c -> min_frag_duration ; <nl> int ret ; <nl>  <nl> if ( st -> first_dts == AV_NOPTS_VALUE )
static int find_headers_search_validate ( FLACParseContext * fpc , int offset ) <nl> (* end_handle )-> offset = offset ; <nl> (* end_handle )-> link_penalty = av_malloc ( sizeof ( int ) * <nl> FLAC_MAX_SEQUENTIAL_HEADERS ); <nl> + if (!(* end_handle )-> link_penalty ) { <nl> + av_freep ( end_handle ); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> + <nl> for ( i = 0 ; i < FLAC_MAX_SEQUENTIAL_HEADERS ; i ++) <nl> (* end_handle )-> link_penalty [ i ] = FLAC_HEADER_NOT_PENALIZED_YET ; <nl> 
static int mxf_write_footer ( AVFormatContext * s ) <nl> AVIOContext * pb = s -> pb ; <nl> int err = 0 ; <nl>  <nl> + if (! mxf -> header_written || <nl> + ( s -> oformat == & ff_mxf_opatom_muxer && ! mxf -> body_partition_offset )) { <nl> + /* reason could be invalid options / not supported codec / out of memory */ <nl> + err = AVERROR_UNKNOWN ; <nl> + goto end ; <nl> + } <nl> + <nl> mxf -> duration = mxf -> last_indexed_edit_unit + mxf -> edit_units_count ; <nl>  <nl> mxf_write_klv_fill ( s );
static int fourxm_read_header ( AVFormatContext * s , <nl> goto fail ; <nl> } <nl> if ( current_track + 1 > fourxm -> track_count ) { <nl> - fourxm -> track_count = current_track + 1 ; <nl> fourxm -> tracks = av_realloc_f ( fourxm -> tracks , <nl> sizeof ( AudioTrack ), <nl> - fourxm -> track_count ); <nl> + current_track + 1 ); <nl> if (! fourxm -> tracks ) { <nl> ret = AVERROR ( ENOMEM ); <nl> goto fail ; <nl> } <nl> + memset (& fourxm -> tracks [ fourxm -> track_count ], 0 , <nl> + sizeof ( AudioTrack ) * ( current_track + 1 - fourxm -> track_count )); <nl> + fourxm -> track_count = current_track + 1 ; <nl> } <nl> fourxm -> tracks [ current_track ]. adpcm = AV_RL32 (& header [ i + 12 ]); <nl> fourxm -> tracks [ current_track ]. channels = AV_RL32 (& header [ i + 36 ]);
static int speex_header ( AVFormatContext * s , int idx ) { <nl>  <nl> spxp -> packet_size = AV_RL32 ( p + 56 ); <nl> frames_per_packet = AV_RL32 ( p + 64 ); <nl> + if ( spxp -> packet_size < 0 || <nl> + frames_per_packet < 0 || <nl> + spxp -> packet_size * ( int64_t ) frames_per_packet > INT32_MAX / 256 ) { <nl> + av_log ( s , AV_LOG_ERROR , " invalid packet_size , frames_per_packet % d % d \ n ", spxp -> packet_size , frames_per_packet ); <nl> + spxp -> packet_size = 0 ; <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> if ( frames_per_packet ) <nl> spxp -> packet_size *= frames_per_packet ; <nl> 
static int tak_decode_frame ( AVCodecContext * avctx , void * data , <nl>  <nl> if ( s -> sample_shift [ chan ] > 0 ) <nl> for ( i = 0 ; i < s -> nb_samples ; i ++) <nl> - decoded [ i ] <<= s -> sample_shift [ chan ]; <nl> + decoded [ i ] *= 1 << s -> sample_shift [ chan ]; <nl> } <nl> } <nl> 
void ff_lzw_decode_tail ( LZWState * p ) <nl>  <nl> if ( s -> mode == FF_LZW_GIF ) { <nl> while ( s -> bs > 0 ) { <nl> - if ( s -> pbuf + s -> bs >= s -> ebuf ) { <nl> + if ( s -> bs >= s -> ebuf - s -> pbuf ) { <nl> s -> pbuf = s -> ebuf ; <nl> break ; <nl> } else {
static void search_for_quantizers_twoloop ( AVCodecContext * avctx , <nl> int toomanybits , toofewbits ; <nl> char nzs [ 128 ]; <nl> uint8_t nextband [ 128 ]; <nl> - int maxsf [ 128 ]; <nl> + int maxsf [ 128 ], minsf [ 128 ]; <nl> float dists [ 128 ] = { 0 }, qenergies [ 128 ] = { 0 }, uplims [ 128 ], euplims [ 128 ], energies [ 128 ]; <nl> float maxvals [ 128 ], spread_thr_r [ 128 ]; <nl> float min_spread_thr_r , max_spread_thr_r ; <nl> static void search_for_quantizers_twoloop ( AVCodecContext * avctx , <nl> abs_pow34_v ( s -> scoefs , sce -> coeffs , 1024 ); <nl> ff_quantize_band_cost_cache_init ( s ); <nl>  <nl> + for ( i = 0 ; i < sizeof ( minsf ) / sizeof ( minsf [ 0 ]); ++ i ) <nl> + minsf [ i ] = 0 ; <nl> for ( w = 0 ; w < sce -> ics . num_windows ; w += sce -> ics . group_len [ w ]) { <nl> start = w * 128 ; <nl> for ( g = 0 ; g < sce -> ics . num_swb ; g ++) { <nl> const float * scaled = s -> scoefs + start ; <nl> maxvals [ w * 16 + g ] = find_max_val ( sce -> ics . group_len [ w ], sce -> ics . swb_sizes [ g ], scaled ); <nl> + minsf [ w * 16 + g ] = coef2minsf ( maxvals [ w * 16 + g ]); <nl> start += sce -> ics . swb_sizes [ g ]; <nl> } <nl> } <nl> static void search_for_quantizers_twoloop ( AVCodecContext * avctx , <nl> recomprd = 1 ; <nl> for ( i = 0 ; i < 128 ; i ++) { <nl> if ( sce -> sf_idx [ i ] > SCALE_ONE_POS ) { <nl> - int new_sf = FFMAX ( SCALE_ONE_POS , sce -> sf_idx [ i ] - qstep ); <nl> + int new_sf = FFMAX3 ( minsf [ i ], SCALE_ONE_POS , sce -> sf_idx [ i ] - qstep ); <nl> if ( new_sf != sce -> sf_idx [ i ]) { <nl> sce -> sf_idx [ i ] = new_sf ; <nl> changed = 1 ; <nl> static void search_for_quantizers_twoloop ( AVCodecContext * avctx , <nl> int cmb = find_min_book ( maxvals [ w * 16 + g ], sce -> sf_idx [ w * 16 + g ]); <nl> int mindeltasf = FFMAX ( 0 , prev - SCALE_MAX_DIFF ); <nl> int maxdeltasf = FFMIN ( SCALE_MAX_POS - SCALE_DIV_512 , prev + SCALE_MAX_DIFF ); <nl> - if ((! cmb || dists [ w * 16 + g ] > uplims [ w * 16 + g ]) && sce -> sf_idx [ w * 16 + g ] > mindeltasf ) { <nl> + if ((! cmb || dists [ w * 16 + g ] > uplims [ w * 16 + g ]) && sce -> sf_idx [ w * 16 + g ] > FFMAX ( mindeltasf , minsf [ w * 16 + g ])) { <nl> /* Try to make sure there is some energy in every nonzero band <nl> * NOTE : This algorithm must be forcibly imbalanced , pushing harder <nl> * on holes or more distorted bands at first , otherwise there ' s
static int init_duplicate_context ( MpegEncContext * s , MpegEncContext * base ){ <nl> int i ; <nl>  <nl> // edge emu needs blocksize + filter length - 1 (= 17x17 for halfpel / 21x21 for h264 ) <nl> - FF_ALLOCZ_OR_GOTO ( s -> avctx , s -> allocated_edge_emu_buffer , ( s -> width + 64 )* 2 * 21 * 2 , fail ); //( width + edge + align )* interlaced * MBsize * tolerance <nl> - s -> edge_emu_buffer = s -> allocated_edge_emu_buffer + ( s -> width + 64 )* 2 * 21 ; <nl> + FF_ALLOCZ_OR_GOTO ( s -> avctx , s -> allocated_edge_emu_buffer , ( s -> width + 64 )* 2 * 21 * 2 * 2 , fail ); //( width + edge + align )* interlaced * MBsize * tolerance <nl> + s -> edge_emu_buffer = s -> allocated_edge_emu_buffer + ( s -> width + 64 )* 2 * 21 * 2 ; <nl>  <nl> // FIXME should be linesize instead of s -> width * 2 but that is not known before get_buffer () <nl> FF_ALLOCZ_OR_GOTO ( s -> avctx , s -> me . scratchpad , ( s -> width + 64 )* 4 * 16 * 2 * sizeof ( uint8_t ), fail )
static int eval_refl ( int * refl , const int16_t * coefs , RA144Context * ractx ) <nl> for ( j = 0 ; j <= i ; j ++) <nl> bp1 [ j ] = (( bp2 [ j ] - (( refl [ i + 1 ] * bp2 [ i - j ]) >> 12 )) * ( 0x1000000 / b )) >> 12 ; <nl>  <nl> - refl [ i ] = bp1 [ i ]; <nl> - <nl> if (( unsigned ) bp1 [ i ] + 0x1000 > 0x1fff ) <nl> return 1 ; <nl>  <nl> + refl [ i ] = bp1 [ i ]; <nl> + <nl> FFSWAP ( int *, bp1 , bp2 ); <nl> } <nl> return 0 ;
static int mv_read_packet ( AVFormatContext * avctx , AVPacket * pkt ) <nl> AVStream * st = avctx -> streams [ mv -> stream_index ]; <nl> const AVIndexEntry * index ; <nl> int frame = mv -> frame [ mv -> stream_index ]; <nl> - int ret ; <nl> + int64_t ret ; <nl> uint64_t pos ; <nl>  <nl> if ( frame < st -> nb_index_entries ) {
static int get_siz ( J2kDecoderContext * s ) <nl> s -> tile_offset_y = bytestream_get_be32 (& s -> buf ); // YT0Siz <nl> s -> ncomponents = bytestream_get_be16 (& s -> buf ); // CSiz <nl>  <nl> + if ( s -> tile_width <= 0 || s -> tile_height <= 0 ) <nl> + return AVERROR ( EINVAL ); <nl> + <nl> if ( s -> buf_end - s -> buf < 2 * s -> ncomponents ) <nl> return AVERROR ( EINVAL ); <nl> 
static int mxf_parse_physical_source_package ( MXFContext * mxf , MXFTrack * source_t <nl> break ; <nl>  <nl> /* the name of physical source package is name of the reel or tape */ <nl> - if ( physical_package -> name [ 0 ]) <nl> + if ( physical_package -> name && physical_package -> name [ 0 ]) <nl> av_dict_set (& st -> metadata , " reel_name ", physical_package -> name , 0 ); <nl>  <nl> /* the source timecode is calculated by adding the start_position of the sourceclip from the file source package track
static int nprobe ( AVFormatContext * s , uint8_t * enc_header , unsigned size , <nl> taglen = AV_RB32 (& enc_header [ pos + 32 ]); <nl> datalen = AV_RB32 (& enc_header [ pos + 36 ]) >> 4 ; <nl>  <nl> - pos += 44 + taglen ; <nl> + pos += 44 ; <nl> + if ( size - pos < taglen ) <nl> + return - 1 ; <nl> + <nl> + pos += taglen ; <nl>  <nl> if ( datalen << 4 > size - pos ) <nl> return - 1 ;
static int mov_text_decode_frame ( AVCodecContext * avctx , <nl> int text_length , tsmb_type , ret_tsmb ; <nl> uint64_t tsmb_size ; <nl> const uint8_t * tsmb ; <nl> + size_t i ; <nl>  <nl> if (! ptr || avpkt -> size < 2 ) <nl> return AVERROR_INVALIDDATA ; <nl> static int mov_text_decode_frame ( AVCodecContext * avctx , <nl> if ( tsmb_size > avpkt -> size - m -> tracksize ) <nl> break ; <nl>  <nl> - for ( size_t i = 0 ; i < box_count ; i ++) { <nl> + for ( i = 0 ; i < box_count ; i ++) { <nl> if ( tsmb_type == box_types [ i ]. type ) { <nl> if ( m -> tracksize + m -> size_var + box_types [ i ]. base_size > avpkt -> size ) <nl> break ;
static int decode_codestream ( J2kDecoderContext * s ) <nl>  <nl> static int jp2_find_codestream ( J2kDecoderContext * s ) <nl> { <nl> - int32_t atom_size ; <nl> + uint32_t atom_size ; <nl> int found_codestream = 0 , search_range = 10 ; <nl>  <nl> // skip jpeg2k signature atom <nl> s -> buf += 12 ; <nl>  <nl> - while (! found_codestream && search_range ) { <nl> + while (! found_codestream && search_range && s -> buf_end - s -> buf >= 8 ) { <nl> atom_size = AV_RB32 ( s -> buf ); <nl> if ( AV_RB32 ( s -> buf + 4 ) == JP2_CODESTREAM ) { <nl> found_codestream = 1 ; <nl> s -> buf += 8 ; <nl> } else { <nl> + if ( s -> buf_end - s -> buf < atom_size ) <nl> + return 0 ; <nl> s -> buf += atom_size ; <nl> search_range --; <nl> } <nl> static int decode_frame ( AVCodecContext * avctx , <nl> return AVERROR ( EINVAL ); <nl>  <nl> // check if the image is in jp2 format <nl> - if (( AV_RB32 ( s -> buf ) == 12 ) && ( AV_RB32 ( s -> buf + 4 ) == JP2_SIG_TYPE ) && <nl> + if ( s -> buf_end - s -> buf >= 12 && <nl> + ( AV_RB32 ( s -> buf ) == 12 ) && ( AV_RB32 ( s -> buf + 4 ) == JP2_SIG_TYPE ) && <nl> ( AV_RB32 ( s -> buf + 8 ) == JP2_SIG_VALUE )) { <nl> if (! jp2_find_codestream ( s )) { <nl> av_log ( avctx , AV_LOG_ERROR , " couldn ' t find jpeg2k codestream atom \ n ");
static int mpeg_decode_slice ( MpegEncContext * s , int mb_y , <nl> if ( mb_y == 0 && s -> codec_tag == AV_RL32 (" SLIF ")) { <nl> skip_bits1 (& s -> gb ); <nl> } else { <nl> - for (;;) { <nl> + while ( get_bits_left (& s -> gb ) > 0 ) { <nl> int code = get_vlc2 (& s -> gb , mbincr_vlc . table , MBINCR_VLC_BITS , 2 ); <nl> if ( code < 0 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " first mb_incr damaged \ n ");
static av_always_inline void filter_mb_dir ( const H264Context * h , H264SliceContex <nl> // Do not use s -> qscale as luma quantizer because it has not the same <nl> // value in IPCM macroblocks . <nl> qp = ( h -> cur_pic . qscale_table [ mb_xy ] + h -> cur_pic . qscale_table [ mbn_xy ] + 1 ) >> 1 ; <nl> - ff_tlog ( h -> avctx , " filter mb :% d /% d dir :% d edge :% d , QPy :% d ls :% d uvls :% d ", mb_x , mb_y , dir , edge , qp , tmp_linesize , tmp_uvlinesize ); <nl> + ff_tlog ( h -> avctx , " filter mb :% d /% d dir :% d , QPy :% d ls :% d uvls :% d ", mb_x , mb_y , dir , qp , tmp_linesize , tmp_uvlinesize ); <nl> { int i ; for ( i = 0 ; i < 4 ; i ++) ff_tlog ( h -> avctx , " bS [% d ]:% d ", i , bS [ i ]); ff_tlog ( h -> avctx , "\ n "); } <nl> filter_mb_edgeh ( & img_y [ j * linesize ], tmp_linesize , bS , qp , a , b , h , 0 ); <nl> chroma_qp_avg [ 0 ] = ( sl -> chroma_qp [ 0 ] + get_chroma_qp ( h -> ps . pps , 0 , h -> cur_pic . qscale_table [ mbn_xy ]) + 1 ) >> 1 ;
static int escape124_decode_frame ( AVCodecContext * avctx , <nl> cb_size = s -> num_superblocks << cb_depth ; <nl> } <nl> } <nl> + if ( s -> num_superblocks >= INT_MAX >> cb_depth ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Depth or num_superblocks are too large \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> av_freep (& s -> codebooks [ i ]. blocks ); <nl> s -> codebooks [ i ] = unpack_codebook (& gb , cb_depth , cb_size ); <nl> if (! s -> codebooks [ i ]. blocks )
static int build_huff ( const uint8_t * src , VLC * vlc , int * fsym ) <nl> * fsym = he [ 0 ]. sym ; <nl> return 0 ; <nl> } <nl> - if ( he [ 0 ]. len > 32 ) <nl> - return - 1 ; <nl>  <nl> last = 255 ; <nl> while ( he [ last ]. len == 255 && last ) <nl> last --; <nl>  <nl> + if ( he [ last ]. len > 32 ) <nl> + return - 1 ; <nl> + <nl> code = 1 ; <nl> for ( i = last ; i >= 0 ; i --) { <nl> codes [ i ] = code >> ( 32 - he [ i ]. len );
static int mov_text_decode_frame ( AVCodecContext * avctx , <nl> m -> size_var = 8 ; <nl> // size_var is equal to 8 or 16 depending on the size of box <nl>  <nl> - if ( m -> tracksize + tsmb_size > avpkt -> size ) <nl> + if ( tsmb_size > avpkt -> size - m -> tracksize ) <nl> break ; <nl>  <nl> for ( size_t i = 0 ; i < box_count ; i ++) {
int av_tempfile ( const char * prefix , char ** filename , int log_offset , void * log_c <nl> if ( fd < 0 ) { <nl> int err = AVERROR ( errno ); <nl> av_log (& file_log_ctx , AV_LOG_ERROR , " ff_tempfile : Cannot open temporary file % s \ n ", * filename ); <nl> + av_freep ( filename ); <nl> return err ; <nl> } <nl> return fd ; /* success */
static int tgv_decode_frame ( AVCodecContext * avctx , <nl> frame -> pict_type = AV_PICTURE_TYPE_I ; <nl>  <nl> if (! s -> frame_buffer && <nl> - !( s -> frame_buffer = av_malloc ( s -> width * s -> height ))) <nl> + !( s -> frame_buffer = av_mallocz ( s -> width * s -> height ))) <nl> return AVERROR ( ENOMEM ); <nl>  <nl> if ( unpack ( buf , buf_end , s -> frame_buffer , s -> avctx -> width , s -> avctx -> height ) < 0 ) {
static int decode_dds1 ( GetByteContext * gb , uint8_t * frame , int width , int height <nl> return AVERROR_INVALIDDATA ; <nl> frame += v ; <nl> } else { <nl> - if ( frame_end - frame < width + 3 ) <nl> + if ( frame_end - frame < width + 4 ) <nl> return AVERROR_INVALIDDATA ; <nl> frame [ 0 ] = frame [ 1 ] = <nl> frame [ width ] = frame [ width + 1 ] = bytestream2_get_byte ( gb );
retry : <nl> } else { <nl> level = SHOW_UBITS ( re , & s -> gb , 5 ); <nl> SKIP_CACHE ( re , & s -> gb , 5 ); <nl> - level |= SHOW_SBITS ( re , & s -> gb , 6 )<< 5 ; <nl> + level |= SHOW_SBITS ( re , & s -> gb , 6 ) * ( 1 << 5 ); <nl> SKIP_COUNTER ( re , & s -> gb , 5 + 6 ); <nl> } <nl> }
void ff_spatial_idwt_slice2 ( DWTContext * d , int y ); <nl> ( b0 + b1 ) <nl>  <nl> # define COMPOSE_FIDELITYiL0 ( b0 , b1 , b2 , b3 , b4 , b5 , b6 , b7 , b8 )\ <nl> - ( b4 - (( int )(- 8 *( b0 +( unsigned ) b8 ) + 21 *( b1 +( unsigned ) b7 ) - 46 *( b2 +( unsigned ) b6 ) + 161 *( b3 +( unsigned ) b5 ) + 128 ) >> 8 )) <nl> + (( unsigned ) b4 - (( int )(- 8 *( b0 +( unsigned ) b8 ) + 21 *( b1 +( unsigned ) b7 ) - 46 *( b2 +( unsigned ) b6 ) + 161 *( b3 +( unsigned ) b5 ) + 128 ) >> 8 )) <nl>  <nl> # define COMPOSE_FIDELITYiH0 ( b0 , b1 , b2 , b3 , b4 , b5 , b6 , b7 , b8 )\ <nl> - ( b4 + (( int )(- 2 *( b0 +( unsigned ) b8 ) + 10 *( b1 +( unsigned ) b7 ) - 25 *( b2 +( unsigned ) b6 ) + 81 *( b3 +( unsigned ) b5 ) + 128 ) >> 8 )) <nl> + (( unsigned ) b4 + (( int )(- 2 *( b0 +( unsigned ) b8 ) + 10 *( b1 +( unsigned ) b7 ) - 25 *( b2 +( unsigned ) b6 ) + 81 *( b3 +( unsigned ) b5 ) + 128 ) >> 8 )) <nl>  <nl> # define COMPOSE_DAUB97iL1 ( b0 , b1 , b2 )\ <nl> ( b1 - (( int )( 1817 *( b0 + ( unsigned ) b2 ) + 2048 ) >> 12 ))
static int asf_read_unknown ( AVFormatContext * s , const GUIDParseTable * g ) <nl> if (( ret = detect_unknown_subobject ( s , asf -> unknown_offset , <nl> asf -> unknown_size )) < 0 ) <nl> return ret ; <nl> - } else <nl> + } else { <nl> + if ( size < 24 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Too small size %" PRIu64 " (< 24 ).\ n ", size ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> avio_skip ( pb , size - 24 ); <nl> + } <nl>  <nl> return 0 ; <nl> }
static int tiff_decode_tag ( TiffContext * s , AVFrame * frame ) <nl> bytestream2_skip (& pal_gb [ 2 ], count / 3 * off * 2 ); <nl>  <nl> off = ( type_sizes [ type ] - 1 ) << 3 ; <nl> + if ( off > 31U ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " palette shift % d is out of range \ n ", off ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> for ( i = 0 ; i < count / 3 ; i ++) { <nl> uint32_t p = 0xFF000000 ; <nl> p |= ( ff_tget (& pal_gb [ 0 ], type , s -> le ) >> off ) << 16 ;
static int dca_find_frame_end ( DCAParseContext * pc1 , const uint8_t * buf , <nl> if ( IS_MARKER ( state , i , buf , buf_size ) && ( state == pc1 -> lastmarker || pc1 -> lastmarker == DCA_HD_MARKER )) { <nl> if ( pc1 -> framesize > pc1 -> size ) <nl> continue ; <nl> - if (! pc1 -> framesize ){ <nl> + // We have to check that we really read a full frame here , and that it isn ' t a pure HD frame , because their size is not constant . <nl> + if (! pc1 -> framesize && state == pc1 -> lastmarker && state != DCA_HD_MARKER ){ <nl> pc1 -> framesize = pc1 -> hd_pos ? pc1 -> hd_pos : pc1 -> size ; <nl> } <nl> pc -> frame_start_found = 0 ;
# include " avformat . h " <nl>  <nl> # define RIFF_TAG MKTAG (' R ', ' I ', ' F ', ' F ') <nl> -# define _4XMV_TAG MKTAG (' 4 ', ' X ', ' M ', ' V ') <nl> +# define FOURXMV_TAG MKTAG (' 4 ', ' X ', ' M ', ' V ') <nl> # define LIST_TAG MKTAG (' L ', ' I ', ' S ', ' T ') <nl> # define HEAD_TAG MKTAG (' H ', ' E ', ' A ', ' D ') <nl> # define TRK__TAG MKTAG (' T ', ' R ', ' K ', ' _ ') <nl> typedef struct FourxmDemuxContext { <nl> static int fourxm_probe ( AVProbeData * p ) <nl> { <nl> if (( AV_RL32 (& p -> buf [ 0 ]) != RIFF_TAG ) || <nl> - ( AV_RL32 (& p -> buf [ 8 ]) != _4XMV_TAG )) <nl> + ( AV_RL32 (& p -> buf [ 8 ]) != FOURXMV_TAG )) <nl> return 0 ; <nl>  <nl> return AVPROBE_SCORE_MAX ;
typedef struct { <nl> struct FFBufQueue queue_top ; <nl> struct FFBufQueue queue_bottom ; <nl> int hsub , vsub ; ///< chroma subsampling values <nl> + int nb_planes ; <nl> int frame_requested ; <nl> char * all_expr ; <nl> enum BlendMode all_mode ; <nl> static int config_input_top ( AVFilterLink * inlink ) <nl>  <nl> b -> hsub = pix_desc -> log2_chroma_w ; <nl> b -> vsub = pix_desc -> log2_chroma_h ; <nl> + b -> nb_planes = av_pix_fmt_count_planes ( inlink -> format ); <nl> return 0 ; <nl> } <nl>  <nl> static void blend_frame ( AVFilterContext * ctx , <nl> FilterParams * param ; <nl> int plane ; <nl>  <nl> - for ( plane = 0 ; dst_buf -> data [ plane ]; plane ++) { <nl> + for ( plane = 0 ; plane < b -> nb_planes ; plane ++) { <nl> int hsub = plane == 1 || plane == 2 ? b -> hsub : 0 ; <nl> int vsub = plane == 1 || plane == 2 ? b -> vsub : 0 ; <nl> int outw = dst_buf -> width >> hsub ; <nl> static int filter_frame ( AVFilterLink * inlink , AVFrame * buf ) <nl>  <nl> b -> frame_requested = 0 ; <nl> blend_frame ( ctx , top_buf , bottom_buf , out_buf ); <nl> - ret = ff_filter_frame ( ctx -> outputs [ 0 ], out_buf ); <nl> + ret = ff_filter_frame ( outlink , out_buf ); <nl> av_frame_free (& top_buf ); <nl> av_frame_free (& bottom_buf ); <nl> }
static int dvbsub_decode ( AVCodecContext * avctx , <nl> break ; <nl> case DVBSUB_DISPLAYDEFINITION_SEGMENT : <nl> dvbsub_parse_display_definition_segment ( avctx , p , segment_length ); <nl> + break ; <nl> case DVBSUB_DISPLAY_SEGMENT : <nl> * data_size = dvbsub_display_end_segment ( avctx , p , segment_length , sub ); <nl> break ;
static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPac <nl> src += 2 ; <nl> chunks = AV_RB16 ( src ); src += 2 ; <nl> while ( chunks --) { <nl> + if ( buf_size - ( src - buf ) < 12 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Premature end of data !\ n "); <nl> + return - 1 ; <nl> + } <nl> dx = AV_RB16 ( src ); src += 2 ; <nl> dy = AV_RB16 ( src ); src += 2 ; <nl> w = AV_RB16 ( src ); src += 2 ;
typedef struct OggVorbisDecContext { <nl> ogg_packet op ; /**< ogg packet */ <nl> } OggVorbisDecContext ; <nl>  <nl> + static int oggvorbis_decode_close ( AVCodecContext * avccontext ); <nl> + <nl> static int oggvorbis_decode_init ( AVCodecContext * avccontext ) { <nl> OggVorbisDecContext * context = avccontext -> priv_data ; <nl> uint8_t * p = avccontext -> extradata ; <nl> static int oggvorbis_decode_init ( AVCodecContext * avccontext ) { <nl> return 0 ; <nl>  <nl> error : <nl> - vorbis_info_clear (& context -> vi ); <nl> - vorbis_comment_clear (& context -> vc ) ; <nl> + oggvorbis_decode_close ( avccontext ); <nl> return ret ; <nl> } <nl>  <nl> static int oggvorbis_decode_frame ( AVCodecContext * avccontext , void * data , <nl> static int oggvorbis_decode_close ( AVCodecContext * avccontext ) { <nl> OggVorbisDecContext * context = avccontext -> priv_data ; <nl>  <nl> + vorbis_block_clear (& context -> vb ); <nl> + vorbis_dsp_clear (& context -> vd ); <nl> vorbis_info_clear (& context -> vi ) ; <nl> vorbis_comment_clear (& context -> vc ) ; <nl> 
static int lag_read_prob_header ( lag_rac * rac , GetBitContext * gb ) <nl> } <nl>  <nl> scale_factor ++; <nl> - cumulative_target = 1 << scale_factor ; <nl> + if ( scale_factor >= 32U ) <nl> + return AVERROR_INVALIDDATA ; <nl> + cumulative_target = 1U << scale_factor ; <nl>  <nl> if ( scaled_cumul_prob > cumulative_target ) { <nl> av_log ( rac -> avctx , AV_LOG_ERROR ,
static void probe_codec ( AVFormatContext * s , AVStream * st , const AVPacket * pkt ) <nl> -- st -> probe_packets ; <nl>  <nl> if ( pkt ) { <nl> - pd -> buf = av_realloc ( pd -> buf , pd -> buf_size + pkt -> size + AVPROBE_PADDING_SIZE ); <nl> + uint8_t * new_buf = av_realloc ( pd -> buf , pd -> buf_size + pkt -> size + AVPROBE_PADDING_SIZE ); <nl> + if (! new_buf ) <nl> + goto no_packet ; <nl> + pd -> buf = new_buf ; <nl> memcpy ( pd -> buf + pd -> buf_size , pkt -> data , pkt -> size ); <nl> pd -> buf_size += pkt -> size ; <nl> memset ( pd -> buf + pd -> buf_size , 0 , AVPROBE_PADDING_SIZE ); <nl> } else { <nl> + no_packet : <nl> st -> probe_packets = 0 ; <nl> } <nl> 
static int fourxm_read_header ( AVFormatContext * s , <nl> goto fail ; <nl> } <nl> current_track = AV_RL32 (& header [ i + 8 ]); <nl> + if (( unsigned ) current_track >= UINT_MAX / sizeof ( AudioTrack ) - 1 ){ <nl> + av_log ( s , AV_LOG_ERROR , " current_track too large \ n "); <nl> + ret = - 1 ; <nl> + goto fail ; <nl> + } <nl> if ( current_track + 1 > fourxm -> track_count ) { <nl> fourxm -> track_count = current_track + 1 ; <nl> - if (( unsigned ) fourxm -> track_count >= UINT_MAX / sizeof ( AudioTrack )){ <nl> - ret = - 1 ; <nl> - goto fail ; <nl> - } <nl> fourxm -> tracks = av_realloc ( fourxm -> tracks , <nl> fourxm -> track_count * sizeof ( AudioTrack )); <nl> if (! fourxm -> tracks ) {
static int ogg_get_length ( AVFormatContext * s ) <nl> ogg_save ( s ); <nl> avio_seek ( s -> pb , s -> data_offset , SEEK_SET ); <nl> ogg_reset ( s ); <nl> + i = - 1 ; <nl> while (! ogg_packet ( s , & i , NULL , NULL , NULL )) { <nl> + if ( i >= 0 ) { <nl> int64_t pts = ogg_calc_pts ( s , i , NULL ); <nl> if ( pts != AV_NOPTS_VALUE && s -> streams [ i ]-> start_time == AV_NOPTS_VALUE && ! ogg -> streams [ i ]. got_start ){ <nl> s -> streams [ i ]-> duration -= pts ; <nl> static int ogg_get_length ( AVFormatContext * s ) <nl> } else if ( s -> streams [ i ]-> start_time != AV_NOPTS_VALUE && ! ogg -> streams [ i ]. got_start ){ <nl> ogg -> streams [ i ]. got_start = 1 ; <nl> streams_left --; <nl> + } <nl> } <nl> if ( streams_left <= 0 ) <nl> break ;
static int decode_frame ( AVCodecContext * avctx , <nl> h -> delayed_output_pic = out ; <nl> # endif <nl>  <nl> - * pict = *( AVFrame *) out ; <nl> + if ( out ) <nl> + * pict = *( AVFrame *) out ; <nl> + else <nl> + av_log ( avctx , AV_LOG_DEBUG , " no picture \ n "); <nl> } <nl>  <nl> - assert ( pict -> data [ 0 ]); <nl> + assert ( pict -> data [ 0 ] || !* data_size ); <nl> ff_print_debug_info ( s , pict ); <nl> // printf (" out % d \ n ", ( int ) pict -> data [ 0 ]); <nl> # if 0 //?
typedef struct AppleHTTPContext { <nl> int cur_seq_no ; <nl> int end_of_segment ; <nl> int first_packet ; <nl> + int64_t first_timestamp ; <nl> AVIOInterruptCB * interrupt_callback ; <nl> } AppleHTTPContext ; <nl>  <nl> static int applehttp_read_header ( AVFormatContext * s , AVFormatParameters * ap ) <nl> } <nl>  <nl> c -> first_packet = 1 ; <nl> + c -> first_timestamp = AV_NOPTS_VALUE ; <nl>  <nl> return 0 ; <nl> fail : <nl> start : <nl> if (! var -> pb . eof_reached ) <nl> return ret ; <nl> reset_packet (& var -> pkt ); <nl> + } else { <nl> + if ( c -> first_timestamp == AV_NOPTS_VALUE ) <nl> + c -> first_timestamp = var -> pkt . dts ; <nl> } <nl> } <nl> /* Check if this stream has the packet with the lowest dts */ <nl> static int applehttp_read_seek ( AVFormatContext * s , int stream_index , <nl> for ( i = 0 ; i < c -> n_variants ; i ++) { <nl> /* Reset reading */ <nl> struct variant * var = c -> variants [ i ]; <nl> - int64_t pos = 0 ; <nl> + int64_t pos = c -> first_timestamp == AV_NOPTS_VALUE ? 0 : <nl> + av_rescale_rnd ( c -> first_timestamp , 1 , <nl> + stream_index >= 0 ? s -> streams [ stream_index ]-> time_base . den : AV_TIME_BASE , <nl> + flags & AVSEEK_FLAG_BACKWARD ? AV_ROUND_DOWN : AV_ROUND_UP ); <nl> if ( var -> input ) { <nl> ffurl_close ( var -> input ); <nl> var -> input = NULL ;
static int nsv_read_chunk ( AVFormatContext * s , int fill_header ) <nl> uint32_t vsize ; <nl> uint16_t asize ; <nl> uint16_t auxsize ; <nl> + int ret ; <nl>  <nl> if ( nsv -> ahead [ 0 ]. data || nsv -> ahead [ 1 ]. data ) <nl> return 0 ; //- 1 ; /* hey ! eat what you ' ve in your plate first ! */ <nl> null_chunk_retry : <nl> if ( vsize && st [ NSV_ST_VIDEO ]) { <nl> nst = st [ NSV_ST_VIDEO ]-> priv_data ; <nl> pkt = & nsv -> ahead [ NSV_ST_VIDEO ]; <nl> - av_get_packet ( pb , pkt , vsize ); <nl> + if (( ret = av_get_packet ( pb , pkt , vsize )) < 0 ) <nl> + return ret ; <nl> pkt -> stream_index = st [ NSV_ST_VIDEO ]-> index ;// NSV_ST_VIDEO ; <nl> pkt -> dts = nst -> frame_offset ; <nl> pkt -> flags |= nsv -> state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0 ; /* keyframe only likely on a sync frame */ <nl> null_chunk_retry : <nl> bps , channels , samplerate ); <nl> } <nl> } <nl> - av_get_packet ( pb , pkt , asize ); <nl> + if (( ret = av_get_packet ( pb , pkt , asize )) < 0 ) <nl> + return ret ; <nl> pkt -> stream_index = st [ NSV_ST_AUDIO ]-> index ;// NSV_ST_AUDIO ; <nl> pkt -> flags |= nsv -> state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0 ; /* keyframe only likely on a sync frame */ <nl> if ( nsv -> state == NSV_HAS_READ_NSVS && st [ NSV_ST_VIDEO ] ) {
static av_cold int adx_encode_init ( AVCodecContext * avctx ) <nl> avctx -> frame_size = BLOCK_SAMPLES ; <nl>  <nl> avctx -> coded_frame = avcodec_alloc_frame (); <nl> + if (! avctx -> coded_frame ) <nl> + return AVERROR ( ENOMEM ); <nl>  <nl> /* the cutoff can be adjusted , but this seems to work pretty well */ <nl> c -> cutoff = 500 ;
static int vmd_read_header ( AVFormatContext * s ) <nl> vst -> codec -> width >>= 1 ; <nl> vst -> codec -> height >>= 1 ; <nl> } <nl> - vst -> codec -> extradata_size = VMD_HEADER_SIZE ; <nl> vst -> codec -> extradata = av_mallocz ( VMD_HEADER_SIZE + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> + if (! vst -> codec -> extradata ) <nl> + return AVERROR ( ENOMEM ); <nl> + vst -> codec -> extradata_size = VMD_HEADER_SIZE ; <nl> memcpy ( vst -> codec -> extradata , vmd -> vmd_header , VMD_HEADER_SIZE ); <nl> } <nl> 
static void ra144_encode_subblock ( RA144Context * ractx , <nl> float zero [ BLOCKSIZE ], cba [ BLOCKSIZE ], cb1 [ BLOCKSIZE ], cb2 [ BLOCKSIZE ]; <nl> int16_t cba_vect [ BLOCKSIZE ]; <nl> int cba_idx , cb1_idx , cb2_idx , gain ; <nl> - int i , n , m [ 3 ]; <nl> + int i , n ; <nl> + unsigned m [ 3 ]; <nl> float g [ 3 ]; <nl> float error , best_error ; <nl> 
static void free_stream ( AVStream ** pst ) <nl> av_freep (& st -> index_entries ); <nl> # if FF_API_LAVF_AVCTX <nl> FF_DISABLE_DEPRECATION_WARNINGS <nl> - av_freep (& st -> codec -> extradata ); <nl> - av_freep (& st -> codec -> subtitle_header ); <nl> - av_freep (& st -> codec ); <nl> + avcodec_free_context (& st -> codec ); <nl> FF_ENABLE_DEPRECATION_WARNINGS <nl> # endif <nl> av_freep (& st -> priv_data );
static int y41p_decode_frame ( AVCodecContext * avctx , void * data , <nl> uint8_t * y , * u , * v ; <nl> int i , j , ret ; <nl>  <nl> - if ( avpkt -> size < 3LL * avctx -> height * avctx -> width / 2 ) { <nl> + if ( avpkt -> size < 3LL * avctx -> height * FFALIGN ( avctx -> width , 8 ) / 2 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Insufficient input data .\ n "); <nl> return AVERROR ( EINVAL ); <nl> }
static int dnxhd_mb_var_thread ( AVCodecContext * avctx , void * arg , int jobnr , int <nl> for ( mb_x = 0 ; mb_x < ctx -> m . mb_width ; ++ mb_x , pix += 16 ) { <nl> unsigned mb = mb_y * ctx -> m . mb_width + mb_x ; <nl> int sum = ctx -> m . dsp . pix_sum ( pix , ctx -> m . linesize ); <nl> - int varc = ( ctx -> m . dsp . pix_norm1 ( pix , ctx -> m . linesize ) - ((( unsigned )( sum * sum ))>> 8 )+ 128 )>> 8 ; <nl> + int varc = ( ctx -> m . dsp . pix_norm1 ( pix , ctx -> m . linesize ) - ((( unsigned ) sum * sum )>> 8 )+ 128 )>> 8 ; <nl> ctx -> mb_cmp [ mb ]. value = varc ; <nl> ctx -> mb_cmp [ mb ]. mb = mb ; <nl> }
void av_dump_format ( AVFormatContext * ic , <nl> int is_output ) <nl> { <nl> int i ; <nl> - uint8_t * printed = av_mallocz ( ic -> nb_streams ); <nl> + uint8_t * printed = ic -> nb_streams ? av_mallocz ( ic -> nb_streams ) : NULL ; <nl> if ( ic -> nb_streams && ! printed ) <nl> return ; <nl> 
int check_stream_specifier ( AVFormatContext * s , AVStream * st , const char * spec ) <nl> case ' a ': type = AVMEDIA_TYPE_AUDIO ; break ; <nl> case ' s ': type = AVMEDIA_TYPE_SUBTITLE ; break ; <nl> case ' d ': type = AVMEDIA_TYPE_DATA ; break ; <nl> + default : abort (); // never reached , silence warning <nl> } <nl> if ( type != st -> codec -> codec_type ) <nl> return 0 ;
static int gif_image_write_image ( ByteIOContext * pb , <nl>  <nl> gif_put_bits_rev (& p , 9 , 0x0100 ); /* clear code */ <nl>  <nl> - for ( i = 0 ; i < GIF_CHUNKS ; i ++) { <nl> + for ( i =( left < GIF_CHUNKS )? left : GIF_CHUNKS ; i ; i --) { <nl> if ( pix_fmt == PIX_FMT_RGB24 ) { <nl> v = gif_clut_index ( ptr [ 0 ], ptr [ 1 ], ptr [ 2 ]); <nl> ptr += 3 ; <nl> static int gif_image_write_image ( ByteIOContext * pb , <nl> put_buffer ( pb , p . buf , pbBufPtr (& p ) - p . buf ); /* the actual buffer */ <nl> p . buf_ptr = p . buf ; /* dequeue the bytes off the bitstream */ <nl> } <nl> - if ( left <= GIF_CHUNKS ) { <nl> - put_byte ( pb , 0x00 ); /* end of image block */ <nl> - } <nl> - <nl> left -= GIF_CHUNKS ; <nl> } <nl> + put_byte ( pb , 0x00 ); /* end of image block */ <nl> + <nl> return 0 ; <nl> } <nl> 
static inline void silk_stabilize_lsf ( int16_t nlsf [ 16 ], int order , const uint16_ <nl> if ( nlsf [ 0 ] < min_delta [ 0 ]) <nl> nlsf [ 0 ] = min_delta [ 0 ]; <nl> for ( i = 1 ; i < order ; i ++) <nl> - if ( nlsf [ i ] < nlsf [ i - 1 ] + min_delta [ i ]) <nl> - nlsf [ i ] = nlsf [ i - 1 ] + min_delta [ i ]; <nl> + nlsf [ i ] = FFMAX ( nlsf [ i ], FFMIN ( nlsf [ i - 1 ] + min_delta [ i ], 32767 )); <nl>  <nl> /* push backwards to increase distance */ <nl> if ( nlsf [ order - 1 ] > 32768 - min_delta [ order ])
static int xan_decode_frame ( AVCodecContext * avctx , <nl> } <nl> buf_size = buf_end - buf ; <nl> } <nl> + if ( s -> palettes_count <= 0 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " No palette found \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> if (( ret = avctx -> get_buffer ( avctx , & s -> current_frame ))) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " get_buffer () failed \ n "); <nl> return ret ;
retry : <nl> if ( c -> itunes_metadata && atom . size > 8 ) { <nl> int data_size = avio_rb32 ( pb ); <nl> int tag = avio_rl32 ( pb ); <nl> - if ( tag == MKTAG (' d ',' a ',' t ',' a ')) { <nl> + if ( tag == MKTAG (' d ',' a ',' t ',' a ') && data_size <= atom . size ) { <nl> data_type = avio_rb32 ( pb ); // type <nl> avio_rb32 ( pb ); // unknown <nl> str_size = data_size - 16 ;
int ff_mpeg_update_thread_context ( AVCodecContext * dst , <nl> if ( dst == src ) <nl> return 0 ; <nl>  <nl> + av_assert0 ( s != s1 ); <nl> + <nl> // FIXME can parameters change on I - frames ? <nl> // in that case dst may need a reinit <nl> if (! s -> context_initialized ) { <nl> int ff_mpeg_update_thread_context ( AVCodecContext * dst , <nl> s -> picture_number = s1 -> picture_number ; <nl> s -> input_picture_number = s1 -> input_picture_number ; <nl>  <nl> + av_assert0 (! s -> picture || s -> picture != s1 -> picture ); <nl> memcpy ( s -> picture , s1 -> picture , s1 -> picture_count * sizeof ( Picture )); <nl> memcpy (& s -> last_picture , & s1 -> last_picture , <nl> ( char *) & s1 -> last_picture_ptr - ( char *) & s1 -> last_picture );
static av_always_inline void rgb16_32ToUV_half_c_template ( int16_t * dstU , <nl> maskb |= maskb << 1 ; <nl> maskg |= maskg << 1 ; <nl> for ( i = 0 ; i < width ; i ++) { <nl> - int px0 = input_pixel ( 2 * i + 0 ) >> shp ; <nl> - int px1 = input_pixel ( 2 * i + 1 ) >> shp ; <nl> + unsigned px0 = input_pixel ( 2 * i + 0 ) >> shp ; <nl> + unsigned px1 = input_pixel ( 2 * i + 1 ) >> shp ; <nl> int b , r , g = ( px0 & maskgx ) + ( px1 & maskgx ); <nl> int rb = px0 + px1 - g ; <nl> 
static int bink_decode_plane ( BinkContext * c , GetBitContext * gb , int plane_idx , <nl> for ( i = 0 ; i < BINK_NB_SRC ; i ++) <nl> read_bundle ( gb , c , i ); <nl>  <nl> - ref_start = c -> last . data [ plane_idx ]; <nl> - ref_end = c -> last . data [ plane_idx ] <nl> + ref_start = c -> last . data [ plane_idx ] ? c -> last . data [ plane_idx ] <nl> + : c -> pic . data [ plane_idx ]; <nl> + ref_end = ref_start <nl> + ( bw - 1 + c -> last . linesize [ plane_idx ] * ( bh - 1 )) * 8 ; <nl>  <nl> for ( i = 0 ; i < 64 ; i ++) <nl> static int bink_decode_plane ( BinkContext * c , GetBitContext * gb , int plane_idx , <nl> if ( by == bh ) <nl> break ; <nl> dst = c -> pic . data [ plane_idx ] + 8 * by * stride ; <nl> - prev = c -> last . data [ plane_idx ] + 8 * by * stride ; <nl> + prev = ( c -> last . data [ plane_idx ] ? c -> last . data [ plane_idx ] <nl> + : c -> pic . data [ plane_idx ]) + 8 * by * stride ; <nl> for ( bx = 0 ; bx < bw ; bx ++, dst += 8 , prev += 8 ) { <nl> blk = get_value ( c , BINK_SRC_BLOCK_TYPES ); <nl> // 16x16 block type on odd line means part of the already decoded block , so skip it
int ff_mjpeg_decode_sof ( MJpegDecodeContext * s ) <nl> else s -> avctx -> pix_fmt = AV_PIX_FMT_YUV420P16 ; <nl> s -> avctx -> color_range = s -> cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG ; <nl> if ( pix_fmt_id == 0x42111100 ) { <nl> + if ( s -> bits > 8 ) <nl> + goto unk_pixfmt ; <nl> s -> upscale_h = 6 ; <nl> } else if ( pix_fmt_id == 0x24111100 ) { <nl> + if ( s -> bits > 8 ) <nl> + goto unk_pixfmt ; <nl> s -> upscale_v = 6 ; <nl> } <nl> break ;
int av_image_fill_pointers ( uint8_t * data [ 4 ], enum PixelFormat pix_fmt , int heigh <nl> has_plane [ desc -> comp [ i ]. plane ] = 1 ; <nl>  <nl> total_size = size [ 0 ]; <nl> - for ( i = 1 ; has_plane [ i ] && i < 4 ; i ++) { <nl> + for ( i = 1 ; i < 4 && has_plane [ i ]; i ++) { <nl> int h , s = ( i == 1 || i == 2 ) ? desc -> log2_chroma_h : 0 ; <nl> data [ i ] = data [ i - 1 ] + size [ i - 1 ]; <nl> h = ( height + ( 1 << s ) - 1 ) >> s ;
static int dv_extract_audio_info ( DVDemuxContext * c , uint8_t * frame ) <nl> stype = ( as_pack [ 3 ] & 0x1f ); /* 0 - 2CH , 2 - 4CH , 3 - 8CH */ <nl> quant = as_pack [ 4 ] & 0x07 ; /* 0 - 16bit linear , 1 - 12bit nonlinear */ <nl>  <nl> + if ( stype > 3 ) { <nl> + av_log ( c -> fctx , AV_LOG_ERROR , " stype % d is invalid \ n ", stype ); <nl> + c -> ach = 0 ; <nl> + return 0 ; <nl> + } <nl> + <nl> /* note : ach counts PAIRS of channels ( i . e . stereo channels ) */ <nl> ach = (( int [ 4 ]){ 1 , 0 , 2 , 4 })[ stype ]; <nl> if ( ach == 1 && quant && freq == 2 )
static void decode_profile_tier_level ( HEVCContext * s , PTLCommon * ptl ) <nl> ptl -> profile_space = get_bits ( gb , 2 ); <nl> ptl -> tier_flag = get_bits1 ( gb ); <nl> ptl -> profile_idc = get_bits ( gb , 5 ); <nl> + if ( ptl -> profile_idc == FF_PROFILE_HEVC_MAIN ) <nl> + av_log ( s -> avctx , AV_LOG_DEBUG , " Main profile bitstream \ n "); <nl> + else if ( ptl -> profile_idc == FF_PROFILE_HEVC_MAIN_10 ) <nl> + av_log ( s -> avctx , AV_LOG_DEBUG , " Main 10 profile bitstream \ n "); <nl> + else if ( ptl -> profile_idc == FF_PROFILE_HEVC_MAIN_STILL_PICTURE ) <nl> + av_log ( s -> avctx , AV_LOG_DEBUG , " Main Still Picture profile bitstream \ n "); <nl> + else <nl> + av_log ( s -> avctx , AV_LOG_WARNING , " Unknown HEVC profile : % d \ n ", ptl -> profile_idc ); <nl>  <nl> for ( i = 0 ; i < 32 ; i ++) <nl> ptl -> profile_compatibility_flag [ i ] = get_bits1 ( gb );
static int wsvqa_read_packet ( AVFormatContext * s , <nl> switch ( chunk_type ) { <nl> case SND1_TAG : <nl> /* unpacked size is stored in header */ <nl> - pkt -> duration = AV_RL16 ( pkt -> data ) / wsvqa -> channels ; <nl> + if ( pkt -> data ) <nl> + pkt -> duration = AV_RL16 ( pkt -> data ) / wsvqa -> channels ; <nl> break ; <nl> case SND2_TAG : <nl> /* 2 samples / byte , 1 or 2 samples per frame depending on stereo */
static av_cold int decode_init ( AVCodecContext * avctx ) <nl> s -> font_height = p [ 0 ]; <nl> s -> flags = p [ 1 ]; <nl> p += 2 ; <nl> + if ( avctx -> extradata_size < 2 + (!!( s -> flags & BINTEXT_PALETTE ))* 3 * 16 <nl> + + (!!( s -> flags & BINTEXT_FONT ))* s -> font_height * 256 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " not enough extradata \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> } else { <nl> s -> font_height = 8 ; <nl> s -> flags = 0 ;
static int X264_frame ( AVCodecContext * ctx , AVPacket * pkt , const AVFrame * frame , <nl> X264Context * x4 = ctx -> priv_data ; <nl> x264_nal_t * nal ; <nl> int nnal , i , ret ; <nl> - x264_picture_t pic_out ; <nl> + x264_picture_t pic_out = { 0 }; <nl>  <nl> x264_picture_init ( & x4 -> pic ); <nl> x4 -> pic . img . i_csp = x4 -> params . i_csp ;
static void vp8_decode_flush ( AVCodecContext * avctx ) <nl>  <nl> static int update_dimensions ( VP8Context * s , int width , int height ) <nl> { <nl> - if ( width != s -> avctx -> width || <nl> + if ( width != s -> avctx -> width || (( width + 15 )/ 16 != s -> mb_width || ( height + 15 )/ 16 != s -> mb_height ) && s -> macroblocks_base || <nl> height != s -> avctx -> height ) { <nl> if ( av_image_check_size ( width , height , 0 , s -> avctx )) <nl> return AVERROR_INVALIDDATA ; <nl> static int decode_frame_header ( VP8Context * s , const uint8_t * buf , int buf_size ) <nl> } <nl>  <nl> if (! s -> macroblocks_base || /* first frame */ <nl> - width != s -> avctx -> width || height != s -> avctx -> height ) { <nl> + width != s -> avctx -> width || height != s -> avctx -> height || ( width + 15 )/ 16 != s -> mb_width || ( height + 15 )/ 16 != s -> mb_height ) { <nl> if (( ret = update_dimensions ( s , width , height )) < 0 ) <nl> return ret ; <nl> }
static av_cold int decode_init ( AVCodecContext * avctx ) <nl> for ( x = 0 ; x < num_possible_block_sizes ; x ++) { <nl> int v = 0 ; <nl> while ( s -> sfb_offsets [ x ][ v + 1 ] << x < offset ) <nl> - ++ v ; <nl> + if (++ v >= MAX_BANDS ) <nl> + return AVERROR_INVALIDDATA ; <nl> s -> sf_offsets [ i ][ x ][ b ] = v ; <nl> } <nl> }
 <nl> static av_always_inline int even ( uint64_t layout ) <nl> { <nl> - return (! layout || ( layout & ( layout - 1 ))); <nl> + return (! layout || !!( layout & ( layout - 1 ))); <nl> } <nl>  <nl> static int sane_layout ( uint64_t layout )
int av_reallocp_array ( void * ptr , size_t nmemb , size_t size ) <nl> { <nl> void ** ptrptr = ptr ; <nl> * ptrptr = av_realloc_f (* ptrptr , nmemb , size ); <nl> - if (!* ptrptr && !( nmemb && size )) <nl> + if (!* ptrptr && nmemb && size ) <nl> return AVERROR ( ENOMEM ); <nl> return 0 ; <nl> }
static int adpcm_decode_frame ( AVCodecContext * avctx , void * data , <nl> int samples_per_block = ff_adpcm_ima_block_samples [ avctx -> bits_per_coded_sample - 2 ]; <nl> GetBitContext g ; <nl>  <nl> - init_get_bits8 (& g , gb . buffer , bytestream2_get_bytes_left (& gb )); <nl> + ret = init_get_bits8 (& g , gb . buffer , bytestream2_get_bytes_left (& gb )); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> for ( n = 0 ; n < ( nb_samples - 1 ) / samples_per_block ; n ++) { <nl> for ( i = 0 ; i < avctx -> channels ; i ++) { <nl> cs = & c -> status [ i ];
static inline int decode_mb ( MDECContext * a , DCTELEM block [ 6 ][ 64 ]){ <nl> a -> dsp . clear_blocks ( block [ 0 ]); <nl>  <nl> for ( i = 0 ; i < 6 ; i ++){ <nl> - if ( mdec_decode_block_intra ( a , block [ block_index [ i ] ], block_index [ i ]) < 0 ) <nl> + if ( mdec_decode_block_intra ( a , block [ block_index [ i ] ], block_index [ i ]) < 0 || <nl> + get_bits_left (& a -> gb ) < 0 ) <nl> return - 1 ; <nl> } <nl> return 0 ;
static int dirac_decode_data_unit ( AVCodecContext * avctx , const uint8_t * buf , int <nl> if ( s -> version . minor == 2 && parse_code == 0x88 ) <nl> s -> ld_picture = 1 ; <nl>  <nl> + if ( s -> low_delay && !( s -> ld_picture || s -> hq_picture ) ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Invalid low delay flag \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> if (( ret = get_buffer_with_edge ( avctx , pic -> avframe , ( parse_code & 0x0C ) == 0x0C ? AV_GET_BUFFER_FLAG_REF : 0 )) < 0 ) <nl> return ret ; <nl> s -> current_picture = pic ;
static void dwt_decode97_int ( DWTContext * s , int32_t * t ) <nl> line += 5 ; <nl>  <nl> for ( i = 0 ; i < w * h ; i ++) <nl> - data [ i ] <<= I_PRESHIFT ; <nl> + data [ i ] *= 1 << I_PRESHIFT ; <nl>  <nl> for ( lev = 0 ; lev < s -> ndeclevels ; lev ++) { <nl> int lh = s -> linelen [ lev ][ 0 ],
static int rtmp_packet_read_one_chunk ( URLContext * h , RTMPPacket * p , <nl> if ( hdr != RTMP_PS_TWELVEBYTES ) <nl> timestamp += prev_pkt [ channel_id ]. timestamp ; <nl>  <nl> + if ( prev_pkt [ channel_id ]. read && size != prev_pkt [ channel_id ]. size ) { <nl> + av_log ( NULL , AV_LOG_ERROR , " RTMP packet size mismatch % d != % d \ n ", <nl> + size , <nl> + prev_pkt [ channel_id ]. size ); <nl> + ff_rtmp_packet_destroy (& prev_pkt [ channel_id ]); <nl> + prev_pkt [ channel_id ]. read = 0 ; <nl> + } <nl> + <nl> if (! prev_pkt [ channel_id ]. read ) { <nl> if (( ret = ff_rtmp_packet_create ( p , channel_id , type , timestamp , <nl> size )) < 0 )
 <nl> # define BITSTREAM_READER_LE <nl> # include " libavutil / attributes . h " <nl> +# include " libavutil / imgutils . h " <nl> # include " libavutil / timer . h " <nl> # include " avcodec . h " <nl> # include " get_bits . h " <nl> av_cold int ff_ivi_init_planes ( IVIPlaneDesc * planes , const IVIPicConfig * cfg , <nl>  <nl> ivi_free_buffers ( planes ); <nl>  <nl> - if ( cfg -> pic_width < 1 || cfg -> pic_height < 1 || <nl> + if ( av_image_check_size ( cfg -> pic_width , cfg -> pic_height , 0 , NULL ) < 0 || <nl> cfg -> luma_bands < 1 || cfg -> chroma_bands < 1 ) <nl> return AVERROR_INVALIDDATA ; <nl> 
static int decode_lt_rps ( HEVCContext * s , LongTermRPS * rps , GetBitContext * gb ) <nl> static int set_sps ( HEVCContext * s , const HEVCSPS * sps ) <nl> { <nl> int ret ; <nl> - int num = 0 , den = 0 ; <nl> + unsigned num = 0 , den = 0 ; <nl>  <nl> pic_arrays_free ( s ); <nl> ret = pic_arrays_init ( s , sps );
int swr_convert_frame ( SwrContext * s , <nl>  <nl> if ( out ) { <nl> if (! out -> linesize [ 0 ]) { <nl> - out -> nb_samples = swr_get_delay ( s , s -> out_sample_rate ) <nl> - + in -> nb_samples *( int64_t ) s -> out_sample_rate / s -> in_sample_rate <nl> - + 3 ; <nl> + out -> nb_samples = swr_get_delay ( s , s -> out_sample_rate ) + 3 ; <nl> + if ( in ) { <nl> + out -> nb_samples += in -> nb_samples *( int64_t ) s -> out_sample_rate / s -> in_sample_rate ; <nl> + } <nl> if (( ret = av_frame_get_buffer ( out , 0 )) < 0 ) { <nl> if ( setup ) <nl> swr_close ( s );
static int http_start_receive_data ( HTTPContext * c ) <nl> ftruncate ( c -> feed_fd , FFM_PACKET_SIZE ); <nl> http_log (" Truncating feed file '% s '\ n ", c -> stream -> feed_filename ); <nl> } else { <nl> - if (( c -> stream -> feed_write_index = ffm_read_write_index ( fd )) < 0 ) { <nl> - http_log (" Error reading write index from feed file : % s \ n ", strerror ( errno )); <nl> - return - 1 ; <nl> - } <nl> + if (( c -> stream -> feed_write_index = ffm_read_write_index ( fd )) < 0 ) { <nl> + http_log (" Error reading write index from feed file : % s \ n ", strerror ( errno )); <nl> + return - 1 ; <nl> + } <nl> } <nl>  <nl> c -> stream -> feed_write_index = FFMAX ( ffm_read_write_index ( fd ), FFM_PACKET_SIZE ); <nl> - <nl> c -> stream -> feed_size = lseek ( fd , 0 , SEEK_END ); <nl> lseek ( fd , 0 , SEEK_SET ); <nl> 
static void qpeg_decode_inter ( const uint8_t * src , uint8_t * dst , int size , <nl> filled = 0 ; <nl> dst -= stride ; <nl> height --; <nl> + if ( height < 0 ) <nl> + break ; <nl> } <nl> } <nl> } else if ( code >= 0xC0 ) { /* copy code : 0xC0 .. 0xDF */ <nl> static void qpeg_decode_inter ( const uint8_t * src , uint8_t * dst , int size , <nl> filled = 0 ; <nl> dst -= stride ; <nl> height --; <nl> + if ( height < 0 ) <nl> + break ; <nl> } <nl> } <nl> size -= code + 1 ;
AV_WN32A ( v0 + i , r ); \ <nl> AV_WN32A ( v1 + i , r ); \ <nl> } \ <nl> - for ( i = 0 ; i < BUF_SIZE * 8 / 3 ; i += 4 ) { \ <nl> + for ( i = 0 ; i < width * 8 / 3 ; i += 4 ) { \ <nl> uint32_t r = rnd (); \ <nl> AV_WN32A ( dst0 + i , r ); \ <nl> AV_WN32A ( dst1 + i , r ); \
static int decode_slice_header ( H264Context * h , H264Context * h0 ){ <nl> || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma <nl> || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc <nl> || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ))) { <nl> - if ( h != h0 ) { <nl> + if ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME )) { <nl> av_log_missing_feature ( s -> avctx , " Width / height / bit depth / chroma idc changing with threads is ", 0 ); <nl> return - 1 ; // width / height changed during parallelized decoding <nl> }
static int matroska_read_header ( AVFormatContext * s ) <nl> track -> audio . sub_packet_h = avio_rb16 (& b ); <nl> track -> audio . frame_size = avio_rb16 (& b ); <nl> track -> audio . sub_packet_size = avio_rb16 (& b ); <nl> + if ( flavor <= 0 || track -> audio . coded_framesize <= 0 || <nl> + track -> audio . sub_packet_h <= 0 || track -> audio . frame_size <= 0 || <nl> + track -> audio . sub_packet_size <= 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> track -> audio . buf = av_malloc ( track -> audio . frame_size * track -> audio . sub_packet_h ); <nl> if ( codec_id == AV_CODEC_ID_RA_288 ) { <nl> st -> codec -> block_align = track -> audio . coded_framesize ;
static int thp_read_packet ( AVFormatContext * s , <nl> pkt -> stream_index = thp -> video_stream_index ; <nl> } else { <nl> ret = av_get_packet ( pb , pkt , thp -> audiosize ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> if ( ret != thp -> audiosize ) { <nl> av_free_packet ( pkt ); <nl> return AVERROR ( EIO );
static void fill_slice_long ( AVCodecContext * avctx , DXVA_Slice_H264_Long * slice , <nl> for ( plane = 0 ; plane < 3 ; plane ++) { <nl> int w , o ; <nl> if ( plane == 0 && h -> luma_weight_flag [ list ]) { <nl> - w = h -> luma_weight [ list ][ i ][ 0 ]; <nl> - o = h -> luma_weight [ list ][ i ][ 1 ]; <nl> + w = h -> luma_weight [ i ][ list ][ 0 ]; <nl> + o = h -> luma_weight [ i ][ list ][ 1 ]; <nl> } else if ( plane >= 1 && h -> chroma_weight_flag [ list ]) { <nl> - w = h -> chroma_weight [ list ][ i ][ plane - 1 ][ 0 ]; <nl> - o = h -> chroma_weight [ list ][ i ][ plane - 1 ][ 1 ]; <nl> + w = h -> chroma_weight [ i ][ list ][ plane - 1 ][ 0 ]; <nl> + o = h -> chroma_weight [ i ][ list ][ plane - 1 ][ 1 ]; <nl> } else { <nl> w = 1 << ( plane == 0 ? h -> luma_log2_weight_denom : <nl> h -> chroma_log2_weight_denom );
static int http_handshake ( URLContext * c ) <nl> av_log ( c , AV_LOG_TRACE , " Lower protocol \ n "); <nl> if (( ret = ffurl_handshake ( cl )) > 0 ) <nl> return 2 + ret ; <nl> - if (( ret < 0 )) <nl> + if ( ret < 0 ) <nl> return ret ; <nl> ch -> handshake_step = READ_HEADERS ; <nl> ch -> is_connected_server = 1 ;
static int au_write_header ( AVFormatContext * s ) <nl> AVIOContext * pb = s -> pb ; <nl> AVCodecContext * enc = s -> streams [ 0 ]-> codec ; <nl>  <nl> - if (! enc -> codec_tag ) <nl> + if ( s -> nb_streams != 1 ) { <nl> + av_log ( s , AV_LOG_ERROR , " only one stream is supported \ n "); <nl> return AVERROR ( EINVAL ); <nl> + } <nl> + <nl> + enc -> codec_tag = ff_codec_get_tag ( codec_au_tags , enc -> codec_id ); <nl> + if (! enc -> codec_tag ) { <nl> + av_log ( s , AV_LOG_ERROR , " unsupported codec \ n "); <nl> + return AVERROR ( EINVAL ); <nl> + } <nl>  <nl> ffio_wfourcc ( pb , ". snd "); /* magic number */ <nl> avio_wb32 ( pb , AU_HEADER_SIZE ); /* header size */
static int build_filter ( ResampleContext * c , void * filter , double factor , int tap <nl> case AV_SAMPLE_FMT_S16P : <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( int16_t *) filter )[ ph * alloc + i ] = av_clip_int16 ( lrintf ( tab [ i ] * scale / norm )); <nl> - if ( tap_count % 2 == 0 ) { <nl> + if ( tap_count % 2 == 0 || tap_count == 1 ) { <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( int16_t *) filter )[( phase_count - ph ) * alloc + tap_count - 1 - i ] = (( int16_t *) filter )[ ph * alloc + i ]; <nl> } <nl> static int build_filter ( ResampleContext * c , void * filter , double factor , int tap <nl> case AV_SAMPLE_FMT_S32P : <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( int32_t *) filter )[ ph * alloc + i ] = av_clipl_int32 ( llrint ( tab [ i ] * scale / norm )); <nl> - if ( tap_count % 2 == 0 ) { <nl> + if ( tap_count % 2 == 0 || tap_count == 1 ) { <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( int32_t *) filter )[( phase_count - ph ) * alloc + tap_count - 1 - i ] = (( int32_t *) filter )[ ph * alloc + i ]; <nl> } <nl> static int build_filter ( ResampleContext * c , void * filter , double factor , int tap <nl> case AV_SAMPLE_FMT_FLTP : <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( float *) filter )[ ph * alloc + i ] = tab [ i ] * scale / norm ; <nl> - if ( tap_count % 2 == 0 ) { <nl> + if ( tap_count % 2 == 0 || tap_count == 1 ) { <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( float *) filter )[( phase_count - ph ) * alloc + tap_count - 1 - i ] = (( float *) filter )[ ph * alloc + i ]; <nl> } <nl> static int build_filter ( ResampleContext * c , void * filter , double factor , int tap <nl> case AV_SAMPLE_FMT_DBLP : <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( double *) filter )[ ph * alloc + i ] = tab [ i ] * scale / norm ; <nl> - if ( tap_count % 2 == 0 ) { <nl> + if ( tap_count % 2 == 0 || tap_count == 1 ) { <nl> for ( i = 0 ; i < tap_count ; i ++) <nl> (( double *) filter )[( phase_count - ph ) * alloc + tap_count - 1 - i ] = (( double *) filter )[ ph * alloc + i ]; <nl> }
static void ict_int ( void * _src0 , void * _src1 , void * _src2 , int csize ) <nl>  <nl> for ( i = 0 ; i < csize ; i ++) { <nl> i0 = * src0 + * src2 + ((( 26345 * * src2 ) + ( 1 << 15 )) >> 16 ); <nl> - i1 = * src0 - ((( i_ict_params [ 1 ] * * src1 ) + ( 1 << 15 )) >> 16 ) <nl> + i1 = * src0 - (( int )((( unsigned ) i_ict_params [ 1 ] * * src1 ) + ( 1 << 15 )) >> 16 ) <nl> - ((( i_ict_params [ 2 ] * * src2 ) + ( 1 << 15 )) >> 16 ); <nl> - i2 = * src0 + ( 2 * * src1 ) + (((- 14942 * * src1 ) + ( 1 << 15 )) >> 16 ); <nl> + i2 = * src0 + ( 2 * * src1 ) + (( int )((- 14942U * * src1 ) + ( 1 << 15 )) >> 16 ); <nl> * src0 ++ = i0 ; <nl> * src1 ++ = i1 ; <nl> * src2 ++ = i2 ;
void ff_set_mpeg4_time ( MpegEncContext * s ) <nl>  <nl> static void mpeg4_encode_gop_header ( MpegEncContext * s ) <nl> { <nl> - int hours , minutes , seconds ; <nl> + int64_t hours , minutes , seconds ; <nl> int64_t time ; <nl>  <nl> put_bits (& s -> pb , 16 , 0 );
int ff_jpeg2000_init_component ( Jpeg2000Component * comp , <nl> if (! prec -> zerobits ) <nl> return AVERROR ( ENOMEM ); <nl>  <nl> - prec -> cblk = av_malloc_array ( prec -> nb_codeblocks_width * <nl> - ( uint64_t ) prec -> nb_codeblocks_height , <nl> - sizeof (* prec -> cblk )); <nl> + prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * <nl> + ( uint64_t ) prec -> nb_codeblocks_height , <nl> + sizeof (* prec -> cblk )); <nl> if (! prec -> cblk ) <nl> return AVERROR ( ENOMEM ); <nl> for ( cblkno = 0 ; cblkno < prec -> nb_codeblocks_width * prec -> nb_codeblocks_height ; cblkno ++) {
vbv_retry : <nl> if ( s -> mb_info ) <nl> av_packet_shrink_side_data ( pkt , AV_PKT_DATA_H263_MB_INFO , s -> mb_info_size ); <nl> } else { <nl> - assert (( put_bits_ptr (& s -> pb ) == s -> pb . buf )); <nl> s -> frame_bits = 0 ; <nl> } <nl> assert (( s -> frame_bits & 7 ) == 0 );
static int svag_read_header ( AVFormatContext * s ) <nl> if ( st -> codec -> sample_rate <= 0 ) <nl> return AVERROR_INVALIDDATA ; <nl> st -> codec -> channels = avio_rl32 ( s -> pb ); <nl> - if ( st -> codec -> channels <= 0 ) <nl> + if ( st -> codec -> channels <= 0 || st -> codec -> channels > 8 ) <nl> return AVERROR_INVALIDDATA ; <nl> st -> duration = size / ( 16 * st -> codec -> channels ) * 28 ; <nl> align = avio_rl32 ( s -> pb );
static int decode_frame_ilbm ( AVCodecContext * avctx , <nl> } else if ( s -> ham ) { // HAM to PIX_FMT_BGR32 <nl> for ( y = 0 ; y < avctx -> height ; y ++) { <nl> uint8_t * row = & s -> frame . data [ 0 ][ y * s -> frame . linesize [ 0 ] ]; <nl> - memset ( s -> ham_buf , 0 , avctx -> width ); <nl> + memset ( s -> ham_buf , 0 , s -> planesize * 8 ); <nl> for ( plane = 0 ; plane < s -> bpp && buf < buf_end ; plane ++) { <nl> decodeplane8 ( s -> ham_buf , buf , FFMIN ( s -> planesize , buf_end - buf ), plane ); <nl> buf += s -> planesize ; <nl> static int decode_frame_byterun1 ( AVCodecContext * avctx , <nl> } else if ( s -> ham ) { // HAM to PIX_FMT_BGR32 <nl> for ( y = 0 ; y < avctx -> height ; y ++) { <nl> uint8_t * row = & s -> frame . data [ 0 ][ y * s -> frame . linesize [ 0 ]]; <nl> - memset ( s -> ham_buf , 0 , avctx -> width ); <nl> + memset ( s -> ham_buf , 0 , s -> planesize * 8 ); <nl> for ( plane = 0 ; plane < s -> bpp ; plane ++) { <nl> buf += decode_byterun ( s -> planebuf , s -> planesize , buf , buf_end ); <nl> decodeplane8 ( s -> ham_buf , s -> planebuf , s -> planesize , plane );
int64_t av_gcd ( int64_t a , int64_t b ) { <nl> v -= u ; <nl> v >>= ff_ctzll ( v ); <nl> } <nl> - return u << k ; <nl> + return ( uint64_t ) u << k ; <nl> } <nl>  <nl> int64_t av_rescale_rnd ( int64_t a , int64_t b , int64_t c , enum AVRounding rnd )
static int vc1_decode_i_block_adv ( VC1Context * v , DCTELEM block [ 64 ], int n , int c <nl> ac_val -= 16 * s -> block_wrap [ n ]; <nl>  <nl> q1 = s -> current_picture . qscale_table [ mb_pos ]; <nl> - if ( dc_pred_dir && c_avail ) q2 = s -> current_picture . qscale_table [ mb_pos - 1 ]; <nl> - if (! dc_pred_dir && a_avail ) q2 = s -> current_picture . qscale_table [ mb_pos - s -> mb_stride ]; <nl> + if ( dc_pred_dir && c_avail && mb_pos ) q2 = s -> current_picture . qscale_table [ mb_pos - 1 ]; <nl> + if (! dc_pred_dir && a_avail && mb_pos >= s -> mb_stride ) q2 = s -> current_picture . qscale_table [ mb_pos - s -> mb_stride ]; <nl> if ( n && n < 4 ) q2 = q1 ; <nl>  <nl> if ( coded ) {
static av_cold int encode_init ( AVCodecContext * avctx ) <nl> } <nl> } <nl> gob_count = strtol ( p , & next , 0 ); <nl> - if ( next == p || gob_count < 0 ){ <nl> + if ( next == p || gob_count <= 0 ){ <nl> av_log ( avctx , AV_LOG_ERROR , " 2Pass file invalid \ n "); <nl> return AVERROR_INVALIDDATA ; <nl> }
ogm_dshow_header ( AVFormatContext * s , int idx ) <nl> if (* p != 1 ) <nl> return 1 ; <nl>  <nl> + if ( os -> psize < 100 ) <nl> + return AVERROR_INVALIDDATA ; <nl> t = AV_RL32 ( p + 96 ); <nl>  <nl> if ( t == 0x05589f80 ){
static int unpack ( const uint8_t * src , const uint8_t * src_end , unsigned char * dst <nl> * @ return 0 on success , - 1 on critical buffer underflow <nl> */ <nl> static int tgv_decode_inter ( TgvContext * s , const uint8_t * buf , const uint8_t * buf_end ){ <nl> - unsigned char * frame0_end = s -> last_frame . data [ 0 ] + s -> avctx -> width * s -> last_frame . linesize [ 0 ]; <nl> + unsigned char * frame0_end = s -> last_frame . data [ 0 ] + s -> avctx -> height * s -> last_frame . linesize [ 0 ]; <nl> int num_mvs ; <nl> int num_blocks_raw ; <nl> int num_blocks_packed ; <nl> static int tgv_decode_inter ( TgvContext * s , const uint8_t * buf , const uint8_t * b <nl> ( y * 4 + s -> mv_codebook [ vector ][ 1 ])* s -> last_frame . linesize [ 0 ] + <nl> x * 4 + s -> mv_codebook [ vector ][ 0 ]; <nl> src_stride = s -> last_frame . linesize [ 0 ]; <nl> - if ( src + 3 * src_stride + 3 >= frame0_end ) <nl> + if ( src < s -> last_frame . data [ 0 ] || src + 3 * src_stride + 3 >= frame0_end ) <nl> continue ; <nl> } else { <nl> int offset = vector - num_mvs ;
int main ( int argc , char * argv []) <nl> } <nl> } <nl>  <nl> - max = ( 1 << ( 8 * len )) - 1 ; <nl> + max = ( 1LL << ( 8 * len )) - 1 ; <nl>  <nl> f [ 0 ] = fopen ( argv [ 1 ], " rb "); <nl> f [ 1 ] = fopen ( argv [ 2 ], " rb ");
static void get_tag ( AVFormatContext * s , const char * key , int type , int len , int <nl> { <nl> char * value ; <nl> int64_t off = avio_tell ( s -> pb ); <nl> +# define LEN 22 <nl>  <nl> - if (( unsigned ) len >= ( UINT_MAX - 1 ) / 2 ) <nl> + if (( unsigned ) len >= ( UINT_MAX - LEN ) / 2 ) <nl> return ; <nl>  <nl> - value = av_malloc ( 2 * len + 1 ); <nl> + value = av_malloc ( 2 * len + LEN ); <nl> if (! value ) <nl> goto finish ; <nl>  <nl> static void get_tag ( AVFormatContext * s , const char * key , int type , int len , int <nl> goto finish ; <nl> } else if ( type > 1 && type <= 5 ) { // boolean or DWORD or QWORD or WORD <nl> uint64_t num = get_value ( s -> pb , type , type2_size ); <nl> - snprintf ( value , len , "%" PRIu64 , num ); <nl> + snprintf ( value , LEN , "%" PRIu64 , num ); <nl> } else if ( type == 6 ) { // ( don ' t ) handle GUID <nl> av_log ( s , AV_LOG_DEBUG , " Unsupported GUID value in tag % s .\ n ", key ); <nl> goto finish ;
static int init_ralf_vlc ( VLC * vlc , const uint8_t * data , int elems ) <nl> int counts [ 17 ], prefixes [ 18 ]; <nl> int i , cur_len ; <nl> int max_bits = 0 ; <nl> - GetBitContext gb ; <nl> - <nl> - init_get_bits (& gb , data , elems * 4 ); <nl> + int nb = 0 ; <nl>  <nl> for ( i = 0 ; i <= 16 ; i ++) <nl> counts [ i ] = 0 ; <nl> for ( i = 0 ; i < elems ; i ++) { <nl> - cur_len = get_bits (& gb , 4 ) + 1 ; <nl> + cur_len = ( nb ? * data & 0xF : * data >> 4 ) + 1 ; <nl> counts [ cur_len ]++; <nl> max_bits = FFMAX ( max_bits , cur_len ); <nl> lens [ i ] = cur_len ; <nl> + data += nb ; <nl> + nb ^= 1 ; <nl> } <nl> prefixes [ 1 ] = 0 ; <nl> for ( i = 1 ; i <= 16 ; i ++)
static char * get_content_url ( xmlNodePtr * baseurl_nodes , <nl> return NULL ; <nl> } <nl> av_strlcpy ( tmp_str , url , sizeof ( tmp_str )); <nl> - av_free ( url ); <nl> } <nl> if ( rep_bandwidth_val && tmp_str [ 0 ] != '\ 0 ') { <nl> + // free any previously assigned url before reassigning <nl> + av_free ( url ); <nl> url = av_strireplace ( tmp_str , "$ Bandwidth $", ( const char *) rep_bandwidth_val ); <nl> if (! url ) { <nl> return NULL ;
static av_cold void uninit ( AVFilterContext * ctx ) <nl> DrawTextContext * s = ctx -> priv ; <nl> int i ; <nl>  <nl> + av_expr_free ( s -> x_pexpr ); <nl> + av_expr_free ( s -> y_pexpr ); <nl> + av_expr_free ( s -> d_pexpr ); <nl> + s -> x_pexpr = s -> y_pexpr = s -> d_pexpr = NULL ; <nl> av_freep (& s -> expanded_text ); <nl> av_freep (& s -> positions ); <nl> av_tree_enumerate ( s -> glyphs , NULL , NULL , glyph_enu_free ); <nl> static int config_input ( AVFilterLink * inlink ) <nl>  <nl> av_lfg_init (& s -> prng , av_get_random_seed ()); <nl>  <nl> + av_expr_free ( s -> x_pexpr ); <nl> + av_expr_free ( s -> y_pexpr ); <nl> + av_expr_free ( s -> d_pexpr ); <nl> + s -> x_pexpr = s -> y_pexpr = s -> d_pexpr = NULL ; <nl> if (( ret = av_expr_parse (& s -> x_pexpr , s -> x_expr , var_names , <nl> NULL , NULL , fun2_names , fun2 , 0 , ctx )) < 0 || <nl> ( ret = av_expr_parse (& s -> y_pexpr , s -> y_expr , var_names ,
static int jpeg2000_decode_packet ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile , <nl> if (! cblk -> npasses ) { <nl> int v = expn [ bandno ] + numgbits - 1 - <nl> tag_tree_decode ( s , prec -> zerobits + cblkno , 100 ); <nl> - if ( v < 0 ) { <nl> + if ( v < 0 || v > 30 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , <nl> - " nonzerobits % d invalid \ n ", v ); <nl> + " nonzerobits % d invalid or unsupported \ n ", v ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> cblk -> nonzerobits = v ;
static int decode_frame_headers ( Indeo3DecodeContext * ctx , AVCodecContext * avctx , <nl>  <nl> if ( ctx -> data_size == 16 ) <nl> return 4 ; <nl> - if ( ctx -> data_size > buf_size ) <nl> - ctx -> data_size = buf_size ; <nl> + ctx -> data_size = FFMIN ( ctx -> data_size , buf_size - 16 ); <nl>  <nl> bytestream2_skip (& gb , 3 ); // skip reserved byte and checksum <nl> 
static int tta_read_header ( AVFormatContext * s , AVFormatParameters * ap ) <nl> return - 1 ; <nl> } <nl> st -> codec -> extradata = av_mallocz ( st -> codec -> extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> + if (! st -> codec -> extradata ) { <nl> + st -> codec -> extradata_size = 0 ; <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> avio_seek ( s -> pb , start_offset , SEEK_SET ); <nl> avio_read ( s -> pb , st -> codec -> extradata , st -> codec -> extradata_size ); <nl> 
static int decode_frame_mp3on4 ( AVCodecContext * avctx , void * data , <nl> } <nl> header = ( AV_RB32 ( buf ) & 0x000fffff ) | s -> syncword ; // patch header <nl>  <nl> - if ( ff_mpa_check_header ( header ) < 0 ) // Bad header , discard block <nl> - break ; <nl> + if ( ff_mpa_check_header ( header ) < 0 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Bad header , discard block \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl>  <nl> avpriv_mpegaudio_decode_header (( MPADecodeHeader *) m , header ); <nl> 
static int dirac_decode_data_unit ( AVCodecContext * avctx , const uint8_t * buf , int <nl> return ret ; <nl> } <nl>  <nl> - ret = ff_set_dimensions ( avctx , dsh -> width , dsh -> height ); <nl> + if ( CALC_PADDING (( int64_t ) dsh -> width , MAX_DWT_LEVELS ) * CALC_PADDING (( int64_t ) dsh -> height , MAX_DWT_LEVELS ) > avctx -> max_pixels ) <nl> + ret = AVERROR ( ERANGE ); <nl> + if ( ret >= 0 ) <nl> + ret = ff_set_dimensions ( avctx , dsh -> width , dsh -> height ); <nl> if ( ret < 0 ) { <nl> av_freep (& dsh ); <nl> return ret ;
static void gmc_motion ( MpegEncContext * s , <nl> s -> sprite_delta [ 0 ][ 0 ], s -> sprite_delta [ 0 ][ 1 ], <nl> s -> sprite_delta [ 1 ][ 0 ], s -> sprite_delta [ 1 ][ 1 ], <nl> a + 1 , ( 1 << ( 2 * a + 1 )) - s -> no_rounding , <nl> - s -> h_edge_pos >> 1 , s -> v_edge_pos >> 1 ); <nl> + ( s -> h_edge_pos + 1 ) >> 1 , ( s -> v_edge_pos + 1 ) >> 1 ); <nl>  <nl> ptr = ref_picture [ 2 ]; <nl> s -> mdsp . gmc ( dest_cr , ptr , uvlinesize , 8 , <nl> static void gmc_motion ( MpegEncContext * s , <nl> s -> sprite_delta [ 0 ][ 0 ], s -> sprite_delta [ 0 ][ 1 ], <nl> s -> sprite_delta [ 1 ][ 0 ], s -> sprite_delta [ 1 ][ 1 ], <nl> a + 1 , ( 1 << ( 2 * a + 1 )) - s -> no_rounding , <nl> - s -> h_edge_pos >> 1 , s -> v_edge_pos >> 1 ); <nl> + ( s -> h_edge_pos + 1 ) >> 1 , ( s -> v_edge_pos + 1 ) >> 1 ); <nl> } <nl>  <nl> static inline int hpel_motion ( MpegEncContext * s ,
static int parse_psfile ( AVFilterContext * ctx , const char * fname ) <nl> return ret ; <nl>  <nl> # define READ16 ( dst ) do { \ <nl> - if ( size < 2 ) \ <nl> - return AVERROR_INVALIDDATA ; \ <nl> + if ( size < 2 ) { \ <nl> + ret = AVERROR_INVALIDDATA ; \ <nl> + goto end ; \ <nl> + } \ <nl> dst = AV_RB16 ( buf ); \ <nl> buf += 2 ; \ <nl> size -= 2 ; \
int opt_default ( const char * opt , const char * arg ){ <nl> if (! o && sws_opts ) <nl> ret = av_set_string3 ( sws_opts , opt , arg , 1 , & o ); <nl> if (! o ){ <nl> - if ( opt [ 0 ] == ' a ') <nl> + if ( opt [ 0 ] == ' a ' && avcodec_opts [ AVMEDIA_TYPE_AUDIO ]) <nl> ret = av_set_string3 ( avcodec_opts [ AVMEDIA_TYPE_AUDIO ], opt + 1 , arg , 1 , & o ); <nl> - else if ( opt [ 0 ] == ' v ') <nl> + else if ( opt [ 0 ] == ' v ' && avcodec_opts [ AVMEDIA_TYPE_VIDEO ]) <nl> ret = av_set_string3 ( avcodec_opts [ AVMEDIA_TYPE_VIDEO ], opt + 1 , arg , 1 , & o ); <nl> - else if ( opt [ 0 ] == ' s ') <nl> + else if ( opt [ 0 ] == ' s ' && avcodec_opts [ AVMEDIA_TYPE_SUBTITLE ]) <nl> ret = av_set_string3 ( avcodec_opts [ AVMEDIA_TYPE_SUBTITLE ], opt + 1 , arg , 1 , & o ); <nl> } <nl> if ( o && ret < 0 ) {
static int flic_decode_frame_8BPP ( AVCodecContext * avctx , <nl> /* iterate through the chunks */ <nl> while (( frame_size > 0 ) && ( num_chunks > 0 )) { <nl> chunk_size = AV_RL32 (& buf [ stream_ptr ]); <nl> + if ( chunk_size > frame_size ) { <nl> + av_log ( avctx , AV_LOG_WARNING , <nl> + " Invalid chunk_size = % u > frame_size = % u \ n ", chunk_size , frame_size ); <nl> + chunk_size = frame_size ; <nl> + } <nl> stream_ptr += 4 ; <nl> chunk_type = AV_RL16 (& buf [ stream_ptr ]); <nl> stream_ptr += 2 ;
void ff_parse_specific_params ( AVStream * st , int * au_rate , <nl>  <nl> void ff_riff_write_info_tag ( AVIOContext * pb , const char * tag , const char * str ) <nl> { <nl> - int len = strlen ( str ); <nl> - if ( len > 0 ) { <nl> + size_t len = strlen ( str ); <nl> + if ( len > 0 && len < UINT32_MAX ) { <nl> len ++; <nl> ffio_wfourcc ( pb , tag ); <nl> avio_wl32 ( pb , len );
static void dequantization_int_97 ( int x , int y , Jpeg2000Cblk * cblk , <nl> int32_t * datap = & comp -> i_data [( comp -> coord [ 0 ][ 1 ] - comp -> coord [ 0 ][ 0 ]) * ( y + j ) + x ]; <nl> int * src = t1 -> data [ j ]; <nl> for ( i = 0 ; i < w ; ++ i ) <nl> - datap [ i ] = ( src [ i ] * band -> i_stepsize + ( 1 << 14 )) >> 15 ; <nl> + datap [ i ] = ( src [ i ] * ( int64_t ) band -> i_stepsize + ( 1 << 14 )) >> 15 ; <nl> } <nl> } <nl> 
static int adpcm_decode_frame ( AVCodecContext * avctx , <nl> if ( n & 1 ) sampledat = * src ++ << 28 ; <nl> else sampledat = (* src & 0xF0 )<< 24 ; <nl>  <nl> - * samples = (( prev [ ch ][ 0 ]* factor1 <nl> + sampledat = (( prev [ ch ][ 0 ]* factor1 <nl> + prev [ ch ][ 1 ]* factor2 ) >> 11 ) + ( sampledat >> exp ); <nl> + CLAMP_TO_SHORT ( sampledat ); <nl> + * samples = sampledat ; <nl> prev [ ch ][ 1 ] = prev [ ch ][ 0 ]; <nl> prev [ ch ][ 0 ] = * samples ++; <nl> 
static int lag_decode_zero_run_line ( LagarithContext * l , uint8_t * dst , <nl> uint8_t * end = dst + ( width - 2 ); <nl>  <nl> avpriv_request_sample ( l -> avctx , " zero_run_line "); <nl> - return AVERROR_PATCHWELCOME ; <nl> + <nl> + memset ( dst , 0 , width ); <nl>  <nl> output_zeros : <nl> if ( l -> zeros_rem ) {
ff_rm_parse_packet ( AVFormatContext * s , AVIOContext * pb , <nl>  <nl> ast -> sub_packet_cnt = 0 ; <nl> rm -> audio_stream_num = st -> index ; <nl> + if ( st -> codecpar -> block_align <= 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Invalid block alignment % d \ n ", st -> codecpar -> block_align ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> rm -> audio_pkt_cnt = h * w / st -> codecpar -> block_align ; <nl> } else if (( ast -> deint_id == DEINT_ID_VBRF ) || <nl> ( ast -> deint_id == DEINT_ID_VBRS )) {
ogm_header ( AVFormatContext * s , int idx ) <nl> size -= 52 ; <nl> if ( bytestream2_get_bytes_left (& p ) < size ) <nl> return AVERROR_INVALIDDATA ; <nl> + av_freep (& st -> codecpar -> extradata ); <nl> if ( ff_alloc_extradata ( st -> codecpar , size ) < 0 ) <nl> return AVERROR ( ENOMEM ); <nl> bytestream2_get_buffer (& p , st -> codecpar -> extradata , st -> codecpar -> extradata_size );
static int mxf_read_close ( AVFormatContext * s ) <nl> av_freep (& mxf -> aesc ); <nl> av_freep (& mxf -> local_tags ); <nl>  <nl> - for ( i = 0 ; i < mxf -> nb_index_tables ; i ++) { <nl> - av_freep (& mxf -> index_tables [ i ]. segments ); <nl> - av_freep (& mxf -> index_tables [ i ]. ptses ); <nl> - av_freep (& mxf -> index_tables [ i ]. fake_index ); <nl> + if ( mxf -> index_tables ) { <nl> + for ( i = 0 ; i < mxf -> nb_index_tables ; i ++) { <nl> + av_freep (& mxf -> index_tables [ i ]. segments ); <nl> + av_freep (& mxf -> index_tables [ i ]. ptses ); <nl> + av_freep (& mxf -> index_tables [ i ]. fake_index ); <nl> + } <nl> } <nl> av_freep (& mxf -> index_tables ); <nl> 
void ff_xvmc_init_block ( MpegEncContext * s ) <nl> { <nl> struct xvmc_render_state * render = ( struct xvmc_render_state *) s -> current_picture . data [ 2 ]; <nl> - assert ( render ); <nl> if (! render || render -> magic != AV_XVMC_RENDER_MAGIC ) { <nl> assert ( 0 ); <nl> return ; // make sure that this is a render packet
reconnect : <nl> (! strcmp ( fname + len - 4 , ". f4v ") || <nl> ! strcmp ( fname + len - 4 , ". mp4 "))) { <nl> memcpy ( rt -> playpath , " mp4 :", 5 ); <nl> - } else if ( len >= 4 && ! strcmp ( fname + len - 4 , ". flv ")) { <nl> - fname [ len - 4 ] = '\ 0 '; <nl> } else { <nl> + if ( len >= 4 && ! strcmp ( fname + len - 4 , ". flv ")) <nl> + fname [ len - 4 ] = '\ 0 '; <nl> rt -> playpath [ 0 ] = 0 ; <nl> } <nl> av_strlcat ( rt -> playpath , fname , PLAYPATH_MAX_LENGTH );
static av_cold void uninit ( AVFilterContext * ctx ) <nl> for ( i = 0 ; i < HIST_SIZE ; i ++) <nl> av_freep (& s -> histogram [ i ]. entries ); <nl> av_freep (& s -> refs ); <nl> - av_freep (& s -> prev_frame ); <nl> + av_frame_free (& s -> prev_frame ); <nl> } <nl>  <nl> static const AVFilterPad palettegen_inputs [] = {
static int read_low_coeffs ( AVCodecContext * avctx , int16_t * dst , int size , int wi <nl> state = 120 * ( escape + flag ) + state - ( 120 * state >> 8 ); <nl> flag = 0 ; <nl>  <nl> - if ( state * 4 > 0xFF || i >= size ) <nl> + if ( state * 4ULL > 0xFF || i >= size ) <nl> continue ; <nl>  <nl> nbits = (( state + 8 ) >> 5 ) + ( state ? ff_clz ( state ) : 32 ) - 24 ; <nl> static int read_high_coeffs ( AVCodecContext * avctx , uint8_t * src , int16_t * dst , i <nl>  <nl> flag = 0 ; <nl>  <nl> - if ( state * 4 > 0xFF || i >= size ) <nl> + if ( state * 4ULL > 0xFF || i >= size ) <nl> continue ; <nl>  <nl> pfx = (( state + 8 ) >> 5 ) + ( state ? ff_clz ( state ): 32 ) - 24 ;
static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * in ) <nl> switch ( h -> mode ) { <nl> case MODE_LEVELS : <nl> for ( k = 0 ; k < h -> ncomp ; k ++) { <nl> + int start = k * ( h -> level_height + h -> scale_height ); <nl> + <nl> for ( i = 0 ; i < in -> video -> h ; i ++) { <nl> src = in -> data [ k ] + i * in -> linesize [ k ]; <nl> for ( j = 0 ; j < in -> video -> w ; j ++) <nl> static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * in ) <nl> for ( i = 0 ; i < 256 ; i ++) <nl> h -> max_hval = FFMAX ( h -> max_hval , h -> histogram [ i ]); <nl>  <nl> - int start = k * ( h -> level_height + h -> scale_height ); <nl> for ( i = 0 ; i < outlink -> w ; i ++) { <nl> int col_height = h -> level_height - ( float ) h -> histogram [ i ] / h -> max_hval * h -> level_height ; <nl> 
int ff_qsv_encode ( AVCodecContext * avctx , QSVEncContext * q , <nl>  <nl> do { <nl> ret = MFXVideoENCODE_EncodeFrameAsync ( q -> session , NULL , surf , & bs , & sync ); <nl> - if ( ret == MFX_WRN_DEVICE_BUSY ) <nl> + if ( ret == MFX_WRN_DEVICE_BUSY ) { <nl> av_usleep ( 1 ); <nl> - } while ( ret > 0 ); <nl> + continue ; <nl> + } <nl> + break ; <nl> + } while ( 1 ); <nl>  <nl> if ( ret < 0 ) <nl> return ( ret == MFX_ERR_MORE_DATA ) ? 0 : ff_qsv_error ( ret );
static int http_server ( void ) <nl> do { <nl> ret = poll ( poll_table , poll_entry - poll_table , delay ); <nl> if ( ret < 0 && ff_neterrno () != AVERROR ( EAGAIN ) && <nl> - ff_neterrno () != AVERROR ( EINTR )) <nl> + ff_neterrno () != AVERROR ( EINTR )) { <nl> + av_free ( poll_table ); <nl> return - 1 ; <nl> + } <nl> } while ( ret < 0 ); <nl>  <nl> cur_time = av_gettime () / 1000 ;
static int mm_decode_inter ( MmContext * s , int half_horiz , int half_vert ) <nl> int replace_array = bytestream2_get_byte (& s -> gb ); <nl> for ( j = 0 ; j < 8 ; j ++) { <nl> int replace = ( replace_array >> ( 7 - j )) & 1 ; <nl> + if ( x + half_horiz >= s -> avctx -> width ) <nl> + return AVERROR_INVALIDDATA ; <nl> if ( replace ) { <nl> int color = bytestream2_get_byte (& data_ptr ); <nl> s -> frame -> data [ 0 ][ y * s -> frame -> linesize [ 0 ] + x ] = color ;
static int latm_decode_audio_specific_config ( struct LATMContext * latmctx , <nl> GetBitContext * gb , int asclen ) <nl> { <nl> AVCodecContext * avctx = latmctx -> aac_ctx . avctx ; <nl> - MPEG4AudioConfig m4ac ; <nl> AACContext * ac = & latmctx -> aac_ctx ; <nl> + MPEG4AudioConfig m4ac = ac -> m4ac ; <nl> int config_start_bit = get_bits_count ( gb ); <nl> int bits_consumed , esize ; <nl>  <nl> static int latm_decode_audio_specific_config ( struct LATMContext * latmctx , <nl>  <nl> if ( bits_consumed < 0 ) <nl> return AVERROR_INVALIDDATA ; <nl> - ac -> m4ac = m4ac ; <nl> + if ( ac -> m4ac . sample_rate != m4ac . sample_rate || m4ac . chan_config != ac -> m4ac . chan_config ) <nl> + ac -> m4ac = m4ac ; <nl>  <nl> esize = ( bits_consumed + 7 ) / 8 ; <nl> 
static int execute_decode_slices ( H264Context * h , int context_count ) <nl> H264Context * hx ; <nl> int i ; <nl>  <nl> + if ( h -> mb_y >= h -> mb_height ) { <nl> + av_log ( h -> avctx , AV_LOG_ERROR , <nl> + " Input contains more MB rows than the frame height .\ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> if ( h -> avctx -> hwaccel ) <nl> return 0 ; <nl> if ( context_count == 1 ) {
static int h263_decode_gob_header ( MpegEncContext * s ) <nl> /* We have a GBSC probably with GSTUFF */ <nl> skip_bits (& s -> gb , 16 ); /* Drop the zeros */ <nl> left = get_bits_left (& s -> gb ); <nl> + left = FFMIN ( left , 32 ); <nl> // MN : we must check the bits left or we might end in an infinite loop ( or segfault ) <nl> for (; left > 13 ; left --){ <nl> if ( get_bits1 (& s -> gb )) break ; /* Seek the ' 1 ' bit */
static void show_packets ( AVFormatContext * fmt_ctx ) <nl>  <nl> av_init_packet (& pkt ); <nl> probe_array_header (" packets ", 0 ); <nl> - while (! av_read_frame ( fmt_ctx , & pkt )) <nl> + while (! av_read_frame ( fmt_ctx , & pkt )) { <nl> show_packet ( fmt_ctx , & pkt ); <nl> + av_packet_unref (& pkt ); <nl> + } <nl> probe_array_footer (" packets ", 0 ); <nl> } <nl> 
static int decode_nal_units ( H264Context * h , const uint8_t * buf , int buf_size ){ <nl> break ; <nl>  <nl> if ( h -> sei_recovery_frame_cnt >= 0 <nl> - && (( h -> recovery_frame - h -> frame_num ) & (( 1 << h -> sps . log2_max_frame_num )- 1 )) > h -> sei_recovery_frame_cnt ) { <nl> + && ( h -> recovery_frame < 0 <nl> + || (( h -> recovery_frame - h -> frame_num ) & (( 1 << h -> sps . log2_max_frame_num )- 1 )) > h -> sei_recovery_frame_cnt )) { <nl> h -> recovery_frame = ( h -> frame_num + h -> sei_recovery_frame_cnt ) % <nl> ( 1 << h -> sps . log2_max_frame_num ); <nl> }
static enum CodecID vfw_codecid ( DWORD biCompression ) <nl> switch ( biCompression ) { <nl> case MKTAG (' d ', ' v ', ' s ', ' d '): <nl> return CODEC_ID_DVVIDEO ; <nl> + case MKTAG (' M ', ' J ', ' P ', ' G '): <nl> + case MKTAG (' m ', ' j ', ' p ', ' g '): <nl> + return CODEC_ID_MJPEG ; <nl> } <nl> return CODEC_ID_NONE ; <nl> }
static void swap_guid ( ff_asf_guid guid ) <nl>  <nl> static void align_position ( AVIOContext * pb , int64_t offset , uint64_t size ) <nl> { <nl> - if ( avio_tell ( pb ) != offset + size ) <nl> + if ( size < INT64_MAX - offset && avio_tell ( pb ) != offset + size ) <nl> avio_seek ( pb , offset + size , SEEK_SET ); <nl> } <nl> 
int ff_mpeg4audio_get_config ( MPEG4AudioConfig * c , const uint8_t * buf , int buf_si <nl> c -> sample_rate = get_sample_rate (& gb , & c -> sampling_index ); <nl> c -> chan_config = get_bits (& gb , 4 ); <nl> c -> sbr = - 1 ; <nl> - if ( c -> object_type == 5 ) { <nl> + if ( c -> object_type == AOT_SBR ) { <nl> c -> ext_object_type = c -> object_type ; <nl> c -> sbr = 1 ; <nl> c -> ext_sample_rate = get_sample_rate (& gb , & c -> ext_sampling_index ); <nl> int ff_mpeg4audio_get_config ( MPEG4AudioConfig * c , const uint8_t * buf , int buf_si <nl> } <nl> specific_config_bitindex = get_bits_count (& gb ); <nl>  <nl> - if ( c -> ext_object_type != 5 ) { <nl> + if ( c -> ext_object_type != AOT_SBR ) { <nl> int bits_left = buf_size * 8 - specific_config_bitindex ; <nl> for (; bits_left > 15 ; bits_left --) { <nl> if ( show_bits (& gb , 11 ) == 0x2b7 ) { // sync extension <nl> get_bits (& gb , 11 ); <nl> c -> ext_object_type = get_object_type (& gb ); <nl> - if ( c -> ext_object_type == 5 && ( c -> sbr = get_bits1 (& gb )) == 1 ) <nl> + if ( c -> ext_object_type == AOT_SBR && ( c -> sbr = get_bits1 (& gb )) == 1 ) <nl> c -> ext_sample_rate = get_sample_rate (& gb , & c -> ext_sampling_index ); <nl> break ; <nl> } else
static int decode_frame_header ( AVCodecContext * ctx , <nl> s -> lf_delta . ref [ 3 ] = - 1 ; <nl> s -> lf_delta . mode [ 0 ] = 0 ; <nl> s -> lf_delta . mode [ 1 ] = 0 ; <nl> + memset ( s -> segmentation . feat , 0 , sizeof ( s -> segmentation . feat )); <nl> } <nl> s -> filter . level = get_bits (& s -> gb , 6 ); <nl> sharp = get_bits (& s -> gb , 3 );
static int seg_write_header ( AVFormatContext * s ) <nl> goto fail ; <nl> } <nl>  <nl> + if ( oc -> avoid_negative_ts > 0 && s -> avoid_negative_ts < 0 ) <nl> + s -> avoid_negative_ts = 1 ; <nl> + <nl> if (! seg -> write_header_trailer ) { <nl> close_null_ctx ( oc -> pb ); <nl> if (( ret = avio_open2 (& oc -> pb , oc -> filename , AVIO_FLAG_WRITE ,
static int on2avc_decode_band_scales ( On2AVCContext * c , GetBitContext * gb ) <nl> } else { <nl> scale += get_vlc2 ( gb , c -> scale_diff . table , 9 , 3 ) - 60 ; <nl> } <nl> - if ( scale < 0 || scale > 128 ) { <nl> + if ( scale < 0 || scale > 127 ) { <nl> av_log ( c -> avctx , AV_LOG_ERROR , " Invalid scale value % d \ n ", <nl> scale ); <nl> return AVERROR_INVALIDDATA ;
enum BandType { <nl> INTENSITY_BT = 15 , ///< Scalefactor data are intensity stereo positions . <nl> }; <nl>  <nl> -# define IS_CODEBOOK_UNSIGNED ( x ) (( x - 1 ) & 10 ) <nl> +# define IS_CODEBOOK_UNSIGNED ( x ) ((( x ) - 1 ) & 10 ) <nl>  <nl> enum ChannelPosition { <nl> AAC_CHANNEL_OFF = 0 ,
static int au_probe ( AVProbeData * p ) <nl> return 0 ; <nl> } <nl>  <nl> +# define BLOCK_SIZE 1024 <nl> + <nl> /* au input */ <nl> static int au_read_header ( AVFormatContext * s ) <nl> { <nl> static int au_read_header ( AVFormatContext * s ) <nl> return AVERROR_PATCHWELCOME ; <nl> } <nl>  <nl> - if ( channels == 0 || channels > 64 ) { <nl> + if ( channels == 0 || channels >= INT_MAX / ( BLOCK_SIZE * bps >> 3 )) { <nl> av_log ( s , AV_LOG_ERROR , " Invalid number of channels % d \ n ", channels ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> static int au_read_header ( AVFormatContext * s ) <nl> return 0 ; <nl> } <nl>  <nl> -# define BLOCK_SIZE 1024 <nl> - <nl> static int au_read_packet ( AVFormatContext * s , <nl> AVPacket * pkt ) <nl> {
again : <nl> break ; <nl>  <nl> if ( h -> sei_recovery_frame_cnt >= 0 && ( h -> frame_num != h -> sei_recovery_frame_cnt || hx -> slice_type_nos != AV_PICTURE_TYPE_I )) <nl> - h -> valid_recovery_point ++; <nl> + h -> valid_recovery_point = 1 ; <nl>  <nl> if ( h -> sei_recovery_frame_cnt >= 0 <nl> && ( h -> recovery_frame < 0
static float dca_dmix_code ( unsigned code ) <nl> static int scan_for_extensions ( AVCodecContext * avctx ) <nl> { <nl> DCAContext * s = avctx -> priv_data ; <nl> - int core_ss_end , ret ; <nl> + int core_ss_end , ret = 0 ; <nl>  <nl> core_ss_end = FFMIN ( s -> frame_size , s -> dca_buffer_size ) * 8 ; <nl> 
static int sync ( AVFormatContext * s , int64_t * timestamp , int * flags , int * stream_ <nl> skip : <nl> /* skip packet if unknown number */ <nl> url_fskip ( pb , len ); <nl> - rm -> remaining_len -= len ; <nl> + rm -> remaining_len = 0 ; <nl> continue ; <nl> } <nl> * stream_index = i ;
static int wav_write_trailer ( AVFormatContext * s ) <nl> # endif /* CONFIG_WAV_MUXER */ <nl>  <nl> /* return the size of the found tag */ <nl> -/* XXX : > 2GB ? */ <nl> - static int find_tag ( ByteIOContext * pb , uint32_t tag1 ) <nl> + static int64_t find_tag ( ByteIOContext * pb , uint32_t tag1 ) <nl> { <nl> unsigned int tag ; <nl> - int size ; <nl> + int64_t size ; <nl>  <nl> for (;;) { <nl> if ( url_feof ( pb )) <nl> static int find_tag ( ByteIOContext * pb , uint32_t tag1 ) <nl> break ; <nl> url_fseek ( pb , size , SEEK_CUR ); <nl> } <nl> - if ( size < 0 ) <nl> - size = 0x7fffffff ; <nl> return size ; <nl> } <nl>  <nl> static int wav_probe ( AVProbeData * p ) <nl> static int wav_read_header ( AVFormatContext * s , <nl> AVFormatParameters * ap ) <nl> { <nl> - int size ; <nl> + int64_t size ; <nl> unsigned int tag ; <nl> ByteIOContext * pb = s -> pb ; <nl> AVStream * st ;
static int rv40_decode_mb_info ( RV34DecContext * r ) <nl> if (-- r -> s . mb_skip_run ) <nl> return RV34_MB_SKIP ; <nl>  <nl> - if ( r -> avail [ 0 ]) <nl> + if ( r -> avail_cache [ 5 - 1 ]) <nl> blocks [ r -> mb_type [ mb_pos - 1 ]]++; <nl> - if ( r -> avail [ 1 ]){ <nl> + if ( r -> avail_cache [ 5 - 4 ]){ <nl> blocks [ r -> mb_type [ mb_pos - s -> mb_stride ]]++; <nl> - if ( r -> avail [ 2 ]) <nl> + if ( r -> avail_cache [ 5 - 2 ]) <nl> blocks [ r -> mb_type [ mb_pos - s -> mb_stride + 1 ]]++; <nl> - if ( r -> avail [ 3 ]) <nl> + if ( r -> avail_cache [ 5 - 5 ]) <nl> blocks [ r -> mb_type [ mb_pos - s -> mb_stride - 1 ]]++; <nl> } <nl> 
static int process_input ( int file_index ) <nl> AVPacket pkt ; <nl> int ret , i , j ; <nl> int64_t duration ; <nl> + int64_t pkt_dts ; <nl>  <nl> is = ifile -> ctx ; <nl> ret = get_input_packet ( ifile , & pkt ); <nl> static int process_input ( int file_index ) <nl> if ( pkt . dts != AV_NOPTS_VALUE ) <nl> pkt . dts *= ist -> ts_scale ; <nl>  <nl> + pkt_dts = av_rescale_q_rnd ( pkt . dts , ist -> st -> time_base , AV_TIME_BASE_Q , AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX ); <nl> if (( ist -> dec_ctx -> codec_type == AVMEDIA_TYPE_VIDEO || <nl> ist -> dec_ctx -> codec_type == AVMEDIA_TYPE_AUDIO ) && <nl> - pkt . dts != AV_NOPTS_VALUE && ist -> next_dts == AV_NOPTS_VALUE && ! copy_ts <nl> + pkt_dts != AV_NOPTS_VALUE && ist -> next_dts == AV_NOPTS_VALUE && ! copy_ts <nl> && ( is -> iformat -> flags & AVFMT_TS_DISCONT ) && ifile -> last_ts != AV_NOPTS_VALUE ) { <nl> - int64_t pkt_dts = av_rescale_q ( pkt . dts , ist -> st -> time_base , AV_TIME_BASE_Q ); <nl> int64_t delta = pkt_dts - ifile -> last_ts ; <nl> if ( delta < - 1LL * dts_delta_threshold * AV_TIME_BASE || <nl> delta > 1LL * dts_delta_threshold * AV_TIME_BASE ){ <nl> static int process_input ( int file_index ) <nl> if ( pkt . dts != AV_NOPTS_VALUE ) <nl> pkt . dts += duration ; <nl>  <nl> + pkt_dts = av_rescale_q_rnd ( pkt . dts , ist -> st -> time_base , AV_TIME_BASE_Q , AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX ); <nl> if (( ist -> dec_ctx -> codec_type == AVMEDIA_TYPE_VIDEO || <nl> ist -> dec_ctx -> codec_type == AVMEDIA_TYPE_AUDIO ) && <nl> - pkt . dts != AV_NOPTS_VALUE && ist -> next_dts != AV_NOPTS_VALUE && <nl> + pkt_dts != AV_NOPTS_VALUE && ist -> next_dts != AV_NOPTS_VALUE && <nl> ! copy_ts ) { <nl> - int64_t pkt_dts = av_rescale_q ( pkt . dts , ist -> st -> time_base , AV_TIME_BASE_Q ); <nl> int64_t delta = pkt_dts - ist -> next_dts ; <nl> if ( is -> iformat -> flags & AVFMT_TS_DISCONT ) { <nl> if ( delta < - 1LL * dts_delta_threshold * AV_TIME_BASE ||
static int decode_slice_header ( H264Context * h , H264Context * h0 ) <nl>  <nl> if ( num_ref_idx_active_override_flag ) { <nl> h -> ref_count [ 0 ] = get_ue_golomb (& s -> gb ) + 1 ; <nl> - if ( h -> slice_type_nos == AV_PICTURE_TYPE_B ) <nl> + if ( h -> ref_count [ 0 ] < 1 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + if ( h -> slice_type_nos == AV_PICTURE_TYPE_B ) { <nl> h -> ref_count [ 1 ] = get_ue_golomb (& s -> gb ) + 1 ; <nl> + if ( h -> ref_count [ 1 ] < 1 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> } <nl>  <nl> if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )
static int config_input_props ( AVFilterLink * inlink ) <nl> AVFilterContext * ctx = inlink -> dst ; <nl> Frei0rContext * s = ctx -> priv ; <nl>  <nl> + if ( s -> destruct && s -> instance ) <nl> + s -> destruct ( s -> instance ); <nl> if (!( s -> instance = s -> construct ( inlink -> w , inlink -> h ))) { <nl> av_log ( ctx , AV_LOG_ERROR , " Impossible to load frei0r instance "); <nl> return AVERROR ( EINVAL ); <nl> static int source_config_props ( AVFilterLink * outlink ) <nl> outlink -> h = s -> h ; <nl> outlink -> time_base = s -> time_base ; <nl>  <nl> + if ( s -> destruct && s -> instance ) <nl> + s -> destruct ( s -> instance ); <nl> if (!( s -> instance = s -> construct ( outlink -> w , outlink -> h ))) { <nl> av_log ( ctx , AV_LOG_ERROR , " Impossible to load frei0r instance "); <nl> return AVERROR ( EINVAL );
static const AVOption avcodec_options [] = { <nl> {" bt ", NULL , 0 , AV_OPT_TYPE_CONST , {. i64 = AV_FIELD_BT }, 0 , 0 , V | D | E , " field_order " }, <nl> {" dump_separator ", " set information dump field separator ", OFFSET ( dump_separator ), AV_OPT_TYPE_STRING , {. str = NULL }, CHAR_MIN , CHAR_MAX , A | V | S | D | E }, <nl> {" codec_whitelist ", " List of decoders that are allowed to be used ", OFFSET ( codec_whitelist ), AV_OPT_TYPE_STRING , { . str = NULL }, CHAR_MIN , CHAR_MAX , A | V | S | D }, <nl> +{" pixel_format ", " set pixel format ", OFFSET ( pix_fmt ), AV_OPT_TYPE_PIXEL_FMT , {. i64 = AV_PIX_FMT_NONE }, - 1 , INT_MAX , 0 }, <nl> +{" video_size ", " set video size ", OFFSET ( width ), AV_OPT_TYPE_IMAGE_SIZE , {. str = NULL }, 0 , INT_MAX , 0 }, <nl> { NULL }, <nl> }; <nl> 
int ff_qsv_enc_init ( AVCodecContext * avctx , QSVEncContext * q ) <nl> } <nl>  <nl> ret = MFXVideoENCODE_Init ( q -> session , & q -> param ); <nl> - if ( ret < 0 ) { <nl> + if ( MFX_WRN_PARTIAL_ACCELERATION == ret ) { <nl> + av_log ( avctx , AV_LOG_WARNING , " Encoder will work with partial HW acceleration \ n "); <nl> + } else if ( ret < 0 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Error initializing the encoder \ n "); <nl> return ff_qsv_error ( ret ); <nl> }
const DVprofile * avpriv_dv_frame_profile2 ( AVCodecContext * codec , const DVprofile <nl> return & dv_profiles [ 2 ]; <nl> } <nl>  <nl> - if ( stype == 0 && codec && codec -> codec_tag == AV_RL32 (" dvsd ") && codec -> width == 720 && codec -> height == 576 ) <nl> + if ( stype == 0 && codec && codec -> codec_tag == AV_RL32 (" dvsd ") && codec -> coded_width == 720 && codec -> coded_height == 576 ) <nl> return & dv_profiles [ 1 ]; <nl>  <nl> for ( i = 0 ; i < FF_ARRAY_ELEMS ( dv_profiles ); i ++)
static int latm_decode_audio_specific_config ( struct LATMContext * latmctx , <nl> " config not byte aligned .\ n ", 1 ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> + if ( asclen <= 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> bits_consumed = decode_audio_specific_config ( NULL , avctx , & m4ac , <nl> gb -> buffer + ( config_start_bit / 8 ), <nl> asclen , sync_extension );
static int mov_read_sidx ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) <nl> MOVFragmentStreamInfo * si ; <nl> si = & item -> stream_info [ j ]; <nl> if ( si -> sidx_pts != AV_NOPTS_VALUE ) { <nl> - ref_st = c -> fc -> streams [ i ]; <nl> + ref_st = c -> fc -> streams [ j ]; <nl> ref_sc = ref_st -> priv_data ; <nl> break ; <nl> }
int av_bsf_list_parse_str ( const char * str , AVBSFContext ** bsf_lst ) <nl> if (! lst ) <nl> return AVERROR ( ENOMEM ); <nl>  <nl> - if (!( dup = buf = av_strdup ( str ))) <nl> - return AVERROR ( ENOMEM ); <nl> + if (!( dup = buf = av_strdup ( str ))) { <nl> + ret = AVERROR ( ENOMEM ); <nl> + goto end ; <nl> + } <nl>  <nl> while ( 1 ) { <nl> bsf_str = av_strtok ( buf , ",", & saveptr );
static void do_apply_filter ( APEContext * ctx , int version , APEFilter * f , <nl> /* Update the adaption coefficients */ <nl> absres = FFABS ( res ); <nl> if ( absres ) <nl> - * f -> adaptcoeffs = (( res & (- 1 << 31 )) ^ (- 1 << 30 )) >> <nl> + * f -> adaptcoeffs = (( res & ((~ 0UL ) << 31 )) ^ ((~ 0UL ) << 30 )) >> <nl> ( 25 + ( absres <= f -> avg * 3 ) + ( absres <= f -> avg * 4 / 3 )); <nl> else <nl> * f -> adaptcoeffs = 0 ;
static void rtsp_cmd_pause ( HTTPContext * c , const char * url , RTSPHeader * h ) <nl> static void rtsp_cmd_teardown ( HTTPContext * c , const char * url , RTSPHeader * h ) <nl> { <nl> HTTPContext * rtp_c ; <nl> + char session_id [ 32 ]; <nl>  <nl> rtp_c = find_rtp_session_with_url ( url , h -> session_id ); <nl> if (! rtp_c ) { <nl> static void rtsp_cmd_teardown ( HTTPContext * c , const char * url , RTSPHeader * h ) <nl> return ; <nl> } <nl>  <nl> + pstrcpy ( session_id , sizeof ( session_id ), rtp_c -> session_id ); <nl> + <nl> /* abort the session */ <nl> close_connection ( rtp_c ); <nl>  <nl> /* now everything is OK , so we can send the connection parameters */ <nl> rtsp_reply_header ( c , RTSP_STATUS_OK ); <nl> /* session ID */ <nl> - url_fprintf ( c -> pb , " Session : % s \ r \ n ", rtp_c -> session_id ); <nl> + url_fprintf ( c -> pb , " Session : % s \ r \ n ", session_id ); <nl> url_fprintf ( c -> pb , "\ r \ n "); <nl> } <nl> 
static void do_apply_filter ( APEContext * ctx , int version , APEFilter * f , <nl> /* Update the adaption coefficients */ <nl> absres = FFABS ( res ); <nl> if ( absres ) <nl> - * f -> adaptcoeffs = (( res & ( 1 << 31 )) - ( 1 << 30 )) >> <nl> + * f -> adaptcoeffs = (( res & (- 1 << 31 )) ^ (- 1 << 30 )) >> <nl> ( 25 + ( absres <= f -> avg * 3 ) + ( absres <= f -> avg * 4 / 3 )); <nl> else <nl> * f -> adaptcoeffs = 0 ;
static int seg_write_header ( AVFormatContext * s ) <nl> } <nl> if ( seg -> oformat -> flags & AVFMT_NOFILE ) { <nl> av_log ( s , AV_LOG_ERROR , " format % s not supported .\ n ", <nl> - oc -> oformat -> name ); <nl> + seg -> oformat -> name ); <nl> ret = AVERROR ( EINVAL ); <nl> goto fail ; <nl> }
# define DELEM int32_t <nl> # define FELEM int32_t <nl> # define FELEM2 int64_t <nl> -# define FELEML int64_t <nl> # define FELEM_MAX INT32_MAX <nl> # define FELEM_MIN INT32_MIN <nl> # define OUT ( d , v ) v = ( v + ( 1 <<( FILTER_SHIFT - 1 )))>> FILTER_SHIFT ;\ <nl> int RENAME ( swri_resample_linear )( ResampleContext * c , <nl> v2 += src [ sample_index + i ] * ( FELEM2 ) filter [ i + c -> filter_alloc ]; <nl> } <nl> # endif <nl> +# ifdef FELEML <nl> val += ( v2 - val ) * ( FELEML ) frac / c -> src_incr ; <nl> +# else <nl> + val += ( v2 - val ) / c -> src_incr * frac ; <nl> +# endif <nl> OUT ( dst [ dst_index ], val ); <nl>  <nl> frac += c -> dst_incr_mod ;
av_cold void ff_ac3dsp_init_x86 ( AC3DSPContext * c , int bit_exact ) <nl> c -> ac3_rshift_int32 = ff_ac3_rshift_int32_mmx ; <nl> } <nl> if ( EXTERNAL_AMD3DNOW ( mm_flags )) { <nl> - c -> extract_exponents = ff_ac3_extract_exponents_3dnow ; <nl> if (! bit_exact ) { <nl> c -> float_to_fixed24 = ff_float_to_fixed24_3dnow ; <nl> }
static int read_sm_data ( AVFormatContext * s , AVIOContext * bc , AVPacket * pkt , int <nl> return ret ; <nl> } <nl> value_len = ffio_read_varlen ( bc ); <nl> - if ( avio_tell ( bc ) + value_len >= maxpos ) <nl> + if ( value_len < 0 || value_len >= maxpos - avio_tell ( bc )) <nl> return AVERROR_INVALIDDATA ; <nl> if (! strcmp ( name , " Palette ")) { <nl> dst = av_packet_new_side_data ( pkt , AV_PKT_DATA_PALETTE , value_len );
static av_cold int decode_init ( AVCodecContext * avctx ){ <nl> // set defaults <nl> // s -> decode_mb = ff_h263_decode_mb ; <nl> s -> quarter_sample = 1 ; <nl> + if (! avctx -> has_b_frames ) <nl> s -> low_delay = 1 ; <nl>  <nl> if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU )
static int config_out_props ( AVFilterLink * outlink ) <nl> outlink -> time_base = inlink -> time_base ; <nl> outlink -> frame_rate = inlink -> frame_rate ; <nl> // half framerate <nl> + outlink -> time_base . num *= 2 ; <nl> outlink -> frame_rate . den *= 2 ; <nl> outlink -> flags |= FF_LINK_FLAG_REQUEST_LOOP ; <nl>  <nl> static int filter_frame ( AVFilterLink * inlink , AVFrame * buf ) <nl> av_frame_copy_props ( out , s -> cur ); <nl> out -> interlaced_frame = 1 ; <nl> out -> top_field_first = tff ; <nl> + out -> pts /= 2 ; // adjust pts to new framerate <nl>  <nl> /* copy upper / lower field from cur */ <nl> copy_picture_field ( s , s -> cur , out , inlink , tff ? FIELD_UPPER : FIELD_LOWER , s -> lowpass );
static void save_bits ( WMAProDecodeCtx * s , GetBitContext * gb , int len , <nl> return ; <nl> } <nl>  <nl> + if ( len > put_bits_left (& s -> pb )) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , <nl> + " Cannot append % d bits , only % d bits available .\ n ", <nl> + len , put_bits_left (& s -> pb )); <nl> + s -> packet_loss = 1 ; <nl> + return ; <nl> + } <nl> + <nl> s -> num_saved_bits += len ; <nl> if (! append ) { <nl> avpriv_copy_bits (& s -> pb , gb -> buffer + ( get_bits_count ( gb ) >> 3 ),
void avfilter_link_free ( AVFilterLink ** link ) <nl>  <nl> av_freep (& picref -> audio ); <nl> av_freep (& picref -> video ); <nl> - av_freep (& picref ); <nl> + av_freep (&(* link )-> pool -> pic [ i ]); <nl> } <nl> } <nl> - av_freep (&(* link )-> pool ); <nl> + (* link )-> pool -> count = 0 ; <nl> +// av_freep (&(* link )-> pool ); <nl> } <nl> av_freep ( link ); <nl> }
static int rle_unpack ( const unsigned char * src , int src_len , int src_count , <nl> l = * ps ++; <nl> if ( l & 0x80 ) { <nl> l = ( l & 0x7F ) * 2 ; <nl> - if ( pd + l > dest_end || ps_end - ps < l ) <nl> + if ( dest_end - pd < l || ps_end - ps < l ) <nl> return ps - src ; <nl> memcpy ( pd , ps , l ); <nl> ps += l ; <nl> pd += l ; <nl> } else { <nl> - if ( pd + i > dest_end || ps_end - ps < 2 ) <nl> + if ( dest_end - pd < i || ps_end - ps < 2 ) <nl> return ps - src ; <nl> for ( i = 0 ; i < l ; i ++) { <nl> * pd ++ = ps [ 0 ];
static void bastardized_rice_decompress ( ALACContext * alac , <nl>  <nl> /* special case : there may be compressed blocks of 0 */ <nl> if (( history < 128 ) && ( output_count + 1 < output_size )) { <nl> - int block_size , k ; <nl> + int k ; <nl> + unsigned int block_size ; <nl>  <nl> sign_modifier = 1 ; <nl>  <nl> static void bastardized_rice_decompress ( ALACContext * alac , <nl> block_size = decode_scalar (& alac -> gb , k , rice_kmodifier , 16 ); <nl>  <nl> if ( block_size > 0 ) { <nl> + if ( block_size >= output_size - output_count ){ <nl> + av_log ( alac -> avctx , AV_LOG_ERROR , " invalid zero block size of % d % d % d \ n ", block_size , output_size , output_count ); <nl> + block_size = output_size - output_count - 1 ; <nl> + } <nl> memset (& output_buffer [ output_count + 1 ], 0 , block_size * 4 ); <nl> output_count += block_size ; <nl> }
static int mxf_get_sorted_table_segments ( MXFContext * mxf , int * nb_sorted_segment <nl> if ( mxf -> metadata_sets [ i ]-> type == IndexTableSegment ) <nl> nb_segments ++; <nl>  <nl> + if (! nb_segments ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> * sorted_segments = av_mallocz ( nb_segments * sizeof (** sorted_segments )); <nl> unsorted_segments = av_mallocz ( nb_segments * sizeof (* unsorted_segments )); <nl> if (! sorted_segments || ! unsorted_segments ) {
static inline int l3_unscale ( int value , int exponent ) <nl> e = FRAC_BITS - e ; <nl> # if FRAC_BITS <= 15 <nl> if ( e > 31 ) <nl> - e = 31 ; <nl> # else <nl> if ( e > 63 ) <nl> - e = 63 ; <nl> # endif <nl> + return 0 ; <nl> m = table_4_3_value [ value ]; <nl> # if FRAC_BITS <= 15 <nl> m = ( m * scale_factor_mult3 [ exponent & 3 ]);
static int get_pcm ( HEVCContext * s , int x , int y ) <nl>  <nl> # define TC_CALC ( qp , bs ) \ <nl> tctable [ av_clip (( qp ) + DEFAULT_INTRA_TC_OFFSET * (( bs ) - 1 ) + \ <nl> - ( tc_offset >> 1 << 1 ), \ <nl> + ( tc_offset & - 2 ), \ <nl> 0 , MAX_QP + DEFAULT_INTRA_TC_OFFSET )] <nl>  <nl> static void deblocking_filter_CTB ( HEVCContext * s , int x0 , int y0 )
static int asf_build_simple_index ( AVFormatContext * s , int stream_index ) <nl> ff_asf_guid g ; <nl> ASFContext * asf = s -> priv_data ; <nl> int64_t current_pos = avio_tell ( s -> pb ); <nl> - int ret = 0 ; <nl> + int64_t ret ; <nl>  <nl> if (( ret = avio_seek ( s -> pb , asf -> data_object_offset + asf -> data_object_size , SEEK_SET )) < 0 ) { <nl> return ret ; <nl> static int asf_read_seek ( AVFormatContext * s , int stream_index , <nl>  <nl> /* Try using the protocol ' s read_seek if available */ <nl> if ( s -> pb ) { <nl> - int ret = avio_seek_time ( s -> pb , stream_index , pts , flags ); <nl> + int64_t ret = avio_seek_time ( s -> pb , stream_index , pts , flags ); <nl> if ( ret >= 0 ) <nl> asf_reset_header ( s ); <nl> if ( ret != AVERROR ( ENOSYS ))
void av_dump_format ( AVFormatContext * ic , int index , <nl> av_log ( NULL , AV_LOG_INFO , " Duration : "); <nl> if ( ic -> duration != AV_NOPTS_VALUE ) { <nl> int hours , mins , secs , us ; <nl> - int64_t duration = ic -> duration + 5000 ; <nl> + int64_t duration = ic -> duration + ( ic -> duration <= INT64_MAX - 5000 ? 5000 : 0 ); <nl> secs = duration / AV_TIME_BASE ; <nl> us = duration % AV_TIME_BASE ; <nl> mins = secs / 60 ;
static void type_a ## _ ## type_b ## _ ## sz ## x ## sz ## _add_c ( uint8_t * _dst , \ <nl> \ <nl> stride /= sizeof ( pixel ); \ <nl> if ( has_dconly && eob == 1 ) { \ <nl> - const int t = ((( block [ 0 ] * 11585 + ( 1 << 13 )) >> 14 ) \ <nl> - * 11585 + ( 1 << 13 )) >> 14 ; \ <nl> + const int t = (((( dctint ) block [ 0 ] * 11585 + ( 1 << 13 )) >> 14 ) \ <nl> + * 11585 + ( 1 << 13 )) >> 14 ; \ <nl> block [ 0 ] = 0 ; \ <nl> for ( i = 0 ; i < sz ; i ++) { \ <nl> for ( j = 0 ; j < sz ; j ++) \
static int theora_decode_header ( AVCodecContext * avctx , GetBitContext * gb ) <nl> { <nl> skip_bits ( gb , 5 ); /* keyframe frequency force */ <nl> avctx -> pix_fmt = theora_pix_fmts [ get_bits ( gb , 2 )]; <nl> + if ( avctx -> pix_fmt == AV_PIX_FMT_NONE ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Invalid pixel format \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> skip_bits ( gb , 3 ); /* reserved */ <nl> } <nl>  <nl> static av_cold int theora_decode_init ( AVCodecContext * avctx ) <nl> switch ( ptype ) <nl> { <nl> case 0x80 : <nl> - theora_decode_header ( avctx , & gb ); <nl> + if ( theora_decode_header ( avctx , & gb ) < 0 ) <nl> + return - 1 ; <nl> break ; <nl> case 0x81 : <nl> // FIXME : is this needed ? it breaks sometimes
static av_always_inline void add_yblock ( SnowContext * s , int sliced , slice_buffer <nl> if (! sliced && ! offset_dst ) <nl> dst -= src_x ; <nl> src_x = 0 ; <nl> - } else if ( src_x + b_w > w ){ <nl> + } <nl> + if ( src_x + b_w > w ){ <nl> b_w = w - src_x ; <nl> } <nl> if ( src_y < 0 ){ <nl> static av_always_inline void add_yblock ( SnowContext * s , int sliced , slice_buffer <nl> if (! sliced && ! offset_dst ) <nl> dst -= src_y * dst_stride ; <nl> src_y = 0 ; <nl> - } else if ( src_y + b_h > h ){ <nl> + } <nl> + if ( src_y + b_h > h ){ <nl> b_h = h - src_y ; <nl> } <nl> 
static int asf_read_unknown ( AVFormatContext * s , const GUIDParseTable * g ) <nl> if (( ret = detect_unknown_subobject ( s , asf -> unknown_offset , <nl> asf -> unknown_size )) < 0 ) <nl> return ret ; <nl> - } else <nl> + } else { <nl> + if ( size < 24 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Too small size %" PRIu64 " (< 24 ).\ n ", size ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> avio_skip ( pb , size - 24 ); <nl> + } <nl>  <nl> return 0 ; <nl> }
static int encode_apng ( AVCodecContext * avctx , AVPacket * pkt , <nl> return AVERROR ( ENOMEM ); <nl>  <nl> if ( avctx -> frame_number == 0 ) { <nl> + if (! pict ) <nl> + return AVERROR ( EINVAL ); <nl> + <nl> s -> bytestream = avctx -> extradata = av_malloc ( FF_MIN_BUFFER_SIZE ); <nl> if (! avctx -> extradata ) <nl> return AVERROR ( ENOMEM );
void avfilter_register ( AVFilter * filter ) <nl> filters = newfilt ; <nl> } <nl>  <nl> - void avfilter_init ( void ) <nl> -{ <nl> - avfilter_register_all (); <nl> -} <nl> - <nl> void avfilter_uninit ( void ) <nl> { <nl> struct FilterList * tmp ;
static void release_delayed_buffers ( PerThreadContext * p ) <nl> FrameThreadContext * fctx = p -> parent ; <nl>  <nl> while ( p -> num_released_buffers > 0 ) { <nl> - AVFrame * f = & p -> released_buffers [-- p -> num_released_buffers ]; <nl> + AVFrame * f ; <nl>  <nl> pthread_mutex_lock (& fctx -> buffer_mutex ); <nl> + f = & p -> released_buffers [-- p -> num_released_buffers ]; <nl> free_progress ( f ); <nl> f -> thread_opaque = NULL ; <nl>  <nl> int ff_thread_get_buffer ( AVCodecContext * avctx , AVFrame * f ) <nl> void ff_thread_release_buffer ( AVCodecContext * avctx , AVFrame * f ) <nl> { <nl> PerThreadContext * p = avctx -> thread_opaque ; <nl> + FrameThreadContext * fctx ; <nl>  <nl> if (!( avctx -> active_thread_type & FF_THREAD_FRAME )) { <nl> avctx -> release_buffer ( avctx , f ); <nl> void ff_thread_release_buffer ( AVCodecContext * avctx , AVFrame * f ) <nl> av_log ( avctx , AV_LOG_DEBUG , " thread_release_buffer called on pic % p , % d buffers used \ n ", <nl> f , f -> owner -> internal_buffer_count ); <nl>  <nl> + fctx = p -> parent ; <nl> + pthread_mutex_lock (& fctx -> buffer_mutex ); <nl> p -> released_buffers [ p -> num_released_buffers ++] = * f ; <nl> + pthread_mutex_unlock (& fctx -> buffer_mutex ); <nl> memset ( f -> data , 0 , sizeof ( f -> data )); <nl> } <nl> 
static int read_code_table ( CLLCContext * ctx , GetBitContext * gb , VLC * vlc ) <nl>  <nl> count ++; <nl> } <nl> + if ( prefix > ( 65535 - 256 )/ 2 ) { <nl> + vlc -> table = NULL ; <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl>  <nl> prefix <<= 1 ; <nl> }
int main ( int argc , char ** argv ) <nl> printf (" Demuxing audio from file '% s ' into '% s '\ n ", src_filename , audio_dst_filename ); <nl>  <nl> /* read frames from the file */ <nl> - while ( av_read_frame ( fmt_ctx , & pkt ) >= 0 ) <nl> + while ( av_read_frame ( fmt_ctx , & pkt ) >= 0 ) { <nl> decode_packet (& got_frame , 0 ); <nl> + av_free_packet (& pkt ); <nl> + } <nl>  <nl> /* flush cached frames */ <nl> pkt . data = NULL ;
static int scale_vector ( int16_t * dst , const int16_t * vector , int length ) <nl> for ( i = 0 ; i < length ; i ++) <nl> max |= FFABS ( vector [ i ]); <nl>  <nl> - max = FFMIN ( max , 0x7FFF ); <nl> bits = normalize_bits ( max , 15 ); <nl>  <nl> if ( bits == 15 )
static int packed_16bpc_bswap ( SwsContext * c , const uint8_t * src [], <nl> int dststr = dstStride [ 0 ] >> 1 ; <nl> uint16_t * dstPtr = ( uint16_t *) dst [ 0 ]; <nl> const uint16_t * srcPtr = ( const uint16_t *) src [ 0 ]; <nl> + int min_stride = FFMIN ( srcstr , dststr ); <nl>  <nl> for ( i = 0 ; i < srcSliceH ; i ++) { <nl> - for ( j = 0 ; j < srcstr ; j ++) { <nl> + for ( j = 0 ; j < min_stride ; j ++) { <nl> dstPtr [ j ] = av_bswap16 ( srcPtr [ j ]); <nl> } <nl> srcPtr += srcstr ;
int ff_fill_line_with_color ( uint8_t * line [ 4 ], int pixel_step [ 4 ], int w , uint8_t <nl> dst_color [ rgba_map [ i ]] = rgba_color [ i ]; <nl>  <nl> line [ 0 ] = av_malloc_array ( w , pixel_step [ 0 ]); <nl> + if (! line [ 0 ]) <nl> + return AVERROR ( ENOMEM ); <nl> for ( i = 0 ; i < w ; i ++) <nl> memcpy ( line [ 0 ] + i * pixel_step [ 0 ], dst_color , pixel_step [ 0 ]); <nl> if ( rgba_map_ptr ) <nl> int ff_fill_line_with_color ( uint8_t * line [ 4 ], int pixel_step [ 4 ], int w , uint8_t <nl> pixel_step [ plane ] = 1 ; <nl> line_size = FF_CEIL_RSHIFT ( w , hsub1 ) * pixel_step [ plane ]; <nl> line [ plane ] = av_malloc ( line_size ); <nl> + if (! line [ plane ]) { <nl> + while ( plane && line [ plane - 1 ]) <nl> + av_freep (& line [-- plane ]); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> memset ( line [ plane ], dst_color [ plane ], line_size ); <nl> } <nl> }
static int mxf_read_header ( AVFormatContext * s ) <nl> } <nl> if ( res < 0 ) { <nl> av_log ( s , AV_LOG_ERROR , " error reading header metadata \ n "); <nl> - return res ; <nl> + ret = res ; <nl> + goto fail ; <nl> } <nl> break ; <nl> } else {
static int parse_adaptation_sets ( AVFormatContext * s ) <nl> if ( as -> streams == NULL ) <nl> return AVERROR ( ENOMEM ); <nl> as -> streams [ as -> nb_streams - 1 ] = to_integer ( p , q - p + 1 ); <nl> - if ( as -> streams [ as -> nb_streams - 1 ] < 0 ) return - 1 ; <nl> + if ( as -> streams [ as -> nb_streams - 1 ] < 0 || <nl> + as -> streams [ as -> nb_streams - 1 ] >= s -> nb_streams ) { <nl> + av_log ( s , AV_LOG_ERROR , " Invalid value for ' streams ' in adapation_sets .\ n "); <nl> + return AVERROR ( EINVAL ); <nl> + } <nl> if (* q == '\ 0 ') break ; <nl> if (* q == ' ') state = new_set ; <nl> p = ++ q ;
static int fourxm_read_packet ( AVFormatContext * s , <nl>  <nl> if ( ret < 0 ) { <nl> av_free_packet ( pkt ); <nl> - } else <nl> + } else { <nl> packet_read = 1 ; <nl> + av_shrink_packet ( pkt , ret + 8 ); <nl> + } <nl> break ; <nl>  <nl> case snd__TAG :
static void psy_3gpp_analyze_channel ( FFPsyContext * ctx , int channel , <nl>  <nl> band -> thr_quiet = band -> thr = FFMAX ( band -> thr , coeffs [ g ]. ath ); <nl> // 5 . 4 . 2 . 5 " Pre - echo control " <nl> - if (!( wi -> window_type [ 0 ] == LONG_STOP_SEQUENCE || ( wi -> window_type [ 1 ] == LONG_START_SEQUENCE && ! w ))) <nl> + if (!( wi -> window_type [ 0 ] == LONG_STOP_SEQUENCE || (! w && wi -> window_type [ 1 ] == LONG_START_SEQUENCE ))) <nl> band -> thr = FFMAX ( PSY_3GPP_RPEMIN * band -> thr , FFMIN ( band -> thr , <nl> PSY_3GPP_RPELEV * pch -> prev_band [ w + g ]. thr_quiet )); <nl>  <nl> static FFPsyWindowInfo psy_lame_window ( FFPsyContext * ctx , const float * audio , <nl> for ( i = 0 ; i < 8 ; i += wi . grouping [ i ]) { <nl> int w ; <nl> float clipping = 0 . 0f ; <nl> - for ( w = 0 ; w < wi . grouping [ i ] && ! clipping ; w ++) <nl> + for ( w = 0 ; w < wi . grouping [ i ]; w ++) <nl> clipping = FFMAX ( clipping , clippings [ i + w ]); <nl> - wi . clipping [ i ] = clipping ; <nl> + for ( w = 0 ; w < wi . grouping [ i ]; w ++) <nl> + wi . clipping [ i + w ] = clipping ; <nl> } <nl> } <nl> 
int ff_hevc_decode_nal_pps ( GetBitContext * gb , AVCodecContext * avctx , <nl> int i , ret = 0 ; <nl> unsigned int pps_id = 0 ; <nl> ptrdiff_t nal_size ; <nl> + unsigned log2_parallel_merge_level_minus2 ; <nl>  <nl> AVBufferRef * pps_buf ; <nl> HEVCPPS * pps = av_mallocz ( sizeof (* pps )); <nl> int ff_hevc_decode_nal_pps ( GetBitContext * gb , AVCodecContext * avctx , <nl> goto err ; <nl> } <nl> pps -> lists_modification_present_flag = get_bits1 ( gb ); <nl> - pps -> log2_parallel_merge_level = get_ue_golomb_long ( gb ) + 2 ; <nl> - if ( pps -> log2_parallel_merge_level > sps -> log2_ctb_size ) { <nl> + log2_parallel_merge_level_minus2 = get_ue_golomb_long ( gb ); <nl> + if ( log2_parallel_merge_level_minus2 > sps -> log2_ctb_size ) { <nl> av_log ( avctx , AV_LOG_ERROR , " log2_parallel_merge_level_minus2 out of range : % d \ n ", <nl> - pps -> log2_parallel_merge_level - 2 ); <nl> + log2_parallel_merge_level_minus2 ); <nl> ret = AVERROR_INVALIDDATA ; <nl> goto err ; <nl> } <nl> + pps -> log2_parallel_merge_level = log2_parallel_merge_level_minus2 + 2 ; <nl>  <nl> pps -> slice_header_extension_present_flag = get_bits1 ( gb ); <nl> 
static int set_segment_filename ( AVFormatContext * s ) <nl> SegmentContext * seg = s -> priv_data ; <nl> AVFormatContext * oc = seg -> avf ; <nl> size_t size ; <nl> + int ret ; <nl>  <nl> if ( seg -> segment_idx_wrap ) <nl> seg -> segment_idx %= seg -> segment_idx_wrap ; <nl> static int set_segment_filename ( AVFormatContext * s ) <nl> if ( seg -> entry_prefix ) <nl> size += strlen ( seg -> entry_prefix ); <nl>  <nl> - seg -> cur_entry . filename = av_mallocz ( size ); <nl> - if (! seg -> cur_entry . filename ) <nl> - return AVERROR ( ENOMEM ); <nl> + if (( ret = av_reallocp (& seg -> cur_entry . filename , size )) < 0 ) <nl> + return ret ; <nl> snprintf ( seg -> cur_entry . filename , size , "% s % s ", <nl> seg -> entry_prefix ? seg -> entry_prefix : "", <nl> av_basename ( oc -> filename ));
int ff_jni_init_jfields ( JNIEnv * env , void * jfields , const struct FFJniField * jfi <nl>  <nl> last_clazz = *( jclass *)(( uint8_t *) jfields + jfields_mapping [ i ]. offset ) = <nl> global ? (* env )-> NewGlobalRef ( env , clazz ) : clazz ; <nl> + <nl> + if ( global ) { <nl> + (* env )-> DeleteLocalRef ( env , clazz ); <nl> + } <nl> + <nl> } else { <nl>  <nl> if (! last_clazz ) {
int main ( void ){ <nl> AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( i ); <nl> if (! desc ) <nl> continue ; <nl> - av_log ( 0 , AV_LOG_INFO , " pix fmt % s % d \ n ", desc -> name , is_yuv_planar ( i )); <nl> + av_log ( 0 , AV_LOG_INFO , " pix fmt % s yuv_plan :% d avg_bpp :% d \ n ", desc -> name , is_yuv_planar ( i ), avg_bits_per_pixel ( i )); <nl> } <nl> return 0 ; <nl> }
static int hls_slice_header ( HEVCContext * s ) <nl> s -> HEVClc -> tu . cu_qp_offset_cb = 0 ; <nl> s -> HEVClc -> tu . cu_qp_offset_cr = 0 ; <nl>  <nl> - s -> no_rasl_output_flag = IS_IDR ( s ) || IS_BLA ( s ) || ( s -> nal_unit_type == HEVC_NAL_CRA_NUT && s -> last_eos ); <nl> - <nl> return 0 ; <nl> } <nl>  <nl> static int hevc_frame_start ( HEVCContext * s ) <nl> s -> is_decoded = 0 ; <nl> s -> first_nal_type = s -> nal_unit_type ; <nl>  <nl> + s -> no_rasl_output_flag = IS_IDR ( s ) || IS_BLA ( s ) || ( s -> nal_unit_type == HEVC_NAL_CRA_NUT && s -> last_eos ); <nl> + <nl> if ( s -> ps . pps -> tiles_enabled_flag ) <nl> lc -> end_of_tiles_x = s -> ps . pps -> column_width [ 0 ] << s -> ps . sps -> log2_ctb_size ; <nl> 
int attribute_align_arg avcodec_encode_audio ( AVCodecContext * avctx , <nl> const short * samples ) <nl> { <nl> AVPacket pkt ; <nl> - AVFrame frame0 ; <nl> + AVFrame frame0 = { 0 }; <nl> AVFrame * frame ; <nl> int ret , samples_size , got_packet ; <nl> 
static int get_qcd ( Jpeg2000DecoderContext * s , int n , Jpeg2000QuantStyle * q , <nl> Jpeg2000QuantStyle tmp ; <nl> int compno , ret ; <nl>  <nl> + memset (& tmp , 0 , sizeof ( tmp )); <nl> + <nl> if (( ret = get_qcx ( s , n , & tmp )) < 0 ) <nl> return ret ; <nl> for ( compno = 0 ; compno < s -> ncomponents ; compno ++)
static int url_open_dyn_buf_internal ( ByteIOContext ** s , int max_packet_size ) <nl> return - 1 ; <nl> d = av_mallocz ( sizeof ( DynBuffer ) + io_buffer_size ); <nl> if (! d ) <nl> - return - 1 ; <nl> + return AVERROR ( ENOMEM ); <nl> * s = av_mallocz ( sizeof ( ByteIOContext )); <nl> if (!* s ) { <nl> av_free ( d );
static int nsv_read_close ( AVFormatContext * s ) <nl>  <nl> av_freep (& nsv -> nsvs_file_offset ); <nl> av_freep (& nsv -> nsvs_timestamps ); <nl> + if ( nsv -> ahead [ 0 ]. data ) <nl> + av_free_packet (& nsv -> ahead [ 0 ]); <nl> + if ( nsv -> ahead [ 1 ]. data ) <nl> + av_free_packet (& nsv -> ahead [ 1 ]); <nl>  <nl> # if 0 <nl> 
int RENAME ( swri_resample )( ResampleContext * c , DELEM * dst , const DELEM * src , int <nl> break ; <nl> } else if ( sample_index < 0 ){ <nl> for ( i = 0 ; i < c -> filter_length ; i ++) <nl> - val += src [ FFABS ( sample_index + i )] * filter [ i ]; <nl> + val += src [ FFABS ( sample_index + i )] * ( FELEM2 ) filter [ i ]; <nl> } else if ( c -> linear ){ <nl> FELEM2 v2 = 0 ; <nl> for ( i = 0 ; i < c -> filter_length ; i ++){
pp_mode * pp_get_mode_by_name_and_quality ( const char * name , int quality ) <nl> } <nl>  <nl> ppMode = av_malloc ( sizeof ( PPMode )); <nl> + if (! ppMode ) <nl> + return NULL ; <nl>  <nl> ppMode -> lumMode = 0 ; <nl> ppMode -> chromMode = 0 ;
int av_probe_input_buffer2 ( AVIOContext * pb , AVInputFormat ** fmt , <nl> for ( probe_size = PROBE_BUF_MIN ; probe_size <= max_probe_size && !* fmt ; <nl> probe_size = FFMIN ( probe_size << 1 , FFMAX ( max_probe_size , probe_size + 1 ))) { <nl>  <nl> - if ( probe_size < offset ) { <nl> - continue ; <nl> - } <nl> score = probe_size < max_probe_size ? AVPROBE_SCORE_RETRY : 0 ; <nl>  <nl> /* read probe data */ <nl> int av_probe_input_buffer2 ( AVIOContext * pb , AVInputFormat ** fmt , <nl> ret = 0 ; /* error was end of file , nothing read */ <nl> } <nl> buf_offset += ret ; <nl> + if ( buf_offset < offset ) <nl> + continue ; <nl> pd . buf_size = buf_offset - offset ; <nl> pd . buf = & buf [ offset ]; <nl> 
static int cdxl_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> height = AV_RB16 (& cdxl -> header [ 16 ]); <nl> palette_size = AV_RB16 (& cdxl -> header [ 20 ]); <nl> audio_size = AV_RB16 (& cdxl -> header [ 22 ]); <nl> + if ( FFALIGN ( width , 16 ) * ( uint64_t ) height * cdxl -> header [ 19 ] > INT_MAX ) <nl> + return AVERROR_INVALIDDATA ; <nl> image_size = FFALIGN ( width , 16 ) * height * cdxl -> header [ 19 ] / 8 ; <nl> video_size = palette_size + image_size ; <nl> 
static int decode_residual ( H264Context * h , GetBitContext * gb , DCTELEM * block , in <nl> else { <nl> if ( max_coeff <= 8 ) { <nl> if ( max_coeff == 4 ) <nl> - zeros_left = get_vlc2 ( gb , ( chroma_dc_total_zeros_vlc - 1 )[ total_coeff ]. table , <nl> + zeros_left = get_vlc2 ( gb , chroma_dc_total_zeros_vlc [ total_coeff - 1 ]. table , <nl> CHROMA_DC_TOTAL_ZEROS_VLC_BITS , 1 ); <nl> else <nl> - zeros_left = get_vlc2 ( gb , ( chroma422_dc_total_zeros_vlc - 1 )[ total_coeff ]. table , <nl> + zeros_left = get_vlc2 ( gb , chroma422_dc_total_zeros_vlc [ total_coeff - 1 ]. table , <nl> CHROMA422_DC_TOTAL_ZEROS_VLC_BITS , 1 ); <nl> } else { <nl> - zeros_left = get_vlc2 ( gb , ( total_zeros_vlc - 1 )[ total_coeff ]. table , TOTAL_ZEROS_VLC_BITS , 1 ); <nl> + zeros_left = get_vlc2 ( gb , total_zeros_vlc [ total_coeff - 1 ]. table , TOTAL_ZEROS_VLC_BITS , 1 ); <nl> } <nl> } <nl>  <nl> static int decode_residual ( H264Context * h , GetBitContext * gb , DCTELEM * block , in <nl> (( type *) block )[* scantable ] = level [ 0 ]; \ <nl> for ( i = 1 ; i < total_coeff && zeros_left > 0 ; i ++) { \ <nl> if ( zeros_left < 7 ) \ <nl> - run_before = get_vlc2 ( gb , ( run_vlc - 1 )[ zeros_left ]. table , RUN_VLC_BITS , 1 ); \ <nl> + run_before = get_vlc2 ( gb , run_vlc [ zeros_left - 1 ]. table , RUN_VLC_BITS , 1 ); \ <nl> else \ <nl> run_before = get_vlc2 ( gb , run7_vlc . table , RUN7_VLC_BITS , 2 ); \ <nl> zeros_left -= run_before ; \ <nl> static int decode_residual ( H264Context * h , GetBitContext * gb , DCTELEM * block , in <nl> (( type *) block )[* scantable ] = (( int )( level [ 0 ] * qmul [* scantable ] + 32 ))>> 6 ; \ <nl> for ( i = 1 ; i < total_coeff && zeros_left > 0 ; i ++) { \ <nl> if ( zeros_left < 7 ) \ <nl> - run_before = get_vlc2 ( gb , ( run_vlc - 1 )[ zeros_left ]. table , RUN_VLC_BITS , 1 ); \ <nl> + run_before = get_vlc2 ( gb , run_vlc [ zeros_left - 1 ]. table , RUN_VLC_BITS , 1 ); \ <nl> else \ <nl> run_before = get_vlc2 ( gb , run7_vlc . table , RUN7_VLC_BITS , 2 ); \ <nl> zeros_left -= run_before ; \
static void add_audio_stream ( OutputStream * ost , AVFormatContext * oc , <nl> c -> channels = 2 ; <nl> c -> channel_layout = AV_CH_LAYOUT_STEREO ; <nl>  <nl> + ost -> st -> time_base = ( AVRational ){ 1 , c -> sample_rate }; <nl> + <nl> // some formats want stream headers to be separate <nl> if ( oc -> oformat -> flags & AVFMT_GLOBALHEADER ) <nl> c -> flags |= CODEC_FLAG_GLOBAL_HEADER ; <nl> static void add_video_stream ( OutputStream * ost , AVFormatContext * oc , <nl> * of which frame timestamps are represented . For fixed - fps content , <nl> * timebase should be 1 / framerate and timestamp increments should be <nl> * identical to 1 . */ <nl> - c -> time_base . den = STREAM_FRAME_RATE ; <nl> - c -> time_base . num = 1 ; <nl> + ost -> st -> time_base = ( AVRational ){ 1 , STREAM_FRAME_RATE }; <nl> + c -> time_base = ost -> st -> time_base ; <nl> + <nl> c -> gop_size = 12 ; /* emit one intra frame every twelve frames at most */ <nl> c -> pix_fmt = STREAM_PIX_FMT ; <nl> if ( c -> codec_id == AV_CODEC_ID_MPEG2VIDEO ) {
void intra_predict ( VP8Context * s , uint8_t * dst [ 3 ], VP8Macroblock * mb , <nl> int mb_x , int mb_y ) <nl> { <nl> AVCodecContext * avctx = s -> avctx ; <nl> - int x , y , mode , nnz , tr ; <nl> + int x , y , mode , nnz ; <nl> + uint32_t tr ; <nl>  <nl> // for the first row , we need to run xchg_mb_border to init the top edge to 127 <nl> // otherwise , skip it if we aren ' t going to deblock <nl> void intra_predict ( VP8Context * s , uint8_t * dst [ 3 ], VP8Macroblock * mb , <nl> // from the top macroblock <nl> if (!(! mb_y && avctx -> flags & CODEC_FLAG_EMU_EDGE ) && <nl> mb_x == s -> mb_width - 1 ) { <nl> - tr = tr_right [- 1 ]* 0x01010101 ; <nl> + tr = tr_right [- 1 ]* 0x01010101u ; <nl> tr_right = ( uint8_t *)& tr ; <nl> } <nl> 
static int aiff_read_header ( AVFormatContext * s , <nl> break ; <nl>  <nl> case MKTAG (' S ', ' S ', ' N ', ' D '): /* Sampled sound chunk */ <nl> - get_be32 ( pb ); /* Block align ... don ' t care */ <nl> offset = get_be32 ( pb ); /* Offset of sound data */ <nl> offset += url_ftell ( pb ); /* Compute absolute data offset */ <nl> + get_be32 ( pb ); /* Block align ... don ' t care */ <nl> if ( st -> codec -> codec_id ) /* Assume COMM already parsed */ <nl> goto got_sound ; <nl> if ( url_is_streamed ( pb )) {
static int find_and_decode_index ( NUTContext * nut ) <nl> has_keyframe [ n ++] = flag ; <nl> has_keyframe [ n ++] = ! flag ; <nl> } else { <nl> + if ( x <= 1 ) { <nl> + av_log ( s , AV_LOG_ERROR , " index : x %" PRIu64 " is invalid \ n ", x ); <nl> + goto fail ; <nl> + } <nl> while ( x != 1 ) { <nl> if ( n >= syncpoint_count + 1 ) { <nl> av_log ( s , AV_LOG_ERROR , " index overflow B \ n ");
static int msf_read_header ( AVFormatContext * s ) <nl> st -> codec -> codec_type = AVMEDIA_TYPE_AUDIO ; <nl> codec = avio_rb32 ( s -> pb ); <nl> st -> codec -> channels = avio_rb32 ( s -> pb ); <nl> - if ( st -> codec -> channels <= 0 ) <nl> + if ( st -> codec -> channels <= 0 || st -> codec -> channels >= INT_MAX / 1024 ) <nl> return AVERROR_INVALIDDATA ; <nl> size = avio_rb32 ( s -> pb ); <nl> st -> codec -> sample_rate = avio_rb32 ( s -> pb );
int ff_dca_lbr_parse ( DCALbrDecoder * s , uint8_t * data , DCAExssAsset * asset ) <nl> LBRChunk hr_grid [ DCA_LBR_CHANNELS / 2 ]; <nl> LBRChunk ts1 [ DCA_LBR_CHANNELS / 2 ]; <nl> LBRChunk ts2 [ DCA_LBR_CHANNELS / 2 ]; <nl> - } chunk = { 0 }; <nl> + } chunk = { { 0 } }; <nl>  <nl> GetByteContext gb ; <nl> 
static int mpeg_mux_init ( AVFormatContext * ctx ) <nl> if (! s -> mux_rate ) { <nl> /* we increase slightly the bitrate to take into account the <nl> headers . XXX : compute it exactly */ <nl> - bitrate += bitrate * 5 / 100 ; <nl> + bitrate += bitrate / 20 ; <nl> bitrate += 10000 ; <nl> s -> mux_rate = ( bitrate + ( 8 * 50 ) - 1 ) / ( 8 * 50 ); <nl> }
static int matroska_read_header ( AVFormatContext * s ) <nl> && ( track -> codec_priv . data != NULL )) { <nl> fourcc = AV_RL32 ( track -> codec_priv . data ); <nl> codec_id = ff_codec_get_id ( ff_codec_movvideo_tags , fourcc ); <nl> - } else if ( codec_id == AV_CODEC_ID_ALAC && track -> codec_priv . size && track -> codec_priv . size < INT_MAX - 12 ) { <nl> + } else if ( codec_id == AV_CODEC_ID_ALAC && track -> codec_priv . size && track -> codec_priv . size < INT_MAX - 12 - FF_INPUT_BUFFER_PADDING_SIZE ) { <nl> /* Only ALAC ' s magic cookie is stored in Matroska ' s track headers . <nl> Create the " atom size ", " tag ", and " tag version " fields the <nl> decoder expects manually . */
static void mpeg_decode_picture_coding_extension ( Mpeg1Context * s1 ) <nl> av_log ( s -> avctx , AV_LOG_WARNING , " invalid frame_pred_frame_dct \ n "); <nl>  <nl> if ( s -> picture_structure == PICT_FRAME ) { <nl> - s -> first_field = 0 ; <nl> s -> v_edge_pos = 16 * s -> mb_height ; <nl> } else { <nl> - s -> first_field ^= 1 ; <nl> s -> v_edge_pos = 8 * s -> mb_height ; <nl> memset ( s -> mbskip_table , 0 , s -> mb_stride * s -> mb_height ); <nl> } <nl> static int mpeg_field_start ( MpegEncContext * s , const uint8_t * buf , int buf_size ) <nl> Mpeg1Context * s1 = ( Mpeg1Context *) s ; <nl> int ret ; <nl>  <nl> + if ( s -> picture_structure == PICT_FRAME ) <nl> + s -> first_field = 0 ; <nl> + else <nl> + s -> first_field ^= 1 ; <nl> + <nl> /* start frame decoding */ <nl> if ( s -> first_field || s -> picture_structure == PICT_FRAME ) { <nl> AVFrameSideData * pan_scan ;
resync : <nl> } <nl> ast -> frame_offset += get_duration ( ast , pkt -> size ); <nl> } <nl> - ast -> remaining -= size ; <nl> + ast -> remaining -= err ; <nl> if (! ast -> remaining ){ <nl> avi -> stream_index = - 1 ; <nl> ast -> packet_size = 0 ;
static int get_siz ( Jpeg2000DecoderContext * s ) <nl> s -> sgnd [ i ] = !!( x & 0x80 ); <nl> s -> cdx [ i ] = bytestream2_get_byteu (& s -> g ); <nl> s -> cdy [ i ] = bytestream2_get_byteu (& s -> g ); <nl> - if (! s -> cdx [ i ] || ! s -> cdy [ i ]) { <nl> + if ( ! s -> cdx [ i ] || s -> cdx [ i ] == 3 || s -> cdx [ i ] > 4 <nl> + || ! s -> cdy [ i ] || s -> cdy [ i ] == 3 || s -> cdy [ i ] > 4 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " Invalid sample seperation \ n "); <nl> return AVERROR_INVALIDDATA ; <nl> }
void av_packet_free ( AVPacket ** pkt ) <nl> static int packet_alloc ( AVBufferRef ** buf , int size ) <nl> { <nl> int ret ; <nl> - if (( unsigned ) size >= ( unsigned ) size + AV_INPUT_BUFFER_PADDING_SIZE ) <nl> + if ( size < 0 || size >= INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE ) <nl> return AVERROR ( EINVAL ); <nl>  <nl> ret = av_buffer_realloc ( buf , size + AV_INPUT_BUFFER_PADDING_SIZE );
static inline void s_zero ( int cur_diff , struct G722Band * band ) <nl> ACCUM ( 3 , band -> diff_mem [ 2 ], 1 ); <nl> ACCUM ( 2 , band -> diff_mem [ 1 ], 1 ); <nl> ACCUM ( 1 , band -> diff_mem [ 0 ], 1 ); <nl> - ACCUM ( 0 , cur_diff << 1 , 1 ); <nl> + ACCUM ( 0 , cur_diff * 2 , 1 ); <nl> } else { <nl> ACCUM ( 5 , band -> diff_mem [ 4 ], 0 ); <nl> ACCUM ( 4 , band -> diff_mem [ 3 ], 0 ); <nl> ACCUM ( 3 , band -> diff_mem [ 2 ], 0 ); <nl> ACCUM ( 2 , band -> diff_mem [ 1 ], 0 ); <nl> ACCUM ( 1 , band -> diff_mem [ 0 ], 0 ); <nl> - ACCUM ( 0 , cur_diff << 1 , 0 ); <nl> + ACCUM ( 0 , cur_diff * 2 , 0 ); <nl> } <nl> # undef ACCUM <nl> band -> s_zero = s_zero ; <nl> static void do_adaptive_prediction ( struct G722Band * band , const int cur_diff ) <nl> band -> part_reconst_mem [ 0 ] = cur_part_reconst ; <nl>  <nl> band -> pole_mem [ 1 ] = av_clip (( sg [ 0 ] * av_clip ( band -> pole_mem [ 0 ], - 8191 , 8191 ) >> 5 ) + <nl> - ( sg [ 1 ] << 7 ) + ( band -> pole_mem [ 1 ] * 127 >> 7 ), - 12288 , 12288 ); <nl> + ( sg [ 1 ] * 128 ) + ( band -> pole_mem [ 1 ] * 127 >> 7 ), - 12288 , 12288 ); <nl>  <nl> limit = 15360 - band -> pole_mem [ 1 ]; <nl> band -> pole_mem [ 0 ] = av_clip (- 192 * sg [ 0 ] + ( band -> pole_mem [ 0 ] * 255 >> 8 ), - limit , limit ); <nl>  <nl> s_zero ( cur_diff , band ); <nl>  <nl> - cur_qtzd_reconst = av_clip_int16 (( band -> s_predictor + cur_diff ) << 1 ); <nl> + cur_qtzd_reconst = av_clip_int16 (( band -> s_predictor + cur_diff ) * 2 ); <nl> band -> s_predictor = av_clip_int16 ( band -> s_zero + <nl> ( band -> pole_mem [ 0 ] * cur_qtzd_reconst >> 15 ) + <nl> ( band -> pole_mem [ 1 ] * band -> prev_qtzd_reconst >> 15 ));
static int xwma_read_header ( AVFormatContext * s ) <nl>  <nl> /* Estimate the duration from the total number of output bytes . */ <nl> const uint64_t total_decoded_bytes = dpds_table [ dpds_table_size - 1 ]; <nl> + <nl> + if (! bytes_per_sample ) { <nl> + av_log ( s , AV_LOG_ERROR , " bytes_per_sample is 0 \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> st -> duration = total_decoded_bytes / bytes_per_sample ; <nl>  <nl> /* Use the dpds data to build a seek table . We can only do this after
static int decode_dvd_subtitles ( DVDSubContext * ctx , AVSubtitle * sub_header , <nl> w = x2 - x1 + 1 ; <nl> if ( w < 0 ) <nl> w = 0 ; <nl> - h = y2 - y1 ; <nl> + h = y2 - y1 + 1 ; <nl> if ( h < 0 ) <nl> h = 0 ; <nl> if ( w > 0 && h > 0 ) {
static int huf_uncompress ( GetByteContext * gb , <nl>  <nl> fail : <nl> for ( i = 0 ; i < HUF_DECSIZE ; i ++) { <nl> - if ( hdec [ i ]. p ) <nl> + if ( hdec ) <nl> av_freep (& hdec [ i ]. p ); <nl> } <nl> 
void ff_check_pixfmt_descriptors ( void ){ <nl> } else { <nl> av_assert0 ( 8 *( c -> step_minus1 + 1 ) >= c -> depth_minus1 + 1 ); <nl> } <nl> - av_read_image_line ( tmp , ( void *) data , linesize , d , 0 , 0 , j , 2 , 0 ); <nl> if (! strncmp ( d -> name , " bayer_ ", 6 )) <nl> continue ; <nl> + av_read_image_line ( tmp , ( void *) data , linesize , d , 0 , 0 , j , 2 , 0 ); <nl> av_assert0 ( tmp [ 0 ] == 0 && tmp [ 1 ] == 0 ); <nl> tmp [ 0 ] = tmp [ 1 ] = ( 1 <<( c -> depth_minus1 + 1 )) - 1 ; <nl> av_write_image_line ( tmp , data , linesize , d , 0 , 0 , j , 2 );
static av_cold int xcbgrab_read_header ( AVFormatContext * s ) <nl>  <nl> c -> conn = xcb_connect ( host , & screen_num ); <nl>  <nl> - if ( opts ) <nl> - av_free ( host ); <nl> - <nl> if (( ret = xcb_connection_has_error ( c -> conn ))) { <nl> av_log ( s , AV_LOG_ERROR , " Cannot open display % s , error % d .\ n ", <nl> s -> filename [ 0 ] ? host : " default ", ret ); <nl> + if ( opts ) <nl> + av_freep (& host ); <nl> return AVERROR ( EIO ); <nl> } <nl> + <nl> + if ( opts ) <nl> + av_freep (& host ); <nl> + <nl> setup = xcb_get_setup ( c -> conn ); <nl>  <nl> c -> screen = get_screen ( setup , screen_num );
static void test2_fill_picture ( AVFilterContext * ctx , AVFrame * frame ) <nl> uint8_t alpha [ 256 ]; <nl>  <nl> r = s -> pts ; <nl> - for ( y = ymin ; y < ymax - 15 ; y += 16 ) { <nl> - for ( x = xmin ; x < xmax - 15 ; x += 16 ) { <nl> + for ( y = ymin ; y + 15 < ymax ; y += 16 ) { <nl> + for ( x = xmin ; x + 15 < xmax ; x += 16 ) { <nl> if (( x ^ y ) & 16 ) <nl> continue ; <nl> for ( i = 0 ; i < 256 ; i ++) {
static void fix_coding_method_array ( int sb , int channels , sb_int8_array coding_ <nl> run = 1 ; <nl> case_val = 8 ; <nl> } else { <nl> - switch ( switchtable [ coding_method [ ch ][ sb ][ j ]]) { <nl> + switch ( switchtable [ coding_method [ ch ][ sb ][ j ]- 8 ]) { <nl> case 0 : run = 10 ; case_val = 10 ; break ; <nl> case 1 : run = 1 ; case_val = 16 ; break ; <nl> case 2 : run = 5 ; case_val = 24 ; break ;
static int parse_video_var ( AVFormatContext * avctx , AVStream * st , const char * nam <nl> } <nl> av_free ( str ); <nl> } else if (! strcmp ( name , " FPS ")) { <nl> - st -> time_base = av_inv_q ( var_read_float ( pb , size )); <nl> + AVRational tb = av_inv_q ( var_read_float ( pb , size )); <nl> + avpriv_set_pts_info ( st , 64 , tb . num , tb . den ); <nl> } else if (! strcmp ( name , " HEIGHT ")) { <nl> st -> codec -> height = var_read_int ( pb , size ); <nl> } else if (! strcmp ( name , " PIXEL_ASPECT ")) { <nl> static int mv_read_header ( AVFormatContext * avctx ) <nl> if (! vst ) <nl> return AVERROR ( ENOMEM ); <nl> vst -> codec -> codec_type = AVMEDIA_TYPE_VIDEO ; <nl> - vst -> time_base = ( AVRational ){ 1 , 15 }; <nl> + avpriv_set_pts_info ( vst , 64 , 1 , 15 ); <nl> vst -> nb_frames = avio_rb32 ( pb ); <nl> v = avio_rb32 ( pb ); <nl> switch ( v ) {
static int svq3_decode_frame ( AVCodecContext * avctx , void * data , <nl>  <nl> h -> cur_pic_ptr = s -> cur_pic ; <nl> av_frame_unref (& h -> cur_pic . f ); <nl> - h -> cur_pic = * s -> cur_pic ; <nl> + memcpy (& h -> cur_pic . tf , & s -> cur_pic -> tf , sizeof ( h -> cur_pic ) - offsetof ( H264Picture , tf )); <nl> ret = av_frame_ref (& h -> cur_pic . f , & s -> cur_pic -> f ); <nl> if ( ret < 0 ) <nl> return ret ;
static inline void mv_pred_direct ( AVSContext * h , cavs_vector * pmv_fw , <nl> cavs_vector * col_mv ) <nl> { <nl> cavs_vector * pmv_bw = pmv_fw + MV_BWD_OFFS ; <nl> - int den = h -> direct_den [ col_mv -> ref ]; <nl> + unsigned den = h -> direct_den [ col_mv -> ref ]; <nl> int m = FF_SIGNBIT ( col_mv -> x ); <nl>  <nl> pmv_fw -> dist = h -> dist [ 1 ];
static int asf_read_marker ( AVFormatContext * s , int64_t size ) <nl> count = avio_rl32 ( pb ); // markers count <nl> avio_rl16 ( pb ); // reserved 2 bytes <nl> name_len = avio_rl16 ( pb ); // name length <nl> - for ( i = 0 ; i < name_len ; i ++) <nl> - avio_r8 ( pb ); // skip the name <nl> + avio_skip ( pb , name_len ); <nl>  <nl> for ( i = 0 ; i < count ; i ++) { <nl> int64_t pres_time ; <nl> int name_len ; <nl>  <nl> + if ( avio_feof ( pb )) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> avio_rl64 ( pb ); // offset , 8 bytes <nl> pres_time = avio_rl64 ( pb ); // presentation time <nl> pres_time -= asf -> hdr . preroll * 10000 ;
static int read_var_block_data ( ALSDecContext * ctx , ALSBlockData * bd ) <nl> for ( k = 1 ; k < sub_blocks ; k ++) <nl> s [ k ] = s [ k - 1 ] + decode_rice ( gb , 0 ); <nl> } <nl> + for ( k = 1 ; k < sub_blocks ; k ++) <nl> + if ( s [ k ] < 0 || s [ k ] > 32 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " k invalid for rice code .\ n "); <nl> + return - 1 ; <nl> + } <nl>  <nl> if ( get_bits1 ( gb )) <nl> * bd -> shift_lsbs = get_bits ( gb , 4 ) + 1 ;
static int encode_picture ( MpegEncContext * s , int picture_number ) <nl> /* Estimate motion for every MB */ <nl> if ( s -> pict_type != I_TYPE ){ <nl> s -> lambda = ( s -> lambda * s -> avctx -> me_penalty_compensation + 128 )>> 8 ; <nl> - s -> lambda2 = ( s -> lambda2 * s -> avctx -> me_penalty_compensation + 128 )>> 8 ; <nl> + s -> lambda2 = ( s -> lambda2 * ( int64_t ) s -> avctx -> me_penalty_compensation + 128 )>> 8 ; <nl> if ( s -> pict_type != B_TYPE && s -> avctx -> me_threshold == 0 ){ <nl> if (( s -> avctx -> pre_me && s -> last_non_b_pict_type == I_TYPE ) || s -> avctx -> pre_me == 2 ){ <nl> s -> avctx -> execute ( s -> avctx , pre_estimate_motion_thread , ( void **)&( s -> thread_context [ 0 ]), NULL , s -> avctx -> thread_count );
static int fdk_aac_decode_frame ( AVCodecContext * avctx , void * data , <nl> return AVERROR_INVALIDDATA ; <nl> } <nl>  <nl> - err = aacDecoder_DecodeFrame ( s -> handle , ( INT_PCM *) s -> decoder_buffer , s -> decoder_buffer_size , 0 ); <nl> + err = aacDecoder_DecodeFrame ( s -> handle , ( INT_PCM *) s -> decoder_buffer , s -> decoder_buffer_size / sizeof ( INT_PCM ), 0 ); <nl> if ( err == AAC_DEC_NOT_ENOUGH_BITS ) { <nl> ret = avpkt -> size - valid ; <nl> goto end ;
static int dv_extract_audio ( uint8_t * frame , uint8_t * ppcm [ 4 ], <nl> * channels 0 , 1 and odd 2 , 3 . */ <nl> ipcm = ( sys -> height == 720 && !( frame [ 1 ] & 0x0C )) ? 2 : 0 ; <nl>  <nl> + if ( ipcm + sys -> n_difchan > ( quant == 1 ? 2 : 4 )) { <nl> + av_log ( NULL , AV_LOG_ERROR , " too many dv pcm frames \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> /* for each DIF channel */ <nl> for ( chan = 0 ; chan < sys -> n_difchan ; chan ++) { <nl> av_assert0 ( ipcm < 4 );
static int decode_header ( EXRContext * s ) <nl> return AVERROR_PATCHWELCOME ; <nl> } <nl>  <nl> - if ( s -> channel_offsets [ channel_index ] == - 1 ){/* channel have not been previously assign */ <nl> - if ( channel_index >= 0 ) { <nl> + if ( channel_index >= 0 && s -> channel_offsets [ channel_index ] == - 1 ) { /* channel has not been previously assigned */ <nl> if ( s -> pixel_type != EXR_UNKNOWN && <nl> s -> pixel_type != current_pixel_type ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , <nl> static int decode_header ( EXRContext * s ) <nl> } <nl> s -> pixel_type = current_pixel_type ; <nl> s -> channel_offsets [ channel_index ] = s -> current_channel_offset ; <nl> - } <nl> } <nl>  <nl> s -> channels = av_realloc ( s -> channels ,
static int ape_tag_read_field ( AVFormatContext * s ) <nl> if (! value ) <nl> return AVERROR ( ENOMEM ); <nl> c = avio_read ( pb , value , size ); <nl> + if ( c < 0 ) <nl> + return c ; <nl> value [ c ] = 0 ; <nl> av_dict_set (& s -> metadata , key , value , AV_DICT_DONT_STRDUP_VAL ); <nl> }
static int read_header ( AVFormatContext * s ) <nl> } <nl>  <nl> if ( size > 0 ) { <nl> - if ( pos + size < pos ) <nl> + if ( pos > INT64_MAX - size ) <nl> return AVERROR_INVALIDDATA ; <nl> avio_skip ( pb , FFMAX ( 0 , pos + size - avio_tell ( pb ))); <nl> }
static av_cold int tta_decode_init ( AVCodecContext * avctx ) <nl> av_log ( s -> avctx , AV_LOG_DEBUG , " data_length : % d frame_length : % d last : % d total : % d \ n ", <nl> s -> data_length , s -> frame_length , s -> last_frame_length , s -> total_frames ); <nl>  <nl> + if ( s -> total_frames < 0 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> // FIXME : seek table <nl> if ( get_bits_left (& s -> gb ) < 32 * s -> total_frames + 32 ) <nl> av_log ( avctx , AV_LOG_WARNING , " Seek table missing or too small \ n "); <nl> else if ( avctx -> err_recognition & AV_EF_CRCCHECK ) { <nl> - if ( tta_check_crc ( s , avctx -> extradata + 22 , s -> total_frames * 4 )) <nl> + if ( avctx -> extradata_size < 26 + s -> total_frames * 4 || tta_check_crc ( s , avctx -> extradata + 22 , s -> total_frames * 4 )) <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> skip_bits_long (& s -> gb , 32 * s -> total_frames );
const uint8_t ff_zigzag248_direct [ 64 ] = { <nl> }; <nl>  <nl> /* not permutated inverse zigzag_direct + 1 for MMX quantizer */ <nl> - DECLARE_ALIGNED_8 ( uint16_t , inv_zigzag_direct16 )[ 64 ]; <nl> + DECLARE_ALIGNED_16 ( uint16_t , inv_zigzag_direct16 )[ 64 ]; <nl>  <nl> const uint8_t ff_alternate_horizontal_scan [ 64 ] = { <nl> 0 , 1 , 2 , 3 , 8 , 9 , 16 , 17 ,
static inline int wv_get_value_integer ( WavpackFrameContext * s , uint32_t * crc , in <nl> if ( s -> extra_bits ){ <nl> S <<= s -> extra_bits ; <nl>  <nl> - if ( s -> got_extra_bits ){ <nl> + if ( s -> got_extra_bits && get_bits_left (& s -> gb_extra_bits ) >= s -> extra_bits ){ <nl> S |= get_bits (& s -> gb_extra_bits , s -> extra_bits ); <nl> * crc = * crc * 9 + ( S & 0xffff ) * 3 + (( unsigned ) S >> 16 ); <nl> }
matroska_parse_block ( MatroskaDemuxContext * matroska , uint8_t * data , int size , <nl> av_free ( origdata ); <nl> return res ; <nl> } <nl> - if ( matroska -> tracks [ track ]-> stream_index < 0 ) <nl> + if ( matroska -> tracks [ track ]-> stream_index < 0 ) { <nl> + av_free ( origdata ); <nl> return res ; <nl> + } <nl> st = matroska -> ctx -> streams [ matroska -> tracks [ track ]-> stream_index ]; <nl> if ( st -> discard >= AVDISCARD_ALL ) { <nl> av_free ( origdata ); <nl> matroska_parse_block ( MatroskaDemuxContext * matroska , uint8_t * data , int size , <nl> is_keyframe = flags & 0x80 ? PKT_FLAG_KEY : 0 ; <nl>  <nl> if ( matroska -> skip_to_keyframe ) { <nl> - if (! is_keyframe || st != matroska -> skip_to_stream ) <nl> + if (! is_keyframe || st != matroska -> skip_to_stream ) { <nl> + av_free ( origdata ); <nl> return res ; <nl> + } <nl> matroska -> skip_to_keyframe = 0 ; <nl> } <nl> 
static int update_offset ( RTMPContext * rt , int size ) <nl> if ( rt -> flv_off < rt -> flv_size ) { <nl> // There is old unread data in the buffer , thus append at the end <nl> old_flv_size = rt -> flv_size ; <nl> - rt -> flv_size += size + 15 ; <nl> + rt -> flv_size += size ; <nl> } else { <nl> // All data has been read , write the new data at the start of the buffer <nl> old_flv_size = 0 ; <nl> - rt -> flv_size = size + 15 ; <nl> + rt -> flv_size = size ; <nl> rt -> flv_off = 0 ; <nl> } <nl>  <nl> static int append_flv_data ( RTMPContext * rt , RTMPPacket * pkt , int skip ) <nl> const int size = pkt -> size - skip ; <nl> uint32_t ts = pkt -> timestamp ; <nl>  <nl> - old_flv_size = update_offset ( rt , size ); <nl> + old_flv_size = update_offset ( rt , size + 15 ); <nl>  <nl> if (( ret = av_reallocp (& rt -> flv_data , rt -> flv_size )) < 0 ) { <nl> rt -> flv_size = rt -> flv_off = 0 ; <nl> static int handle_metadata ( RTMPContext * rt , RTMPPacket * pkt ) <nl> next += size + 3 + 4 ; <nl> p += size + 3 + 4 ; <nl> } <nl> - memcpy ( p , next , RTMP_HEADER ); <nl>  <nl> return 0 ; <nl> }
static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * insamples ) <nl> if ( inlink == ctx -> inputs [ input_number ]) <nl> break ; <nl> av_assert1 ( input_number < am -> nb_inputs ); <nl> + if ( ff_bufqueue_is_full (& am -> in [ input_number ]. queue )) { <nl> + av_log ( ctx , AV_LOG_ERROR , " Buffer queue overflow \ n "); <nl> + avfilter_unref_buffer ( insamples ); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> ff_bufqueue_add ( ctx , & am -> in [ input_number ]. queue , insamples ); <nl> am -> in [ input_number ]. nb_samples += insamples -> audio -> nb_samples ; <nl> nb_samples = am -> in [ 0 ]. nb_samples ;
static int asf_read_frame_header ( AVFormatContext * s , AVIOContext * pb ){ <nl> av_dlog ( asf , " key :% d stream :% d seq :% d offset :% d replic_size :% d \ n ", <nl> asf -> packet_key_frame , asf -> stream_index , asf -> packet_seq , <nl> asf -> packet_frag_offset , asf -> packet_replic_size ); <nl> - if ( rsize + asf -> packet_replic_size > asf -> packet_size_left ) { <nl> + if ( rsize +( int64_t ) asf -> packet_replic_size > asf -> packet_size_left ) { <nl> av_log ( s , AV_LOG_ERROR , " packet_replic_size % d is invalid \ n ", asf -> packet_replic_size ); <nl> return AVERROR_INVALIDDATA ; <nl> }
static const OptionDef options [] = { <nl> # endif <nl> { " rdftspeed ", OPT_INT | HAS_ARG | OPT_AUDIO | OPT_EXPERT , {( void *)& rdftspeed }, " rdft speed ", " msecs " }, <nl> { " default ", OPT_FUNC2 | HAS_ARG | OPT_AUDIO | OPT_VIDEO | OPT_EXPERT , {( void *) opt_default }, " generic catch all option ", "" }, <nl> - { " i ", OPT_DUMMY , NULL , " ffmpeg compatibility dummy option ", ""}, <nl> + { " i ", OPT_DUMMY , { NULL }, " ffmpeg compatibility dummy option ", ""}, <nl> { NULL , }, <nl> }; <nl> 
int ff_img_read_packet ( AVFormatContext * s1 , AVPacket * pkt ) <nl> } <nl>  <nl> if ( codec -> codec_id == AV_CODEC_ID_NONE ) { <nl> - AVProbeData pd ; <nl> + AVProbeData pd = { 0 }; <nl> AVInputFormat * ifmt ; <nl> uint8_t header [ PROBE_BUF_MIN + AVPROBE_PADDING_SIZE ]; <nl> int ret ;
static int decklink_write_video_packet ( AVFormatContext * avctx , AVPacket * pkt ) <nl> pthread_mutex_unlock (& ctx -> mutex ); <nl>  <nl> /* Schedule frame for playback . */ <nl> - hr = ctx -> dlo -> ScheduleVideoFrame (( struct IDeckLinkVideoFrame *) frame , <nl> + hr = ctx -> dlo -> ScheduleVideoFrame (( class IDeckLinkVideoFrame *) frame , <nl> pkt -> pts * ctx -> bmd_tb_num , <nl> ctx -> bmd_tb_num , ctx -> bmd_tb_den ); <nl> /* Pass ownership to DeckLink , or release on failure */
static int mxf_read_primer_pack ( MXFContext * mxf ) <nl>  <nl> static int mxf_add_metadata_set ( MXFContext * mxf , void * metadata_set ) <nl> { <nl> + if ( mxf -> metadata_sets_count + 1 >= UINT_MAX / sizeof (* mxf -> metadata_sets )) <nl> + return AVERROR ( ENOMEM ); <nl> mxf -> metadata_sets = av_realloc ( mxf -> metadata_sets , ( mxf -> metadata_sets_count + 1 ) * sizeof (* mxf -> metadata_sets )); <nl> if (! mxf -> metadata_sets ) <nl> return - 1 ;
static int http_connect ( URLContext * h , const char * path , const char * hoststr , <nl> if ( post ) { <nl> /* always use chunked encoding for upload data */ <nl> s -> chunksize = 0 ; <nl> + /* Pretend that it did work . We didn ' t read any header yet , since <nl> + * we ' ve still to send the POST data , but the code calling this <nl> + * function will check http_code after we return . */ <nl> + s -> http_code = 200 ; <nl> return 0 ; <nl> } <nl> 
static int adx_decode_header ( AVCodecContext * avctx , const uint8_t * buf , <nl> if ( bufsize < offset || memcmp ( buf + offset - 6 , "( c ) CRI ", 6 )) <nl> return AVERROR_INVALIDDATA ; <nl>  <nl> + /* check for encoding = 3 block_size = 18 , sample_size = 4 */ <nl> + if ( buf [ 4 ] != 3 || buf [ 5 ] != 18 || buf [ 6 ] != 4 ) { <nl> + av_log_ask_for_sample ( avctx , " unsupported ADX format \ n "); <nl> + return AVERROR_PATCHWELCOME ; <nl> + } <nl> + <nl> c -> channels = avctx -> channels = buf [ 7 ]; <nl> if ( avctx -> channels > 2 ) <nl> return AVERROR_INVALIDDATA ;
static void write_section_data ( MpegTSContext * ts , MpegTSFilter * tss1 , <nl> } else <nl> crc_valid = 2 ; <nl> } <nl> - if ( crc_valid ) <nl> + if ( crc_valid ) { <nl> tss -> section_cb ( tss1 , tss -> section_buf , tss -> section_h_size ); <nl> + if ( crc_valid != 1 ) <nl> + tss -> last_ver = - 1 ; <nl> + } <nl> } <nl> } <nl> 
# include " libavdevice / avdevice . h " <nl> # include " libavresample / avresample . h " <nl> # include " libswscale / swscale . h " <nl> +# include " libavutil / avassert . h " <nl> # include " libavutil / avstring . h " <nl> # include " libavutil / mathematics . h " <nl> # include " libavutil / parseutils . h " <nl> int check_stream_specifier ( AVFormatContext * s , AVStream * st , const char * spec ) <nl> case ' s ': type = AVMEDIA_TYPE_SUBTITLE ; break ; <nl> case ' d ': type = AVMEDIA_TYPE_DATA ; break ; <nl> case ' t ': type = AVMEDIA_TYPE_ATTACHMENT ; break ; <nl> + default : av_assert0 ( 0 ); <nl> } <nl> if ( type != st -> codec -> codec_type ) <nl> return 0 ;
static void search_for_quantizers_anmr ( AVCodecContext * avctx , AACEncContext * s , <nl> } <nl> while ( idx ) { <nl> sce -> sf_idx [ bandaddr [ idx ]] = minq + q0 ; <nl> - minq = paths [ idx ][ minq ]. prev ; <nl> + minq = FFMAX ( paths [ idx ][ minq ]. prev , 0 ); <nl> idx --; <nl> } <nl> // set the same quantizers inside window groups
static int wavpack_decode_block ( AVCodecContext * avctx , int block_no , <nl>  <nl> if ( wc -> ch_offset + s -> stereo >= avctx -> channels ) { <nl> av_log ( avctx , AV_LOG_WARNING , " Too many channels coded in a packet .\ n "); <nl> - return ( avctx -> err_recognition & AV_EF_EXPLODE ) ? AVERROR_INVALIDDATA : 0 ; <nl> + return (( avctx -> err_recognition & AV_EF_EXPLODE ) || ! wc -> ch_offset ) ? AVERROR_INVALIDDATA : 0 ; <nl> } <nl>  <nl> samples_l = frame -> extended_data [ wc -> ch_offset ];
typedef struct AVStream { <nl> * String containing pairs of key and values describing recommended encoder configuration . <nl> * Pairs are separated by ','. <nl> * Keys are separated from values by '='. <nl> + * <nl> + * @ deprecated unused <nl> */ <nl> attribute_deprecated <nl> char * recommended_encoder_configuration ; <nl> attribute_deprecated <nl> AVRational av_stream_get_r_frame_rate ( const AVStream * s ); <nl> attribute_deprecated <nl> void av_stream_set_r_frame_rate ( AVStream * s , AVRational r ); <nl> - attribute_deprecated <nl> # if FF_API_LAVF_FFSERVER <nl> + attribute_deprecated <nl> char * av_stream_get_recommended_encoder_configuration ( const AVStream * s ); <nl> attribute_deprecated <nl> void av_stream_set_recommended_encoder_configuration ( AVStream * s , char * configuration );
static int extract_header ( AVCodecContext * const avctx , <nl> s -> mask_buf = av_malloc (( s -> planesize * 32 ) + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> if (! s -> mask_buf ) <nl> return AVERROR ( ENOMEM ); <nl> + if ( s -> bpp > 16 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " bpp % d too large for palette \ n ", s -> bpp ); <nl> + av_freep (& s -> mask_buf ); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> s -> mask_palbuf = av_malloc (( 2 << s -> bpp ) * sizeof ( uint32_t ) + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> if (! s -> mask_palbuf ) { <nl> av_freep (& s -> mask_buf );
static int msnwc_tcp_read_packet ( AVFormatContext * ctx , AVPacket * pkt ) <nl> AVIOContext * pb = ctx -> pb ; <nl> uint16_t keyframe ; <nl> uint32_t size , timestamp ; <nl> + int ret ; <nl>  <nl> avio_skip ( pb , 1 ); /* one byte has been read ahead */ <nl> avio_skip ( pb , 2 ); <nl> static int msnwc_tcp_read_packet ( AVFormatContext * ctx , AVPacket * pkt ) <nl> avio_skip ( pb , 4 ); <nl> timestamp = avio_rl32 ( pb ); <nl>  <nl> - if (! size || av_get_packet ( pb , pkt , size ) != size ) <nl> - return - 1 ; <nl> + if (! size ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> + if (( ret = av_get_packet ( pb , pkt , size )) < 0 ) <nl> + return ret ; <nl>  <nl> avio_skip ( pb , 1 ); /* Read ahead one byte of struct size like read_header */ <nl> 
static AVStream * init_stream ( AVFormatContext * s ) <nl> avpriv_set_pts_info ( st , 60 , bin -> framerate . den , bin -> framerate . num ); <nl>  <nl> /* simulate tty display speed */ <nl> - bin -> chars_per_frame = FFMAX ( av_q2d ( st -> time_base ) * bin -> chars_per_frame , 1 ); <nl> + bin -> chars_per_frame = av_clip ( av_q2d ( st -> time_base ) * bin -> chars_per_frame , 1 , INT_MAX ); <nl>  <nl> return st ; <nl> }
int ff_get_qtpalette ( int codec_id , AVIOContext * pb , uint32_t * palette ) <nl>  <nl> /* If the depth is 1 , 2 , 4 , or 8 bpp , file is palettized . */ <nl> if (( bit_depth == 1 || bit_depth == 2 || bit_depth == 4 || bit_depth == 8 )) { <nl> - int color_count , color_start , color_end ; <nl> + uint32_t color_count , color_start , color_end ; <nl> uint32_t a , r , g , b ; <nl>  <nl> /* Ignore the greyscale bit for 1 - bit video and sample
static int http_prepare_data ( HTTPContext * c ) <nl> pkt . pts = av_rescale_q ( pkt . pts , <nl> c -> fmt_in -> streams [ source_index ]-> time_base , <nl> ctx -> streams [ pkt . stream_index ]-> time_base ); <nl> - if ( av_write_frame ( ctx , & pkt )) <nl> + if ( av_write_frame ( ctx , & pkt ) < 0 ) { <nl> + http_log (" Error writing frame to output \ n "); <nl> c -> state = HTTPSTATE_SEND_DATA_TRAILER ; <nl> + } <nl>  <nl> len = url_close_dyn_buf ( ctx -> pb , & c -> pb_buffer ); <nl> c -> cur_frame_bytes = len ;
 <nl> static int null_filter_samples ( AVFilterLink * link , AVFilterBufferRef * samplesref ) <nl> { <nl> + avfilter_unref_bufferp (& samplesref ); <nl> return 0 ; <nl> } <nl> 
static int mxf_read_primer_pack ( void * arg , AVIOContext * pb , int tag , int size , U <nl> av_log ( mxf -> fc , AV_LOG_ERROR , " item_num % d is too large \ n ", item_num ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> + if ( mxf -> local_tags ) <nl> + av_log ( mxf -> fc , AV_LOG_VERBOSE , " Multiple primer packs \ n "); <nl> + av_free ( mxf -> local_tags ); <nl> + mxf -> local_tags_count = 0 ; <nl> mxf -> local_tags = av_calloc ( item_num , item_len ); <nl> if (! mxf -> local_tags ) <nl> return AVERROR ( ENOMEM );
int ff_rtsp_send_cmd_with_content ( AVFormatContext * s , <nl> { <nl> RTSPState * rt = s -> priv_data ; <nl> HTTPAuthType cur_auth_type ; <nl> - int ret ; <nl> + int ret , attempts = 0 ; <nl>  <nl> retry : <nl> cur_auth_type = rt -> auth_state . auth_type ; <nl> retry : <nl>  <nl> if (( ret = ff_rtsp_read_reply ( s , reply , content_ptr , 0 , method ) ) < 0 ) <nl> return ret ; <nl> + attempts ++; <nl>  <nl> - if ( reply -> status_code == 401 && cur_auth_type == HTTP_AUTH_NONE && <nl> - rt -> auth_state . auth_type != HTTP_AUTH_NONE ) <nl> + if ( reply -> status_code == 401 && <nl> + ( cur_auth_type == HTTP_AUTH_NONE || rt -> auth_state . stale ) && <nl> + rt -> auth_state . auth_type != HTTP_AUTH_NONE && attempts < 2 ) <nl> goto retry ; <nl>  <nl> if ( reply -> status_code > 400 ){
static int old_codec47 ( SANMVideoContext * ctx , int top , <nl> if ( bytestream2_get_bytes_left (& ctx -> gb ) < width * height ) <nl> return AVERROR_INVALIDDATA ; <nl> for ( j = 0 ; j < height ; j ++) { <nl> - for ( i = 0 ; i < width ; i ++) <nl> - bytestream2_get_bufferu (& ctx -> gb , dst , width ); <nl> + bytestream2_get_bufferu (& ctx -> gb , dst , width ); <nl> dst += stride ; <nl> } <nl> break ;
static int ea_read_packet ( AVFormatContext * s , <nl> case AV_CODEC_ID_ADPCM_EA_R1 : <nl> case AV_CODEC_ID_ADPCM_EA_R2 : <nl> case AV_CODEC_ID_ADPCM_IMA_EA_EACS : <nl> - pkt -> duration = AV_RL32 ( pkt -> data ); <nl> + if ( pkt -> size >= 4 ) <nl> + pkt -> duration = AV_RL32 ( pkt -> data ); <nl> break ; <nl> case AV_CODEC_ID_ADPCM_EA_R3 : <nl> - pkt -> duration = AV_RB32 ( pkt -> data ); <nl> + if ( pkt -> size >= 4 ) <nl> + pkt -> duration = AV_RB32 ( pkt -> data ); <nl> break ; <nl> case AV_CODEC_ID_ADPCM_IMA_EA_SEAD : <nl> pkt -> duration = ret * 2 / ea -> num_channels ;
static int g2m_init_buffers ( G2MContext * c ) <nl> int aligned_height ; <nl>  <nl> if (! c -> framebuf || c -> old_width < c -> width || c -> old_height < c -> height ) { <nl> - c -> framebuf_stride = FFALIGN ( c -> width * 3 , 16 ); <nl> - aligned_height = FFALIGN ( c -> height , 16 ); <nl> + c -> framebuf_stride = FFALIGN ( c -> width + 15 , 16 ) * 3 ; <nl> + aligned_height = c -> height + 15 ; <nl> av_free ( c -> framebuf ); <nl> c -> framebuf = av_mallocz ( c -> framebuf_stride * aligned_height ); <nl> if (! c -> framebuf )
void ff_pred4x4_vertical_vp8_mmxext ( uint8_t * src , const uint8_t * topright , int s <nl> # if CONFIG_H264DSP <nl> void ff_h264_pred_init_x86 ( H264PredContext * h , int codec_id ) <nl> { <nl> + mm_flags = mm_support (); <nl> + <nl> # if HAVE_YASM <nl> if ( mm_flags & FF_MM_MMX ) { <nl> h -> pred16x16 [ VERT_PRED8x8 ] = ff_pred16x16_vertical_mmx ;
static int kempf_decode_tile ( G2MContext * c , int tile_x , int tile_y , <nl> src += 3 ; <nl> } <nl> npal = * src ++ + 1 ; <nl> + if ( src_end - src < npal * 3 ) <nl> + return AVERROR_INVALIDDATA ; <nl> memcpy ( pal , src , npal * 3 ); src += npal * 3 ; <nl> if ( sub_type != 2 ) { <nl> for ( i = 0 ; i < npal ; i ++) {
static av_always_inline int inv_recenter_nonneg ( int v , int m ) <nl> // differential forward probability updates <nl> static int update_prob ( VP56RangeCoder * c , int p ) <nl> { <nl> - static const int inv_map_table [ 254 ] = { <nl> + static const int inv_map_table [ 255 ] = { <nl> 7 , 20 , 33 , 46 , 59 , 72 , 85 , 98 , 111 , 124 , 137 , 150 , 163 , 176 , <nl> 189 , 202 , 215 , 228 , 241 , 254 , 1 , 2 , 3 , 4 , 5 , 6 , 8 , 9 , <nl> 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 21 , 22 , 23 , 24 , <nl> static int update_prob ( VP56RangeCoder * c , int p ) <nl> 207 , 208 , 209 , 210 , 211 , 212 , 213 , 214 , 216 , 217 , 218 , 219 , 220 , 221 , <nl> 222 , 223 , 224 , 225 , 226 , 227 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , <nl> 237 , 238 , 239 , 240 , 242 , 243 , 244 , 245 , 246 , 247 , 248 , 249 , 250 , 251 , <nl> - 252 , 253 , <nl> + 252 , 253 , 253 , <nl> }; <nl> int d ; <nl>  <nl> static int update_prob ( VP56RangeCoder * c , int p ) <nl> if ( d >= 65 ) <nl> d = ( d << 1 ) - 65 + vp8_rac_get ( c ); <nl> d += 64 ; <nl> + av_assert2 ( d < FF_ARRAY_ELEMS ( inv_map_table )); <nl> } <nl>  <nl> return p <= 128 ? 1 + inv_recenter_nonneg ( inv_map_table [ d ], p - 1 ) :
static void apply_channel_coupling ( AACContext * ac , ChannelElement * cc , <nl> /** <nl> * Convert spectral data to samples , applying all supported tools as appropriate . <nl> */ <nl> - static void spectral_to_sample ( AACContext * ac ) <nl> + static void spectral_to_sample ( AACContext * ac , int samples ) <nl> { <nl> int i , type ; <nl> void (* imdct_and_window )( AACContext * ac , SingleChannelElement * sce ); <nl> static void spectral_to_sample ( AACContext * ac ) <nl> { <nl> int j ; <nl> /* preparation for resampler */ <nl> - for ( j = 0 ; j < 2048 ; j ++){ <nl> + for ( j = 0 ; j < samples ; j ++){ <nl> che -> ch [ 0 ]. ret [ j ] = ( int32_t ) av_clipl_int32 (( int64_t ) che -> ch [ 0 ]. ret [ j ]<< 7 )+ 0x8000 ; <nl> che -> ch [ 1 ]. ret [ j ] = ( int32_t ) av_clipl_int32 (( int64_t ) che -> ch [ 1 ]. ret [ j ]<< 7 )+ 0x8000 ; <nl> } <nl> static int aac_decode_er_frame ( AVCodecContext * avctx , void * data , <nl> return err ; <nl> } <nl>  <nl> - spectral_to_sample ( ac ); <nl> + spectral_to_sample ( ac , samples ); <nl>  <nl> ac -> frame -> nb_samples = samples ; <nl> ac -> frame -> sample_rate = avctx -> sample_rate ; <nl> static int aac_decode_frame_int ( AVCodecContext * avctx , void * data , <nl> return 0 ; <nl> } <nl>  <nl> - spectral_to_sample ( ac ); <nl> - <nl> multiplier = ( ac -> oc [ 1 ]. m4ac . sbr == 1 ) ? ac -> oc [ 1 ]. m4ac . ext_sample_rate > ac -> oc [ 1 ]. m4ac . sample_rate : 0 ; <nl> samples <<= multiplier ; <nl>  <nl> + spectral_to_sample ( ac , samples ); <nl> + <nl> if ( ac -> oc [ 1 ]. status && audio_found ) { <nl> avctx -> sample_rate = ac -> oc [ 1 ]. m4ac . sample_rate << multiplier ; <nl> avctx -> frame_size = samples ;
static int mxf_write_header ( AVFormatContext * s ) <nl>  <nl> sc -> video_bit_rate = st -> codec -> bit_rate ? st -> codec -> bit_rate : st -> codec -> rc_max_rate ; <nl> if ( s -> oformat == & ff_mxf_d10_muxer ) { <nl> - if ( sc -> video_bit_rate == 50000000 ) { <nl> - if ( mxf -> time_base . den == 25 ) sc -> index = 3 ; <nl> - else sc -> index = 5 ; <nl> + if (( sc -> video_bit_rate == 50000000 ) && ( mxf -> time_base . den == 25 )) { <nl> + sc -> index = 3 ; <nl> + } else if (( sc -> video_bit_rate == 49999840 || sc -> video_bit_rate == 50000000 ) && ( mxf -> time_base . den != 25 )) { <nl> + sc -> index = 5 ; <nl> } else if ( sc -> video_bit_rate == 40000000 ) { <nl> if ( mxf -> time_base . den == 25 ) sc -> index = 7 ; <nl> else sc -> index = 9 ;
int av_write_header ( AVFormatContext * s ) <nl> char tagbuf [ 32 ]; <nl> av_get_codec_tag_string ( tagbuf , sizeof ( tagbuf ), st -> codec -> codec_tag ); <nl> av_log ( s , AV_LOG_ERROR , <nl> - " Tag % s / 0x % 08x incompatible with output codec '% s '\ n ", <nl> - tagbuf , st -> codec -> codec_tag , st -> codec -> codec -> name ); <nl> + " Tag % s / 0x % 08x incompatible with output codec id '% d '\ n ", <nl> + tagbuf , st -> codec -> codec_tag , st -> codec -> codec_id ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> } else
av_cold int avcodec_close ( AVCodecContext * avctx ) <nl> avctx -> codec -> close ( avctx ); <nl> avcodec_default_free_buffers ( avctx ); <nl> avctx -> coded_frame = NULL ; <nl> - if ( avctx -> codec -> priv_class ) <nl> + if ( avctx -> codec && avctx -> codec -> priv_class ) <nl> av_opt_free ( avctx -> priv_data ); <nl> av_opt_free ( avctx ); <nl> av_freep (& avctx -> priv_data );
static int probe_buf_write ( void * opaque , uint8_t * buf , int buf_size ) <nl> int main ( int argc , char ** argv ) <nl> { <nl> int ret ; <nl> - uint8_t * buffer = av_malloc ( AVP_BUFFSIZE ); <nl> + uint8_t * buffer = av_mallocz ( AVP_BUFFSIZE ); <nl>  <nl> if (! buffer ) <nl> exit ( 1 );
retry : <nl> StreamInfo * stream = st -> priv_data ; <nl> const int avail_data = av_fifo_size ( stream -> fifo ); <nl> const int space = stream -> max_buffer_size - stream -> buffer_index ; <nl> - int rel_space = 1024 * space / stream -> max_buffer_size ; <nl> + int rel_space = 1024LL * space / stream -> max_buffer_size ; <nl> PacketDesc * next_pkt = stream -> premux_packet ; <nl>  <nl> /* for subtitle , a single PES packet must be generated ,
static int crypto_open ( URLContext * h , const char * uri , int flags ) <nl>  <nl> return 0 ; <nl> err : <nl> - av_free ( c -> key ); <nl> - av_free ( c -> iv ); <nl> + av_freep ( c -> key ); <nl> + av_freep ( c -> iv ); <nl> return ret ; <nl> } <nl>  <nl> static int crypto_close ( URLContext * h ) <nl> if ( c -> hd ) <nl> ffurl_close ( c -> hd ); <nl> av_freep (& c -> aes ); <nl> - av_freep (& c -> key ); <nl> - av_freep (& c -> iv ); <nl> return 0 ; <nl> } <nl> 
static int rtp_write_packet ( AVFormatContext * s1 , AVPacket * pkt ) <nl> const uint8_t * mb_info = <nl> av_packet_get_side_data ( pkt , AV_PKT_DATA_H263_MB_INFO , <nl> & mb_info_size ); <nl> + if (! mb_info ) { <nl> + av_log ( s1 , AV_LOG_ERROR , " failed to allocate side data \ n "); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> ff_rtp_send_h263_rfc2190 ( s1 , pkt -> data , size , mb_info , mb_info_size ); <nl> break ; <nl> }
retry : <nl> es_size -= stream -> premux_packet -> unwritten_size ; <nl> stream -> premux_packet = stream -> premux_packet -> next ; <nl> } <nl> - if ( es_size ) <nl> + if ( stream -> premux_packet && es_size ) <nl> stream -> premux_packet -> unwritten_size -= es_size ; <nl>  <nl> if ( remove_decoded_packets ( ctx , s -> last_scr ) < 0 )
static int mp_decode_frame ( AVCodecContext * avctx , <nl> if ( sz == 0 ) <nl> goto end ; <nl>  <nl> + if ( mp -> max_codes_bits <= 0 ) <nl> + goto end ; <nl> if ( init_vlc (& mp -> vlc , mp -> max_codes_bits , mp -> codes_count , & mp -> codes [ 0 ]. size , sizeof ( HuffCode ), 1 , & mp -> codes [ 0 ]. code , sizeof ( HuffCode ), 4 , 0 )) <nl> goto end ; <nl> mp_decode_frame_helper ( mp , & gb );
void ff_ac3_bit_alloc_calc_mask ( AC3BitAllocParameters * s , int16_t * band_psd , <nl> if ( dba_mode == DBA_REUSE || dba_mode == DBA_NEW ) { <nl> int band , seg , delta ; <nl> band = 0 ; <nl> - for ( seg = 0 ; seg < dba_nsegs ; seg ++) { <nl> - band += dba_offsets [ seg ]; <nl> + for ( seg = 0 ; seg < FFMIN ( 8 , dba_nsegs ); seg ++) { <nl> + band = FFMIN ( 49 , band + dba_offsets [ seg ]); <nl> if ( dba_values [ seg ] >= 4 ) { <nl> delta = ( dba_values [ seg ] - 3 ) << 7 ; <nl> } else {
static int init_image ( TiffContext * s , AVFrame * frame ) <nl> { <nl> int ret ; <nl>  <nl> + // make sure there is no aliasing in the following switch <nl> + if ( s -> bpp >= 100 || s -> bppcount >= 10 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , <nl> + " Unsupported image parameters : bpp =% d , bppcount =% d \ n ", <nl> + s -> bpp , s -> bppcount ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> switch ( s -> planar * 1000 + s -> bpp * 10 + s -> bppcount ) { <nl> case 11 : <nl> s -> avctx -> pix_fmt = AV_PIX_FMT_MONOBLACK ;
static int decode_residual ( const H264Context * h , H264SliceContext * sl , <nl> for ( i = 1 ; i < total_coeff && zeros_left > 0 ; i ++) { \ <nl> if ( zeros_left < 7 ) \ <nl> run_before = get_vlc2 ( gb , run_vlc [ zeros_left - 1 ]. table , RUN_VLC_BITS , 1 ); \ <nl> - else \ <nl> + else {\ <nl> run_before = get_vlc2 ( gb , run7_vlc . table , RUN7_VLC_BITS , 2 ); \ <nl> + run_before = FFMIN ( zeros_left , run_before );\ <nl> + }\ <nl> zeros_left -= run_before ; \ <nl> scantable -= 1 + run_before ; \ <nl> (( type *) block )[* scantable ]= level [ i ]; \ <nl> static int decode_residual ( const H264Context * h , H264SliceContext * sl , <nl> for ( i = 1 ; i < total_coeff && zeros_left > 0 ; i ++) { \ <nl> if ( zeros_left < 7 ) \ <nl> run_before = get_vlc2 ( gb , run_vlc [ zeros_left - 1 ]. table , RUN_VLC_BITS , 1 ); \ <nl> - else \ <nl> + else {\ <nl> run_before = get_vlc2 ( gb , run7_vlc . table , RUN7_VLC_BITS , 2 ); \ <nl> + run_before = FFMIN ( zeros_left , run_before );\ <nl> + }\ <nl> zeros_left -= run_before ; \ <nl> scantable -= 1 + run_before ; \ <nl> (( type *) block )[* scantable ]= (( int )( level [ i ] * qmul [* scantable ] + 32 ))>> 6 ; \
AVCodec ff_mjpeg_encoder = { <nl> . type = AVMEDIA_TYPE_VIDEO , <nl> . id = AV_CODEC_ID_MJPEG , <nl> . priv_data_size = sizeof ( MpegEncContext ), <nl> - . priv_class = & mjpeg_class , <nl> . init = ff_mpv_encode_init , <nl> . encode2 = ff_mpv_encode_picture , <nl> . close = ff_mpv_encode_end ,
static void ict_int ( void * _src0 , void * _src1 , void * _src2 , int csize ) <nl> int i ; <nl>  <nl> for ( i = 0 ; i < csize ; i ++) { <nl> - i0 = * src0 + * src2 + ((( 26345 * * src2 ) + ( 1 << 15 )) >> 16 ); <nl> + i0 = * src0 + * src2 + (( int )(( 26345U * * src2 ) + ( 1 << 15 )) >> 16 ); <nl> i1 = * src0 - (( int )((( unsigned ) i_ict_params [ 1 ] * * src1 ) + ( 1 << 15 )) >> 16 ) <nl> - - ((( i_ict_params [ 2 ] * * src2 ) + ( 1 << 15 )) >> 16 ); <nl> + - (( int )((( unsigned ) i_ict_params [ 2 ] * * src2 ) + ( 1 << 15 )) >> 16 ); <nl> i2 = * src0 + ( 2 * * src1 ) + (( int )((- 14942U * * src1 ) + ( 1 << 15 )) >> 16 ); <nl> * src0 ++ = i0 ; <nl> * src1 ++ = i1 ;
void ff_h264_free_tables ( H264Context * h , int free_rbsp ) <nl> if ( free_rbsp && h -> DPB ) { <nl> for ( i = 0 ; i < H264_MAX_PICTURE_COUNT ; i ++) <nl> ff_h264_unref_picture ( h , & h -> DPB [ i ]); <nl> + memset ( h -> delayed_pic , 0 , sizeof ( h -> delayed_pic )); <nl> av_freep (& h -> DPB ); <nl> } else if ( h -> DPB ) { <nl> for ( i = 0 ; i < H264_MAX_PICTURE_COUNT ; i ++)
static av_cold int tgv_decode_init ( AVCodecContext * avctx ){ <nl> */ <nl> static int unpack ( const uint8_t * src , const uint8_t * src_end , unsigned char * dst , int width , int height ) { <nl> unsigned char * dst_end = dst + width * height ; <nl> - int size , size1 , size2 , offset , run ; <nl> + int size , size1 , size2 , av_uninit ( offset ), run ; <nl> unsigned char * dst_start = dst ; <nl>  <nl> if ( src [ 0 ] & 0x01 )
static int cinepak_decode ( CinepakContext * s ) <nl> * If the frame header is followed by the bytes FE 00 00 06 00 00 then <nl> * this is probably one of the two known files that have 6 extra bytes <nl> * after the frame header . Else , assume 2 extra bytes . */ <nl> - if (( s -> data [ 10 ] == 0xFE ) && <nl> + if ( s -> size >= 16 && <nl> + ( s -> data [ 10 ] == 0xFE ) && <nl> ( s -> data [ 11 ] == 0x00 ) && <nl> ( s -> data [ 12 ] == 0x00 ) && <nl> ( s -> data [ 13 ] == 0x06 ) &&
static int alloc_sequence_buffers ( DiracContext * s ) <nl> s -> mctmp = av_malloc (( w + 64 + MAX_BLOCKSIZE ) * ( h * MAX_BLOCKSIZE ) * sizeof (* s -> mctmp )); <nl> s -> mcscratch = av_malloc (( w + 64 )* MAX_BLOCKSIZE ); <nl>  <nl> - if (! s -> sbsplit || ! s -> blmotion ) <nl> + if (! s -> sbsplit || ! s -> blmotion || ! s -> mctmp || ! s -> mcscratch ) <nl> return AVERROR ( ENOMEM ); <nl> return 0 ; <nl> }
static inline int pic_is_unused ( MpegEncContext * s , Picture * pic ) <nl> && pic -> f . qscale_table // check if the frame has anything allocated <nl> && pic -> period_since_free < s -> avctx -> thread_count ) <nl> return 0 ; <nl> + if ( pic == s -> last_picture_ptr ) <nl> + return 0 ; <nl> if ( pic -> f . data [ 0 ] == NULL ) <nl> return 1 ; <nl> if ( pic -> needs_realloc && !( pic -> reference & DELAYED_PIC_REF )) <nl> static int find_unused_picture ( MpegEncContext * s , int shared ) <nl>  <nl> if ( shared ) { <nl> for ( i = 0 ; i < MAX_PICTURE_COUNT ; i ++) { <nl> - if ( s -> picture [ i ]. f . data [ 0 ] == NULL ) <nl> + if ( s -> picture [ i ]. f . data [ 0 ] == NULL && & s -> picture [ i ] != s -> last_picture_ptr ) <nl> return i ; <nl> } <nl> } else {
static int aac_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , <nl> } <nl>  <nl> for ( k = 0 ; k < 1024 ; k ++) { <nl> - if (! isfinite ( cpe -> ch [ ch ]. coeffs [ k ])) { <nl> - av_log ( avctx , AV_LOG_ERROR , " Input contains NaN /+- Inf \ n "); <nl> + if (!( fabs ( cpe -> ch [ ch ]. coeffs [ k ]) < 1E16 )) { // Ensure headroom for energy calculation <nl> + av_log ( avctx , AV_LOG_ERROR , " Input contains ( near ) NaN /+- Inf \ n "); <nl> return AVERROR ( EINVAL ); <nl> } <nl> }
static int libx265_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , <nl> int ret ; <nl> int i ; <nl>  <nl> + x265_picture_init ( ctx -> params , & x265pic ); <nl> + <nl> if ( pic ) { <nl> for ( i = 0 ; i < 3 ; i ++) { <nl> x265pic . planes [ i ] = pic -> data [ i ];
static int get_siz ( Jpeg2000DecoderContext * s ) <nl> avpriv_request_sample ( s -> avctx , " Support for image offsets "); <nl> return AVERROR_PATCHWELCOME ; <nl> } <nl> + if ( s -> width > 32768U || s -> height > 32768U ) { <nl> + avpriv_request_sample ( s -> avctx , " Large Dimensions "); <nl> + return AVERROR_PATCHWELCOME ; <nl> + } <nl>  <nl> if ( ncomponents <= 0 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " Invalid number of components : % d \ n ",
static int vqf_read_header ( AVFormatContext * s ) <nl> rate_flag = AV_RB32 ( comm_chunk + 8 ); <nl> avio_skip ( s -> pb , len - 12 ); <nl>  <nl> + if ( st -> codec -> channels <= 0 ) { <nl> + av_log ( s , AV_LOG_ERROR , " Invalid number of channels \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> st -> codec -> bit_rate = read_bitrate * 1000 ; <nl> break ; <nl> case MKTAG (' D ',' S ',' I ',' Z '): // size of compressed data
again : <nl>  <nl> if ( avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || <nl> h -> cur_chroma_format_idc != h -> sps . chroma_format_idc ) { <nl> + if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU <nl> + && ( h -> sps . bit_depth_luma != 8 || <nl> + h -> sps . chroma_format_idc > 1 )) { <nl> + av_log ( avctx , AV_LOG_ERROR , <nl> + " VDPAU decoding does not support video " <nl> + " colorspace \ n "); <nl> + buf_index = - 1 ; <nl> + goto end ; <nl> + } <nl> if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 10 ) { <nl> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma ; <nl> h -> cur_chroma_format_idc = h -> sps . chroma_format_idc ;
int MPV_common_init ( MpegEncContext * s ) <nl> { <nl> int y_size , c_size , yc_size , i , mb_array_size , mv_table_size , x , y ; <nl>  <nl> - if ( s -> avctx -> thread_count > MAX_THREADS || ( 16 * s -> avctx -> thread_count > s -> height && s -> height )){ <nl> + s -> mb_height = ( s -> height + 15 ) / 16 ; <nl> + <nl> + if ( s -> avctx -> thread_count > MAX_THREADS || ( s -> avctx -> thread_count > s -> mb_height && s -> mb_height )){ <nl> av_log ( s -> avctx , AV_LOG_ERROR , " too many threads \ n "); <nl> return - 1 ; <nl> } <nl> int MPV_common_init ( MpegEncContext * s ) <nl> s -> flags2 = s -> avctx -> flags2 ; <nl>  <nl> s -> mb_width = ( s -> width + 15 ) / 16 ; <nl> - s -> mb_height = ( s -> height + 15 ) / 16 ; <nl> s -> mb_stride = s -> mb_width + 1 ; <nl> s -> b8_stride = s -> mb_width * 2 + 1 ; <nl> s -> b4_stride = s -> mb_width * 4 + 1 ;
int ff_rtsp_open_transport_ctx ( AVFormatContext * s , RTSPStream * rtsp_st ) <nl>  <nl> if (! rtsp_st -> transport_priv ) { <nl> return AVERROR ( ENOMEM ); <nl> - } else if ( CONFIG_RTPDEC && rt -> transport == RTSP_TRANSPORT_RTP ) { <nl> + } else if ( CONFIG_RTPDEC && rt -> transport == RTSP_TRANSPORT_RTP && <nl> + s -> iformat ) { <nl> RTPDemuxContext * rtpctx = rtsp_st -> transport_priv ; <nl> rtpctx -> ssrc = rtsp_st -> ssrc ; <nl> if ( rtsp_st -> dynamic_handler ) {
static int xan_huffman_decode ( unsigned char * dest , const unsigned char * src , <nl> val = src [ val - 0x17 + get_bits1 (& gb ) * byte ]; <nl>  <nl> if ( val < 0x16 ) { <nl> - if ( dest + 1 > dest_end ) <nl> + if ( dest >= dest_end ) <nl> return 0 ; <nl> * dest ++ = val ; <nl> val = ival ;
static inline void drawbox ( AVFilterBufferRef * picref , unsigned int x , unsigned i <nl> static int draw_glyphs ( DrawTextContext * dtext , AVFilterBufferRef * picref , <nl> int width , int height , const uint8_t rgbcolor [ 4 ], const uint8_t yuvcolor [ 4 ], int x , int y ) <nl> { <nl> - char * text = dtext -> text ; <nl> + char * text = HAVE_LOCALTIME_R ? dtext -> expanded_text : dtext -> text ; <nl> uint32_t code = 0 ; <nl> int i ; <nl> uint8_t * p ;
static int hds_write_header ( AVFormatContext * s ) <nl>  <nl> snprintf ( os -> temp_filename , sizeof ( os -> temp_filename ), <nl> "% s / stream % d_temp ", s -> filename , i ); <nl> - init_file ( s , os , 0 ); <nl> + ret = init_file ( s , os , 0 ); <nl> + if ( ret < 0 ) <nl> + goto fail ; <nl>  <nl> if (! os -> has_video && c -> min_frag_duration <= 0 ) { <nl> av_log ( s , AV_LOG_WARNING ,
static int init_filters ( const char * filters_descr ) <nl> abuffersink_params -> packing_fmts = packing_fmts ; <nl> ret = avfilter_graph_create_filter (& buffersink_ctx , abuffersink , " out ", <nl> NULL , abuffersink_params , filter_graph ); <nl> + av_free ( abuffersink_params ); <nl> if ( ret < 0 ) { <nl> av_log ( NULL , AV_LOG_ERROR , " Cannot create audio buffer sink \ n "); <nl> return ret ;
static int aac_decode_frame ( AVCodecContext * avccontext , void * data , <nl> memset ( new_che_pos , 0 , 4 * MAX_ELEM_ID * sizeof ( new_che_pos [ 0 ][ 0 ])); <nl> if (( err = decode_pce ( ac , new_che_pos , & gb ))) <nl> break ; <nl> - if ( ac -> output_configured <= OC_TRIAL_PCE ) <nl> + if ( ac -> output_configured > OC_TRIAL_PCE ) <nl> av_log ( avccontext , AV_LOG_ERROR , <nl> " Not evaluating a further program_config_element as this construct is dubious at best .\ n "); <nl> else
static int filter_samples ( AVFilterLink * inlink , AVFilterBufferRef * buf ) <nl>  <nl> if ( labs ( delta ) > s -> min_delta ) { <nl> av_log ( ctx , AV_LOG_VERBOSE , " Discontinuity - %" PRId64 " samples .\ n ", delta ); <nl> - out_size += delta ; <nl> + out_size = av_clipl_int32 (( int64_t ) out_size + delta ); <nl> } else { <nl> if ( s -> resample ) { <nl> int comp = av_clip ( delta , - s -> max_comp , s -> max_comp );
static int process_ipmovie_chunk ( IPMVEContext * s , AVIOContext * pb , <nl>  <nl> case OPCODE_INIT_AUDIO_BUFFERS : <nl> av_dlog ( NULL , " initialize audio buffers \ n "); <nl> - if (( opcode_version > 1 ) || ( opcode_size > 10 )) { <nl> + if (( opcode_version > 1 ) || ( opcode_size > 10 ) || opcode_size < 6 ) { <nl> av_dlog ( NULL , " bad init_audio_buffers opcode \ n "); <nl> chunk_type = CHUNK_BAD ; <nl> break ;
int ff_get_wav_header ( AVIOContext * pb , AVCodecContext * codec , int size ) <nl> codec -> sample_rate = 0 ; <nl> } <nl> /* override bits_per_coded_sample for G . 726 */ <nl> - if ( codec -> codec_id == AV_CODEC_ID_ADPCM_G726 ) <nl> + if ( codec -> codec_id == AV_CODEC_ID_ADPCM_G726 && codec -> sample_rate ) <nl> codec -> bits_per_coded_sample = codec -> bit_rate / codec -> sample_rate ; <nl>  <nl> return 0 ;
static int read_ffserver_streams ( OptionsContext * o , AVFormatContext * s , const ch <nl> { <nl> int i , err ; <nl> AVFormatContext * ic = avformat_alloc_context (); <nl> + if (! ic ) <nl> + return AVERROR ( ENOMEM ); <nl>  <nl> ic -> interrupt_callback = int_cb ; <nl> err = avformat_open_input (& ic , filename , NULL , NULL );
static int decode_nal_units ( H264Context * h , const uint8_t * buf , int buf_size ){ <nl> switch ( hx -> nal_unit_type ) { <nl> case NAL_SPS : <nl> case NAL_PPS : <nl> + nals_needed = nal_index ; <nl> + break ; <nl> case NAL_IDR_SLICE : <nl> case NAL_SLICE : <nl> - nals_needed = nal_index ; <nl> + init_get_bits (& hx -> s . gb , ptr , bit_length ); <nl> + if (! get_ue_golomb (& hx -> s . gb )) <nl> + nals_needed = nal_index ; <nl> } <nl> continue ; <nl> }
static av_cold int movie_common_init ( AVFilterContext * ctx ) <nl> timestamp = movie -> seek_point ; <nl> // add the stream start time , should it exist <nl> if ( movie -> format_ctx -> start_time != AV_NOPTS_VALUE ) { <nl> - if ( timestamp > INT64_MAX - movie -> format_ctx -> start_time ) { <nl> + if ( timestamp > 0 && movie -> format_ctx -> start_time > INT64_MAX - timestamp ) { <nl> av_log ( ctx , AV_LOG_ERROR , <nl> "% s : seek value overflow with start_time :%" PRId64 " seek_point :%" PRId64 "\ n ", <nl> movie -> file_name , movie -> format_ctx -> start_time , movie -> seek_point );
int ff_wma_end ( AVCodecContext * avctx ) <nl> free_vlc (& s -> coef_vlc [ i ]); <nl> av_free ( s -> run_table [ i ]); <nl> av_free ( s -> level_table [ i ]); <nl> + av_free ( s -> int_table [ i ]); <nl> } <nl>  <nl> return 0 ;
static const AVCodecDescriptor codec_descriptors [] = { <nl> . type = AVMEDIA_TYPE_VIDEO , <nl> . name = " fraps ", <nl> . long_name = NULL_IF_CONFIG_SMALL (" Fraps "), <nl> - . props = AV_CODEC_PROP_LOSSLESS , <nl> + . props = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS , <nl> }, <nl> { <nl> . id = AV_CODEC_ID_TRUEMOTION2 ,
static int mov_read_extradata ( MOVContext * c , AVIOContext * pb , MOVAtom atom , <nl> av_log ( c -> fc , AV_LOG_WARNING , " truncated extradata \ n "); <nl> st -> codec -> extradata_size -= atom . size - err ; <nl> } <nl> + memset ( buf + 8 + err , 0 , FF_INPUT_BUFFER_PADDING_SIZE ); <nl> return 0 ; <nl> } <nl> 
static int rv30_decode_mb_info ( RV34DecContext * r ) <nl> GetBitContext * gb = & s -> gb ; <nl> int code = svq3_get_ue_golomb ( gb ); <nl>  <nl> - if ( code > 11 ){ <nl> + if ( code < 0 || code > 11 ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " Incorrect MB type code \ n "); <nl> return - 1 ; <nl> }
static int read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> } <nl> } <nl>  <nl> + if ( s -> pb -> eof_reached ) <nl> + return AVERROR_EOF ; <nl> + <nl> return AVERROR ( EIO ); <nl> } <nl> 
typedef struct MmContext { <nl> AVCodecContext * avctx ; <nl> AVFrame * frame ; <nl> - int palette [ AVPALETTE_COUNT ]; <nl> + unsigned int palette [ AVPALETTE_COUNT ]; <nl> GetByteContext gb ; <nl> } MmContext ; <nl> 
static int zero12v_decode_frame ( AVCodecContext * avctx , void * data , <nl> const uint8_t * line_end , * src = avpkt -> data ; <nl> int stride = avctx -> width * 8 / 3 ; <nl>  <nl> - if ( width == 1 ) { <nl> - av_log ( avctx , AV_LOG_ERROR , " Width 1 not supported .\ n "); <nl> + if ( width <= 1 || avctx -> height <= 0 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Dimensions % dx % d not supported .\ n ", width , avctx -> height ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> 
static int asf_read_frame_header ( AVFormatContext * s , AVIOContext * pb ){ <nl> if ( asf -> packet_flags & 0x01 ) { <nl> DO_2BITS ( asf -> packet_segsizetype >> 6 , asf -> packet_frag_size , 0 ); // 0 is illegal <nl> if ( asf -> packet_frag_size > asf -> packet_size_left - rsize ){ <nl> - av_log ( s , AV_LOG_ERROR , " packet_frag_size is invalid \ n "); <nl> - return - 1 ; <nl> + if ( asf -> packet_frag_size > asf -> packet_size_left - rsize + asf -> packet_padsize ) { <nl> + av_log ( s , AV_LOG_ERROR , " packet_frag_size is invalid (% d -% d )\ n ", asf -> packet_size_left , rsize ); <nl> + return - 1 ; <nl> + } else { <nl> + int diff = asf -> packet_frag_size - ( asf -> packet_size_left - rsize ); <nl> + asf -> packet_size_left += diff ; <nl> + asf -> packet_padsize -= diff ; <nl> + } <nl> } <nl> // printf (" Fragsize % d \ n ", asf -> packet_frag_size ); <nl> } else {
static int mp3_read_probe ( AVProbeData * p ) <nl> int fsize , frames ; <nl> uint32_t header ; <nl> const uint8_t * buf , * buf0 , * buf2 , * end ; <nl> - AVCodecContext avctx ; <nl> + AVCodecContext * avctx = avcodec_alloc_context3 ( NULL ); <nl>  <nl> buf0 = p -> buf ; <nl> end = p -> buf + p -> buf_size - sizeof ( uint32_t ); <nl> static int mp3_read_probe ( AVProbeData * p ) <nl> for ( frames = 0 ; buf2 < end ; frames ++) { <nl> int dummy ; <nl> header = AV_RB32 ( buf2 ); <nl> - fsize = avpriv_mpa_decode_header (& avctx , header , & dummy , & dummy , & dummy , & dummy ); <nl> + fsize = avpriv_mpa_decode_header ( avctx , header , & dummy , & dummy , & dummy , & dummy ); <nl> if ( fsize < 0 ) <nl> break ; <nl> buf2 += fsize ; <nl> static int mp3_read_probe ( AVProbeData * p ) <nl> if ( buf == buf0 ) <nl> first_frames = frames ; <nl> } <nl> + avcodec_free_context (& avctx ); <nl> // keep this in sync with ac3 probe , both need to avoid <nl> // issues with MPEG - files ! <nl> if ( first_frames >= 4 ) return AVPROBE_SCORE_EXTENSION + 1 ;
int av_opt_query_ranges_default ( AVOptionRanges ** ranges_arg , void * obj , const ch <nl> fail : <nl> av_free ( ranges ); <nl> av_free ( range ); <nl> + av_free ( range_array ); <nl> return ret ; <nl> } <nl> 
unk_pixfmt : <nl> av_log ( s -> avctx , AV_LOG_DEBUG , " decode_sof0 : error , len (% d ) mismatch \ n ", len ); <nl> } <nl>  <nl> - if ( s -> rgb && ! s -> lossless && ! s -> ls ) { <nl> + if (( s -> rgb && ! s -> lossless && ! s -> ls ) || <nl> + (! s -> rgb && s -> ls && s -> nb_components > 1 )) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " Unsupported coding and pixel format combination \ n "); <nl> return AVERROR_PATCHWELCOME ; <nl> }
int ff_load_image ( uint8_t * data [ 4 ], int linesize [ 4 ], <nl> av_image_copy ( data , linesize , ( const uint8_t **) frame -> data , frame -> linesize , * pix_fmt , * w , * h ); <nl>  <nl> end : <nl> - if ( codec_ctx ) <nl> - avcodec_close ( codec_ctx ); <nl> + avcodec_close ( codec_ctx ); <nl> if ( format_ctx ) <nl> avformat_close_input (& format_ctx ); <nl> av_freep (& frame );
static int decode_header ( SnowContext * s ){ <nl> Plane * p = & s -> plane [ plane_index ]; <nl> p -> diag_mc = get_rac (& s -> c , s -> header_state ); <nl> htaps = get_symbol (& s -> c , s -> header_state , 0 )* 2 + 2 ; <nl> - if (( unsigned ) htaps > HTAPS_MAX || htaps == 0 ) <nl> + if (( unsigned ) htaps >= HTAPS_MAX || htaps == 0 ) <nl> return AVERROR_INVALIDDATA ; <nl> p -> htaps = htaps ; <nl> for ( i = htaps / 2 ; i ; i --){
static int filter_frame ( AVFilterLink * inlink , AVFrame * frame ) <nl> int ret ; <nl>  <nl> if ( s -> reload ) { <nl> - if (( ret = load_textfile ( ctx )) < 0 ) <nl> + if (( ret = load_textfile ( ctx )) < 0 ) { <nl> + av_frame_free (& frame ); <nl> return ret ; <nl> + } <nl> # if CONFIG_LIBFRIBIDI <nl> if ( s -> text_shaping ) <nl> - if (( ret = shape_text ( ctx )) < 0 ) <nl> + if (( ret = shape_text ( ctx )) < 0 ) { <nl> + av_frame_free (& frame ); <nl> return ret ; <nl> + } <nl> # endif <nl> } <nl> 
static void hl_motion ( H264Context * h , uint8_t * dest_y , uint8_t * dest_cb , uint8_t <nl> } <nl>  <nl>  <nl> - static void free_tables ( H264Context * h ){ <nl> + static void free_tables ( H264Context * h , int free_rbsp ){ <nl> int i ; <nl> H264Context * hx ; <nl> av_freep (& h -> intra4x4_pred_mode ); <nl> static void free_tables ( H264Context * h ){ <nl> av_freep (& hx -> top_borders [ 1 ]); <nl> av_freep (& hx -> top_borders [ 0 ]); <nl> av_freep (& hx -> s . obmc_scratchpad ); <nl> + if ( free_rbsp ){ <nl> av_freep (& hx -> rbsp_buffer [ 1 ]); <nl> av_freep (& hx -> rbsp_buffer [ 0 ]); <nl> hx -> rbsp_buffer_size [ 0 ] = 0 ; <nl> hx -> rbsp_buffer_size [ 1 ] = 0 ; <nl> + } <nl> if ( i ) av_freep (& h -> thread_context [ i ]); <nl> } <nl> } <nl> int ff_h264_alloc_tables ( H264Context * h ){ <nl>  <nl> return 0 ; <nl> fail : <nl> - free_tables ( h ); <nl> + free_tables ( h , 1 ); <nl> return - 1 ; <nl> } <nl>  <nl> static int decode_slice_header ( H264Context * h , H264Context * h0 ){ <nl> || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ))) { <nl> if ( h != h0 ) <nl> return - 1 ; // width / height changed during parallelized decoding <nl> - free_tables ( h ); <nl> + free_tables ( h , 0 ); <nl> flush_dpb ( s -> avctx ); <nl> MPV_common_end ( s ); <nl> } <nl> av_cold void ff_h264_free_context ( H264Context * h ) <nl> { <nl> int i ; <nl>  <nl> - free_tables ( h ); // FIXME cleanup init stuff perhaps <nl> + free_tables ( h , 1 ); // FIXME cleanup init stuff perhaps <nl>  <nl> for ( i = 0 ; i < MAX_SPS_COUNT ; i ++) <nl> av_freep ( h -> sps_buffers + i );
static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPac <nl> size_left = buf_size - ( src - buf ); <nl> switch ( enc ) { <nl> case MAGIC_WMVd : // cursor <nl> + if ( w *( int64_t ) h * c -> bpp2 > INT_MAX / 2 - 2 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " dimensions too large \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> if ( size_left < 2 + w * h * c -> bpp2 * 2 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Premature end of data ! ( need % i got % i )\ n ", 2 + w * h * c -> bpp2 * 2 , size_left ); <nl> return - 1 ;
static int hds_write_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> HDSContext * c = s -> priv_data ; <nl> AVStream * st = s -> streams [ pkt -> stream_index ]; <nl> OutputStream * os = & c -> streams [ s -> streams [ pkt -> stream_index ]-> id ]; <nl> - int64_t end_dts = ( os -> fragment_index ) * c -> min_frag_duration ; <nl> + int64_t end_dts = os -> fragment_index * ( int64_t ) c -> min_frag_duration ; <nl> int ret ; <nl>  <nl> if ( st -> first_dts == AV_NOPTS_VALUE )
static int vdpau_vc1_start_frame ( AVCodecContext * avctx , <nl>  <nl> switch ( s -> pict_type ) { <nl> case AV_PICTURE_TYPE_B : <nl> + if ( s -> next_picture_ptr ) { <nl> ref = ff_vdpau_get_surface_id (& s -> next_picture ); <nl> assert ( ref != VDP_INVALID_HANDLE ); <nl> info -> backward_reference = ref ; <nl> + } <nl> /* fall - through */ <nl> case AV_PICTURE_TYPE_P : <nl> + if ( s -> last_picture_ptr ) { <nl> ref = ff_vdpau_get_surface_id (& s -> last_picture ); <nl> assert ( ref != VDP_INVALID_HANDLE ); <nl> info -> forward_reference = ref ; <nl> + } <nl> } <nl>  <nl> info -> slice_count = 0 ;
static av_cold int decode_init ( AVCodecContext * avctx ) <nl> return AVERROR_INVALIDDATA ; <nl> } <nl>  <nl> - if ( s -> avctx -> sample_rate <= 0 ) { <nl> - av_log ( avctx , AV_LOG_ERROR , " invalid sample rate \ n "); <nl> - return AVERROR_INVALIDDATA ; <nl> - } <nl> - <nl> s -> num_channels = avctx -> channels ; <nl>  <nl> if ( s -> num_channels < 0 ) {
static int vp9_superframe_filter ( AVBSFContext * ctx , AVPacket * out ) <nl> goto done ; <nl> } <nl>  <nl> - av_packet_move_ref ( s -> cache [ s -> n_cache ++], in ); <nl> + res = av_packet_ref ( s -> cache [ s -> n_cache ++], in ); <nl> + if ( res < 0 ) <nl> + goto done ; <nl>  <nl> if ( invisible ) { <nl> res = AVERROR ( EAGAIN );
static av_cold int g726_decode_init ( AVCodecContext * avctx ) <nl> { <nl> G726Context * c = avctx -> priv_data ; <nl>  <nl> + if ( avctx -> channels > 1 ){ <nl> + avpriv_request_sample ( avctx , " Decoding more than one channel "); <nl> + return AVERROR_PATCHWELCOME ; <nl> + } <nl> avctx -> channels = 1 ; <nl> avctx -> channel_layout = AV_CH_LAYOUT_MONO ; <nl> 
static int decode_frame ( AVCodecContext * avctx , <nl> int prev_y = 0 , prev_u = 0 , prev_v = 0 ; <nl> uint8_t * rbuf ; <nl>  <nl> - if ( buf_size <= 8 ) { <nl> + if ( buf_size < 8 + avctx -> height * ( avctx -> width / 2 )/ 8 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Packet size % d is too small \ n ", buf_size ); <nl> return AVERROR_INVALIDDATA ; <nl> }
static av_cold void uninit ( AVFilterContext * ctx ) <nl> avfilter_unref_buffer ( deshake -> ref ); <nl> if ( deshake -> fp ) <nl> fclose ( deshake -> fp ); <nl> - avcodec_close ( deshake -> avctx ); <nl> + if ( deshake -> avctx ) <nl> + avcodec_close ( deshake -> avctx ); <nl> av_freep (& deshake -> avctx ); <nl> } <nl> 
static int fourxm_read_header ( AVFormatContext * s , <nl> fourxm -> tracks [ current_track ]. sample_rate = AV_RL32 (& header [ i + 40 ]); <nl> fourxm -> tracks [ current_track ]. bits = AV_RL32 (& header [ i + 44 ]); <nl> fourxm -> tracks [ current_track ]. audio_pts = 0 ; <nl> + if ( fourxm -> tracks [ current_track ]. channels <= 0 <nl> + || fourxm -> tracks [ current_track ]. sample_rate <= 0 <nl> + || fourxm -> tracks [ current_track ]. bits < 0 ){ <nl> + av_log ( s , AV_LOG_ERROR , " audio header invalid \ n "); <nl> + ret = - 1 ; <nl> + goto fail ; <nl> + } <nl> i += 8 + size ; <nl>  <nl> /* allocate a new AVStream */ <nl> static int fourxm_read_packet ( AVFormatContext * s , <nl> out_size = get_le32 ( pb ); <nl> size -= 8 ; <nl>  <nl> - if ( track_number < fourxm -> track_count ) { <nl> + if ( track_number < fourxm -> track_count && fourxm -> tracks [ track_number ]. channels > 0 ) { <nl> ret = av_get_packet ( s -> pb , pkt , size ); <nl> if ( ret < 0 ) <nl> return AVERROR ( EIO );
av_cold int ff_mss12_decode_init ( MSS12Context * c , int version , <nl> return AVERROR_INVALIDDATA ; <nl> } <nl>  <nl> - avctx -> coded_width = AV_RB32 ( avctx -> extradata + 20 ); <nl> - avctx -> coded_height = AV_RB32 ( avctx -> extradata + 24 ); <nl> + avctx -> coded_width = FFMAX ( AV_RB32 ( avctx -> extradata + 20 ), avctx -> width ); <nl> + avctx -> coded_height = FFMAX ( AV_RB32 ( avctx -> extradata + 24 ), avctx -> height ); <nl> if ( avctx -> coded_width > 4096 || avctx -> coded_height > 4096 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Frame dimensions % dx % d too large ", <nl> avctx -> coded_width , avctx -> coded_height );
static int load_textfile ( AVFilterContext * ctx ) <nl> DrawTextContext * s = ctx -> priv ; <nl> int err ; <nl> uint8_t * textbuf ; <nl> + uint8_t * tmp ; <nl> size_t textbuf_size ; <nl>  <nl> if (( err = av_file_map ( s -> textfile , & textbuf , & textbuf_size , 0 , ctx )) < 0 ) { <nl> static int load_textfile ( AVFilterContext * ctx ) <nl> return err ; <nl> } <nl>  <nl> - if (!( s -> text = av_realloc ( s -> text , textbuf_size + 1 ))) <nl> + if (!( tmp = av_realloc ( s -> text , textbuf_size + 1 ))) { <nl> + av_file_unmap ( textbuf , textbuf_size ); <nl> return AVERROR ( ENOMEM ); <nl> + } <nl> + s -> text = tmp ; <nl> memcpy ( s -> text , textbuf , textbuf_size ); <nl> s -> text [ textbuf_size ] = 0 ; <nl> av_file_unmap ( textbuf , textbuf_size );
static int bit_allocation ( IMCContext * q , IMCChannel * chctx , <nl> iacc += chctx -> bandWidthT [ i ]; <nl> summa += chctx -> bandWidthT [ i ] * chctx -> flcoeffs4 [ i ]; <nl> } <nl> + <nl> + if (! iacc ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> chctx -> bandWidthT [ BANDS - 1 ] = 0 ; <nl> summa = ( summa * 0 . 5 - freebits ) / iacc ; <nl> 
void avfilter_start_frame ( AVFilterLink * link , AVFilterBufferRef * picref ) <nl> picref -> perms , <nl> link_dpad ( link ). min_perms , link_dpad ( link ). rej_perms ); <nl>  <nl> - link -> cur_buf = avfilter_default_get_video_buffer ( link , dst -> min_perms , link -> w , link -> h ); <nl> + link -> cur_buf = avfilter_get_video_buffer ( link , dst -> min_perms , link -> w , link -> h ); <nl> link -> src_buf = picref ; <nl> avfilter_copy_buffer_ref_props ( link -> cur_buf , link -> src_buf ); <nl> }
static av_cold int alac_encode_init ( AVCodecContext * avctx ) <nl> return - 1 ; <nl> } <nl>  <nl> + /* TODO : Correctly implement multi - channel ALAC . <nl> + It is similar to multi - channel AAC , in that it has a series of <nl> + single - channel ( SCE ), channel - pair ( CPE ), and LFE elements . */ <nl> + if ( avctx -> channels > 2 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " only mono or stereo input is currently supported \ n "); <nl> + return AVERROR_PATCHWELCOME ; <nl> + } <nl> + <nl> // Set default compression level <nl> if ( avctx -> compression_level == FF_COMPRESSION_DEFAULT ) <nl> s -> compression_level = 2 ;
static int decode_chunks ( AVCodecContext * avctx , <nl> buf_ptr = avpriv_find_start_code ( buf_ptr , buf_end , & start_code ); <nl> if ( start_code > 0x1ff ) { <nl> if (! skip_frame ) { <nl> - if ( HAVE_THREADS && ( avctx -> active_thread_type & FF_THREAD_SLICE )) { <nl> + if ( HAVE_THREADS && ( avctx -> active_thread_type & FF_THREAD_SLICE ) && <nl> + ! avctx -> hwaccel ) { <nl> int i ; <nl>  <nl> avctx -> execute ( avctx , slice_decode_thread , & s2 -> thread_context [ 0 ], NULL , s -> slice_count , sizeof ( void *)); <nl> static int decode_chunks ( AVCodecContext * avctx , <nl> return AVERROR_INVALIDDATA ; <nl> } <nl>  <nl> - if ( HAVE_THREADS && ( avctx -> active_thread_type & FF_THREAD_SLICE ) && s -> slice_count ) { <nl> + if ( HAVE_THREADS && ( avctx -> active_thread_type & FF_THREAD_SLICE ) && <nl> + ! avctx -> hwaccel && s -> slice_count ) { <nl> int i ; <nl>  <nl> avctx -> execute ( avctx , slice_decode_thread , <nl> static int decode_chunks ( AVCodecContext * avctx , <nl> break ; <nl> } <nl>  <nl> - if ( HAVE_THREADS && ( avctx -> active_thread_type & FF_THREAD_SLICE )) { <nl> + if ( HAVE_THREADS && ( avctx -> active_thread_type & FF_THREAD_SLICE ) && <nl> + ! avctx -> hwaccel ) { <nl> int threshold = ( s2 -> mb_height * s -> slice_count + <nl> s2 -> slice_context_count / 2 ) / <nl> s2 -> slice_context_count ;
static void free_tables ( H264Context * h ){ <nl> av_freep (& hx -> top_borders [ 1 ]); <nl> av_freep (& hx -> top_borders [ 0 ]); <nl> av_freep (& hx -> s . obmc_scratchpad ); <nl> + av_freep (& hx -> rbsp_buffer [ 1 ]); <nl> + av_freep (& hx -> rbsp_buffer [ 0 ]); <nl> + if ( i ) av_freep (& h -> thread_context [ i ]); <nl> } <nl> } <nl>  <nl> av_cold void ff_h264_free_context ( H264Context * h ) <nl> { <nl> int i ; <nl>  <nl> - av_freep (& h -> rbsp_buffer [ 0 ]); <nl> - av_freep (& h -> rbsp_buffer [ 1 ]); <nl> free_tables ( h ); // FIXME cleanup init stuff perhaps <nl>  <nl> for ( i = 0 ; i < MAX_SPS_COUNT ; i ++)
static unsigned compute_avg_bitrate ( MOVTrack * track ) <nl> { <nl> uint64_t size = 0 ; <nl> int i ; <nl> + if (! track -> track_duration ) <nl> + return 0 ; <nl> for ( i = 0 ; i < track -> entry ; i ++) <nl> size += track -> cluster [ i ]. size ; <nl> return size * 8 * track -> timescale / track -> track_duration ; <nl> static int mov_write_moov_tag ( AVIOContext * pb , MOVMuxContext * mov , <nl> mov -> tracks [ i ]. time = mov -> time ; <nl> mov -> tracks [ i ]. track_id = i + 1 ; <nl>  <nl> - build_chunks (& mov -> tracks [ i ]); <nl> + if ( mov -> tracks [ i ]. entry ) <nl> + build_chunks (& mov -> tracks [ i ]); <nl> } <nl>  <nl> if ( mov -> chapter_track )
typedef struct HEVCPPS { <nl> uint8_t chroma_qp_offset_list_enabled_flag ; <nl> uint8_t diff_cu_chroma_qp_offset_depth ; <nl> uint8_t chroma_qp_offset_list_len_minus1 ; <nl> - int8_t cb_qp_offset_list [ 5 ]; <nl> - int8_t cr_qp_offset_list [ 5 ]; <nl> + int8_t cb_qp_offset_list [ 6 ]; <nl> + int8_t cr_qp_offset_list [ 6 ]; <nl> uint8_t log2_sao_offset_scale_luma ; <nl> uint8_t log2_sao_offset_scale_chroma ; <nl> 
int ff_audio_mix ( AudioMix * am , AudioData * src ) <nl>  <nl> if ( am -> in_matrix_channels && am -> out_matrix_channels ) { <nl> uint8_t ** data ; <nl> - uint8_t * data0 [ AVRESAMPLE_MAX_CHANNELS ]; <nl> + uint8_t * data0 [ AVRESAMPLE_MAX_CHANNELS ] = { NULL }; <nl>  <nl> if ( am -> out_matrix_channels < am -> out_channels || <nl> am -> in_matrix_channels < am -> in_channels ) {
static av_cold int peak_init_writer ( AVFormatContext * s ) <nl> } <nl>  <nl> wav -> peak_maxpos = av_mallocz ( enc -> channels * sizeof (* wav -> peak_maxpos )); <nl> - if (! wav -> peak_maxpos ) <nl> - goto nomem ; <nl> wav -> peak_maxneg = av_mallocz ( enc -> channels * sizeof (* wav -> peak_maxneg )); <nl> - if (! wav -> peak_maxneg ) <nl> - goto nomem ; <nl> - <nl> wav -> peak_output = av_malloc ( PEAK_BUFFER_SIZE ); <nl> - if (! wav -> peak_output ) <nl> + if (! wav -> peak_maxpos || ! wav -> peak_maxneg || ! wav -> peak_output ) <nl> goto nomem ; <nl>  <nl> wav -> peak_outbuf_size = PEAK_BUFFER_SIZE ;
static int dtext_prepare_text ( AVFilterContext * ctx ) <nl> /* get glyph */ <nl> dummy . code = code ; <nl> glyph = av_tree_find ( dtext -> glyphs , & dummy , glyph_cmp , NULL ); <nl> - if (! glyph ) <nl> + if (! glyph ) { <nl> ret = load_glyph ( ctx , & glyph , code ); <nl> - if ( ret ) return ret ; <nl> + if ( ret ) <nl> + return ret ; <nl> + } <nl>  <nl> y_min = FFMIN ( glyph -> bbox . yMin , y_min ); <nl> y_max = FFMAX ( glyph -> bbox . yMax , y_max );
static av_cold int vpx_init ( AVCodecContext * avctx , <nl> if ( enccfg . g_pass == VPX_RC_FIRST_PASS ) <nl> enccfg . g_lag_in_frames = 0 ; <nl> else if ( enccfg . g_pass == VPX_RC_LAST_PASS ) { <nl> - int decode_size ; <nl> + int decode_size , ret ; <nl>  <nl> if (! avctx -> stats_in ) { <nl> av_log ( avctx , AV_LOG_ERROR , " No stats file for second pass \ n "); <nl> static av_cold int vpx_init ( AVCodecContext * avctx , <nl> } <nl>  <nl> ctx -> twopass_stats . sz = strlen ( avctx -> stats_in ) * 3 / 4 ; <nl> - ctx -> twopass_stats . buf = av_malloc ( ctx -> twopass_stats . sz ); <nl> - if (! ctx -> twopass_stats . buf ) { <nl> + ret = av_reallocp (& ctx -> twopass_stats . buf , ctx -> twopass_stats . sz ); <nl> + if ( ret < 0 ) { <nl> av_log ( avctx , AV_LOG_ERROR , <nl> " Stat buffer alloc (% zu bytes ) failed \ n ", <nl> ctx -> twopass_stats . sz ); <nl> - return AVERROR ( ENOMEM ); <nl> + return ret ; <nl> } <nl> decode_size = av_base64_decode ( ctx -> twopass_stats . buf , avctx -> stats_in , <nl> ctx -> twopass_stats . sz );
static int mov_finalize_stsd_codec ( MOVContext * c , AVIOContext * pb , <nl> switch ( st -> codec -> codec_id ) { <nl> # if CONFIG_DV_DEMUXER <nl> case AV_CODEC_ID_DVAUDIO : <nl> - c -> dv_fctx = avformat_alloc_context (); <nl> + c -> dv_fctx = avformat_alloc_context (); <nl> + if (! c -> dv_fctx ) { <nl> + av_log ( c -> fc , AV_LOG_ERROR , " dv demux context alloc error \ n "); <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> c -> dv_demux = avpriv_dv_init_demux ( c -> dv_fctx ); <nl> if (! c -> dv_demux ) { <nl> av_log ( c -> fc , AV_LOG_ERROR , " dv demux context init error \ n ");
need_realloc : <nl> av_opt_set_int ( ost -> swr , " icl ", av_get_default_channel_layout ( ost -> audio_channels_mapped ), 0 ); <nl> av_opt_set_int ( ost -> swr , " uch ", ost -> audio_channels_mapped , 0 ); <nl> } <nl> - av_opt_set_int ( ost -> swr , " ich ", dec -> channels , 0 ); <nl> - av_opt_set_int ( ost -> swr , " och ", enc -> channels , 0 ); <nl> + if ( av_opt_set_int ( ost -> swr , " ich ", dec -> channels , 0 ) < 0 ) { <nl> + av_log ( NULL , AV_LOG_FATAL , " Unsupported number of input channels \ n "); <nl> + exit_program ( 1 ); <nl> + } <nl> + if ( av_opt_set_int ( ost -> swr , " och ", enc -> channels , 0 ) < 0 ) { <nl> + av_log ( NULL , AV_LOG_FATAL , " Unsupported number of output channels \ n "); <nl> + exit_program ( 1 ); <nl> + } <nl> if ( audio_sync_method > 1 ) av_opt_set_int ( ost -> swr , " flags ", SWR_FLAG_RESAMPLE , 0 ); <nl> if ( ost -> swr && swr_init ( ost -> swr ) < 0 ){ <nl> av_log ( NULL , AV_LOG_FATAL , " swr_init () failed \ n ");
static int ljpeg_decode_yuv_scan ( MJpegDecodeContext * s , int predictor , <nl>  <nl> for ( mb_y = 0 ; mb_y < s -> mb_height ; mb_y ++) { <nl> for ( mb_x = 0 ; mb_x < s -> mb_width ; mb_x ++) { <nl> + if ( get_bits_left (& s -> gb ) < 1 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " bitstream end in yuv_scan \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> if ( s -> restart_interval && ! s -> restart_count ){ <nl> s -> restart_count = s -> restart_interval ; <nl> resync_mb_x = mb_x ;
static void ffserver_apply_stream_config ( AVCodecContext * enc , const AVDictionary <nl> enc -> mb_decision = FF_MB_DECISION_BITS ; <nl> if (( e = av_dict_get ( conf , " VideoTag ", NULL , 0 ))) <nl> enc -> codec_tag = MKTAG ( e -> value [ 0 ], e -> value [ 1 ], e -> value [ 2 ], e -> value [ 3 ]); <nl> - if ( av_dict_get ( conf , " Qscale ", NULL , 0 )) { <nl> + if (( e = av_dict_get ( conf , " Qscale ", NULL , 0 ))) { <nl> enc -> flags |= CODEC_FLAG_QSCALE ; <nl> ffserver_set_int_param (& enc -> global_quality , e -> value , FF_QP2LAMBDA , <nl> INT_MIN , INT_MAX , NULL , 0 , NULL ); <nl> static int ffserver_parse_config_stream ( FFServerConfig * config , const char * cmd , <nl> if ( av_dict_set (& config -> video_conf , cmd , arg , 0 ) < 0 ) <nl> goto nomem ; <nl> } else if (! av_strcasecmp ( cmd , " VideoIntraOnly ")) { <nl> - if ( av_dict_set (& config -> video_conf , cmd , " 1 ", 0 ) < 0 ) <nl> + if ( av_dict_set (& config -> video_conf , " VideoGopSize ", " 1 ", 0 ) < 0 ) <nl> goto nomem ; <nl> } else if (! av_strcasecmp ( cmd , " VideoHighQuality ")) { <nl> if ( av_dict_set (& config -> video_conf , cmd , "", 0 ) < 0 ) <nl> static int ffserver_parse_config_stream ( FFServerConfig * config , const char * cmd , <nl> } else if (! av_strcasecmp ( cmd , " VideoTag ")) { <nl> ffserver_get_arg ( arg , sizeof ( arg ), p ); <nl> if ( strlen ( arg ) == 4 ) { <nl> - if ( av_dict_set (& config -> video_conf , " VideoTag ", " arg ", 0 ) < 0 ) <nl> + if ( av_dict_set (& config -> video_conf , " VideoTag ", arg , 0 ) < 0 ) <nl> goto nomem ; <nl> } <nl> } else if (! av_strcasecmp ( cmd , " BitExact ")) {
static int write_extradata ( FFV1Context * f ) <nl> f -> avctx -> extradata_size = 10000 + 4 + <nl> ( 11 * 11 * 5 * 5 * 5 + 11 * 11 * 11 ) * 32 ; <nl> f -> avctx -> extradata = av_malloc ( f -> avctx -> extradata_size ); <nl> + if (! f -> avctx -> extradata ) <nl> + return AVERROR ( ENOMEM ); <nl> ff_init_range_encoder ( c , f -> avctx -> extradata , f -> avctx -> extradata_size ); <nl> ff_build_rac_states ( c , 0 . 05 * ( 1LL << 32 ), 256 - 8 ); <nl> 
static int mjpeg_decode_app ( MJpegDecodeContext * s ) <nl>  <nl> if ( id == AV_RB32 (" JFIF ")) { <nl> int t_w , t_h , v1 , v2 ; <nl> + if ( len < 8 ) <nl> + goto out ; <nl> skip_bits (& s -> gb , 8 ); /* the trailing zero - byte */ <nl> v1 = get_bits (& s -> gb , 8 ); <nl> v2 = get_bits (& s -> gb , 8 );
static int handle_eac3 ( MOVMuxContext * mov , AVPacket * pkt , MOVTrack * track ) <nl> info -> ec3_done = 1 ; <nl> goto concatenate ; <nl> } <nl> + } else { <nl> + if ( hdr -> substreamid != 0 ) { <nl> + avpriv_request_sample ( mov -> fc , " Multiple non EAC3 independent substreams "); <nl> + ret = AVERROR_PATCHWELCOME ; <nl> + goto end ; <nl> + } <nl> } <nl>  <nl> /* fill the info needed for the " dec3 " atom */
static const struct URLProtocol * url_find_protocol ( const char * filename ) <nl> return up ; <nl> } <nl> } <nl> + av_freep (& protocols ); <nl>  <nl> return NULL ; <nl> }
make_setup_request ( AVFormatContext * s , const char * host , int port , <nl> rtp_opened : <nl> port = rtp_get_local_port ( rtsp_st -> rtp_handle ); <nl> snprintf ( transport , sizeof ( transport ) - 1 , <nl> - "% s / UDP ; unicast ; client_port =% d ", <nl> - trans_pref , port ); <nl> + "% s / UDP ;", trans_pref ); <nl> + if ( rt -> server_type != RTSP_SERVER_REAL ) <nl> + av_strlcat ( transport , " unicast ;", sizeof ( transport )); <nl> + av_strlcatf ( transport , sizeof ( transport ), <nl> + " client_port =% d ", port ); <nl> if ( rt -> server_type == RTSP_SERVER_RTP ) <nl> av_strlcatf ( transport , sizeof ( transport ), "-% d ", port + 1 ); <nl> }
static int ogg_read_page ( AVFormatContext * s , int * str ) <nl>  <nl> if ( flags & OGG_FLAG_CONT || os -> incomplete ){ <nl> if (! os -> psize ){ <nl> + // If this is the very first segment we started <nl> + // playback in the middle of a continuation packet . <nl> + // Discard it since we missed the start of it . <nl> while ( os -> segp < os -> nsegs ){ <nl> int seg = os -> segments [ os -> segp ++]; <nl> os -> pstart += seg ; <nl> static int ogg_packet ( AVFormatContext * s , int * str , int * dstart , int * dsize , <nl>  <nl> if (! complete && os -> segp == os -> nsegs ){ <nl> ogg -> curidx = - 1 ; <nl> - os -> incomplete = 1 ; <nl> + // Do not set incomplete for empty packets . <nl> + // Together with the code in ogg_read_page <nl> + // that discards all continuation of empty packets <nl> + // we would get an infinite loop . <nl> + os -> incomplete = !! os -> psize ; <nl> } <nl> } while (! complete ); <nl> 
static int find_start_code ( const uint8_t * buf , int buf_size , <nl> buf [ buf_index + 2 ] == 1 ) <nl> break ; <nl>  <nl> - if ( buf_index + 3 >= buf_size ) <nl> + buf_index += 3 ; <nl> + <nl> + if ( buf_index >= buf_size ) <nl> return buf_size ; <nl>  <nl> - return buf_index + 3 ; <nl> + return buf_index ; <nl> } <nl>  <nl> static int get_avc_nalsize ( H264Context * h , const uint8_t * buf ,
fail : <nl> fail_at_end : <nl> av_freep (& pic -> codec_picture_params ); <nl> av_frame_free (& pic -> recon_image ); <nl> + av_buffer_unref (& pic -> output_buffer_ref ); <nl> + pic -> output_buffer = VA_INVALID_ID ; <nl> return err ; <nl> } <nl> 
int av_parser_parse2 ( AVCodecParserContext * s , AVCodecContext * avctx , <nl> int index , i ; <nl> uint8_t dummy_buf [ AV_INPUT_BUFFER_PADDING_SIZE ]; <nl>  <nl> + /* Parsers only work for the specified codec ids . */ <nl> + av_assert1 ( avctx -> codec_id == s -> parser -> codec_ids [ 0 ] || <nl> + avctx -> codec_id == s -> parser -> codec_ids [ 1 ] || <nl> + avctx -> codec_id == s -> parser -> codec_ids [ 2 ] || <nl> + avctx -> codec_id == s -> parser -> codec_ids [ 3 ] || <nl> + avctx -> codec_id == s -> parser -> codec_ids [ 4 ]); <nl> + <nl> if (!( s -> flags & PARSER_FLAG_FETCHED_OFFSET )) { <nl> s -> next_frame_offset = <nl> s -> cur_offset = pos ;
static int dfa_probe ( AVProbeData * p ) <nl> if ( p -> buf_size < 4 || AV_RL32 ( p -> buf ) != MKTAG (' D ', ' F ', ' I ', ' A ')) <nl> return 0 ; <nl>  <nl> + if ( AV_RL32 ( p -> buf + 16 ) != 0x80 ) <nl> + return AVPROBE_SCORE_MAX / 4 ; <nl> + <nl> return AVPROBE_SCORE_MAX ; <nl> } <nl> 
ImgReSampleContext * img_resample_full_init ( int owidth , int oheight , <nl> { <nl> ImgReSampleContext * s ; <nl>  <nl> + if (! owidth || ! oheight || ! iwidth || ! iheight ) <nl> + return NULL ; <nl> + <nl> s = av_mallocz ( sizeof ( ImgReSampleContext )); <nl> if (! s ) <nl> return NULL ;
static int tls_client_handshake_loop ( URLContext * h , int initial ) <nl> TLSContext * c = h -> priv_data ; <nl> TLSShared * s = & c -> tls_shared ; <nl> SECURITY_STATUS sspi_ret ; <nl> - SecBuffer outbuf [ 3 ]; <nl> + SecBuffer outbuf [ 3 ] = { 0 }; <nl> SecBufferDesc outbuf_desc ; <nl> SecBuffer inbuf [ 2 ]; <nl> SecBufferDesc inbuf_desc ;
static int decode_slice_header ( H264Context * h , H264Context * h0 ) <nl> av_log ( h -> avctx , AV_LOG_DEBUG , " Frame num gap % d % d \ n ", <nl> h -> frame_num , h -> prev_frame_num ); <nl> ret = h264_frame_start ( h ); <nl> - if ( ret < 0 ) <nl> + if ( ret < 0 ) { <nl> + h0 -> first_field = 0 ; <nl> return ret ; <nl> + } <nl> + <nl> h -> prev_frame_num ++; <nl> h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num ; <nl> h -> cur_pic_ptr -> frame_num = h -> prev_frame_num ;
static av_cold int ptx_init ( AVCodecContext * avctx ) { <nl> static int ptx_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , <nl> AVPacket * avpkt ) { <nl> const uint8_t * buf = avpkt -> data ; <nl> + const uint8_t * buf_end = avpkt -> data + avpkt -> size ; <nl> PTXContext * const s = avctx -> priv_data ; <nl> AVFrame * picture = data ; <nl> AVFrame * const p = & s -> picture ; <nl> unsigned int offset , w , h , y , stride , bytes_per_pixel ; <nl> uint8_t * ptr ; <nl>  <nl> + if ( buf_end - buf < 14 ) <nl> + return AVERROR_INVALIDDATA ; <nl> offset = AV_RL16 ( buf ); <nl> w = AV_RL16 ( buf + 8 ); <nl> h = AV_RL16 ( buf + 10 ); <nl> static int ptx_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , <nl>  <nl> avctx -> pix_fmt = PIX_FMT_RGB555 ; <nl>  <nl> + if ( buf_end - buf < offset ) <nl> + return AVERROR_INVALIDDATA ; <nl> if ( offset != 0x2c ) <nl> av_log_ask_for_sample ( avctx , " offset != 0x2c \ n "); <nl>  <nl> static int ptx_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , <nl> stride = p -> linesize [ 0 ]; <nl>  <nl> for ( y = 0 ; y < h ; y ++) { <nl> + if ( buf_end - buf < w * bytes_per_pixel ) <nl> + break ; <nl> # if HAVE_BIGENDIAN <nl> unsigned int x ; <nl> for ( x = 0 ; x < w * bytes_per_pixel ; x += bytes_per_pixel )
static int remove_decoded_packets ( AVFormatContext * ctx , int64_t scr ){ <nl> while ( pkt_desc && scr > pkt_desc -> dts ){ // FIXME > vs >= <nl> if ( stream -> buffer_index < pkt_desc -> size || <nl> stream -> predecode_packet == stream -> premux_packet ){ <nl> - av_log ( ctx , AV_LOG_ERROR , " buffer underflow \ n "); <nl> + av_log ( ctx , AV_LOG_ERROR , <nl> + " buffer underflow i =% d bufi =% d size =% d \ n ", <nl> + i , stream -> buffer_index , pkt_desc -> size ); <nl> break ; <nl> } <nl> stream -> buffer_index -= pkt_desc -> size ;
do { \ <nl> # define SAMPLES_NEEDED_2 ( why ) \ <nl> av_log ( NULL , AV_LOG_INFO ," This file triggers some missing code . Please contact the developers .\ nPosition : % s \ n ", why ); <nl>  <nl> +# define QDM2_MAX_FRAME_SIZE 512 <nl>  <nl> typedef int8_t sb_int8_array [ 2 ][ 30 ][ 64 ]; <nl>  <nl> typedef struct { <nl> /// I / O data <nl> const uint8_t * compressed_data ; <nl> int compressed_size ; <nl> - float output_buffer [ 1024 ]; <nl> + float output_buffer [ QDM2_MAX_FRAME_SIZE * 2 ]; <nl>  <nl> /// Synthesis filter <nl> MPADSPContext mpadsp ; <nl> static av_cold int qdm2_decode_init ( AVCodecContext * avctx ) <nl>  <nl> avctx -> channels = s -> nb_channels = s -> channels = AV_RB32 ( extradata ); <nl> extradata += 4 ; <nl> + if ( s -> channels > MPA_MAX_CHANNELS ) <nl> + return AVERROR_INVALIDDATA ; <nl>  <nl> avctx -> sample_rate = AV_RB32 ( extradata ); <nl> extradata += 4 ; <nl> static av_cold int qdm2_decode_init ( AVCodecContext * avctx ) <nl> // something like max decodable tones <nl> s -> group_order = av_log2 ( s -> group_size ) + 1 ; <nl> s -> frame_size = s -> group_size / 16 ; // 16 iterations per super block <nl> + if ( s -> frame_size > QDM2_MAX_FRAME_SIZE ) <nl> + return AVERROR_INVALIDDATA ; <nl>  <nl> s -> sub_sampling = s -> fft_order - 7 ; <nl> s -> frequency_range = 255 / ( 1 << ( 2 - s -> sub_sampling ));
static inline int ape_decode_value_3900 ( APEContext * ctx , APERice * rice ) <nl> } else <nl> tmpk = ( rice -> k < 1 ) ? 0 : rice -> k - 1 ; <nl>  <nl> - if ( tmpk <= 16 || ctx -> fileversion < 3910 ) <nl> + if ( tmpk <= 16 || ctx -> fileversion < 3910 ) { <nl> + if ( tmpk > 23 ) { <nl> + av_log ( ctx -> avctx , AV_LOG_ERROR , " Too many bits : % d \ n ", tmpk ); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> x = range_decode_bits ( ctx , tmpk ); <nl> - else if ( tmpk <= 32 ) { <nl> + } else if ( tmpk <= 32 ) { <nl> x = range_decode_bits ( ctx , 16 ); <nl> x |= ( range_decode_bits ( ctx , tmpk - 16 ) << 16 ); <nl> } else {
static void ff_eac3_decode_transform_coeffs_aht_ch ( AC3DecodeContext * s , int ch ) <nl> /* Vector Quantization */ <nl> int v = get_bits ( gbc , bits ); <nl> for ( blk = 0 ; blk < 6 ; blk ++) { <nl> - s -> pre_mantissa [ ch ][ bin ][ blk ] = ff_eac3_mantissa_vq [ hebap ][ v ][ blk ] << 8 ; <nl> + s -> pre_mantissa [ ch ][ bin ][ blk ] = ff_eac3_mantissa_vq [ hebap ][ v ][ blk ] * ( 1 << 8 ); <nl> } <nl> } else { <nl> /* Gain Adaptive Quantization */ <nl> static void ff_eac3_decode_transform_coeffs_aht_ch ( AC3DecodeContext * s , int ch ) <nl> int b ; <nl> int mbits = bits - ( 2 - log_gain ); <nl> mant = get_sbits ( gbc , mbits ); <nl> - mant <<= ( 23 - ( mbits - 1 )); <nl> + mant = (( unsigned ) mant ) << ( 23 - ( mbits - 1 )); <nl> /* remap mantissa value to correct for asymmetric quantization */ <nl> if ( mant >= 0 ) <nl> b = 1 << ( 23 - log_gain ); <nl> else <nl> - b = ff_eac3_gaq_remap_2_4_b [ hebap - 8 ][ log_gain - 1 ] << 8 ; <nl> + b = ff_eac3_gaq_remap_2_4_b [ hebap - 8 ][ log_gain - 1 ] * ( 1 << 8 ); <nl> mant += (( ff_eac3_gaq_remap_2_4_a [ hebap - 8 ][ log_gain - 1 ] * ( int64_t ) mant ) >> 15 ) + b ; <nl> } else { <nl> /* small mantissa , no GAQ , or Gk = 1 */
static int filter_frame ( AVFilterLink * inlink , AVFrame * in ) <nl> { <nl> AVFilterContext * ctx = inlink -> dst ; <nl> ReverseContext * s = ctx -> priv ; <nl> + void * ptr ; <nl>  <nl> - if ( s -> nb_frames + 1 > s -> frames_size / sizeof (*( s -> frames ))) { <nl> - void * ptr ; <nl> - <nl> + if ( s -> nb_frames + 1 > s -> pts_size / sizeof (*( s -> pts ))) { <nl> ptr = av_fast_realloc ( s -> pts , & s -> pts_size , s -> pts_size * 2 ); <nl> if (! ptr ) <nl> return AVERROR ( ENOMEM ); <nl> s -> pts = ptr ; <nl> + } <nl>  <nl> + if ( s -> nb_frames + 1 > s -> frames_size / sizeof (*( s -> frames ))) { <nl> ptr = av_fast_realloc ( s -> frames , & s -> frames_size , s -> frames_size * 2 ); <nl> if (! ptr ) <nl> return AVERROR ( ENOMEM );
static int decode_frame ( AVCodecContext * avctx , void * data , <nl> // Zero out the start if ymin is not 0 <nl> for ( i = 0 ; i < planes ; i ++) { <nl> ptr = picture -> data [ i ]; <nl> - for ( y = 0 ; y < s -> ymin ; y ++) { <nl> + for ( y = 0 ; y < FFMIN ( s -> ymin , s -> h ); y ++) { <nl> memset ( ptr , 0 , out_line_size ); <nl> ptr += picture -> linesize [ i ]; <nl> }
int ff_dirac_golomb_read_16bit ( DiracGolombLUT * lut_ctx , const uint8_t * buf , <nl> if (( c_idx + 1 ) > coeffs ) <nl> return c_idx ; <nl>  <nl> + if ( res_bits >= RSIZE_BITS ) <nl> + res_bits = res = 0 ; <nl> + <nl> if ( res_bits && l -> sign ) { <nl> int32_t coeff = 1 ; <nl> APPEND_RESIDUE ( res , l -> preamble );
enum AVCodecID av_codec_get_id ( const AVCodecTag * const * tags , unsigned int tag ) <nl> static void compute_chapters_end ( AVFormatContext * s ) <nl> { <nl> unsigned int i , j ; <nl> - int64_t max_time = s -> duration + <nl> + int64_t max_time = 0 ; <nl> + <nl> + if ( s -> duration > 0 ) <nl> + max_time = s -> duration + <nl> (( s -> start_time == AV_NOPTS_VALUE ) ? 0 : s -> start_time ); <nl>  <nl> for ( i = 0 ; i < s -> nb_chapters ; i ++)
static int get_cookies ( HTTPContext * s , char ** cookies , const char * path , <nl> while (( param = av_strtok ( cookie , "; ", & next_param ))) { <nl> cookie = NULL ; <nl> if (! av_strncasecmp (" path =", param , 5 )) { <nl> + av_free ( cpath ); <nl> cpath = av_strdup (& param [ 5 ]); <nl> } else if (! av_strncasecmp (" domain =", param , 7 )) { <nl> + av_free ( cdomain ); <nl> cdomain = av_strdup (& param [ 7 ]); <nl> } else if (! av_strncasecmp (" secure ", param , 6 ) || <nl> ! av_strncasecmp (" comment ", param , 7 ) || <nl> static int get_cookies ( HTTPContext * s , char ** cookies , const char * path , <nl> ! av_strncasecmp (" version ", param , 7 )) { <nl> // ignore Comment , Max - Age , Secure and Version <nl> } else { <nl> + av_free ( cvalue ); <nl> cvalue = av_strdup ( param ); <nl> } <nl> }
static void apply_channel_coupling ( AC3EncodeContext * s ) <nl> # else <nl> int32_t (* fixed_cpl_coords )[ AC3_MAX_CHANNELS ][ 16 ] = cpl_coords ; <nl> # endif <nl> - int blk , ch , bnd , i , j ; <nl> + int av_uninit ( blk ), ch , bnd , i , j ; <nl> CoefSumType energy [ AC3_MAX_BLOCKS ][ AC3_MAX_CHANNELS ][ 16 ] = {{{ 0 }}}; <nl> int cpl_start , num_cpl_coefs ; <nl> 
static int submit_stats ( AVCodecContext * avctx ) <nl> } <nl> h -> stats_size = strlen ( avctx -> stats_in ) * 3 / 4 ; <nl> h -> stats = av_malloc ( h -> stats_size ); <nl> + if (! h -> stats ) { <nl> + h -> stats_size = 0 ; <nl> + return AVERROR ( ENOMEM ); <nl> + } <nl> h -> stats_size = av_base64_decode ( h -> stats , avctx -> stats_in , h -> stats_size ); <nl> } <nl> while ( h -> stats_size - h -> stats_offset > 0 ) {
static int open_slave ( AVFormatContext * avf , char * slave , TeeSlave * tee_slave ) <nl>  <nl> end : <nl> av_free ( format ); <nl> + av_free ( select ); <nl> av_dict_free (& options ); <nl> return ret ; <nl> }
static void decode_pitch_lag_low ( int * lag_int , int * lag_frac , int pitch_index , <nl> if ( subframe == 0 || ( subframe == 2 && mode != MODE_6k60 )) { <nl> if ( pitch_index < 116 ) { <nl> * lag_int = ( pitch_index + 69 ) >> 1 ; <nl> - * lag_frac = ( pitch_index - (* lag_int << 1 ) + 68 ) << 1 ; <nl> + * lag_frac = ( pitch_index - (* lag_int << 1 ) + 68 ) * 2 ; <nl> } else { <nl> * lag_int = pitch_index - 24 ; <nl> * lag_frac = 0 ; <nl> static void decode_pitch_lag_low ( int * lag_int , int * lag_frac , int pitch_index , <nl> AMRWB_P_DELAY_MIN , AMRWB_P_DELAY_MAX - 15 ); <nl> } else { <nl> * lag_int = ( pitch_index + 1 ) >> 1 ; <nl> - * lag_frac = ( pitch_index - (* lag_int << 1 )) << 1 ; <nl> + * lag_frac = ( pitch_index - (* lag_int << 1 )) * 2 ; <nl> * lag_int += * base_lag_int ; <nl> } <nl> }
static int decode_slice ( struct AVCodecContext * avctx , void * arg ) <nl> avctx -> codec_id != AV_CODEC_ID_H264 || <nl> ( CONFIG_GRAY && ( h -> flags & CODEC_FLAG_GRAY )); <nl>  <nl> - if (!( h -> avctx -> active_thread_type & FF_THREAD_SLICE ) && h -> picture_structure == PICT_FRAME ) { <nl> + if (!( h -> avctx -> active_thread_type & FF_THREAD_SLICE ) && h -> picture_structure == PICT_FRAME && h -> er . error_status_table ) { <nl> const int start_i = av_clip ( h -> resync_mb_x + h -> resync_mb_y * h -> mb_width , 0 , h -> mb_num - 1 ); <nl> if ( start_i ) { <nl> int prev_status = h -> er . error_status_table [ h -> er . mb_index2xy [ start_i - 1 ]];
static int vc1_decode_frame ( AVCodecContext * avctx , void * data , <nl> if ( avctx -> codec_id == AV_CODEC_ID_VC1 || avctx -> codec_id == AV_CODEC_ID_VC1IMAGE ) { <nl> int buf_size2 = 0 ; <nl> buf2 = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ); <nl> + if (! buf2 ) <nl> + return AVERROR ( ENOMEM ); <nl>  <nl> if ( IS_MARKER ( AV_RB32 ( buf ))) { /* frame starts with marker and needs to be parsed */ <nl> const uint8_t * start , * end , * next ;
AVStream * avformat_new_stream ( AVFormatContext * s , const AVCodec * c ) <nl> } <nl>  <nl> st -> codec = avcodec_alloc_context3 ( c ); <nl> + if (! st -> codec ) { <nl> + av_free ( st -> info ); <nl> + av_free ( st ); <nl> + return NULL ; <nl> + } <nl> if ( s -> iformat ) { <nl> /* no default bitrate if decoding */ <nl> st -> codec -> bit_rate = 0 ;
/* <nl> * Copyright ( c ) 2002 Jindrich Makovicka < makovick @ gmail . com > <nl> * Copyright ( c ) 2011 Stefano Sabatini <nl> - * Copyright ( c ) 2013 Jean Delvare < jdelvare @ suse . com > <nl> + * Copyright ( c ) 2013 , 2015 Jean Delvare < jdelvare @ suse . com > <nl> * <nl> * This file is part of FFmpeg . <nl> * <nl> static void apply_delogo ( uint8_t * dst , int dst_linesize , <nl> xdst = dst + logo_x1 + 1 , <nl> xsrc = src + logo_x1 + 1 ; x < logo_x2 - 1 ; x ++, xdst ++, xsrc ++) { <nl>  <nl> + if ( show && ( y == logo_y + 1 || y == logo_y + logo_h - 2 || <nl> + x == logo_x + 1 || x == logo_x + logo_w - 2 )) { <nl> + * xdst = 0 ; <nl> + continue ; <nl> + } <nl> + <nl> /* Weighted interpolation based on relative distances , taking SAR into account */ <nl> weightl = ( uint64_t ) ( logo_x2 - 1 - x ) * ( y - logo_y1 ) * ( logo_y2 - 1 - y ) * sar . den ; <nl> weightr = ( uint64_t )( x - logo_x1 ) * ( y - logo_y1 ) * ( logo_y2 - 1 - y ) * sar . den ; <nl> static void apply_delogo ( uint8_t * dst , int dst_linesize , <nl> dist = FFMAX ( dist , y -( logo_y + logo_h - 1 - band )); <nl>  <nl> * xdst = (* xsrc * dist + interp *( band - dist ))/ band ; <nl> - if ( show && ( dist == band - 1 )) <nl> - * xdst = 0 ; <nl> } <nl> } <nl> 
# include " fft . h " <nl> # include " aacps . h " <nl> # include " libavutil / libm . h " <nl> +# include " libavutil / avassert . h " <nl>  <nl> # include < stdint . h > <nl> # include < float . h > <nl> static void sbr_mapping ( AACContext * ac , SpectralBandReplication * sbr , <nl> uint16_t * table = ch_data -> bs_freq_res [ e + 1 ] ? sbr -> f_tablehigh : sbr -> f_tablelow ; <nl> int k ; <nl>  <nl> + av_assert0 ( sbr -> kx [ 1 ] <= table [ 0 ]); <nl> for ( i = 0 ; i < ilim ; i ++) <nl> for ( m = table [ i ]; m < table [ i + 1 ]; m ++) <nl> sbr -> e_origmapped [ e ][ m - sbr -> kx [ 1 ]] = ch_data -> env_facs [ e + 1 ][ i ];
static int v4l2_read_header ( AVFormatContext * s1 ) <nl> } <nl>  <nl> if (! s -> width && ! s -> height ) { <nl> - struct v4l2_format fmt ; <nl> + struct v4l2_format fmt = { . type = V4L2_BUF_TYPE_VIDEO_CAPTURE }; <nl>  <nl> av_log ( s1 , AV_LOG_VERBOSE , <nl> " Querying the device for the current frame size \ n "); <nl> - fmt . type = V4L2_BUF_TYPE_VIDEO_CAPTURE ; <nl> if ( v4l2_ioctl ( s -> fd , VIDIOC_G_FMT , & fmt ) < 0 ) { <nl> res = AVERROR ( errno ); <nl> av_log ( s1 , AV_LOG_ERROR , " ioctl ( VIDIOC_G_FMT ): % s \ n ", av_err2str ( res ));
static int avs_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> sub_type = avio_r8 ( s -> pb ); <nl> type = avio_r8 ( s -> pb ); <nl> size = avio_rl16 ( s -> pb ); <nl> + if ( size < 4 ) <nl> + return AVERROR_INVALIDDATA ; <nl> avs -> remaining_frame_size -= size ; <nl>  <nl> switch ( type ) {
static int aasc_decode_frame ( AVCodecContext * avctx , <nl> AascContext * s = avctx -> priv_data ; <nl> int compr , i , stride , ret ; <nl>  <nl> + if ( buf_size < 4 ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> if (( ret = ff_reget_buffer ( avctx , s -> frame )) < 0 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " reget_buffer () failed \ n "); <nl> return ret ; <nl> static int aasc_decode_frame ( AVCodecContext * avctx , <nl> switch ( compr ) { <nl> case 0 : <nl> stride = ( avctx -> width * 3 + 3 ) & ~ 3 ; <nl> + if ( buf_size < stride * avctx -> height ) <nl> + return AVERROR_INVALIDDATA ; <nl> for ( i = avctx -> height - 1 ; i >= 0 ; i --) { <nl> memcpy ( s -> frame -> data [ 0 ] + i * s -> frame -> linesize [ 0 ], buf , avctx -> width * 3 ); <nl> buf += stride ;
static void sbr_qmf_synthesis ( DSPContext * dsp , FFTContext * mdct , <nl> const float * sbr_qmf_window = div ? sbr_qmf_window_ds : sbr_qmf_window_us ; <nl> float * v ; <nl> for ( i = 0 ; i < 32 ; i ++) { <nl> - if (* v_off == 0 ) { <nl> + if (* v_off < 128 >> div ) { <nl> int saved_samples = ( 1280 - 128 ) >> div ; <nl> memcpy (& v0 [ SBR_SYNTHESIS_BUF_SIZE - saved_samples ], v0 , saved_samples * sizeof ( float )); <nl> * v_off = SBR_SYNTHESIS_BUF_SIZE - saved_samples - ( 128 >> div );
static int rm_read_audio_stream_info ( AVFormatContext * s , AVIOContext * pb , <nl> if ( ast -> sub_packet_size <= 0 || <nl> ast -> sub_packet_size > ast -> audio_framesize ) <nl> return AVERROR_INVALIDDATA ; <nl> + if ( ast -> audio_framesize % ast -> sub_packet_size ) <nl> + return AVERROR_INVALIDDATA ; <nl> break ; <nl> case DEINT_ID_SIPR : <nl> case DEINT_ID_INT0 :
av_cold void ff_psy_preprocess_end ( struct FFPsyPreprocessContext * ctx ) <nl> for ( i = 0 ; i < ctx -> avctx -> channels ; i ++) <nl> ff_iir_filter_free_state ( ctx -> fstate [ i ]); <nl> av_freep (& ctx -> fstate ); <nl> + av_free ( ctx ); <nl> } <nl> 
static int dv1394_close ( AVFormatContext * context ) <nl> av_log ( context , AV_LOG_ERROR , " Failed to munmap DV1394 ring buffer : % s \ n ", strerror ( errno )); <nl>  <nl> close ( dv -> fd ); <nl> - av_free ( dv -> dv_demux ); <nl> + av_freep (& dv -> dv_demux ); <nl>  <nl> return 0 ; <nl> }
int ff_ass_split_override_codes ( const ASSCodesCallbacks * callbacks , void * priv , <nl> char new_line [ 2 ]; <nl> int text_len = 0 ; <nl>  <nl> - while (* buf ) { <nl> + while ( buf && * buf ) { <nl> if ( text && callbacks -> text && <nl> ( sscanf ( buf , "\\% 1 [ nN ]", new_line ) == 1 || <nl> ! strncmp ( buf , "{\\", 2 ))) {
static int bit_allocation ( IMCContext * q , IMCChannel * chctx , <nl> iacc += chctx -> bandWidthT [ i ]; <nl> summa += chctx -> bandWidthT [ i ] * chctx -> flcoeffs4 [ i ]; <nl> } <nl> + <nl> + if (! iacc ) <nl> + return AVERROR_INVALIDDATA ; <nl> + <nl> chctx -> bandWidthT [ BANDS - 1 ] = 0 ; <nl> summa = ( summa * 0 . 5 - freebits ) / iacc ; <nl> 
static int wavpack_decode_block ( AVCodecContext * avctx , int block_no , <nl> } <nl> switch ( id & WP_IDF_MASK ){ <nl> case WP_ID_DECTERMS : <nl> - s -> terms = size ; <nl> - if ( s -> terms > MAX_TERMS ){ <nl> + if ( size > MAX_TERMS ){ <nl> av_log ( avctx , AV_LOG_ERROR , " Too many decorrelation terms \ n "); <nl> + s -> terms = 0 ; <nl> buf += ssize ; <nl> continue ; <nl> } <nl> + s -> terms = size ; <nl> for ( i = 0 ; i < s -> terms ; i ++) { <nl> s -> decorr [ s -> terms - i - 1 ]. value = (* buf & 0x1F ) - 5 ; <nl> s -> decorr [ s -> terms - i - 1 ]. delta = * buf >> 5 ;
static int decode_header_trees ( SmackVContext * smk ) { <nl> full_size = AV_RL32 ( smk -> avctx -> extradata + 8 ); <nl> type_size = AV_RL32 ( smk -> avctx -> extradata + 12 ); <nl>  <nl> - init_get_bits8 (& gb , smk -> avctx -> extradata + 16 , smk -> avctx -> extradata_size - 16 ); <nl> + ret = init_get_bits8 (& gb , smk -> avctx -> extradata + 16 , smk -> avctx -> extradata_size - 16 ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl>  <nl> if (! get_bits1 (& gb )) { <nl> av_log ( smk -> avctx , AV_LOG_INFO , " Skipping MMAP tree \ n ");
static int read_extra_header ( FFV1Context * f ) <nl> f -> quant_table_count = get_symbol ( c , state , 0 ); <nl> if ( f -> quant_table_count > ( unsigned ) MAX_QUANT_TABLES || ! f -> quant_table_count ) { <nl> av_log ( f -> avctx , AV_LOG_ERROR , " quant table count % d is invalid \ n ", f -> quant_table_count ); <nl> + f -> quant_table_count = 0 ; <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> 
static int read_quant_table ( RangeCoder * c , int16_t * quant_table , int scale ){ <nl> memset ( state , 128 , sizeof ( state )); <nl>  <nl> for ( v = 0 ; i < 128 ; v ++){ <nl> - int len = get_symbol ( c , state , 0 ) + 1 ; <nl> + unsigned len = get_symbol ( c , state , 0 ) + 1 ; <nl>  <nl> - if ( len + i > 128 ) return - 1 ; <nl> + if ( len > 128 - i ) return - 1 ; <nl>  <nl> while ( len --){ <nl> quant_table [ i ] = scale * v ;
static av_cold int decode_end ( AVCodecContext * avctx ) <nl> { <nl> MadContext * t = avctx -> priv_data ; <nl> av_frame_free (& t -> last_frame ); <nl> - av_free ( t -> bitstream_buf ); <nl> + av_freep (& t -> bitstream_buf ); <nl> return 0 ; <nl> } <nl> 
static void exit_program ( void ) <nl> /* close files */ <nl> for ( i = 0 ; i < nb_output_files ; i ++) { <nl> AVFormatContext * s = output_files [ i ]-> ctx ; <nl> - if (!( s -> oformat -> flags & AVFMT_NOFILE ) && s -> pb ) <nl> + if ( s && s -> oformat && !( s -> oformat -> flags & AVFMT_NOFILE ) && s -> pb ) <nl> avio_close ( s -> pb ); <nl> avformat_free_context ( s ); <nl> av_dict_free (& output_files [ i ]-> opts );
static int ivr_probe ( AVProbeData * p ) <nl> static int ivr_read_header ( AVFormatContext * s ) <nl> { <nl> unsigned tag , type , len , tlen , value ; <nl> - int i , j , n , count , nb_streams , ret ; <nl> + int i , j , n , count , nb_streams = 0 , ret ; <nl> uint8_t key [ 256 ], val [ 256 ]; <nl> AVIOContext * pb = s -> pb ; <nl> AVStream * st ;
static int mmap_read_frame ( struct video_data * s , void * frame , int64_t * ts ) <nl> return - 1 ; <nl> } <nl> assert ( buf . index < s -> buffers ); <nl> - assert ( buf . bytesused == s -> frame_size ); <nl> + if ( buf . bytesused != s -> frame_size ) { <nl> + av_log ( NULL , AV_LOG_ERROR , " The v4l2 frame is % d bytes , but % d bytes are expected \ n ", buf . bytesused , s -> frame_size ); <nl> + <nl> + return - 1 ; <nl> + } <nl> + <nl> /* Image is at s -> buff_start [ buf . index ] */ <nl> memcpy ( frame , s -> buf_start [ buf . index ], buf . bytesused ); <nl> * ts = buf . timestamp . tv_sec * int64_t_C ( 1000000 ) + buf . timestamp . tv_usec ;
static int cdxl_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> if ( cdxl -> framerate ) <nl> st -> duration = frames ; <nl> else <nl> - st -> duration = frames * audio_size ; <nl> + st -> duration = frames * ( int64_t ) audio_size ; <nl> } <nl> st -> start_time = 0 ; <nl> cdxl -> video_stream_index = st -> index ;
static int ogg_build_flac_headers ( AVCodecContext * avctx , <nl> oggstream -> header_len [ 0 ] = 51 ; <nl> oggstream -> header [ 0 ] = av_mallocz ( 51 ); // per ogg flac specs <nl> p = oggstream -> header [ 0 ]; <nl> + if (! p ) <nl> + return AVERROR_NOMEM ; <nl> bytestream_put_byte (& p , 0x7F ); <nl> bytestream_put_buffer (& p , " FLAC ", 4 ); <nl> bytestream_put_byte (& p , 1 ); // major version <nl> static int ogg_build_flac_headers ( AVCodecContext * avctx , <nl> oggstream -> header_len [ 1 ] = 1 + 3 + 4 + strlen ( vendor )+ 4 ; <nl> oggstream -> header [ 1 ] = av_mallocz ( oggstream -> header_len [ 1 ]); <nl> p = oggstream -> header [ 1 ]; <nl> + if (! p ) <nl> + return AVERROR_NOMEM ; <nl> bytestream_put_byte (& p , 0x84 ); // last metadata block and vorbis comment <nl> bytestream_put_be24 (& p , oggstream -> header_len [ 1 ] - 4 ); <nl> bytestream_put_le32 (& p , strlen ( vendor ));
static int mp3_read_probe ( AVProbeData * p ) <nl> const uint8_t * buf , * buf0 , * buf2 , * end ; <nl> AVCodecContext * avctx = avcodec_alloc_context3 ( NULL ); <nl>  <nl> + if (! avctx ) <nl> + return 0 ; <nl> + <nl> buf0 = p -> buf ; <nl> end = p -> buf + p -> buf_size - sizeof ( uint32_t ); <nl> while ( buf0 < end && !* buf0 )
static int mov_write_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> /* copy frame to create needed atoms */ <nl> trk -> vosLen = size ; <nl> trk -> vosData = av_malloc ( size ); <nl> + if (! trk -> vosData ) <nl> + return AVERROR ( ENOMEM ); <nl> memcpy ( trk -> vosData , pkt -> data , size ); <nl> } <nl> 
 <nl> static const uint8_t * avc_mp4_find_startcode ( const uint8_t * start , const uint8_t * end , int nal_length_size ) <nl> { <nl> - int res = 0 ; <nl> + unsigned int res = 0 ; <nl>  <nl> if ( end - start < nal_length_size ) <nl> return NULL ; <nl> while ( nal_length_size --) <nl> res = ( res << 8 ) | * start ++; <nl>  <nl> - if ( start + res > end || res < 0 || start + res < start ) <nl> + if ( res > end - start ) <nl> return NULL ; <nl>  <nl> return start + res ;
static int oggvorbis_encode_frame ( AVCodecContext * avccontext , <nl> * not , apparently the end of stream decision is in libogg . */ <nl> if ( op . bytes == 1 && op . e_o_s ) <nl> continue ; <nl> + if ( context -> buffer_index + sizeof ( ogg_packet ) + op . bytes > BUFFER_SIZE ) { <nl> + av_log ( avccontext , AV_LOG_ERROR , " libvorbis : buffer overflow ."); <nl> + return - 1 ; <nl> + } <nl> memcpy ( context -> buffer + context -> buffer_index , & op , sizeof ( ogg_packet )); <nl> context -> buffer_index += sizeof ( ogg_packet ); <nl> memcpy ( context -> buffer + context -> buffer_index , op . packet , op . bytes ); <nl> static int oggvorbis_encode_frame ( AVCodecContext * avccontext , <nl> avccontext -> coded_frame -> pts = av_rescale_q ( op2 -> granulepos , ( AVRational ){ 1 , avccontext -> sample_rate }, avccontext -> time_base ); <nl> // FIXME we should reorder the user supplied pts and not assume that they are spaced by 1 / sample_rate <nl>  <nl> + if ( l > buf_size ) { <nl> + av_log ( avccontext , AV_LOG_ERROR , " libvorbis : buffer overflow ."); <nl> + return - 1 ; <nl> + } <nl> + <nl> memcpy ( packets , op2 -> packet , l ); <nl> context -> buffer_index -= l + sizeof ( ogg_packet ); <nl> memmove ( context -> buffer , context -> buffer + l + sizeof ( ogg_packet ), context -> buffer_index );
int ff_hevc_decode_nal_sps ( HEVCContext * s ) <nl> goto err ; <nl> } <nl>  <nl> + if (! s -> vps_list [ sps -> vps_id ]) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " VPS does not exist \ n "); <nl> + ret = AVERROR_INVALIDDATA ; <nl> + goto err ; <nl> + } <nl> + <nl> sps -> max_sub_layers = get_bits ( gb , 3 ) + 1 ; <nl> if ( sps -> max_sub_layers > MAX_SUB_LAYERS ) { <nl> av_log ( s -> avctx , AV_LOG_ERROR , " sps_max_sub_layers out of range : % d \ n ",
av_cold int ff_yuv2rgb_c_init_tables ( SwsContext * c , const int inv_table [ 4 ], int <nl> y_table32 = c -> yuvTable ; <nl> yb = -( 384 << 16 ) - oy ; <nl> for ( i = 0 ; i < 1024 ; i ++) { <nl> - uint8_t yval = av_clip_uint8 (( yb + 0x8000 ) >> 16 ); <nl> - y_table32 [ i ] = ( yval << rbase ) + ( needAlpha ? 0 : ( 255 << abase )); <nl> + unsigned yval = av_clip_uint8 (( yb + 0x8000 ) >> 16 ); <nl> + y_table32 [ i ] = ( yval << rbase ) + ( needAlpha ? 0 : ( 255u << abase )); <nl> y_table32 [ i + 1024 ] = yval << gbase ; <nl> y_table32 [ i + 2048 ] = yval << bbase ; <nl> yb += cy ;
static int dpcm_decode_frame ( AVCodecContext * avctx , void * data , <nl> int stereo = s -> channels - 1 ; <nl> int16_t * output_samples ; <nl>  <nl> + if ( stereo && ( buf_size & 1 )) { <nl> + buf_size --; <nl> + buf_end --; <nl> + } <nl> + <nl> /* calculate output size */ <nl> switch ( avctx -> codec -> id ) { <nl> case CODEC_ID_ROQ_DPCM : <nl> static int dpcm_decode_frame ( AVCodecContext * avctx , void * data , <nl> * got_frame_ptr = 1 ; <nl> *( AVFrame *) data = s -> frame ; <nl>  <nl> - return buf_size ; <nl> + return avpkt -> size ; <nl> } <nl>  <nl> # define DPCM_DECODER ( id_ , name_ , long_name_ ) \
*/ <nl> # include " avformat . h " <nl>  <nl> -# if ! defined ( CONFIG_NOCUTILS ) <nl> /** <nl> * Return TRUE if val is a prefix of str . If it returns TRUE , ptr is <nl> * set to the next character in ' str ' after the prefix . <nl> char * pstrcat ( char * buf , int buf_size , const char * s ) <nl> return buf ; <nl> } <nl>  <nl> -# endif <nl> - <nl> /* add one element to a dynamic array */ <nl> void __dynarray_add ( unsigned long ** tab_ptr , int * nb_ptr , unsigned long elem ) <nl> {
static int aic_decode_coeffs ( GetBitContext * gb , int16_t * dst , <nl> int has_skips , coeff_type , coeff_bits , skip_type , skip_bits ; <nl> const int num_coeffs = aic_num_band_coeffs [ band ]; <nl> const uint8_t * scan = aic_scan [ band ]; <nl> - int mb , idx , val ; <nl> + int mb , idx ; <nl> + unsigned val ; <nl>  <nl> has_skips = get_bits1 ( gb ); <nl> coeff_type = get_bits1 ( gb ); <nl> static int aic_decode_coeffs ( GetBitContext * gb , int16_t * dst , <nl> idx = - 1 ; <nl> do { <nl> GET_CODE ( val , skip_type , skip_bits ); <nl> + if ( val >= 0x10000 ) <nl> + return AVERROR_INVALIDDATA ; <nl> idx += val + 1 ; <nl> if ( idx >= num_coeffs ) <nl> break ;
static int config_input ( AVFilterLink * inlink ) <nl> spp -> hsub = desc -> log2_chroma_w ; <nl> spp -> vsub = desc -> log2_chroma_h ; <nl> spp -> temp_linesize = FFALIGN ( inlink -> w + 16 , 16 ); <nl> - spp -> temp = av_malloc ( spp -> temp_linesize * h * sizeof (* spp -> temp )); <nl> - spp -> src = av_malloc ( spp -> temp_linesize * h * sizeof (* spp -> src )); <nl> + spp -> temp = av_malloc_array ( spp -> temp_linesize , h * sizeof (* spp -> temp )); <nl> + spp -> src = av_malloc_array ( spp -> temp_linesize , h * sizeof (* spp -> src )); <nl> if (! spp -> use_bframe_qp ) { <nl> /* we are assuming here the qp blocks will not be smaller that 16x16 */ <nl> spp -> non_b_qp_alloc_size = FF_CEIL_RSHIFT ( inlink -> w , 4 ) * FF_CEIL_RSHIFT ( inlink -> h , 4 );
void ff_spatial_idwt_slice2 ( DWTContext * d , int y ); <nl> ( b1 + (( int )( b0 + ( unsigned )( b2 ) + 1 ) >> 1 )) <nl>  <nl> # define COMPOSE_DD97iH0 ( b0 , b1 , b2 , b3 , b4 )\ <nl> - ( b2 + (( int )(- b0 + 9U * b1 + 9U * b3 - b4 + 8 ) >> 4 )) <nl> + ( int )((( unsigned )( b2 ) + (( int )(- b0 + 9U * b1 + 9U * b3 - b4 + 8 ) >> 4 ))) <nl>  <nl> # define COMPOSE_DD137iL0 ( b0 , b1 , b2 , b3 , b4 )\ <nl> - ( b2 - (( int )(- b0 + 9U * b1 + 9U * b3 - b4 + 16 ) >> 5 )) <nl> + ( int )((( unsigned )( b2 ) - (( int )(- b0 + 9U * b1 + 9U * b3 - b4 + 16 ) >> 5 ))) <nl>  <nl> # define COMPOSE_HAARiL0 ( b0 , b1 )\ <nl> ( b0 - (( b1 + 1 ) >> 1 ))
typedef struct SmcContext { <nl> row_ptr += stride * 4 ; \ <nl> } \ <nl> total_blocks --; \ <nl> - if ( total_blocks < 0 ) \ <nl> + if ( total_blocks < !! n_blocks ) \ <nl> { \ <nl> av_log ( s -> avctx , AV_LOG_INFO , " warning : block counter just went negative ( this should not happen )\ n "); \ <nl> return ; \
# include " audioconvert . h " <nl> # include " libavutil / avassert . h " <nl> # include " libavutil / channel_layout . h " <nl> +# include " libavutil / internal . h " <nl>  <nl> # include < float . h > <nl>  <nl> int swr_is_initialized ( struct SwrContext * s ) { <nl> return !! s -> in_buffer . ch_count ; <nl> } <nl>  <nl> - int swr_convert ( struct SwrContext * s , uint8_t * out_arg [ SWR_CH_MAX ], int out_count , <nl> - const uint8_t * in_arg [ SWR_CH_MAX ], int in_count ){ <nl> + int attribute_align_arg swr_convert ( struct SwrContext * s , uint8_t * out_arg [ SWR_CH_MAX ], int out_count , <nl> + const uint8_t * in_arg [ SWR_CH_MAX ], int in_count ){ <nl> AudioData * in = & s -> in ; <nl> AudioData * out = & s -> out ; <nl> 
int ff_h264_decode_seq_parameter_set ( H264Context * h ){ <nl>  <nl> if ( sps -> profile_idc >= 100 ){ // high profile <nl> sps -> chroma_format_idc = get_ue_golomb_31 (& s -> gb ); <nl> + if ( sps -> chroma_format_idc > 3U ) { <nl> + av_log ( h -> s . avctx , AV_LOG_ERROR , " chroma_format_idc % d is illegal \ n ", sps -> chroma_format_idc ); <nl> + goto fail ; <nl> + } <nl> if ( sps -> chroma_format_idc == 3 ) <nl> sps -> residual_color_transform_flag = get_bits1 (& s -> gb ); <nl> sps -> bit_depth_luma = get_ue_golomb (& s -> gb ) + 8 ;
static int ape_decode_frame ( AVCodecContext * avctx , void * data , <nl> int32_t * sample24 ; <nl> int i , ch , ret ; <nl> int blockstodecode ; <nl> + uint64_t decoded_buffer_size ; <nl>  <nl> /* this should never be negative , but bad things will happen if it is , so <nl> check it just to make sure . */ <nl> static int ape_decode_frame ( AVCodecContext * avctx , void * data , <nl> skip_bits_long (& s -> gb , offset ); <nl> } <nl>  <nl> - if (! nblocks || nblocks > INT_MAX ) { <nl> + if (! nblocks || nblocks > INT_MAX / 2 / sizeof (* s -> decoded_buffer ) - 8 ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Invalid sample count : %" PRIu32 ".\ n ", <nl> nblocks ); <nl> return AVERROR_INVALIDDATA ; <nl> static int ape_decode_frame ( AVCodecContext * avctx , void * data , <nl> blockstodecode = s -> samples ; <nl>  <nl> /* reallocate decoded sample buffer if needed */ <nl> - av_fast_malloc (& s -> decoded_buffer , & s -> decoded_size , <nl> - 2 * FFALIGN ( blockstodecode , 8 ) * sizeof (* s -> decoded_buffer )); <nl> + decoded_buffer_size = 2LL * FFALIGN ( blockstodecode , 8 ) * sizeof (* s -> decoded_buffer ); <nl> + av_assert0 ( decoded_buffer_size <= INT_MAX ); <nl> + av_fast_malloc (& s -> decoded_buffer , & s -> decoded_size , decoded_buffer_size ); <nl> if (! s -> decoded_buffer ) <nl> return AVERROR ( ENOMEM ); <nl> memset ( s -> decoded_buffer , 0 , s -> decoded_size );
static int dnxhd_decode_header ( DNXHDContext * ctx , const uint8_t * buf , int buf_si <nl> for ( i = 0 ; i < ctx -> mb_height ; i ++) { <nl> ctx -> mb_scan_index [ i ] = AV_RB32 ( buf + 0x170 + ( i << 2 )); <nl> av_dlog ( ctx -> avctx , " mb scan index % d \ n ", ctx -> mb_scan_index [ i ]); <nl> - if ( buf_size < ctx -> mb_scan_index [ i ] + 0x280 ) { <nl> + if ( buf_size < ctx -> mb_scan_index [ i ] + 0x280LL ) { <nl> av_log ( ctx -> avctx , AV_LOG_ERROR , " invalid mb scan index \ n "); <nl> return - 1 ; <nl> }
static int mov_write_hdlr_tag ( AVIOContext * pb , MOVTrack * track ) <nl> } else if ( track -> enc -> codec_tag == MKTAG (' r ',' t ',' p ',' ')) { <nl> hdlr_type = " hint "; <nl> descr = " HintHandler "; <nl> + } else { <nl> + hdlr = " dhlr "; <nl> + hdlr_type = " url "; <nl> + descr = " DataHandler "; <nl> } <nl> } <nl>  <nl> static int mov_write_header ( AVFormatContext * s ) <nl> } <nl> } else if ( st -> codec -> codec_type == AVMEDIA_TYPE_SUBTITLE ){ <nl> track -> timescale = st -> codec -> time_base . den ; <nl> + } else { <nl> + track -> timescale = MOV_TIMESCALE ; <nl> } <nl> if (! track -> height ) <nl> track -> height = st -> codec -> height ;
static int start_frame ( AVFilterLink * inlink , AVFilterBufferRef * picref ) <nl> avfilter_unref_buffer ( tinterlace -> cur ); <nl> tinterlace -> cur = tinterlace -> next ; <nl> tinterlace -> next = picref ; <nl> + inlink -> cur_buf = NULL ; <nl> return 0 ; <nl> } <nl> 
single_col : <nl>  <nl> { <nl> const int16_t * mv_col = l1mv [ x8 * 3 + y8 * b4_stride ]; <nl> - int my_col = ( mv_col [ 1 ] << y_shift ) / 2 ; <nl> + int my_col = ( mv_col [ 1 ] * ( 1 << y_shift )) / 2 ; <nl> int mx = ( scale * mv_col [ 0 ] + 128 ) >> 8 ; <nl> int my = ( scale * my_col + 128 ) >> 8 ; <nl> fill_rectangle (& sl -> mv_cache [ 0 ][ scan8 [ i8 * 4 ]], 2 , 2 , 8 ,
static int parse_interval ( Interval * interval , int interval_count , <nl> char * start , * end ; <nl>  <nl> start = av_strtok ( intervalstr , "-", & end ); <nl> + if (! start ) { <nl> + ret = AVERROR ( EINVAL ); <nl> + av_log ( log_ctx , AV_LOG_ERROR , <nl> + " Invalid interval specification '% s ' in interval #% d \ n ", <nl> + intervalstr , interval_count ); <nl> + goto end ; <nl> + } <nl> if (( ret = av_parse_time (& interval -> start_ts , start , 1 )) < 0 ) { <nl> av_log ( log_ctx , AV_LOG_ERROR , <nl> " Invalid start time specification '% s ' in interval #% d \ n ",
static void ac3_decode_transform_coeffs_ch ( AC3DecodeContext * s , int ch_index , ma <nl> break ; <nl> default : /* 6 to 15 */ <nl> /* Shift mantissa and sign - extend it . */ <nl> + if ( bap > 15 ) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " bap % d is invalid in plain AC - 3 \ n ", bap ); <nl> + bap = 15 ; <nl> + } <nl> mantissa = get_sbits ( gbc , quantization_tab [ bap ]); <nl> mantissa <<= 24 - quantization_tab [ bap ]; <nl> break ;
AVRational av_guess_frame_rate ( AVFormatContext * format , AVStream * st , AVFrame * f <nl>  <nl>  <nl> if ( st -> codec -> ticks_per_frame > 1 ) { <nl> - if ( codec_fr . num > 0 && codec_fr . den > 0 && av_q2d ( codec_fr ) < av_q2d ( fr )* 0 . 7 <nl> - && fabs ( 1 . 0 - av_q2d ( av_div_q ( avg_fr , fr ))) > 0 . 1 ) <nl> + if ( codec_fr . num > 0 && codec_fr . den > 0 && <nl> + ( fr . num == 0 || av_q2d ( codec_fr ) < av_q2d ( fr )* 0 . 7 && fabs ( 1 . 0 - av_q2d ( av_div_q ( avg_fr , fr ))) > 0 . 1 )) <nl> fr = codec_fr ; <nl> } <nl> 
static AVCRC av_crc_table [ AV_CRC_MAX ][ 257 ]; <nl> * @ return < 0 on failure <nl> */ <nl> int av_crc_init ( AVCRC * ctx , int le , int bits , uint32_t poly , int ctx_size ){ <nl> - int i , j ; <nl> + unsigned i , j ; <nl> uint32_t c ; <nl>  <nl> if ( bits < 8 || bits > 32 || poly >= ( 1LL << bits ))
static int av_read_frame_internal ( AVFormatContext * s , AVPacket * pkt ) <nl> return 0 ; <nl> } <nl> } else { <nl> + /* free packet */ <nl> + av_free_packet (& s -> cur_pkt ); <nl> s -> cur_st = NULL ; <nl> } <nl> } else { <nl> - /* free previous packet */ <nl> - if ( s -> cur_st && s -> cur_st -> parser ) <nl> - av_free_packet (& s -> cur_pkt ); <nl> - <nl> /* read next packet */ <nl> ret = av_read_packet ( s , & s -> cur_pkt ); <nl> if ( ret < 0 )
static int imc_decode_frame ( AVCodecContext * avctx , void * data , <nl>  <nl> IMCContext * q = avctx -> priv_data ; <nl>  <nl> - LOCAL_ALIGNED_16 ( uint16_t , buf16 , [ IMC_BLOCK_SIZE / 2 ]); <nl> + LOCAL_ALIGNED_16 ( uint16_t , buf16 , [( IMC_BLOCK_SIZE + FF_INPUT_BUFFER_PADDING_SIZE ) / 2 ]); <nl>  <nl> if ( buf_size < IMC_BLOCK_SIZE * avctx -> channels ) { <nl> av_log ( avctx , AV_LOG_ERROR , " frame too small !\ n ");
static int svq1_decode_frame ( AVCodecContext * avctx , void * data , <nl> uint8_t * current ; <nl> int result , i , x , y , width , height ; <nl> svq1_pmv * pmv ; <nl> + int ret ; <nl>  <nl> /* initialize bit buffer */ <nl> - init_get_bits8 (& s -> gb , buf , buf_size ); <nl> + ret = init_get_bits8 (& s -> gb , buf , buf_size ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl>  <nl> /* decode frame header */ <nl> s -> frame_code = get_bits (& s -> gb , 22 );
static int write_adaptation_set ( AVFormatContext * s , int as_index ) <nl> if ( w -> is_live ) { <nl> AVDictionaryEntry * filename = <nl> av_dict_get ( s -> streams [ as -> streams [ i ]]-> metadata , FILENAME , NULL , 0 ); <nl> - if (! filename || <nl> - ( ret = parse_filename ( filename -> value , & representation_id , NULL , NULL ))) { <nl> + if (! filename ) <nl> + return AVERROR ( EINVAL ); <nl> + if ( ret = parse_filename ( filename -> value , & representation_id , NULL , NULL )) <nl> return ret ; <nl> - } <nl> } else { <nl> representation_id = av_asprintf ("% d ", w -> representation_id ++); <nl> if (! representation_id ) return AVERROR ( ENOMEM );
static int flv_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> type , size , flags ); <nl>  <nl> skip : <nl> - avio_seek ( s -> pb , next , SEEK_SET ); <nl> + if ( avio_seek ( s -> pb , next , SEEK_SET ) != next ) { <nl> + // This can happen if flv_read_metabody above read past <nl> + // next , on a non - seekable input , and the preceding data has <nl> + // been flushed out from the IO buffer . <nl> + av_log ( s , AV_LOG_ERROR , " Unable to seek to the next packet \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> continue ; <nl> } <nl> 
static int paf_video_decode ( AVCodecContext * avctx , void * data , <nl> bytestream2_init (& c -> gb , pkt -> data , pkt -> size ); <nl>  <nl> code = bytestream2_get_byte (& c -> gb ); <nl> - if (( code & 0xF ) > 4 ) { <nl> + if (( code & 0xF ) > 4 || ( code & 0xF ) == 3 ) { <nl> avpriv_request_sample ( avctx , " unknown / invalid code "); <nl> return AVERROR_INVALIDDATA ; <nl> }
static int dnxhd_decode_header ( DNXHDContext * ctx , AVFrame * frame , <nl> frame -> top_field_first = first_field ^ ctx -> cur_field ; <nl> av_log ( ctx -> avctx , AV_LOG_DEBUG , <nl> " interlaced % d , cur field % d \ n ", buf [ 5 ] & 3 , ctx -> cur_field ); <nl> + } else { <nl> + ctx -> cur_field = 0 ; <nl> } <nl>  <nl> ctx -> height = AV_RB16 ( buf + 0x18 );
static pgm_structure * generate_half_size_image ( vf_instance_t * vf , pgm_structur <nl> * \ brief Checks if YV12 is supported by the next filter . <nl> */ <nl> static unsigned int find_best ( struct vf_instance * vf ){ <nl> - int is_format_okay = vf -> next -> query_format ( vf -> next , IMGFMT_YV12 ); <nl> + int is_format_okay = vf_next_query_format ( vf , IMGFMT_YV12 ); <nl> if (( is_format_okay & VFCAP_CSP_SUPPORTED_BY_HW ) || ( is_format_okay & VFCAP_CSP_SUPPORTED )) <nl> return IMGFMT_YV12 ; <nl> else <nl> static int put_image ( struct vf_instance * vf , mp_image_t * mpi , double pts ){ <nl> static int query_format ( struct vf_instance * vf , unsigned int fmt ) <nl> { <nl> if ( fmt == IMGFMT_YV12 ) <nl> - return vf -> next -> query_format ( vf -> next , IMGFMT_YV12 ); <nl> + return vf_next_query_format ( vf , IMGFMT_YV12 ); <nl> else <nl> return 0 ; <nl> }
static int wavpack_decode_block ( AVCodecContext * avctx , int block_no , <nl> int16_t * dst = ( int16_t *) samples + 1 ; <nl> int16_t * src = ( int16_t *) samples ; <nl> int cnt = samplecount ; <nl> - while ( cnt --){ <nl> + while ( cnt -- > 0 ){ <nl> * dst = * src ; <nl> src += channel_stride ; <nl> dst += channel_stride ; <nl> static int wavpack_decode_block ( AVCodecContext * avctx , int block_no , <nl> int32_t * dst = ( int32_t *) samples + 1 ; <nl> int32_t * src = ( int32_t *) samples ; <nl> int cnt = samplecount ; <nl> - while ( cnt --){ <nl> + while ( cnt -- > 0 ){ <nl> * dst = * src ; <nl> src += channel_stride ; <nl> dst += channel_stride ; <nl> static int wavpack_decode_block ( AVCodecContext * avctx , int block_no , <nl> float * dst = ( float *) samples + 1 ; <nl> float * src = ( float *) samples ; <nl> int cnt = samplecount ; <nl> - while ( cnt --){ <nl> + while ( cnt -- > 0 ){ <nl> * dst = * src ; <nl> src += channel_stride ; <nl> dst += channel_stride ;
static int parse_MP4SLDescrTag ( MP4DescrParseContext * d , int64_t off , int len ) <nl> descr -> sl . timestamp_res = avio_rb32 (& d -> pb ); <nl> avio_rb32 (& d -> pb ); <nl> descr -> sl . timestamp_len = avio_r8 (& d -> pb ); <nl> + if ( descr -> sl . timestamp_len > 64 ) { <nl> + avpriv_request_sample ( NULL , " timestamp_len > 64 "); <nl> + descr -> sl . timestamp_len = 64 ; <nl> + return AVERROR_PATCHWELCOME ; <nl> + } <nl> descr -> sl . ocr_len = avio_r8 (& d -> pb ); <nl> descr -> sl . au_len = avio_r8 (& d -> pb ); <nl> descr -> sl . inst_bitrate_len = avio_r8 (& d -> pb );
typedef struct Indeo3DecodeContext { <nl>  <nl> int16_t width , height ; <nl> uint32_t frame_num ; ///< current frame number ( zero - based ) <nl> - uint32_t data_size ; ///< size of the frame data in bytes <nl> + int data_size ; ///< size of the frame data in bytes <nl> uint16_t frame_flags ; ///< frame properties <nl> uint8_t cb_offset ; ///< needed for selecting VQ tables <nl> uint8_t buf_sel ; ///< active frame buffer : 0 - primary , 1 - secondary <nl> static int decode_frame_headers ( Indeo3DecodeContext * ctx , AVCodecContext * avctx , <nl> GetByteContext gb ; <nl> const uint8_t * bs_hdr ; <nl> uint32_t frame_num , word2 , check_sum , data_size ; <nl> - uint32_t y_offset , u_offset , v_offset , starts [ 3 ], ends [ 3 ]; <nl> + int y_offset , u_offset , v_offset ; <nl> + uint32_t starts [ 3 ], ends [ 3 ]; <nl> uint16_t height , width ; <nl> int i , j ; <nl> 
static int smacker_read_packet ( AVFormatContext * s , AVPacket * pkt ) <nl> for ( i = 0 ; i < 7 ; i ++) { <nl> if ( flags & 1 ) { <nl> int size ; <nl> + uint8_t * tmpbuf ; <nl> + <nl> size = avio_rl32 ( s -> pb ) - 4 ; <nl> frame_size -= size ; <nl> frame_size -= 4 ; <nl> smk -> curstream ++; <nl> - smk -> bufs [ smk -> curstream ] = av_realloc ( smk -> bufs [ smk -> curstream ], size ); <nl> + tmpbuf = av_realloc ( smk -> bufs [ smk -> curstream ], size ); <nl> + if (! tmpbuf ) <nl> + return AVERROR ( ENOMEM ); <nl> + smk -> bufs [ smk -> curstream ] = tmpbuf ; <nl> smk -> buf_sizes [ smk -> curstream ] = size ; <nl> ret = avio_read ( s -> pb , smk -> bufs [ smk -> curstream ], size ); <nl> if ( ret != size )
int avpriv_dv_produce_packet ( DVDemuxContext * c , AVPacket * pkt , <nl> c -> audio_pkt [ i ]. pts = c -> abytes * 30000 * 8 / c -> ast [ i ]-> codec -> bit_rate ; <nl> ppcm [ i ] = c -> audio_buf [ i ]; <nl> } <nl> - dv_extract_audio ( buf , ppcm , c -> sys ); <nl> + if ( c -> ach ) <nl> + dv_extract_audio ( buf , ppcm , c -> sys ); <nl>  <nl> /* We work with 720p frames split in half , thus even frames have <nl> * channels 0 , 1 and odd 2 , 3 . */
static void ps_tableinit ( void ) <nl> } <nl>  <nl> for ( k = 0 ; k < NR_ALLPASS_BANDS20 ; k ++) { <nl> - int theta , f_center ; <nl> + int theta ; <nl> + int64_t f_center ; <nl> int c , s ; <nl>  <nl> if ( k < FF_ARRAY_ELEMS ( f_center_20 )) <nl> static void ps_tableinit ( void ) <nl> if ( k < FF_ARRAY_ELEMS ( f_center_34 )) <nl> f_center = f_center_34 [ k ]; <nl> else <nl> - f_center = ( k << 26 ) - ( 53 << 25 ); <nl> + f_center = (( int64_t ) k << 26 ) - ( 53 << 25 ); <nl>  <nl> for ( m = 0 ; m < PS_AP_LINKS ; m ++) { <nl> theta = ( int )((( int64_t ) fractional_delay_links [ m ] * f_center + 0x10000000 ) >> 27 );
ERROR <nl> # endif <nl>  <nl> void RENAME ( swri_noise_shaping )( SwrContext * s , AudioData * dsts , const AudioData * srcs , const AudioData * noises , int count ){ <nl> - int i , j , pos , ch ; <nl> + int pos = s -> dither . ns_pos ; <nl> + int i , j , ch ; <nl> int taps = s -> dither . ns_taps ; <nl> float S = s -> dither . ns_scale ; <nl> float S_1 = s -> dither . ns_scale_1 ;
static int request_frame ( AVFilterLink * outlink ) <nl> TestSourceContext * test = outlink -> src -> priv ; <nl> AVFilterBufferRef * picref ; <nl>  <nl> - if ( test -> max_pts >= 0 && test -> pts > test -> max_pts ) <nl> + if ( test -> max_pts >= 0 && test -> pts >= test -> max_pts ) <nl> return AVERROR_EOF ; <nl> picref = avfilter_get_video_buffer ( outlink , AV_PERM_WRITE , <nl> test -> w , test -> h );
static av_cold int decode_init ( AVCodecContext * avctx ) <nl> zret = inflateInit (& c -> zstream ); <nl> if ( zret != Z_OK ) { <nl> av_log ( avctx , AV_LOG_ERROR , " Inflate init error : % d \ n ", zret ); <nl> + av_freep (& c -> decomp_buf ); <nl> return 1 ; <nl> } <nl> } <nl> static av_cold int decode_end ( AVCodecContext * avctx ) <nl> { <nl> LclDecContext * const c = avctx -> priv_data ; <nl>  <nl> + av_freep (& c -> decomp_buf ); <nl> if ( c -> pic . data [ 0 ]) <nl> avctx -> release_buffer ( avctx , & c -> pic ); <nl> # if CONFIG_ZLIB_DECODER
static int webm_dash_manifest_cues ( AVFormatContext * s , int64_t init_range ) <nl> "%" PRId64 , s -> streams [ 0 ]-> index_entries [ i ]. timestamp ); <nl> if ( ret <= 0 || ( ret == 20 && i == s -> streams [ 0 ]-> nb_index_entries - 1 )) { <nl> av_log ( s , AV_LOG_ERROR , " timestamp too long .\ n "); <nl> + av_free ( buf ); <nl> return AVERROR_INVALIDDATA ; <nl> } <nl> end += ret ;
static int aac_decode_frame_int ( AVCodecContext * avctx , void * data , <nl>  <nl> if ( samples ) <nl> ac -> frame -> nb_samples = samples ; <nl> + else <nl> + av_frame_unref ( ac -> frame ); <nl> * got_frame_ptr = !! samples ; <nl>  <nl> if ( is_dmono ) {
static int xan_huffman_decode ( unsigned char * dest , int dest_len , <nl> init_get_bits (& gb , ptr , ptr_len * 8 ); <nl>  <nl> while ( val != 0x16 ) { <nl> - val = src [ val - 0x17 + get_bits1 (& gb ) * byte ]; <nl> + unsigned idx = val - 0x17 + get_bits1 (& gb ) * byte ; <nl> + if ( idx >= 2 * byte ) <nl> + return - 1 ; <nl> + val = src [ idx ]; <nl>  <nl> if ( val < 0x16 ) { <nl> if ( dest >= dest_end )
static int doTest ( uint8_t * ref [ 3 ], int refStride [ 3 ], int w , int h , int srcFormat <nl> int srcStride [ 3 ], dstStride [ 3 ]; <nl> int i ; <nl> uint64_t ssdY , ssdU , ssdV ; <nl> - struct SwsContext * srcContext , * dstContext , * outContext ; <nl> + struct SwsContext * srcContext = NULL , * dstContext = NULL , <nl> + * outContext = NULL ; <nl> int res ; <nl>  <nl> res = 0 ; <nl> static int doTest ( uint8_t * ref [ 3 ], int refStride [ 3 ], int w , int h , int srcFormat <nl> } <nl> } <nl>  <nl> - dstContext = outContext = NULL ; <nl> srcContext = sws_getContext ( w , h , PIX_FMT_YUV420P , srcW , srcH , srcFormat , flags , NULL , NULL , NULL ); <nl> if (! srcContext ) { <nl> fprintf ( stderr , " Failed to get % s ---> % s \ n ",
int sws_setColorspaceDetails ( SwsContext * c , const int inv_table [ 4 ], int srcRange <nl>  <nl> int sws_getColorspaceDetails ( SwsContext * c , int ** inv_table , int * srcRange , int ** table , int * dstRange , int * brightness , int * contrast , int * saturation ) <nl> { <nl> - if ( isYUV ( c -> dstFormat ) || isGray ( c -> dstFormat )) return - 1 ; <nl> + if (! c || isYUV ( c -> dstFormat ) || isGray ( c -> dstFormat )) return - 1 ; <nl>  <nl> * inv_table = c -> srcColorspaceTable ; <nl> * table = c -> dstColorspaceTable ;
static int64_t mpegps_read_dts ( AVFormatContext * s , int stream_index , <nl> # ifdef DEBUG_SEEK <nl> printf (" read_dts : pos = 0x %" PRIx64 " next =% d -> ", pos , find_next ); <nl> # endif <nl> - url_fseek ( s -> pb , pos , SEEK_SET ); <nl> + if ( url_fseek ( s -> pb , pos , SEEK_SET ) < 0 ) <nl> + return AV_NOPTS_VALUE ; <nl> + <nl> for (;;) { <nl> len = mpegps_read_pes_header ( s , & pos , & startcode , & pts , & dts ); <nl> if ( len < 0 ) {
resync : <nl> err = av_get_packet ( pb , pkt , size ); <nl> if ( err < 0 ) <nl> return err ; <nl> + size = err ; <nl>  <nl> if ( ast -> has_pal && pkt -> data && pkt -> size <( unsigned ) INT_MAX / 2 ){ <nl> uint8_t * pal ;
static float lame_calc_attack_threshold ( int bitrate ) <nl> * LAME psy model specific initialization <nl> */ <nl> static void lame_window_init ( AacPsyContext * ctx , AVCodecContext * avctx ) { <nl> - int i ; <nl> + int i , j ; <nl>  <nl> for ( i = 0 ; i < avctx -> channels ; i ++) { <nl> AacPsyChannel * pch = & ctx -> ch [ i ]; <nl> static void lame_window_init ( AacPsyContext * ctx , AVCodecContext * avctx ) { <nl> else <nl> pch -> attack_threshold = lame_calc_attack_threshold ( avctx -> bit_rate / avctx -> channels / 1000 ); <nl>  <nl> - for ( i = 0 ; i < AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS ; i ++) <nl> - pch -> prev_energy_subshort [ i ] = 10 . 0f ; <nl> + for ( j = 0 ; j < AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS ; j ++) <nl> + pch -> prev_energy_subshort [ j ] = 10 . 0f ; <nl> } <nl> } <nl> 
static int update_wrap_reference ( AVFormatContext * s , AVStream * st , int stream_in <nl>  <nl> if ( ref == AV_NOPTS_VALUE ) <nl> ref = pkt -> pts ; <nl> - if ( ref == AV_NOPTS_VALUE ) <nl> + if ( st -> pts_wrap_reference != AV_NOPTS_VALUE || st -> pts_wrap_bits >= 63 || ref == AV_NOPTS_VALUE || ! s -> correct_ts_overflow ) <nl> return 0 ; <nl> ref &= ( 1LL << st -> pts_wrap_bits )- 1 ; <nl>  <nl> - if ( s -> correct_ts_overflow && st -> pts_wrap_bits < 63 && <nl> - st -> pts_wrap_reference == AV_NOPTS_VALUE ) { <nl> + { <nl> int i ; <nl>  <nl> // reference time stamp should be 60 s before first time stamp <nl> static int update_wrap_reference ( AVFormatContext * s , AVStream * st , int stream_in <nl> } <nl> return 1 ; <nl> } <nl> - return 0 ; <nl> } <nl>  <nl> static void update_initial_timestamps ( AVFormatContext * s , int stream_index ,
static int mxf_read_index_entry_array ( AVIOContext * pb , MXFIndexTableSegment * seg <nl> segment -> nb_index_entries = avio_rb32 ( pb ); <nl>  <nl> length = avio_rb32 ( pb ); <nl> + if ( segment -> nb_index_entries && length < 11 ) <nl> + return AVERROR_INVALIDDATA ; <nl>  <nl> if (!( segment -> temporal_offset_entries = av_calloc ( segment -> nb_index_entries , sizeof (* segment -> temporal_offset_entries ))) || <nl> !( segment -> flag_entries = av_calloc ( segment -> nb_index_entries , sizeof (* segment -> flag_entries ))) || <nl> static int mxf_read_index_entry_array ( AVIOContext * pb , MXFIndexTableSegment * seg <nl> } <nl>  <nl> for ( i = 0 ; i < segment -> nb_index_entries ; i ++) { <nl> + if ( avio_feof ( pb )) <nl> + return AVERROR_INVALIDDATA ; <nl> segment -> temporal_offset_entries [ i ] = avio_r8 ( pb ); <nl> avio_r8 ( pb ); /* KeyFrameOffset */ <nl> segment -> flag_entries [ i ] = avio_r8 ( pb );
int ff_j2k_init_component ( J2kComponent * comp , J2kCodingStyle * codsty , J2kQuantSt <nl> band -> cblk = av_malloc ( sizeof ( J2kCblk ) * band -> cblknx * band -> cblkny ); <nl> if (! band -> cblk ) <nl> return AVERROR ( ENOMEM ); <nl> - band -> prec = av_malloc ( reslevel -> num_precincts_x * reslevel -> num_precincts_y * sizeof ( J2kPrec )); <nl> + band -> prec = av_malloc ( sizeof ( J2kCblk ) * reslevel -> num_precincts_x * reslevel -> num_precincts_y ); <nl> if (! band -> prec ) <nl> return AVERROR ( ENOMEM ); <nl> 
static int av_encode ( AVFormatContext ** output_files , <nl> switch ( ist -> st -> codec . codec_type ) { <nl> case CODEC_TYPE_AUDIO : <nl> av_frac_init (& ist -> next_pts , <nl> - 0 , 0 , is -> pts_num * ist -> st -> codec . sample_rate ); <nl> + 0 , 0 , ( uint64_t ) is -> pts_num * ist -> st -> codec . sample_rate ); <nl> break ; <nl> case CODEC_TYPE_VIDEO : <nl> av_frac_init (& ist -> next_pts , <nl> - 0 , 0 , is -> pts_num * ist -> st -> codec . frame_rate ); <nl> + 0 , 0 , ( uint64_t ) is -> pts_num * ist -> st -> codec . frame_rate ); <nl> break ; <nl> default : <nl> break ; <nl> static int av_encode ( AVFormatContext ** output_files , <nl> } <nl> data_buf = ( uint8_t *) samples ; <nl> av_frac_add (& ist -> next_pts , <nl> - is -> pts_den * data_size / ( 2 * ist -> st -> codec . channels )); <nl> + ( uint64_t ) is -> pts_den * data_size / ( 2 * ist -> st -> codec . channels )); <nl> break ; <nl> case CODEC_TYPE_VIDEO : <nl> { <nl> static int av_encode ( AVFormatContext ** output_files , <nl> continue ; <nl> } <nl> av_frac_add (& ist -> next_pts , <nl> - is -> pts_den * ist -> st -> codec . frame_rate_base ); <nl> + ( uint64_t ) is -> pts_den * ist -> st -> codec . frame_rate_base ); <nl> } <nl> break ; <nl> default :
static int parse_palette ( AVCodecContext * avctx , GetByteContext * gbc , <nl> bytestream2_skip ( gbc , 1 ); <nl> b = bytestream2_get_byte ( gbc ); <nl> bytestream2_skip ( gbc , 1 ); <nl> - pal [ idx ] = ( r << 16 ) | ( g << 8 ) | b ; <nl> + pal [ idx ] = ( 0xFFU << 24 ) | ( r << 16 ) | ( g << 8 ) | b ; <nl> } <nl> return 0 ; <nl> }
/* <nl> * MPEG - DASH ISO BMFF segmenter <nl> * Copyright ( c ) 2014 Martin Storsjo <nl> + * Copyright ( c ) 2018 Akamai Technologies , Inc . <nl> * <nl> * This file is part of FFmpeg . <nl> * <nl> static void dash_free ( AVFormatContext * s ) <nl> av_free ( os -> segments ); <nl> } <nl> av_freep (& c -> streams ); <nl> + <nl> + ff_format_io_close ( s , & c -> mpd_out ); <nl> + ff_format_io_close ( s , & c -> m3u8_out ); <nl> } <nl>  <nl> static void output_segment_list ( OutputStream * os , AVIOContext * out , AVFormatContext * s ,
# include < string . h > <nl>  <nl> # include " parser . h " <nl> -# include " internal . h " <nl> # include " libavutil / mem . h " <nl>  <nl> static AVCodecParser * av_first_parser = NULL ; <nl> AVCodecParserContext * av_parser_init ( int codec_id ) <nl> s -> fetch_timestamp = 1 ; <nl> s -> pict_type = AV_PICTURE_TYPE_I ; <nl> if ( parser -> parser_init ) { <nl> - if ( ff_lock_avcodec ( NULL ) < 0 ) <nl> - goto err_out ; <nl> ret = parser -> parser_init ( s ); <nl> - ff_unlock_avcodec (); <nl> if ( ret != 0 ) <nl> goto err_out ; <nl> } <nl> int av_parser_change ( AVCodecParserContext * s , <nl> void av_parser_close ( AVCodecParserContext * s ) <nl> { <nl> if ( s ){ <nl> - if ( s -> parser -> parser_close ) { <nl> - ff_lock_avcodec ( NULL ); <nl> + if ( s -> parser -> parser_close ) <nl> s -> parser -> parser_close ( s ); <nl> - ff_unlock_avcodec (); <nl> - } <nl> av_free ( s -> priv_data ); <nl> av_free ( s ); <nl> }
static int init_pass2 ( MpegEncContext * s ) <nl> double rate_factor = 0 ; <nl> double step ; <nl> const int filter_size = ( int )( a -> qblur * 4 ) | 1 ; <nl> - double expected_bits ; <nl> + double expected_bits = 0 ; // init to silence gcc warning <nl> double * qscale , * blurred_qscale , qscale_sum ; <nl>  <nl> /* find complexity & const_bits & decide the pict_types */
static int config_props ( AVFilterLink * outlink ) <nl> scale -> isws [ 0 ] = scale -> isws [ 1 ] = scale -> sws = NULL ; <nl> if ( inlink0 -> w == outlink -> w && <nl> inlink0 -> h == outlink -> h && <nl> + ! scale -> out_color_matrix && <nl> scale -> in_range == scale -> out_range && <nl> inlink0 -> format == outlink -> format ) <nl> ;
static void vector_fmul_window_fixed_c ( int32_t * dst , const int32_t * src0 , <nl> AVFixedDSPContext * avpriv_alloc_fixed_dsp ( int bit_exact ) <nl> { <nl> AVFixedDSPContext * fdsp = av_malloc ( sizeof ( AVFixedDSPContext )); <nl> + <nl> + if (! fdsp ) <nl> + return NULL ; <nl> + <nl> fdsp -> vector_fmul_window_scaled = vector_fmul_window_fixed_scaled_c ; <nl> fdsp -> vector_fmul_window = vector_fmul_window_fixed_c ; <nl> 
static int sp5x_decode_frame ( AVCodecContext * avctx , <nl> recoded [ j ++] = 0xFF ; <nl> recoded [ j ++] = 0xD9 ; <nl>  <nl> - avctx -> flags &= ~ CODEC_FLAG_EMU_EDGE ; <nl> av_init_packet (& avpkt_recoded ); <nl> avpkt_recoded . data = recoded ; <nl> avpkt_recoded . size = j ; <nl> AVCodec ff_amv_decoder = { <nl> NULL , <nl> ff_mjpeg_decode_end , <nl> sp5x_decode_frame , <nl> - CODEC_CAP_DR1 , <nl> + 0 , <nl> . long_name = NULL_IF_CONFIG_SMALL (" AMV Video "), <nl> };
static int avi_read_header ( AVFormatContext * s ) <nl> codec_type = AVMEDIA_TYPE_VIDEO ; <nl>  <nl> ast -> sample_size = 0 ; <nl> + st -> avg_frame_rate = av_inv_q ( st -> time_base ); <nl> break ; <nl> case MKTAG (' a ', ' u ', ' d ', ' s '): <nl> codec_type = AVMEDIA_TYPE_AUDIO ;
static inline void dv_decode_video_segment ( DVVideoContext * s , <nl> if ( DV_PROFILE_IS_HD ( s -> sys )) { <nl> mb -> idct_put = s -> idct_put [ 0 ]; <nl> mb -> scan_table = s -> dv_zigzag [ 0 ]; <nl> - mb -> factor_table = s -> dv100_idct_factor [(( s -> sys -> height == 720 )<< 1 )&( j < 4 )][ class1 ][ quant ]; <nl> + mb -> factor_table = s -> dv100_idct_factor [(( s -> sys -> height == 720 )<< 1 )|( j >= 4 )][ class1 ][ quant ]; <nl> is_field_mode [ mb_index ] |= ! j && dct_mode ; <nl> } else { <nl> mb -> idct_put = s -> idct_put [ dct_mode && log2_blocksize == 3 ];
static int has_codec_parameters ( AVStream * st , const char ** errmsg_ptr ) <nl> FAIL (" unspecified sample rate "); <nl> if (! avctx -> channels ) <nl> FAIL (" unspecified number of channels "); <nl> + if ( st -> info -> found_decoder >= 0 && ! st -> nb_decoded_frames && avctx -> codec_id == AV_CODEC_ID_DTS ) <nl> + FAIL (" no decodable DTS frames "); <nl> break ; <nl> case AVMEDIA_TYPE_VIDEO : <nl> if (! avctx -> width )
void av_packet_free ( AVPacket ** pkt ) <nl> static int packet_alloc ( AVBufferRef ** buf , int size ) <nl> { <nl> int ret ; <nl> - if (( unsigned ) size >= ( unsigned ) size + AV_INPUT_BUFFER_PADDING_SIZE ) <nl> + if ( size < 0 || size >= INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE ) <nl> return AVERROR ( EINVAL ); <nl>  <nl> ret = av_buffer_realloc ( buf , size + AV_INPUT_BUFFER_PADDING_SIZE );
RMStream * ff_rm_alloc_rmstream ( void ) <nl>  <nl> void ff_rm_free_rmstream ( RMStream * rms ) <nl> { <nl> - av_free ( rms -> videobuf ); <nl> - av_free ( rms -> audiobuf ); <nl> + av_freep (& rms -> videobuf ); <nl> + av_freep (& rms -> audiobuf ); <nl> } <nl>  <nl> static int rm_read_audio_stream_info ( AVFormatContext * s , ByteIOContext * pb ,
static int msvideo1_decode_frame ( AVCodecContext * avctx , <nl> s -> buf = buf ; <nl> s -> size = buf_size ; <nl>  <nl> + // Discard frame if its smaller than the minimum frame size <nl> + if ( buf_size < ( avctx -> width / 4 ) * ( avctx -> height / 4 ) / 512 ) { <nl> + av_log ( avctx , AV_LOG_ERROR , " Packet is too small \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> + <nl> if (( ret = ff_reget_buffer ( avctx , s -> frame )) < 0 ) <nl> return ret ; <nl> 
static int hls_slice_header ( HEVCContext * s ) <nl>  <nl> if ( s -> pps -> slice_header_extension_present_flag ) { <nl> unsigned int length = get_ue_golomb_long ( gb ); <nl> + if ( length * 8LL > get_bits_left ( gb )) { <nl> + av_log ( s -> avctx , AV_LOG_ERROR , " too many slice_header_extension_data_bytes \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl> for ( i = 0 ; i < length ; i ++) <nl> skip_bits ( gb , 8 ); // slice_header_extension_data_byte <nl> }
static const float fir_32bands_nonperfect [] = <nl> + 1 . 390191784E - 007 <nl> }; <nl>  <nl> -// FIXME the coeffs are symetric <nl> +// FIXME the coeffs are symmetric <nl> static const float lfe_fir_64 [] = <nl> { <nl> 2 . 6584343868307770E - 004 , <nl> static const float lfe_fir_64 [] = <nl> 2 . 6584343868307770E - 004 <nl> }; <nl>  <nl> -// FIXME the coeffs are symetric <nl> +// FIXME the coeffs are symmetric <nl>  <nl> static const float lfe_fir_128 [] = <nl> { <nl> static const float lfe_fir_128 [] = <nl> 0 . 00053168571 <nl> }; <nl>  <nl> -/* 10 ^-( dB / 20 ), with dB beeing a list of dB values rangeing from 0 to - 72 */ <nl> +/* 10 ^-( dB / 20 ), with dB being a list of dB values ranging from 0 to - 72 */ <nl> /* do a 20 * log10 ( dca_downmix_coeffs ) to reconvert the values */ <nl>  <nl> static const float dca_downmix_coeffs [ 65 ] = {
static int webm_dash_manifest_read_header ( AVFormatContext * s ) <nl> av_log ( s , AV_LOG_ERROR , " Failed to read file headers \ n "); <nl> return - 1 ; <nl> } <nl> + if (! s -> nb_streams ) { <nl> + matroska_read_close ( s ); <nl> + av_log ( s , AV_LOG_ERROR , " No streams found \ n "); <nl> + return AVERROR_INVALIDDATA ; <nl> + } <nl>  <nl> if (! matroska -> is_live ) { <nl> buf = av_asprintf ("% g ", matroska -> duration );
enum DCAMode { <nl> # define HEADER_SIZE 14 <nl> # define CONVERT_BIAS 384 <nl>  <nl> -# define DCA_MAX_FRAME_SIZE 16383 <nl> +# define DCA_MAX_FRAME_SIZE 16384 <nl>  <nl> /** Bit allocation */ <nl> typedef struct {
-/* $ OpenBSD : creator . c , v 1 . 15 2002 / 07 / 26 18 : 00 : 08 jason Exp $ */ <nl> +/* $ OpenBSD : creator . c , v 1 . 16 2002 / 07 / 26 18 : 23 : 34 jason Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2002 Jason L . Wright ( jason @ thought . net ) <nl> void <nl> creator_ras_fill ( sc ) <nl> struct creator_softc * sc ; <nl> { <nl> - creator_ras_fifo_wait ( sc , 5 ); <nl> + creator_ras_fifo_wait ( sc , 6 ); <nl> FBC_WRITE ( sc , FFB_FBC_PPC , <nl> FBC_PPC_VCE_DIS | FBC_PPC_TBE_OPAQUE | <nl> FBC_PPC_APE_DIS | FBC_PPC_CS_CONST );
-/* $ OpenBSD : uhcireg . h , v 1 . 15 2013 / 04 / 15 09 : 23 : 02 mglocker Exp $ */ <nl> +/* $ OpenBSD : uhcireg . h , v 1 . 16 2016 / 12 / 27 14 : 41 : 45 kettenis Exp $ */ <nl> /* $ NetBSD : uhcireg . h , v 1 . 16 2002 / 07 / 11 21 : 14 : 29 augustss Exp $ */ <nl> /* $ FreeBSD : src / sys / dev / usb / uhcireg . h , v 1 . 12 1999 / 11 / 17 22 : 33 : 42 n_hibma Exp $ */ <nl>  <nl> struct uhci_td { <nl> # define UHCI_TD_GET_ENDPT ( s ) ((( s ) >> 15 ) & 0xf ) <nl> # define UHCI_TD_SET_DT ( t ) (( t ) << 19 ) <nl> # define UHCI_TD_GET_DT ( s ) ((( s ) >> 19 ) & 1 ) <nl> -# define UHCI_TD_SET_MAXLEN ( l ) ((( l )- 1 ) << 21 ) <nl> +# define UHCI_TD_SET_MAXLEN ( l ) ((( uint32_t )( l )- 1 ) << 21 ) <nl> # define UHCI_TD_GET_MAXLEN ( s ) (((( s ) >> 21 ) + 1 ) & 0x7ff ) <nl> # define UHCI_TD_MAXLEN_MASK 0xffe00000 <nl> u_int32_t td_buffer ;
-/* $ OpenBSD : ldconfig . c , v 1 . 34 2015 / 01 / 18 04 : 48 : 24 deraadt Exp $ */ <nl> +/* $ OpenBSD : ldconfig . c , v 1 . 35 2015 / 11 / 15 02 : 49 : 59 deraadt Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1993 , 1995 Paul Kranenburg <nl> main ( int argc , char * argv []) <nl> int i , c ; <nl> int rval = 0 ; <nl>  <nl> + if ( pledge (" stdio rpath wpath cpath tmppath fattr ", NULL ) == - 1 ) <nl> + err ( 1 , " pledge "); <nl> + <nl> while (( c = getopt ( argc , argv , " DmPrRsSUv ")) != - 1 ) { <nl> switch ( c ) { <nl> case ' R ':
-/* $ OpenBSD : vacation . c , v 1 . 9 1998 / 02 / 07 02 : 47 : 21 millert Exp $ */ <nl> +/* $ OpenBSD : vacation . c , v 1 . 10 1998 / 07 / 08 21 : 39 : 08 deraadt Exp $ */ <nl> /* $ NetBSD : vacation . c , v 1 . 7 1995 / 04 / 29 05 : 58 : 27 cgd Exp $ */ <nl>  <nl> /* <nl> static char copyright [] = <nl> # if 0 <nl> static char sccsid [] = "@(#) vacation . c 8 . 2 ( Berkeley ) 1 / 26 / 94 "; <nl> # endif <nl> - static char rcsid [] = "$ OpenBSD : vacation . c , v 1 . 9 1998 / 02 / 07 02 : 47 : 21 millert Exp $"; <nl> + static char rcsid [] = "$ OpenBSD : vacation . c , v 1 . 10 1998 / 07 / 08 21 : 39 : 08 deraadt Exp $"; <nl> # endif /* not lint */ <nl>  <nl> /* <nl> sendmessage ( myname ) <nl> dup2 ( pvect [ 0 ], 0 ); <nl> close ( pvect [ 0 ]); <nl> close ( pvect [ 1 ]); <nl> - fclose ( mfp ); <nl> + close ( fileno ( mfp )); <nl> execl ( _PATH_SENDMAIL , " sendmail ", "- f ", myname , "--", <nl> from , NULL ); <nl> syslog ( LOG_ERR , " vacation : can ' t exec % s : % m ", _PATH_SENDMAIL );
-/* $ OpenBSD : igmp . c , v 1 . 7 1999 / 12 / 28 07 : 17 : 38 itojun Exp $ */ <nl> +/* $ OpenBSD : igmp . c , v 1 . 8 2000 / 04 / 25 19 : 05 : 43 aaron Exp $ */ <nl> /* $ NetBSD : igmp . c , v 1 . 15 1996 / 02 / 13 23 : 41 : 25 christos Exp $ */ <nl>  <nl> /* <nl> igmp_input ( m , va_alist ) <nl> } <nl>  <nl> timer = igmp -> igmp_code * PR_FASTHZ / IGMP_TIMER_SCALE ; <nl> + if ( timer == 0 ) <nl> + timer = 1 ; <nl>  <nl> /* <nl> * Start the timers in all of our membership records
-/* $ OpenBSD : rtsold . c , v 1 . 53 2014 / 08 / 27 14 : 04 : 16 florian Exp $ */ <nl> +/* $ OpenBSD : rtsold . c , v 1 . 54 2014 / 10 / 08 04 : 55 : 27 deraadt Exp $ */ <nl> /* $ KAME : rtsold . c , v 1 . 75 2004 / 01 / 03 00 : 00 : 07 itojun Exp $ */ <nl>  <nl> /* <nl> autoifprobe ( u_int rdomain ) <nl> if ( n != 0 && dflag > 1 ) <nl> warnx (" multiple interfaces found "); <nl>  <nl> - a = ( char **) realloc ( argv , ( n + 1 ) * sizeof ( char **)); <nl> + a = reallocarray ( argv , n + 1 , sizeof ( char **)); <nl> if ( a == NULL ) <nl> err ( 1 , " realloc "); <nl> argv = a ; <nl> autoifprobe ( u_int rdomain ) <nl> } <nl>  <nl> if ( n ) { <nl> - a = ( char **) realloc ( argv , ( n + 1 ) * sizeof ( char **)); <nl> + a = reallocarray ( argv , n + 1 , sizeof ( char **)); <nl> if ( a == NULL ) <nl> err ( 1 , " realloc "); <nl> argv = a ;
-/* $ OpenBSD : subr_disk . c , v 1 . 66 2007 / 11 / 09 11 : 32 : 57 jsing Exp $ */ <nl> +/* $ OpenBSD : subr_disk . c , v 1 . 67 2007 / 12 / 16 20 : 57 : 17 otto Exp $ */ <nl> /* $ NetBSD : subr_disk . c , v 1 . 17 1996 / 03 / 16 23 : 17 : 08 christos Exp $ */ <nl>  <nl> /* <nl> bounds_check_with_label ( struct buf * bp , struct disklabel * lp , int wlabel ) <nl> if ( lp -> d_secpercyl == 0 ) <nl> goto bad ; <nl>  <nl> + if ( bp -> b_blkno < 0 || sz < 0 ) <nl> + panic (" bounds_check_with_label % lld % lld \ n ", bp -> b_blkno , sz ); <nl> + <nl> /* beyond partition ? */ <nl> if ( bp -> b_blkno + sz > blockpersec ( DL_GETPSIZE ( p ), lp )) { <nl> sz = blockpersec ( DL_GETPSIZE ( p ), lp ) - bp -> b_blkno ;
-/* $ OpenBSD : mountd . c , v 1 . 23 1997 / 12 / 19 09 : 21 : 40 deraadt Exp $ */ <nl> +/* $ OpenBSD : mountd . c , v 1 . 24 1998 / 03 / 01 20 : 06 : 30 millert Exp $ */ <nl> /* $ NetBSD : mountd . c , v 1 . 31 1996 / 02 / 18 11 : 57 : 53 fvdl Exp $ */ <nl>  <nl> /* <nl> get_exportlist () <nl> nextfield (& cp , & endcp ); <nl> len = endcp - cp ; <nl> } <nl> + if ( has_host == FALSE && tgrp -> gr_type == GT_NULL ) { <nl> + getexp_err ( ep , tgrp ); <nl> + goto nextline ; <nl> + } <nl> if ( check_options ( dirhead )) { <nl> getexp_err ( ep , tgrp ); <nl> goto nextline ;
-/* $ OpenBSD : bounce . c , v 1 . 24 2010 / 11 / 28 13 : 56 : 43 gilles Exp $ */ <nl> +/* $ OpenBSD : bounce . c , v 1 . 25 2011 / 03 / 21 13 : 06 : 25 gilles Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2009 Gilles Chehade < gilles @ openbsd . org > <nl> bounce_session ( struct smtpd * env , int fd , struct message * messagep ) <nl> /* get message content */ <nl> if (( msgfd = queue_open_message_file ( messagep -> message_id )) == - 1 ) <nl> goto fail ; <nl> - <nl> + <nl> /* init smtp session */ <nl> - if (( cc = calloc ( 1 , sizeof (* cc ))) == NULL ) <nl> + if (( cc = calloc ( 1 , sizeof (* cc ))) == NULL ) { <nl> + close ( msgfd ); <nl> goto fail ; <nl> + } <nl> cc -> pcb = client_init ( fd , msgfd , env -> sc_hostname , 1 ); <nl> cc -> env = env ; <nl> cc -> m = * messagep ; <nl> bounce_session ( struct smtpd * env , int fd , struct message * messagep ) <nl>  <nl> return 1 ; <nl> fail : <nl> - close ( msgfd ); <nl> if ( cc && cc -> pcb ) <nl> client_close ( cc -> pcb ); <nl> free ( cc );
-/* $ OpenBSD : snapper . c , v 1 . 9 2005 / 05 / 22 18 : 08 : 13 jason Exp $ */ <nl> +/* $ OpenBSD : snapper . c , v 1 . 10 2005 / 05 / 22 18 : 28 : 20 jason Exp $ */ <nl> /* $ NetBSD : snapper . c , v 1 . 1 2003 / 12 / 27 02 : 19 : 34 grant Exp $ */ <nl>  <nl> /*- <nl> snapper_query_encoding ( h , ae ) <nl> ae -> flags = AUDIO_ENCODINGFLAG_EMULATED ; <nl> break ; <nl> case 3 : <nl> - strlcpy ( ae -> name , AudioEslinear_be , sizeof ( ae -> name )); <nl> + strlcpy ( ae -> name , AudioEulinear_be , sizeof ( ae -> name )); <nl> ae -> encoding = AUDIO_ENCODING_ULINEAR_BE ; <nl> ae -> precision = 16 ; <nl> ae -> flags = AUDIO_ENCODINGFLAG_EMULATED ; <nl> break ; <nl> case 4 : <nl> - strlcpy ( ae -> name , AudioEslinear_le , sizeof ( ae -> name )); <nl> + strlcpy ( ae -> name , AudioEulinear_le , sizeof ( ae -> name )); <nl> ae -> encoding = AUDIO_ENCODING_ULINEAR_LE ; <nl> ae -> precision = 16 ; <nl> ae -> flags = AUDIO_ENCODINGFLAG_EMULATED ;
-/* $ OpenBSD : login_tis . c , v 1 . 2 2005 / 01 / 04 18 : 24 : 33 moritz Exp $ */ <nl> +/* $ OpenBSD : login_tis . c , v 1 . 3 2005 / 03 / 08 22 : 02 : 08 cloder Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2004 Todd C . Miller < Todd . Miller @ courtesan . com > <nl> main ( int argc , char * argv []) <nl> switch ( mode ) { <nl> case MODE_LOGIN : <nl> if ( rtype == display ) { <nl> - printf ( chalbuf ); <nl> + printf ("% s ", chalbuf ); <nl> exit ( 1 ); <nl> } <nl> alarm ( TIS_PASSWD_TIMEOUT );
-/* $ OpenBSD : print - ip6 . c , v 1 . 3 2002 / 02 / 19 19 : 39 : 40 millert Exp $ */ <nl> +/* $ OpenBSD : print - ip6 . c , v 1 . 4 2003 / 01 / 27 10 : 00 : 40 henning Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1988 , 1989 , 1990 , 1991 , 1992 , 1993 , 1994 <nl> ip6_print ( register const u_char * bp , register int length ) <nl> ( void ) printf (" ip - proto -% d % d ", ip6 -> ip6_nxt , len ); <nl> goto end ; <nl> } <nl> + if ( hlen == 0 ) <nl> + break ; <nl> } <nl>  <nl> end :
-/* $ OpenBSD : rcsprog . c , v 1 . 134 2006 / 11 / 13 11 : 22 : 57 xsa Exp $ */ <nl> +/* $ OpenBSD : rcsprog . c , v 1 . 135 2006 / 12 / 27 07 : 43 : 24 niallo Exp $ */ <nl> /* <nl> * Copyright ( c ) 2005 Jean - Francois Brousseau < jfb @ openbsd . org > <nl> * All rights reserved . <nl> void <nl> rcs_usage ( void ) <nl> { <nl> fprintf ( stderr , <nl> - " usage : rcs [- eIiLqTUV ] [- Aoldfile ] [- ausers ] [- b [ rev ]]\ n " <nl> + " usage : rcs [- IiLqTUV ] [- Aoldfile ] [- ausers ] [- b [ rev ]]\ n " <nl> " [- cstring ] [- e [ users ]] [- kmode ] [- l [ rev ]] [- mrev : msg ]\ n " <nl> " [- orev ] [- sstate [: rev ]] [- tstr ] [- u [ rev ]]\ n " <nl> " [- xsuffixes ] file ...\ n ");
-/* $ OpenBSD : xbf . c , v 1 . 14 2016 / 12 / 23 12 : 52 : 12 mikeb Exp $ */ <nl> +/* $ OpenBSD : xbf . c , v 1 . 15 2017 / 01 / 18 22 : 18 : 47 mikeb Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2016 Mike Belopuhov <nl> xbf_ring_destroy ( struct xbf_softc * sc ) <nl> sizeof ( bus_dmamap_t )); <nl> sc -> sc_xs_map = NULL ; <nl> } <nl> + if ( sc -> sc_xs_bb ) { <nl> + free ( sc -> sc_xs_bb , M_DEVBUF , sc -> sc_xr_ndesc * <nl> + sizeof ( struct xbf_dma_mem )); <nl> + sc -> sc_xs_bb = NULL ; <nl> + } <nl>  <nl> xbf_dma_free ( sc , & sc -> sc_xr_dma ); <nl> 
-/* $ OpenBSD : init_main . c , v 1 . 240 2015 / 05 / 18 04 : 07 : 26 miod Exp $ */ <nl> +/* $ OpenBSD : init_main . c , v 1 . 241 2015 / 06 / 24 03 : 42 : 08 dlg Exp $ */ <nl> /* $ NetBSD : init_main . c , v 1 . 84 . 4 . 1 1996 / 06 / 02 09 : 08 : 06 mrg Exp $ */ <nl>  <nl> /* <nl> main ( void * framep ) <nl> /* <nl> * Start the idle pool page garbage collector <nl> */ <nl> -# if notyet <nl> pool_gc_pages ( NULL ); <nl> -# endif <nl>  <nl> /* <nl> * proc0 : nothing to do , back to sleep
-/* $ OpenBSD : vipw . c , v 1 . 17 2014 / 05 / 07 21 : 20 : 06 schwarze Exp $ */ <nl> +/* $ OpenBSD : vipw . c , v 1 . 18 2015 / 10 / 16 22 : 54 : 15 deraadt Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1987 , 1993 , 1994 <nl> main ( int argc , char * argv []) <nl> if ( argc != 0 ) <nl> usage (); <nl>  <nl> + if ( pledge (" stdio rpath wpath cpath fattr proc exec ", NULL ) == - 1 ) <nl> + err ( 1 , " pledge "); <nl> + <nl> pw_init (); <nl> tfd = pw_lock ( 0 ); <nl> if ( tfd < 0 )
-/* $ OpenBSD : cdio . h , v 1 . 14 2006 / 04 / 27 02 : 17 : 21 tedu Exp $ */ <nl> +/* $ OpenBSD : cdio . h , v 1 . 15 2006 / 07 / 11 00 : 32 : 27 pedro Exp $ */ <nl> /* $ NetBSD : cdio . h , v 1 . 11 1996 / 02 / 19 18 : 29 : 04 scottr Exp $ */ <nl>  <nl> # ifndef _SYS_CDIO_H_ <nl> struct ioc_toc_header { <nl> struct ioc_read_toc_entry { <nl> u_char address_format ; <nl> u_char starting_track ; <nl> +# define CD_TRACK_LEADOUT 0xaa <nl> u_short data_len ; <nl> struct cd_toc_entry * data ; <nl> };
-/* $ OpenBSD : machdep . c , v 1 . 172 2016 / 05 / 10 18 : 39 : 40 deraadt Exp $ */ <nl> +/* $ OpenBSD : machdep . c , v 1 . 173 2016 / 05 / 11 17 : 59 : 58 deraadt Exp $ */ <nl> /* $ NetBSD : machdep . c , v 1 . 210 2000 / 06 / 01 17 : 12 : 38 thorpej Exp $ */ <nl>  <nl> /*- <nl> sys_sigreturn ( p , v , retval ) <nl> return ( EFAULT ); <nl> } <nl>  <nl> + /* Prevent reuse of the sigcontext cookie */ <nl> + ksc . sc_cookie = 0 ; <nl> + ( void ) copyout (& ksc . sc_cookie , ( caddr_t ) scp + <nl> + offsetof ( struct sigcontext , sc_cookie ), <nl> + sizeof ( ksc . sc_cookie )); <nl> + <nl> if ( ksc . sc_regs [ R_ZERO ] != 0xACEDBADE ) /* magic number */ <nl> return ( EINVAL ); <nl> /*
-/* $ OpenBSD : dev . c , v 1 . 71 2011 / 11 / 20 22 : 54 : 51 ratchov Exp $ */ <nl> +/* $ OpenBSD : dev . c , v 1 . 72 2011 / 12 / 02 10 : 30 : 12 ratchov Exp $ */ <nl> /* <nl> * Copyright ( c ) 2008 Alexandre Ratchov < alex @ caoua . org > <nl> * <nl> dev_new ( char * path , unsigned mode , <nl> d -> hold = hold ; <nl> d -> autovol = autovol ; <nl> d -> autostart = 0 ; <nl> + d -> refcnt = 0 ; <nl> d -> pstate = DEV_CLOSED ; <nl> d -> serial = 0 ; <nl> for ( i = 0 ; i < CTL_NSLOT ; i ++) {
-/* $ OpenBSD : who . c , v 1 . 13 2003 / 04 / 07 21 : 14 : 28 deraadt Exp $ */ <nl> +/* $ OpenBSD : who . c , v 1 . 14 2003 / 04 / 14 03 : 13 : 07 deraadt Exp $ */ <nl> /* $ NetBSD : who . c , v 1 . 4 1994 / 12 / 07 04 : 28 : 49 jtc Exp $ */ <nl>  <nl> /* <nl> static char copyright [] = <nl> # if 0 <nl> static char sccsid [] = "@(#) who . c 8 . 1 ( Berkeley ) 6 / 6 / 93 "; <nl> # endif <nl> - static char rcsid [] = "$ OpenBSD : who . c , v 1 . 13 2003 / 04 / 07 21 : 14 : 28 deraadt Exp $"; <nl> + static char rcsid [] = "$ OpenBSD : who . c , v 1 . 14 2003 / 04 / 14 03 : 13 : 07 deraadt Exp $"; <nl> # endif /* not lint */ <nl>  <nl> # include < sys / types . h > <nl> output ( up ) <nl> if ( now == 0 ) <nl> time (& now ); <nl>  <nl> - strcpy ( line , _PATH_DEV ); <nl> - strncat ( line , up -> ut_line , sizeof ( up -> ut_line )); <nl> + memset ( line , 0 , sizeof line ); <nl> + strlcpy ( line , _PATH_DEV , sizeof line ); <nl> + strlcat ( line , up -> ut_line , sizeof line ); <nl>  <nl> if ( stat ( line , & sb ) == 0 ) { <nl> state = ( sb . st_mode & 020 ) ? '+' : '-';
-/* $ OpenBSD : usbdi . c , v 1 . 34 2007 / 10 / 11 18 : 30 : 50 deraadt Exp $ */ <nl> +/* $ OpenBSD : usbdi . c , v 1 . 35 2008 / 06 / 21 22 : 24 : 45 fgsch Exp $ */ <nl> /* $ NetBSD : usbdi . c , v 1 . 103 2002 / 09 / 27 15 : 37 : 38 provos Exp $ */ <nl> /* $ FreeBSD : src / sys / dev / usb / usbdi . c , v 1 . 28 1999 / 11 / 17 22 : 33 : 49 n_hibma Exp $ */ <nl>  <nl> usb_transfer_complete ( usbd_xfer_handle xfer ) <nl>  <nl> # ifdef DIAGNOSTIC <nl> if ( pipe == NULL ) { <nl> - printf (" usbd_transfer_cb : pipe == 0 , xfer =% p \ n ", xfer ); <nl> + printf (" usbd_transfer_complete : pipe == 0 , xfer =% p \ n ", xfer ); <nl> return ; <nl> } <nl> # endif <nl> usb_transfer_complete ( usbd_xfer_handle xfer ) <nl> xfer -> done = 1 ; <nl> if (! xfer -> status && xfer -> actlen < xfer -> length && <nl> !( xfer -> flags & USBD_SHORT_XFER_OK )) { <nl> - DPRINTFN (- 1 ,(" usbd_transfer_cb : short transfer % d <% d \ n ", <nl> + DPRINTFN (- 1 ,(" usbd_transfer_complete : short transfer % d <% d \ n ", <nl> xfer -> actlen , xfer -> length )); <nl> xfer -> status = USBD_SHORT_XFER ; <nl> }
-/* $ OpenBSD : tls . c , v 1 . 27 2015 / 09 / 12 21 : 00 : 38 beck Exp $ */ <nl> +/* $ OpenBSD : tls . c , v 1 . 28 2015 / 09 / 13 13 : 44 : 07 beck Exp $ */ <nl> /* <nl> * Copyright ( c ) 2014 Joel Sing < jsing @ openbsd . org > <nl> * <nl> tls_handshake ( struct tls * ctx ) <nl> { <nl> int rv = - 1 ; <nl>  <nl> - if (( ctx -> conninfo = calloc ( 1 , sizeof (* ctx -> conninfo ))) == NULL ) <nl> + if ( ctx -> conninfo == NULL && <nl> + ( ctx -> conninfo = calloc ( 1 , sizeof (* ctx -> conninfo ))) == NULL ) <nl> goto out ; <nl>  <nl> if (( ctx -> flags & TLS_CLIENT ) != 0 )
-/* $ OpenBSD : softraid . c , v 1 . 152 2009 / 06 / 17 22 : 44 : 42 marco Exp $ */ <nl> +/* $ OpenBSD : softraid . c , v 1 . 153 2009 / 06 / 17 23 : 13 : 36 jordan Exp $ */ <nl> /* <nl> * Copyright ( c ) 2007 Marco Peereboom < marco @ peereboom . us > <nl> * Copyright ( c ) 2008 Chris Kuethe < ckuethe @ openbsd . org > <nl> sr_ioctl_createraid ( struct sr_softc * sc , struct bioc_createraid * bc , int user ) <nl> strlcpy ( sd -> sd_name , " RAID 1 ", sizeof ( sd -> sd_name )); <nl> vol_size = ch_entry -> src_meta . scmi . scm_coerced_size ; <nl> break ; <nl> -# ifdef not_yet <nl> case 4 : <nl> case 5 : <nl> if ( no_chunk < 3 ) <nl> sr_ioctl_createraid ( struct sr_softc * sc , struct bioc_createraid * bc , int user ) <nl> ( ch_entry -> src_meta . scmi . scm_coerced_size & <nl> ~(( strip_size >> DEV_BSHIFT ) - 1 )) * ( no_chunk - 1 ); <nl> break ; <nl> -# endif /* not_yet */ <nl> # ifdef AOE <nl> # ifdef not_yet <nl> case ' A ':
-/* $ OpenBSD : ike_auth . c , v 1 . 26 2000 / 06 / 20 05 : 55 : 15 niklas Exp $ */ <nl> -/* $ EOM : ike_auth . c , v 1 . 52 2000 / 06 / 19 07 : 41 : 07 niklas Exp $ */ <nl> +/* $ OpenBSD : ike_auth . c , v 1 . 27 2000 / 08 / 03 07 : 23 : 32 niklas Exp $ */ <nl> +/* $ EOM : ike_auth . c , v 1 . 53 2000 / 07 / 25 17 : 15 : 40 provos Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1998 , 1999 , 2000 Niklas Hallqvist . All rights reserved . <nl> pre_shared_gen_skeyid ( struct exchange * exchange , size_t * sz ) <nl> if ( buf ) <nl> free ( buf ); <nl>  <nl> + /* Fail if no key could be found */ <nl> + if ( key == NULL ) <nl> + return 0 ; <nl> + <nl> /* Store the secret key for later policy processing . */ <nl> exchange -> recv_cert = malloc ( keylen ); <nl> if (! exchange -> recv_cert )
-/* $ OpenBSD : radeon_ring . c , v 1 . 2 2014 / 02 / 09 11 : 03 : 31 jsg Exp $ */ <nl> +/* $ OpenBSD : radeon_ring . c , v 1 . 3 2014 / 02 / 09 13 : 22 : 04 jsg Exp $ */ <nl> /* <nl> * Copyright 2008 Advanced Micro Devices , Inc . <nl> * Copyright 2008 Red Hat Inc . <nl> int radeon_ring_alloc ( struct radeon_device * rdev , struct radeon_ring * ring , unsi <nl> return - ENOMEM ; <nl> /* Align requested size with padding so unlock_commit can <nl> * pad safely */ <nl> + radeon_ring_free_size ( rdev , ring ); <nl> + if ( ring -> ring_free_dw == ( ring -> ring_size / 4 )) { <nl> + /* This is an empty ring update lockup info to avoid <nl> + * false positive . <nl> + */ <nl> + radeon_ring_lockup_update ( ring ); <nl> + } <nl> ndw = ( ndw + ring -> align_mask ) & ~ ring -> align_mask ; <nl> while ( ndw > ( ring -> ring_free_dw - 1 )) { <nl> radeon_ring_free_size ( rdev , ring );
*/ <nl>  <nl> # include " includes . h " <nl> - RCSID ("$ OpenBSD : sshd . c , v 1 . 131 2000 / 10 / 12 09 : 59 : 20 markus Exp $"); <nl> + RCSID ("$ OpenBSD : sshd . c , v 1 . 132 2000 / 10 / 13 18 : 34 : 46 markus Exp $"); <nl>  <nl> # include " xmalloc . h " <nl> # include " rsa . h " <nl> sshd_exchange_identification ( int sock_in , int sock_out ) <nl> if ( buf [ i ] == '\ r ') { <nl> buf [ i ] = '\ n '; <nl> buf [ i + 1 ] = 0 ; <nl> + /* Kludge for F - Secure Macintosh < 1 . 0 . 2 */ <nl> + if ( i == 12 && <nl> + strncmp ( buf , " SSH - 1 . 5 - W1 . 0 ", 12 ) == 0 ) <nl> + break ; <nl> continue ; <nl> } <nl> if ( buf [ i ] == '\ n ') {
struct node { <nl> virtual const char * type () = 0 ; <nl> }; <nl>  <nl> - inline node :: node () : next ( 0 ) <nl> + inline node :: node () : next ( 0 ), last ( 0 ) <nl> { <nl> } <nl>  <nl> - inline node :: node ( node * n ) : next ( n ) <nl> + inline node :: node ( node * n ) : next ( n ), last ( 0 ) <nl> { <nl> } <nl> 
-/* $ OpenBSD : ipmi . c , v 1 . 25 2005 / 12 / 16 03 : 16 : 47 marco Exp $ */ <nl> +/* $ OpenBSD : ipmi . c , v 1 . 26 2006 / 01 / 04 23 : 51 : 16 marco Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2005 Jordan Hargrave <nl> bmc_io_wait_cold ( struct ipmi_softc * sc , int offset , u_int8_t mask , <nl> u_int8_t value , const char * lbl ) <nl> { <nl> volatile u_int8_t v ; <nl> - int count = 1000 ; <nl> + int count = 100000 ; <nl>  <nl> while ( count --) { <nl> v = bmc_read ( sc , offset ); <nl> ipmi_attach ( struct device * parent , struct device * self , void * aux ) <nl> /* setup ticker */ <nl> sc -> sc_retries = 0 ; <nl> sc -> sc_wakeup = 0 ; <nl> - sc -> sc_max_retries = 1000 ; /* XXX 50ms the right value ? */ <nl> + sc -> sc_max_retries = 100000 ; /* XXX 5s the right value ? */ <nl> timeout_set (& sc -> sc_timeout , _bmc_io_wait , sc ); <nl> } <nl> 
-/* $ OpenBSD : kern_tame . c , v 1 . 59 2015 / 10 / 06 14 : 02 : 49 deraadt Exp $ */ <nl> +/* $ OpenBSD : kern_tame . c , v 1 . 60 2015 / 10 / 06 14 : 38 : 23 deraadt Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2015 Nicholas Marriott < nicm @ openbsd . org > <nl> tame_namei ( struct proc * p , char * origpath ) <nl>  <nl> if ( p -> p_p -> ps_tame & TAME_RPATH ) <nl> return ( 0 ); <nl> - <nl> if ( p -> p_p -> ps_tame & TAME_WPATH ) <nl> return ( 0 ); <nl> + if ( p -> p_p -> ps_tame & TAME_CPATH ) <nl> + return ( 0 ); <nl>  <nl> return ( tame_fail ( p , EPERM , TAME_RPATH )); <nl> }
-/* $ OpenBSD : bwi . c , v 1 . 32 2007 / 09 / 16 12 : 15 : 57 mglocker Exp $ */ <nl> +/* $ OpenBSD : bwi . c , v 1 . 33 2007 / 09 / 16 12 : 33 : 26 jsg Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2007 The DragonFly Project . All rights reserved . <nl> int bwi_debug = 1 ; <nl> # endif <nl>  <nl> /* XXX temporary porting goop */ <nl> -# define KKASSERT ( cond ) if (!( cond )) panic (" bwi KKASSERT !\ n ") <nl> +# define KKASSERT ( cond ) if (!( cond )) panic (" KKASSERT : % s in % s ", # cond , __func__ ) <nl> # undef KASSERT <nl> # define KASSERT ( cond , complaint ) if (!( cond )) panic complaint <nl> 
-/* $ OpenBSD : bcw . c , v 1 . 31 2007 / 01 / 05 12 : 52 : 30 mglocker Exp $ */ <nl> +/* $ OpenBSD : bcw . c , v 1 . 32 2007 / 01 / 06 18 : 35 : 09 mglocker Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2006 Jon Simola < jsimola @ gmail . com > <nl> bcw_get_firmware ( const char * name , const uint8_t * ucode , size_t size_ucode , <nl>  <nl> /* get number of firmware files */ <nl> bcopy ( ucode , & nfiles , sizeof ( nfiles )); <nl> + nfiles = ntohl ( nfiles ); <nl> off += sizeof ( nfiles ); <nl>  <nl> /* parse header and search the firmware */ <nl> bcw_get_firmware ( const char * name , const uint8_t * ucode , size_t size_ucode , <nl>  <nl> if ( strcmp ( name , h -> filename ) == 0 ) { <nl> ret = 0 ; <nl> - * size = h -> filesize ; <nl> - * offset = h -> fileoffset ; <nl> + * size = ntohl ( h -> filesize ); <nl> + * offset = ntohl ( h -> fileoffset ); <nl> break ; <nl> } <nl> }
getfstab () <nl> return ; <nl> } <nl> while (( fs = getfsent ()) != NULL ) { <nl> + if ( strcmp ( fs -> fs_vfstype , " ffs ")) <nl> + continue ; <nl> if ( strcmp ( fs -> fs_type , FSTAB_RW ) && <nl> strcmp ( fs -> fs_type , FSTAB_RO ) && <nl> strcmp ( fs -> fs_type , FSTAB_RQ ))
-/* $ OpenBSD : elink3 . c , v 1 . 16 1996 / 11 / 28 23 : 27 : 49 niklas Exp $ */ <nl> +/* $ OpenBSD : elink3 . c , v 1 . 17 1997 / 01 / 05 04 : 03 : 26 deraadt Exp $ */ <nl> /* $ NetBSD : elink3 . c , v 1 . 11 1996 / 10 / 21 22 : 34 : 21 thorpej Exp $ */ <nl>  <nl> /* <nl> epintr ( arg ) <nl> u_int16_t status ; <nl> int ret = 0 ; <nl>  <nl> + if ( sc -> bustype == EP_BUS_PCMCIA && ( sc -> pcmcia_flags & EP_ABSENT )) <nl> + return ( ret ); <nl> + <nl> for (;;) { <nl> bus_space_write_2 ( iot , ioh , EP_COMMAND , C_INTR_LATCH ); <nl> 
-/* $ OpenBSD : ca . c , v 1 . 64 2020 / 07 / 15 14 : 45 : 15 tobhe Exp $ */ <nl> +/* $ OpenBSD : ca . c , v 1 . 65 2020 / 07 / 27 14 : 22 : 53 tobhe Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2010 - 2013 Reyk Floeter < reyk @ openbsd . org > <nl> ca_validate_pubkey ( struct iked * env , struct iked_static_id * id , <nl> if ( localkey == NULL ) <nl> goto sslerr ; <nl>  <nl> - if ( peerkey && ! EVP_PKEY_cmp ( peerkey , localkey )) { <nl> + if ( peerkey && EVP_PKEY_cmp ( peerkey , localkey ) != 1 ) { <nl> log_debug ("% s : public key does not match % s ", __func__ , file ); <nl> goto done ; <nl> }
-/* $ OpenBSD : uvm_map . c , v 1 . 101 2008 / 07 / 18 16 : 40 : 17 kurt Exp $ */ <nl> +/* $ OpenBSD : uvm_map . c , v 1 . 102 2008 / 07 / 25 12 : 02 : 09 art Exp $ */ <nl> /* $ NetBSD : uvm_map . c , v 1 . 86 2000 / 11 / 27 08 : 40 : 03 chs Exp $ */ <nl>  <nl> /* <nl> uvm_map_p ( struct vm_map * map , vaddr_t * startp , vsize_t size , <nl>  <nl> if (( map -> flags & VM_MAP_INTRSAFE ) == 0 ) <nl> splassert ( IPL_NONE ); <nl> + else <nl> + splassert ( IPL_VM ); <nl>  <nl> /* <nl> * step 0 : sanity check of protection code <nl> uvm_unmap_remove ( struct vm_map * map , vaddr_t start , vaddr_t end , <nl>  <nl> if (( map -> flags & VM_MAP_INTRSAFE ) == 0 ) <nl> splassert ( IPL_NONE ); <nl> + else <nl> + splassert ( IPL_VM ); <nl>  <nl> /* <nl> * find first entry
-/* $ Id : make_keypair . c , v 1 . 1 . 1 . 1 1995 / 12 / 14 06 : 52 : 53 tholo Exp $ */ <nl> +/* $ Id : make_keypair . c , v 1 . 2 1995 / 12 / 29 09 : 49 : 55 tholo Exp $ */ <nl>  <nl> /*- <nl> * Copyright ( c ) 1988 , 1993 <nl> static char sccsid [] = "@(#) make_keypair . c 8 . 1 ( Berkeley ) 6 / 1 / 93 "; <nl> # include " pathnames . h " <nl> # include " register_proto . h " <nl>  <nl> + char * progname ; <nl> + <nl> extern void herror (); <nl> void make_key (), usage (); <nl>  <nl> main ( argc , argv ) <nl> int i ; <nl> struct sockaddr_in sin ; <nl>  <nl> + progname = ( addr = strrchr (* argv , '/')) ? addr + 1 : * argv ; <nl> if ( argc != 2 ) { <nl> usage ( argv [ 0 ]); <nl> exit ( 1 ); <nl> make_key ( addr ) <nl> char namebuf [ 255 ]; <nl> int fd ; <nl>  <nl> - ( void ) sprintf ( namebuf , ".% s % s ", <nl> - CLIENT_KEYFILE , <nl> + ( void ) sprintf ( namebuf , "% s ", <nl> inet_ntoa ( addr )); <nl> fd = open ( namebuf , O_WRONLY | O_CREAT , 0600 ); <nl> if ( fd < 0 ) {
-/* $ OpenBSD : lka . c , v 1 . 35 2009 / 03 / 11 11 : 11 : 08 pea Exp $ */ <nl> +/* $ OpenBSD : lka . c , v 1 . 36 2009 / 03 / 20 09 : 34 : 34 gilles Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2008 Pierre - Yves Ritschard < pyr @ openbsd . org > <nl> lka_encode_credentials ( char * dest , char * src ) <nl> sizeof ( buffer ) - 1 ) <nl> return 0 ; <nl>  <nl> - while ( i ++ < len ) { <nl> + for ( i = 0 ; i < len ; ++ i ) { <nl> if ( buffer [ i ] == ':') { <nl> buffer [ i ] = '\ 0 '; <nl> break ;
-/* $ OpenBSD : tag . c , v 1 . 14 2016 / 11 / 08 15 : 27 : 06 schwarze Exp $ */ <nl> +/* $ OpenBSD : tag . c , v 1 . 15 2016 / 11 / 08 15 : 57 : 12 schwarze Exp $ */ <nl> /* <nl> * Copyright ( c ) 2015 , 2016 Ingo Schwarze < schwarze @ openbsd . org > <nl> * <nl> tag_put ( const char * s , int prio , size_t line ) <nl> size_t len ; <nl> unsigned int slot ; <nl>  <nl> - if ( tag_files . tfd <= 0 || strchr ( s , ' ') != NULL ) <nl> + /* Sanity checks . */ <nl> + <nl> + if ( tag_files . tfd <= 0 ) <nl> + return ; <nl> + if ( s [ 0 ] == '\\' && ( s [ 1 ] == '&' || s [ 1 ] == ' e ')) <nl> + s += 2 ; <nl> + if (* s == '\ 0 ' || strchr ( s , ' ') != NULL ) <nl> return ; <nl>  <nl> slot = ohash_qlookup (& tag_data , s );
-/* $ NetBSD : zs . c , v 1 . 11 1995 / 12 / 03 14 : 32 : 39 leo Exp $ */ <nl> +/* $ NetBSD : zs . c , v 1 . 12 1995 / 12 / 16 21 : 45 : 31 leo Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1995 L . Weppelman ( Atari modifications ) <nl>  <nl> # if NZS > 0 <nl>  <nl> -# define PCLK ( 8000000 ) /* PCLK pin input clock rate */ <nl> +# define PCLK ( 8053976 ) /* PCLK pin input clock rate */ <nl>  <nl> # define splzs spl5 <nl> 
-/* $ OpenBSD : editor . c , v 1 . 279 2014 / 02 / 15 00 : 10 : 17 krw Exp $ */ <nl> +/* $ OpenBSD : editor . c , v 1 . 280 2014 / 02 / 15 02 : 39 : 38 krw Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1997 - 2000 Todd C . Miller < Todd . Miller @ courtesan . com > <nl> mpfree ( char ** mp ) <nl> { <nl> int part ; <nl>  <nl> + if ( mp == NULL ) <nl> + return ; <nl> + <nl> for ( part == 0 ; part < MAXPARTITIONS ; part ++) { <nl> free ( mp [ part ]); <nl> mp [ part ] = NULL ;
-/* $ OpenBSD : kern_tame . c , v 1 . 11 2015 / 07 / 20 21 : 36 : 27 tedu Exp $ */ <nl> +/* $ OpenBSD : kern_tame . c , v 1 . 12 2015 / 07 / 21 16 : 17 : 17 guenther Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2015 Nicholas Marriott < nicm @ openbsd . org > <nl> int canonpath ( const char * input , char * buf , size_t bufsize ); <nl>  <nl> const u_int tame_syscalls [ SYS_MAXSYSCALL ] = { <nl> [ SYS_exit ] = 0xffffffff , <nl> + [ SYS_kbind ] = 0xffffffff , <nl>  <nl> [ SYS_getuid ] = _TM_SELF , <nl> [ SYS_geteuid ] = _TM_SELF , <nl> const u_int tame_syscalls [ SYS_MAXSYSCALL ] = { <nl> [ SYS___thrsleep ] = _TM_SELF , <nl> [ SYS___thrwakeup ] = _TM_SELF , <nl> [ SYS___threxit ] = _TM_SELF , <nl> + [ SYS___thrsigdivert ] = _TM_SELF , <nl>  <nl> [ SYS_sendsyslog ] = _TM_SELF , <nl> [ SYS_nanosleep ] = _TM_SELF , <nl> tame_check ( struct proc * p , int code ) <nl> return ( 0 ); <nl>  <nl> if ( p -> p_p -> ps_tame == 0 ) <nl> - return ( code == SYS_exit ); <nl> + return ( code == SYS_exit || code == SYS_kbind ); <nl> return ( p -> p_p -> ps_tame & tame_syscalls [ code ]); <nl> } <nl> 
-/* $ OpenBSD : tftpd . c , v 1 . 30 2015 / 10 / 06 06 : 03 : 11 deraadt Exp $ */ <nl> +/* $ OpenBSD : tftpd . c , v 1 . 31 2015 / 10 / 10 22 : 21 : 39 deraadt Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2012 David Gwynne < dlg @ uq . edu . au > <nl> main ( int argc , char * argv []) <nl> if (! debug && daemon ( 1 , 0 ) == - 1 ) <nl> err ( 1 , " unable to daemonize "); <nl>  <nl> + if ( pledge (" stdio rpath wpath cpath fattr inet ", NULL ) == - 1 ) <nl> + err ( 1 , " pledge "); <nl> + <nl> event_init (); <nl>  <nl> if ( rewrite != NULL )
-/* $ OpenBSD : kroute . c , v 1 . 55 2004 / 01 / 08 16 : 52 : 05 henning Exp $ */ <nl> +/* $ OpenBSD : kroute . c , v 1 . 56 2004 / 01 / 08 16 : 55 : 25 henning Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2003 , 2004 Henning Brauer < henning @ openbsd . org > <nl> knexthop_validate ( struct knexthop_node * kn ) <nl>  <nl> bzero (& n , sizeof ( n )); <nl> n . nexthop = kn -> nexthop ; <nl> + kroute_detach_nexthop ( kn ); <nl>  <nl> if (( kr = kroute_match ( kn -> nexthop )) == NULL ) { /* no match */ <nl> if ( was_valid ) <nl> send_nexthop_update (& n ); <nl> - kroute_detach_nexthop ( kn ); <nl> } else { /* found match */ <nl> if ( kr -> flags & F_DOWN ) { /* but is down */ <nl> if ( was_valid )
-/* $ OpenBSD : if_spppsubr . c , v 1 . 35 2005 / 08 / 03 21 : 50 : 21 canacar Exp $ */ <nl> +/* $ OpenBSD : if_spppsubr . c , v 1 . 36 2005 / 08 / 12 21 : 29 : 10 canacar Exp $ */ <nl> /* <nl> * Synchronous PPP / Cisco link level subroutines . <nl> * Keepalive protocol implemented in both Cisco and PPP modes . <nl> sppp_input ( struct ifnet * ifp , struct mbuf * m ) <nl> struct ifqueue * inq = 0 ; <nl> struct sppp * sp = ( struct sppp *) ifp ; <nl> struct timeval tv ; <nl> + void * prej ; <nl> int debug = ifp -> if_flags & IFF_DEBUG ; <nl> int s ; <nl>  <nl> sppp_input ( struct ifnet * ifp , struct mbuf * m ) <nl> } <nl>  <nl> if ( sp -> pp_flags & PP_NOFRAMING ) { <nl> - memcpy (& ht . protocol , mtod ( m , void *), 2 ); <nl> + prej = mtod ( m , void *); <nl> + memcpy (& ht . protocol , prej , sizeof ( ht . protocol )); <nl> m_adj ( m , 2 ); <nl> ht . control = PPP_UI ; <nl> ht . address = PPP_ALLSTATIONS ; <nl> sppp_input ( struct ifnet * ifp , struct mbuf * m ) <nl> } else { <nl> /* Get PPP header . */ <nl> h = mtod ( m , struct ppp_header *); <nl> + prej = & h -> protocol ; <nl> m_adj ( m , PPP_HEADER_LEN ); <nl> } <nl>  <nl> sppp_input ( struct ifnet * ifp , struct mbuf * m ) <nl> default : <nl> if ( sp -> state [ IDX_LCP ] == STATE_OPENED ) <nl> sppp_cp_send ( sp , PPP_LCP , PROTO_REJ , <nl> - ++ sp -> pp_seq , m -> m_pkthdr . len + 2 , <nl> - & h -> protocol ); <nl> + ++ sp -> pp_seq , m -> m_pkthdr . len + 2 , prej ); <nl> if ( debug ) <nl> log ( LOG_DEBUG , <nl> SPP_FMT " invalid input protocol "
-/* $ OpenBSD : main . c , v 1 . 111 2016 / 11 / 06 13 : 16 : 50 jsing Exp $ */ <nl> +/* $ OpenBSD : main . c , v 1 . 112 2016 / 11 / 30 07 : 55 : 24 mestre Exp $ */ <nl> /* $ NetBSD : main . c , v 1 . 24 1997 / 08 / 18 10 : 20 : 26 lukem Exp $ */ <nl>  <nl> /* <nl> main ( volatile int argc , char * argv []) <nl> tls_config = tls_config_new (); <nl> if ( tls_config == NULL ) <nl> errx ( 1 , " tls config failed "); <nl> - tls_config_set_protocols ( tls_config , TLS_PROTOCOLS_ALL ); <nl> + if ( tls_config_set_protocols ( tls_config , <nl> + TLS_PROTOCOLS_ALL ) != 0 ) <nl> + errx ( 1 , " tls set protocols failed : % s ", <nl> + tls_config_error ( tls_config )); <nl> if ( tls_config_set_ciphers ( tls_config , " legacy ") != 0 ) <nl> errx ( 1 , " tls set ciphers failed : % s ", <nl> tls_config_error ( tls_config ));
-/* $ OpenBSD : ftpd . c , v 1 . 22 1996 / 10 / 15 12 : 29 : 27 deraadt Exp $ */ <nl> +/* $ OpenBSD : ftpd . c , v 1 . 23 1996 / 10 / 18 20 : 12 : 45 deraadt Exp $ */ <nl> /* $ NetBSD : ftpd . c , v 1 . 15 1995 / 06 / 03 22 : 46 : 47 mycroft Exp $ */ <nl>  <nl> /* <nl> sgetpwnam ( name ) <nl> return ( p ); <nl> if ( save . pw_name ) { <nl> free ( save . pw_name ); <nl> + memset ( save . pw_passwd , 0 , strlen ( save . pw_passwd ); <nl> free ( save . pw_passwd ); <nl> free ( save . pw_gecos ); <nl> free ( save . pw_dir );
 <nl> # include " form . priv . h " <nl>  <nl> - MODULE_ID ("$ Id : frm_driver . c , v 1 . 9 2010 / 01 / 12 23 : 22 : 07 nicm Exp $") <nl> + MODULE_ID ("$ Id : frm_driver . c , v 1 . 10 2011 / 01 / 18 18 : 57 : 51 nicm Exp $") <nl>  <nl> /*---------------------------------------------------------------------------- <nl> This is the core module of the form library . It contains the majority <nl> set_field_buffer ( FIELD * field , int buffer , const char * value ) <nl> * field -> cols )))) <nl> RETURN ( E_SYSTEM_ERROR ); <nl>  <nl> +# if ! USE_WIDEC_SUPPORT <nl> len = vlen ; <nl> +# endif <nl> } <nl> } <nl>  <nl> set_field_buffer ( FIELD * field , int buffer , const char * value ) <nl> delwin ( field -> working ); <nl> field -> working = newpad ( field -> drows , field -> dcols ); <nl> } <nl> + len = Buffer_Length ( field ); <nl> wclear ( field -> working ); <nl> mvwaddstr ( field -> working , 0 , 0 , value ); <nl> 
-/* $ OpenBSD : editor . c , v 1 . 314 2018 / 02 / 27 14 : 58 : 05 krw Exp $ */ <nl> +/* $ OpenBSD : editor . c , v 1 . 315 2018 / 03 / 01 15 : 19 : 05 krw Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 1997 - 2000 Todd C . Miller < Todd . Miller @ courtesan . com > <nl> editor_resize ( struct disklabel * lp , char * p ) <nl> } <nl> secs = getuint64 ( lp , "[+|-] new size ( with unit )", <nl> " new size or amount to grow (+) or shrink (-) partition including unit ", <nl> - sz , editor_countfree ( lp ), 0 , DO_CONVERSIONS ); <nl> + sz , sz + editor_countfree ( lp ), 0 , DO_CONVERSIONS ); <nl>  <nl> - if ( secs <= 0 ) { <nl> + if ( secs == ULLONG_MAX - 1 ) { <nl> fputs (" Command aborted \ n ", stderr ); <nl> return ; <nl> + } else if ( secs == ULLONG_MAX ) { <nl> + fputs (" Invalid entry \ n ", stderr ); <nl> + return ; <nl> } <nl>  <nl> # ifdef SUN_CYLCHECK
-/* $ OpenBSD : wskbd . c , v 1 . 27 2001 / 10 / 25 14 : 30 : 43 drahn Exp $ */ <nl> +/* $ OpenBSD : wskbd . c , v 1 . 28 2001 / 10 / 30 05 : 15 : 37 mickey Exp $ */ <nl> /* $ NetBSD : wskbd . c , v 1 . 38 2000 / 03 / 23 07 : 01 : 47 thorpej Exp $ */ <nl>  <nl> /* <nl> getbell : <nl> kkdp = & sc -> sc_keyrepeat_data ; <nl> setkeyrepeat : <nl> ukdp = ( struct wskbd_keyrepeat_data *) data ; <nl> + if (( ukdp -> which & WSKBD_KEYREPEAT_DODEL1 && <nl> + ( hz * ukdp -> del1 ) / 1000 <= 0 ) || <nl> + ( ukdp -> which & WSKBD_KEYREPEAT_DODELN && <nl> + ( hz * ukdp -> delN ) / 1000 <= 0 )) <nl> + return ( EINVAL ); <nl> SETKEYREPEAT ( kkdp , ukdp , kkdp ); <nl> return ( 0 ); <nl> 
-/* $ OpenBSD : fuse_device . c , v 1 . 18 2015 / 02 / 10 22 : 04 : 00 miod Exp $ */ <nl> +/* $ OpenBSD : fuse_device . c , v 1 . 19 2015 / 09 / 02 04 : 07 : 11 deraadt Exp $ */ <nl> /* <nl> * Copyright ( c ) 2012 - 2013 Sylvestre Gallon < ccna . syl @ gmail . com > <nl> * <nl> fuse_destroy ( dev_t dev , struct fuse_d * fd ) <nl> { <nl> LIST_REMOVE ( fd , fd_list ); <nl> fuse_device_cleanup ( dev , NULL ); <nl> - free ( fd , M_DEVBUF , 0 ); <nl> + free ( fd , M_DEVBUF , sizeof * fd ); <nl> } <nl>  <nl> /*
-/* $ OpenBSD : wdc . c , v 1 . 132 2017 / 07 / 12 13 : 40 : 59 mikeb Exp $ */ <nl> +/* $ OpenBSD : wdc . c , v 1 . 133 2017 / 09 / 26 22 : 12 : 04 mikeb Exp $ */ <nl> /* $ NetBSD : wdc . c , v 1 . 68 1999 / 06 / 23 19 : 00 : 17 bouyer Exp $ */ <nl> /* <nl> * Copyright ( c ) 1998 , 2001 Manuel Bouyer . All rights reserved . <nl> wdcprobe ( struct channel_softc * chp ) <nl> if ( ret_value == 0 ) <nl> return 0 ; <nl>  <nl> - if ( chp -> wdc -> quirks & WDC_QUIRK_NOATAPI ) <nl> + if ( chp -> wdc && ( chp -> wdc -> quirks & WDC_QUIRK_NOATAPI )) <nl> goto noatapi ; <nl>  <nl> /* <nl> wdcprobe ( struct channel_softc * chp ) <nl> } <nl>  <nl> noatapi : <nl> - if ( chp -> wdc -> quirks & WDC_QUIRK_NOATA ) <nl> + if ( chp -> wdc && ( chp -> wdc -> quirks & WDC_QUIRK_NOATA )) <nl> goto noata ; <nl>  <nl> /*
-/* $ OpenBSD : keymap . c , v 1 . 25 2002 / 09 / 28 05 : 18 : 48 deraadt Exp $ */ <nl> +/* $ OpenBSD : keymap . c , v 1 . 26 2002 / 12 / 09 08 : 20 : 46 deraadt Exp $ */ <nl>  <nl> /* <nl> * Keyboard maps . This is character set dependent . The terminal specific <nl> static PF cXcar [] = { <nl> rescan , /* e */ <nl> # endif /* ! NO_MACRO */ <nl> setfillcol , /* f */ <nl> - rescan , /* g */ <nl> + gotoline , /* g */ <nl> rescan , /* h */ <nl> fileinsert , /* i */ <nl> rescan , /* j */
-/* $ OpenBSD : digest - openssl . c , v 1 . 5 2014 / 12 / 21 22 : 27 : 56 djm Exp $ */ <nl> +/* $ OpenBSD : digest - openssl . c , v 1 . 6 2017 / 03 / 10 02 : 59 : 51 dtucker Exp $ */ <nl> /* <nl> * Copyright ( c ) 2013 Damien Miller < djm @ mindrot . org > <nl> * <nl> ssh_digest_final ( struct ssh_digest_ctx * ctx , u_char * d , size_t dlen ) <nl> const struct ssh_digest * digest = ssh_digest_by_alg ( ctx -> alg ); <nl> u_int l = dlen ; <nl>  <nl> - if ( dlen > UINT_MAX ) <nl> + if ( digest == NULL || dlen > UINT_MAX ) <nl> return SSH_ERR_INVALID_ARGUMENT ; <nl> if ( dlen < digest -> digest_len ) /* No truncation allowed */ <nl> return SSH_ERR_INVALID_ARGUMENT ;
-/* $ OpenBSD : uhub . c , v 1 . 58 2011 / 07 / 03 15 : 47 : 17 matthew Exp $ */ <nl> +/* $ OpenBSD : uhub . c , v 1 . 59 2011 / 09 / 29 11 : 18 : 01 stsp Exp $ */ <nl> /* $ NetBSD : uhub . c , v 1 . 64 2003 / 02 / 08 03 : 32 : 51 ichiro Exp $ */ <nl> /* $ FreeBSD : src / sys / dev / usb / uhub . c , v 1 . 18 1999 / 11 / 17 22 : 33 : 43 n_hibma Exp $ */ <nl>  <nl> uhub_attach ( struct device * parent , struct device * self , void * aux ) <nl> bad : <nl> if ( sc -> sc_statusbuf ) <nl> free ( sc -> sc_statusbuf , M_USBDEV ); <nl> - if ( hub -> ports ) <nl> - free ( hub -> ports , M_USBDEV ); <nl> - if ( hub ) <nl> + if ( hub ) { <nl> + if ( hub -> ports ) <nl> + free ( hub -> ports , M_USBDEV ); <nl> free ( hub , M_USBDEV ); <nl> + } <nl> dev -> hub = NULL ; <nl> } <nl> 
-/* $ OpenBSD : pf . c , v 1 . 1009 2016 / 12 / 29 13 : 01 : 48 bluhm Exp $ */ <nl> +/* $ OpenBSD : pf . c , v 1 . 1010 2017 / 01 / 09 14 : 47 : 13 mpi Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2001 Daniel Hartmeier <nl> pf_purge_thread ( void * v ) <nl> for (;;) { <nl> tsleep ( pf_purge_thread , PWAIT , " pftm ", 1 * hz ); <nl>  <nl> - s = splsoftnet (); <nl> + NET_LOCK ( s ); <nl>  <nl> /* process a fraction of the state table every second */ <nl> pf_purge_expired_states ( 1 + ( pf_status . states <nl> pf_purge_thread ( void * v ) <nl> nloops = 0 ; <nl> } <nl>  <nl> - splx ( s ); <nl> + NET_UNLOCK ( s ); <nl> } <nl> } <nl> 
-/* $ OpenBSD : smfb . c , v 1 . 16 2013 / 10 / 21 10 : 36 : 14 miod Exp $ */ <nl> +/* $ OpenBSD : smfb . c , v 1 . 17 2017 / 01 / 10 08 : 26 : 41 fcambus Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2009 , 2010 Miodrag Vallat . <nl> smfb_attach_common ( struct smfb_softc * sc , int is5xx , bus_space_tag_t memt , <nl> } <nl> } <nl>  <nl> - /* XXX print resolution */ <nl> - printf ("\ n "); <nl> + printf (": % dx % d , % dbpp \ n ", sc -> sc_fb -> ri . ri_width , <nl> + sc -> sc_fb -> ri . ri_height , sc -> sc_fb -> ri . ri_depth ); <nl>  <nl> sc -> sc_scrlist [ 0 ] = & sc -> sc_fb -> wsd ; <nl> sc -> sc_wsl . nscreens = 1 ;
-/* $ OpenBSD : radeon_combios . c , v 1 . 3 2014 / 02 / 10 00 : 10 : 12 jsg Exp $ */ <nl> +/* $ OpenBSD : radeon_combios . c , v 1 . 4 2014 / 02 / 10 00 : 17 : 30 jsg Exp $ */ <nl> /* <nl> * Copyright 2004 ATI Technologies Inc ., Markham , Ontario <nl> * Copyright 2007 - 8 Advanced Micro Devices , Inc . <nl> struct radeon_encoder_primary_dac * radeon_combios_get_primary_dac_info ( struct <nl> dac = RBIOS8 ( dac_info + 0x3 ) & 0xf ; <nl> p_dac -> ps2_pdac_adj = ( bg << 8 ) | ( dac ); <nl> } <nl> - /* if the values are all zeros , use the table */ <nl> - if ( p_dac -> ps2_pdac_adj ) <nl> + /* if the values are zeros , use the table */ <nl> + if (( dac == 0 ) || ( bg == 0 )) <nl> + found = 0 ; <nl> + else <nl> found = 1 ; <nl> } <nl> 
-/* $ OpenBSD : tree . c , v 1 . 9 1999 / 07 / 14 13 : 37 : 24 millert Exp $ */ <nl> +/* $ OpenBSD : tree . c , v 1 . 10 2002 / 02 / 27 19 : 37 : 09 dhartmei Exp $ */ <nl>  <nl> /* <nl> * command tree climbing <nl> tcopy ( t , ap ) <nl> for ( tw = t -> vars ; * tw ++ != NULL ; ) <nl> ; <nl> rw = r -> vars = ( char **) <nl> - alloc (( int )( tw - t -> vars ) * sizeof (* tw ), ap ); <nl> + alloc (( tw - t -> vars + 1 ) * sizeof (* tw ), ap ); <nl> for ( tw = t -> vars ; * tw != NULL ; ) <nl> * rw ++ = wdcopy (* tw ++, ap ); <nl> * rw = NULL ; <nl> tcopy ( t , ap ) <nl> for ( tw = t -> args ; * tw ++ != NULL ; ) <nl> ; <nl> rw = r -> args = ( char **) <nl> - alloc (( int )( tw - t -> args ) * sizeof (* tw ), ap ); <nl> + alloc (( tw - t -> args + 1 ) * sizeof (* tw ), ap ); <nl> for ( tw = t -> args ; * tw != NULL ; ) <nl> * rw ++ = wdcopy (* tw ++, ap ); <nl> * rw = NULL ; <nl> iocopy ( iow , ap ) <nl>  <nl> for ( ior = iow ; * ior ++ != NULL ; ) <nl> ; <nl> - ior = ( struct ioword **) alloc (( int )( ior - iow ) * sizeof (* ior ), ap ); <nl> + ior = ( struct ioword **) alloc (( ior - iow + 1 ) * sizeof (* ior ), ap ); <nl>  <nl> for ( i = 0 ; iow [ i ] != NULL ; i ++) { <nl> register struct ioword * p , * q ;
-/* $ OpenBSD : expl . c , v 1 . 4 1999 / 02 / 01 06 : 53 : 56 d Exp $ */ <nl> +/* $ OpenBSD : expl . c , v 1 . 5 1999 / 08 / 30 23 : 30 : 08 d Exp $ */ <nl> /* $ NetBSD : expl . c , v 1 . 2 1997 / 10 / 10 16 : 33 : 18 lukem Exp $ */ <nl> /* <nl> * Hunt <nl> showexpl ( y , x , type ) <nl> if ( x < 0 || x >= WIDTH ) <nl> return ; <nl> ep = ( EXPL *) malloc ( sizeof ( EXPL )); /* NOSTRICT */ <nl> + if ( ep == NULL ) { <nl> + log ( LOG_ERR , " malloc "); <nl> + return ; <nl> + } <nl> ep -> e_y = y ; <nl> ep -> e_x = x ; <nl> ep -> e_char = type ;
-/* $ OpenBSD : ruserpass . c , v 1 . 21 2007 / 03 / 22 11 : 35 : 02 moritz Exp $ */ <nl> +/* $ OpenBSD : ruserpass . c , v 1 . 22 2007 / 03 / 22 15 : 25 : 17 moritz Exp $ */ <nl> /* $ NetBSD : ruserpass . c , v 1 . 14 1997 / 07 / 20 09 : 46 : 01 lukem Exp $ */ <nl>  <nl> /* <nl> static char sccsid [] = "@(#) ruserpass . c 8 . 4 ( Berkeley ) 4 / 27 / 95 "; <nl> # else <nl> # ifndef SMALL <nl> - static const char rcsid [] = "$ OpenBSD : ruserpass . c , v 1 . 21 2007 / 03 / 22 11 : 35 : 02 moritz Exp $"; <nl> + static const char rcsid [] = "$ OpenBSD : ruserpass . c , v 1 . 22 2007 / 03 / 22 15 : 25 : 17 moritz Exp $"; <nl> # endif /* SMALL */ <nl> # endif <nl> # endif /* not lint */ <nl> ruserpass ( const char * host , char ** aname , char ** apass , char ** aacct ) <nl> hdir = getenv (" HOME "); <nl> if ( hdir == NULL || * hdir == '\ 0 ') <nl> return ( 0 ); <nl> - if ( strlen ( hdir ) + sizeof (". netrc ") < sizeof ( buf )) { <nl> - ( void ) snprintf ( buf , sizeof buf , "% s /. netrc ", hdir ); <nl> - } else { <nl> + i = snprintf ( buf , sizeof ( buf ), "% s /. netrc ", hdir ); <nl> + if ( i < 0 || i >= sizeof ( buf )) { <nl> warnx ("% s /. netrc : % s ", hdir , strerror ( ENAMETOOLONG )); <nl> return ( 0 ); <nl> }
-/* $ OpenBSD : ipmi . c , v 1 . 99 2017 / 09 / 08 05 : 36 : 52 deraadt Exp $ */ <nl> +/* $ OpenBSD : ipmi . c , v 1 . 100 2018 / 01 / 01 16 : 16 : 23 bluhm Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2015 Masao Uebayashi <nl> ipmi_match ( struct device * parent , void * match , void * aux ) <nl> return ( 0 ); <nl>  <nl> /* XXX local softc is wrong wrong wrong */ <nl> - sc = malloc ( sizeof (* sc ), M_TEMP , M_NOWAIT | M_ZERO ); <nl> + sc = malloc ( sizeof (* sc ), M_TEMP , M_WAITOK | M_ZERO ); <nl> mtx_init (& sc -> sc_cmd_mtx , IPL_NONE ); <nl> strlcpy ( sc -> sc_dev . dv_xname , " ipmi0 ", sizeof ( sc -> sc_dev . dv_xname )); <nl> 
-/* $ OpenBSD : ip_icmp . c , v 1 . 53 2002 / 08 / 28 15 : 43 : 03 pefo Exp $ */ <nl> +/* $ OpenBSD : ip_icmp . c , v 1 . 54 2003 / 01 / 31 17 : 23 : 34 henning Exp $ */ <nl> /* $ NetBSD : ip_icmp . c , v 1 . 19 1996 / 02 / 13 23 : 42 : 22 christos Exp $ */ <nl>  <nl> /* <nl> icmp_reflect ( m ) <nl> if ( ro . ro_rt == 0 ) <nl> { <nl> ipstat . ips_noroute ++; <nl> + m_freem ( m ); <nl> goto done ; <nl> } <nl> 
-/* $ OpenBSD : inp . c , v 1 . 38 2014 / 10 / 08 04 : 06 : 23 doug Exp $ */ <nl> +/* $ OpenBSD : inp . c , v 1 . 39 2014 / 11 / 15 16 : 35 : 47 tobias Exp $ */ <nl>  <nl> /* <nl> * patch - a program to apply diffs to original files <nl> void <nl> re_input ( void ) <nl> { <nl> if ( using_plan_a ) { <nl> - i_size = 0 ; <nl> free ( i_ptr ); <nl> i_ptr = NULL ; <nl> if ( i_womp != NULL ) { <nl> munmap ( i_womp , i_size ); <nl> i_womp = NULL ; <nl> } <nl> + i_size = 0 ; <nl> } else { <nl> using_plan_a = true ; /* maybe the next one is smaller */ <nl> close ( tifd );
-/* $ OpenBSD : acpihpet . c , v 1 . 12 2010 / 07 / 21 19 : 35 : 15 deraadt Exp $ */ <nl> +/* $ OpenBSD : acpihpet . c , v 1 . 13 2011 / 01 / 10 13 : 36 : 57 mikeb Exp $ */ <nl> /* <nl> * Copyright ( c ) 2005 Thorsten Lockert < tholo @ sigmasoft . com > <nl> * <nl> # include < dev / acpi / acpivar . h > <nl> # include < dev / acpi / acpidev . h > <nl>  <nl> + int acpihpet_attached ; <nl> + <nl> int acpihpet_match ( struct device *, void *, void *); <nl> void acpihpet_attach ( struct device *, struct device *, void *); <nl> int acpihpet_activate ( struct device *, int ); <nl> acpihpet_match ( struct device * parent , void * match , void * aux ) <nl> struct acpi_table_header * hdr ; <nl>  <nl> /* <nl> - * If we do not have a table , it is not us <nl> + * If we do not have a table , it is not us ; attach only once <nl> */ <nl> - if ( aaa -> aaa_table == NULL ) <nl> + if ( acpihpet_attached || aaa -> aaa_table == NULL ) <nl> return ( 0 ); <nl>  <nl> /* <nl> acpihpet_attach ( struct device * parent , struct device * self , void * aux ) <nl> hpet_timecounter . tc_name = sc -> sc_dev . dv_xname ; <nl> tc_init (& hpet_timecounter ); <nl> # endif <nl> + acpihpet_attached ++; <nl> } <nl>  <nl> # ifdef __HAVE_TIMECOUNTER
ksymsmmap ( dev , off , prot ) <nl> int off , prot ; <nl> { <nl> # define ksyms_btop ( x ) (( vm_offset_t )( x ) >> PGSHIFT <nl> + if ( off < 0 ) <nl> + return (- 1 ); <nl> if (( unsigned ) off >= ( unsigned )( esym - symtab ) + k1 -> a_text ) <nl> return (- 1 ); <nl> 
zcfree ( notused , ptr ) <nl> void * notused ; <nl> void * ptr ; <nl> { <nl> - free ( ptr , M_DEVBUF ); <nl> + free ( ptr , M_DEVBUF , 0 ); <nl> }
-/* $ OpenBSD : log . c , v 1 . 42 2004 / 11 / 18 14 : 30 : 10 henning Exp $ */ <nl> +/* $ OpenBSD : log . c , v 1 . 43 2005 / 03 / 26 18 : 49 : 34 tedu Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2003 , 2004 Henning Brauer < henning @ openbsd . org > <nl> log_notification ( const struct peer * peer , u_int8_t errcode , u_int8_t subcode , <nl> p = log_fmt_peer (& peer -> conf ); <nl> switch ( errcode ) { <nl> case ERR_HEADER : <nl> - if ( subcode > sizeof ( suberr_header_names )/ sizeof ( char *)) <nl> + if ( subcode >= sizeof ( suberr_header_names )/ sizeof ( char *)) <nl> uk = 1 ; <nl> else <nl> suberrname = suberr_header_names [ subcode ]; <nl> break ; <nl> case ERR_OPEN : <nl> - if ( subcode > sizeof ( suberr_open_names )/ sizeof ( char *)) <nl> + if ( subcode >= sizeof ( suberr_open_names )/ sizeof ( char *)) <nl> uk = 1 ; <nl> else <nl> suberrname = suberr_open_names [ subcode ]; <nl> break ; <nl> case ERR_UPDATE : <nl> - if ( subcode > sizeof ( suberr_update_names )/ sizeof ( char *)) <nl> + if ( subcode >= sizeof ( suberr_update_names )/ sizeof ( char *)) <nl> uk = 1 ; <nl> else <nl> suberrname = suberr_update_names [ subcode ];
-/* $ OpenBSD : icmp6 . c , v 1 . 91 2007 / 01 / 15 21 : 32 : 29 itojun Exp $ */ <nl> +/* $ OpenBSD : icmp6 . c , v 1 . 92 2007 / 01 / 16 11 : 05 : 25 itojun Exp $ */ <nl> /* $ KAME : icmp6 . c , v 1 . 217 2001 / 06 / 20 15 : 03 : 29 jinmei Exp $ */ <nl>  <nl> /* <nl> icmp6_input ( mp , offp , proto ) <nl> } else { <nl> deliverecho : <nl> nip6 = mtod ( n , struct ip6_hdr *); <nl> - IP6_EXTHDR_GET ( nicmp6 , struct icmp6_hdr *, n , off , NULL ); <nl> - nicmp6 = ( struct icmp6_hdr *)(( caddr_t ) nip6 + off ); <nl> + IP6_EXTHDR_GET ( nicmp6 , struct icmp6_hdr *, n , off , <nl> + sizeof (* nicmp6 )); <nl> noff = off ; <nl> } <nl> nicmp6 -> icmp6_type = ICMP6_ECHO_REPLY ;
-/* $ OpenBSD : dhcrelay . c , v 1 . 44 2016 / 12 / 07 13 : 19 : 18 rzalamena Exp $ */ <nl> +/* $ OpenBSD : dhcrelay . c , v 1 . 45 2016 / 12 / 07 16 : 41 : 17 reyk Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2004 Henning Brauer < henning @ cvs . openbsd . org > <nl> main ( int argc , char * argv []) <nl> log_perror = 0 ; <nl> } <nl>  <nl> + if ( pledge (" stdio route ", NULL ) == - 1 ) <nl> + error (" pledge "); <nl> + <nl> dispatch (); <nl> /* not reached */ <nl> 
-/* $ OpenBSD : packet . c , v 1 . 144 2006 / 09 / 16 19 : 53 : 37 djm Exp $ */ <nl> +/* $ OpenBSD : packet . c , v 1 . 145 2006 / 09 / 19 21 : 14 : 08 markus Exp $ */ <nl> /* <nl> * Author : Tatu Ylonen < ylo @ cs . hut . fi > <nl> * Copyright ( c ) 1995 Tatu Ylonen < ylo @ cs . hut . fi >, Espoo , Finland <nl> packet_enable_delayed_compress ( void ) <nl> */ <nl> after_authentication = 1 ; <nl> for ( mode = 0 ; mode < MODE_MAX ; mode ++) { <nl> + /* protocol error : USERAUTH_SUCCESS received before NEWKEYS */ <nl> + if ( newkeys [ mode ] == NULL ) <nl> + continue ; <nl> comp = & newkeys [ mode ]-> comp ; <nl> if ( comp && ! comp -> enabled && comp -> type == COMP_DELAYED ) { <nl> packet_init_compression ();
-/* $ OpenBSD : tag . c , v 1 . 66 2008 / 02 / 09 11 : 56 : 58 joris Exp $ */ <nl> +/* $ OpenBSD : tag . c , v 1 . 67 2008 / 02 / 09 13 : 03 : 29 joris Exp $ */ <nl> /* <nl> * Copyright ( c ) 2006 Xavier Santolaria < xsa @ openbsd . org > <nl> * <nl> tag_add ( struct cvs_file * cf ) <nl> cvs_printf (" : NOT MOVING tag to version % s \ n ", revbuf ); <nl>  <nl> return (- 1 ); <nl> - } else if ( runflags & T_FORCE_MOVE ) { <nl> + } else { <nl> sym = rcs_sym_get ( cf -> file_rcs , tag_name ); <nl> rcsnum_cpy ( srev , sym -> rs_num , 0 ); <nl> cf -> file_rcs -> rf_flags &= ~ RCS_SYNCED ;
hv_handle_alloc ( struct hv_channel * ch , void * buffer , uint32_t buflen , <nl>  <nl> /* Prepare array of frame addresses */ <nl> if (( frames = mallocarray ( total , sizeof (* frames ), M_DEVBUF , M_ZERO | <nl> - waitok )) == NULL ) <nl> + waitok )) == NULL ) { <nl> + free ( msg , M_DEVBUF , sizeof (* msg )); <nl> return ( ENOMEM ); <nl> + } <nl> for ( i = 0 ; i < total ; i ++) { <nl> if (! pmap_extract ( pmap_kernel (), ( vaddr_t ) buffer + <nl> PAGE_SIZE * i , & pa )) {
*/ <nl>  <nl> # include " includes . h " <nl> - RCSID ("$ OpenBSD : channels . c , v 1 . 182 2002 / 09 / 13 19 : 23 : 09 stevesk Exp $"); <nl> + RCSID ("$ OpenBSD : channels . c , v 1 . 183 2002 / 09 / 17 07 : 47 : 02 itojun Exp $"); <nl>  <nl> # include " ssh . h " <nl> # include " ssh1 . h " <nl> x11_create_display_inet ( int x11_display_offset , int x11_use_localhost , <nl> if ( bind ( sock , ai -> ai_addr , ai -> ai_addrlen ) < 0 ) { <nl> debug (" bind port % d : %. 100s ", port , strerror ( errno )); <nl> close ( sock ); <nl> + <nl> + if ( ai -> ai_next ) <nl> + continue ; <nl> + <nl> for ( n = 0 ; n < num_socks ; n ++) { <nl> close ( socks [ n ]); <nl> }
-/* $ OpenBSD : pchb . c , v 1 . 49 2005 / 06 / 14 20 : 35 : 45 deraadt Exp $ */ <nl> +/* $ OpenBSD : pchb . c , v 1 . 50 2005 / 12 / 29 04 : 26 : 17 brad Exp $ */ <nl> /* $ NetBSD : pchb . c , v 1 . 6 1997 / 06 / 06 23 : 29 : 16 thorpej Exp $ */ <nl>  <nl> /* <nl> pchbattach ( parent , self , aux ) <nl> printf (": Compatibility PB ( bus % d )", pbnum ); <nl> break ; <nl> case PCISET_INTEL_TYPE_AUX : <nl> - printf (": Auxiliary PB ( bus % d )\ n ", pbnum ); <nl> + printf (": Auxiliary PB ( bus % d )", pbnum ); <nl> neednl = 0 ; <nl>  <nl> /*
void kvm_irqchip_commit_routes ( KVMState * s ) <nl> { <nl> int ret ; <nl>  <nl> + if ( kvm_gsi_direct_mapping ()) { <nl> + return ; <nl> + } <nl> + <nl> + if (! kvm_gsi_routing_enabled ()) { <nl> + return ; <nl> + } <nl> + <nl> s -> irq_routes -> flags = 0 ; <nl> trace_kvm_irqchip_commit_routes (); <nl> ret = kvm_vm_ioctl ( s , KVM_SET_GSI_ROUTING , s -> irq_routes );
gboolean vnc_client_io ( QIOChannel * ioc G_GNUC_UNUSED , <nl> VncState * vs = opaque ; <nl> if ( condition & G_IO_IN ) { <nl> if ( vnc_client_read ( vs ) < 0 ) { <nl> - goto end ; <nl> + /* vs is free () ed here */ <nl> + return TRUE ; <nl> } <nl> } <nl> if ( condition & G_IO_OUT ) { <nl> vnc_client_write ( vs ); <nl> } <nl> - end : <nl> + <nl> if ( vs -> disconnecting ) { <nl> if ( vs -> ioc_tag != 0 ) { <nl> g_source_remove ( vs -> ioc_tag );
int vhost_set_vring_enable ( NetClientState * nc , int enable ) <nl>  <nl> nc -> vring_enable = enable ; <nl>  <nl> - if ( vhost_ops -> vhost_set_vring_enable ) { <nl> + if ( vhost_ops && vhost_ops -> vhost_set_vring_enable ) { <nl> return vhost_ops -> vhost_set_vring_enable (& net -> dev , enable ); <nl> } <nl> 
static int qed_create ( const char * filename , uint32_t cluster_size , <nl> return ret ; <nl> } <nl>  <nl> + /* File must start empty and grow , check truncate is supported */ <nl> + ret = bdrv_truncate ( bs , 0 ); <nl> + if ( ret < 0 ) { <nl> + goto out ; <nl> + } <nl> + <nl> if ( backing_file ) { <nl> header . features |= QED_F_BACKING_FILE ; <nl> header . backing_filename_offset = sizeof ( le_header );
static void chr_read ( void * opaque , const void * buf , size_t size ) <nl> g_free ( elem ); <nl> } <nl> virtio_notify ( vdev , vrng -> vq ); <nl> + <nl> + if (! virtio_queue_empty ( vrng -> vq )) { <nl> + /* If we didn ' t drain the queue , call virtio_rng_process <nl> + * to take care of asking for more data as appropriate . <nl> + */ <nl> + virtio_rng_process ( vrng ); <nl> + } <nl> } <nl>  <nl> static void virtio_rng_process ( VirtIORNG * vrng )
static inline int cpu_interrupts_enabled ( CPUSPARCState * env1 ) <nl> if ( env1 -> psret != 0 ) <nl> return 1 ; <nl> # else <nl> - if ( env1 -> pstate & PS_IE ) <nl> + if (( env1 -> pstate & PS_IE ) && ! cpu_hypervisor_mode ( env1 )) { <nl> return 1 ; <nl> + } <nl> # endif <nl>  <nl> return 0 ;
static void virtio_gpu_set_scanout ( VirtIOGPU * g , <nl> cmd -> error = VIRTIO_GPU_RESP_ERR_UNSPEC ; <nl> return ; <nl> } <nl> + pixman_image_unref ( rect ); <nl> dpy_gfx_replace_surface ( g -> scanout [ ss . scanout_id ]. con , scanout -> ds ); <nl> } <nl> 
static void slavio_timer_get_out ( SLAVIO_TIMERState * s ) <nl> out = ( ticks > s -> expire_time ); <nl> if ( out ) <nl> s -> reached = 0x80000000 ; <nl> - if (! s -> limit ) <nl> - limit = 0x7fffffff ; <nl> - else <nl> - limit = s -> limit ; <nl> - <nl> // Convert register units to counter ticks <nl> - limit = limit >> 9 ; <nl> + limit = s -> limit >> 9 ; <nl> + <nl> + if (! limit ) <nl> + limit = 0x7fffffff >> 9 ; <nl>  <nl> // Convert cpu ticks to counter ticks <nl> diff = muldiv64 ( ticks - s -> count_load_time , CNT_FREQ , ticks_per_sec );
int virtio_set_features ( VirtIODevice * vdev , uint32_t val ) <nl>  <nl> int virtio_load ( VirtIODevice * vdev , QEMUFile * f ) <nl> { <nl> - int num , i , ret ; <nl> + int i , ret ; <nl> + uint32_t num ; <nl> uint32_t features ; <nl> uint32_t supported_features ; <nl> BusState * qbus = qdev_get_parent_bus ( DEVICE ( vdev )); <nl> int virtio_load ( VirtIODevice * vdev , QEMUFile * f ) <nl>  <nl> num = qemu_get_be32 ( f ); <nl>  <nl> + if ( num > VIRTIO_PCI_QUEUE_MAX ) { <nl> + error_report (" Invalid number of PCI queues : 0x % x ", num ); <nl> + return - 1 ; <nl> + } <nl> + <nl> for ( i = 0 ; i < num ; i ++) { <nl> vdev -> vq [ i ]. vring . num = qemu_get_be32 ( f ); <nl> if ( k -> has_variable_vring_alignment ) {
static int64_t expr_unary ( Monitor * mon ) <nl> n = 0 ; <nl> break ; <nl> default : <nl> + errno = 0 ; <nl> # if TARGET_PHYS_ADDR_BITS > 32 <nl> n = strtoull ( pch , & p , 0 ); <nl> # else <nl> n = strtoul ( pch , & p , 0 ); <nl> # endif <nl> + if ( errno == ERANGE ) { <nl> + expr_error ( mon , " number too large "); <nl> + } <nl> if ( pch == p ) { <nl> expr_error ( mon , " invalid char in expression "); <nl> }
static void usb_msd_realize_bot ( USBDevice * dev , Error ** errp ) <nl> usb_desc_init ( dev ); <nl> scsi_bus_new (& s -> bus , sizeof ( s -> bus ), DEVICE ( dev ), <nl> & usb_msd_scsi_info_bot , NULL ); <nl> - s -> bus . qbus . allow_hotplug = 0 ; <nl> usb_msd_handle_reset ( dev ); <nl> } <nl> 
int ram_load ( QEMUFile * f , void * opaque , int version_id ) <nl> void * host ; <nl>  <nl> host = host_from_stream_offset ( f , addr , flags ); <nl> + if (! host ) { <nl> + return - EINVAL ; <nl> + } <nl>  <nl> qemu_get_buffer ( f , host , TARGET_PAGE_SIZE ); <nl> }
void tb_invalidate_phys_addr ( target_phys_addr_t addr ) <nl>  <nl> static void breakpoint_invalidate ( CPUArchState * env , target_ulong pc ) <nl> { <nl> - tb_invalidate_phys_addr ( cpu_get_phys_page_debug ( env , pc )); <nl> + tb_invalidate_phys_addr ( cpu_get_phys_page_debug ( env , pc ) | <nl> + ( pc & ~ TARGET_PAGE_MASK )); <nl> } <nl> # endif <nl> # endif /* TARGET_HAS_ICE */
static void xenfb_invalidate ( void * opaque ) <nl>  <nl> static void xenfb_handle_events ( struct XenFB * xenfb ) <nl> { <nl> - uint32_t prod , cons ; <nl> + uint32_t prod , cons , out_cons ; <nl> struct xenfb_page * page = xenfb -> c . page ; <nl>  <nl> prod = page -> out_prod ; <nl> - if ( prod == page -> out_cons ) <nl> + out_cons = page -> out_cons ; <nl> + if ( prod == out_cons ) <nl> return ; <nl> xen_rmb (); /* ensure we see ring contents up to prod */ <nl> - for ( cons = page -> out_cons ; cons != prod ; cons ++) { <nl> + for ( cons = out_cons ; cons != prod ; cons ++) { <nl> union xenfb_out_event * event = & XENFB_OUT_RING_REF ( page , cons ); <nl> + uint8_t type = event -> type ; <nl> int x , y , w , h ; <nl>  <nl> - switch ( event -> type ) { <nl> + switch ( type ) { <nl> case XENFB_TYPE_UPDATE : <nl> if ( xenfb -> up_count == UP_QUEUE ) <nl> xenfb -> up_fullscreen = 1 ;
static inline int <nl> is_vlan_packet ( E1000State * s , const uint8_t * buf ) <nl> { <nl> return ( be16_to_cpup (( uint16_t *)( buf + 12 )) == <nl> - le16_to_cpup (( uint16_t *)( s -> mac_reg + VET ))); <nl> + le16_to_cpu ( s -> mac_reg [ VET ])); <nl> } <nl>  <nl> static inline int <nl> process_tx_desc ( E1000State * s , struct e1000_tx_desc * dp ) <nl> ( tp -> cptse || txd_lower & E1000_TXD_CMD_EOP )) { <nl> tp -> vlan_needed = 1 ; <nl> stw_be_p ( tp -> vlan_header , <nl> - le16_to_cpup (( uint16_t *)( s -> mac_reg + VET ))); <nl> + le16_to_cpu ( s -> mac_reg [ VET ])); <nl> stw_be_p ( tp -> vlan_header + 2 , <nl> le16_to_cpu ( dp -> upper . fields . special )); <nl> }
static const TypeInfo qemu_s390_skeys_info = { <nl> . instance_init = qemu_s390_skeys_init , <nl> . instance_size = sizeof ( QEMUS390SKeysState ), <nl> . class_init = qemu_s390_skeys_class_init , <nl> - . instance_size = sizeof ( S390SKeysClass ), <nl> + . class_size = sizeof ( S390SKeysClass ), <nl> }; <nl>  <nl> static void s390_storage_keys_save ( QEMUFile * f , void * opaque )
void ppce500_init ( MachineState * machine , PPCE500Params * params ) <nl> exit ( 1 ); <nl> } <nl> } <nl> + g_free ( filename ); <nl>  <nl> /* Reserve space for dtb */ <nl> dt_base = ( loadaddr + bios_size + DTC_LOAD_PAD ) & ~ DTC_PAD_MASK ;
abi_long do_syscall ( void * cpu_env , int num , abi_long arg1 , <nl> break ; <nl> } <nl>  <nl> + cpu_list_lock (); <nl> + <nl> if ( CPU_NEXT ( first_cpu )) { <nl> TaskState * ts ; <nl>  <nl> - cpu_list_lock (); <nl> /* Remove the CPU from the list . */ <nl> QTAILQ_REMOVE (& cpus , cpu , node ); <nl> + <nl> cpu_list_unlock (); <nl> + <nl> ts = cpu -> opaque ; <nl> if ( ts -> child_tidptr ) { <nl> put_user_u32 ( 0 , ts -> child_tidptr ); <nl> abi_long do_syscall ( void * cpu_env , int num , abi_long arg1 , <nl> rcu_unregister_thread (); <nl> pthread_exit ( NULL ); <nl> } <nl> + <nl> + cpu_list_unlock (); <nl> # ifdef TARGET_GPROF <nl> _mcleanup (); <nl> # endif
static void * qpa_thread_out ( void * arg ) <nl> return NULL ; <nl> } <nl>  <nl> + pa -> live = 0 ; <nl> pa -> rpos = rpos ; <nl> - pa -> live -= decr ; <nl> pa -> decr += decr ; <nl> } <nl> 
static inline void vhost_dev_log_resize ( struct vhost_dev * dev , uint64_t size ) <nl> int r ; <nl>  <nl> log = g_malloc0 ( size * sizeof * log ); <nl> - log_base = ( uint64_t )( unsigned long ) log ; <nl> + log_base = ( uintptr_t ) log ; <nl> r = dev -> vhost_ops -> vhost_call ( dev , VHOST_SET_LOG_BASE , & log_base ); <nl> assert ( r >= 0 ); <nl> /* Sync only the range covered by the old log */ <nl> int vhost_dev_start ( struct vhost_dev * hdev , VirtIODevice * vdev ) <nl> } <nl>  <nl> if ( hdev -> log_enabled ) { <nl> + uint64_t log_base ; <nl> + <nl> hdev -> log_size = vhost_get_log_size ( hdev ); <nl> hdev -> log = hdev -> log_size ? <nl> g_malloc0 ( hdev -> log_size * sizeof * hdev -> log ) : NULL ; <nl> - r = hdev -> vhost_ops -> vhost_call ( hdev , VHOST_SET_LOG_BASE , hdev -> log ); <nl> + log_base = ( uintptr_t ) hdev -> log ; <nl> + r = hdev -> vhost_ops -> vhost_call ( hdev , VHOST_SET_LOG_BASE , & log_base ); <nl> if ( r < 0 ) { <nl> r = - errno ; <nl> goto fail_log ;
void ahci_init ( AHCIState * s , DeviceState * qdev , DMAContext * dma , int ports ) <nl> ad -> port_no = i ; <nl> ad -> port . dma = & ad -> dma ; <nl> ad -> port . dma -> ops = & ahci_dma_ops ; <nl> - ad -> port_regs . cmd = PORT_CMD_SPIN_UP | PORT_CMD_POWER_ON ; <nl> } <nl> } <nl>  <nl> void ahci_reset ( AHCIState * s ) <nl> pr -> irq_stat = 0 ; <nl> pr -> irq_mask = 0 ; <nl> pr -> scr_ctl = 0 ; <nl> + pr -> cmd = PORT_CMD_SPIN_UP | PORT_CMD_POWER_ON ; <nl> ahci_reset_port ( s , i ); <nl> } <nl> }
static int get_cluster_offset ( BlockDriverState * bs , <nl> uint32_t min_count , * l2_table ; <nl> bool zeroed = false ; <nl> int64_t ret ; <nl> - int32_t cluster_sector ; <nl> + int64_t cluster_sector ; <nl>  <nl> if ( m_data ) { <nl> m_data -> valid = 0 ;
static uint32_t vmxnet3_get_interrupt_config ( VMXNET3State * s ) <nl> static void vmxnet3_fill_stats ( VMXNET3State * s ) <nl> { <nl> int i ; <nl> + <nl> + if (! s -> device_active ) <nl> + return ; <nl> + <nl> for ( i = 0 ; i < s -> txq_num ; i ++) { <nl> cpu_physical_memory_write ( s -> txq_descr [ i ]. tx_stats_pa , <nl> & s -> txq_descr [ i ]. txq_stats ,
static void dp8393x_class_init ( ObjectClass * klass , void * data ) <nl> dc -> reset = dp8393x_reset ; <nl> dc -> vmsd = & vmstate_dp8393x ; <nl> dc -> props = dp8393x_properties ; <nl> + /* Reason : dma_mr property can ' t be set */ <nl> + dc -> cannot_instantiate_with_device_add_yet = true ; <nl> } <nl>  <nl> static const TypeInfo dp8393x_info = {
static int handle_instruction ( CPUState * env , struct kvm_run * run ) <nl> if ( r < 0 ) { <nl> enter_pgmcheck ( env , 0x0001 ); <nl> } <nl> - return r ; <nl> + return 0 ; <nl> } <nl>  <nl> static int handle_intercept ( CPUState * env )
void memory_region_allocate_system_memory ( MemoryRegion * mr , Object * owner , <nl> exit ( 1 ); <nl> } <nl>  <nl> + host_memory_backend_set_mapped ( backend , true ); <nl> memory_region_add_subregion ( mr , addr , seg ); <nl> vmstate_register_ram_global ( seg ); <nl> addr += size ;
static const RunStateTransition runstate_transitions_def [] = { <nl> { RUN_STATE_WATCHDOG , RUN_STATE_FINISH_MIGRATE }, <nl>  <nl> { RUN_STATE_GUEST_PANICKED , RUN_STATE_PAUSED }, <nl> + { RUN_STATE_GUEST_PANICKED , RUN_STATE_FINISH_MIGRATE }, <nl>  <nl> { RUN_STATE_MAX , RUN_STATE_MAX }, <nl> };
void set_link_completion ( ReadLineState * rs , int nb_args , const char * str ) <nl> count = qemu_find_net_clients_except ( NULL , ncs , <nl> NET_CLIENT_OPTIONS_KIND_NONE , <nl> MAX_QUEUE_NUM ); <nl> - for ( i = 0 ; i < count ; i ++) { <nl> + for ( i = 0 ; i < MIN ( count , MAX_QUEUE_NUM ); i ++) { <nl> const char * name = ncs [ i ]-> name ; <nl> if (! strncmp ( str , name , len )) { <nl> readline_add_completion ( rs , name ); <nl> void netdev_del_completion ( ReadLineState * rs , int nb_args , const char * str ) <nl> readline_set_completion_index ( rs , len ); <nl> count = qemu_find_net_clients_except ( NULL , ncs , NET_CLIENT_OPTIONS_KIND_NIC , <nl> MAX_QUEUE_NUM ); <nl> - for ( i = 0 ; i < count ; i ++) { <nl> + for ( i = 0 ; i < MIN ( count , MAX_QUEUE_NUM ); i ++) { <nl> QemuOpts * opts ; <nl> const char * name = ncs [ i ]-> name ; <nl> if ( strncmp ( str , name , len )) { <nl> void host_net_remove_completion ( ReadLineState * rs , int nb_args , const char * str ) <nl> count = qemu_find_net_clients_except ( NULL , ncs , <nl> NET_CLIENT_OPTIONS_KIND_NONE , <nl> MAX_QUEUE_NUM ); <nl> - for ( i = 0 ; i < count ; i ++) { <nl> + for ( i = 0 ; i < MIN ( count , MAX_QUEUE_NUM ); i ++) { <nl> int id ; <nl> char name [ 16 ]; <nl>  <nl> void host_net_remove_completion ( ReadLineState * rs , int nb_args , const char * str ) <nl> count = qemu_find_net_clients_except ( NULL , ncs , <nl> NET_CLIENT_OPTIONS_KIND_NIC , <nl> MAX_QUEUE_NUM ); <nl> - for ( i = 0 ; i < count ; i ++) { <nl> + for ( i = 0 ; i < MIN ( count , MAX_QUEUE_NUM ); i ++) { <nl> int id ; <nl> const char * name ; <nl> 
CharDriverState * qemu_chr_new_from_opts ( QemuOpts * opts , <nl> ChardevBackend * backend = g_new0 ( ChardevBackend , 1 ); <nl> ChardevReturn * ret = NULL ; <nl> const char * id = qemu_opts_id ( opts ); <nl> - const char * bid = NULL ; <nl> + char * bid = NULL ; <nl>  <nl> if ( qemu_opt_get_bool ( opts , " mux ", 0 )) { <nl> bid = g_strdup_printf ("% s - base ", id ); <nl> CharDriverState * qemu_chr_new_from_opts ( QemuOpts * opts , <nl> backend -> kind = CHARDEV_BACKEND_KIND_MUX ; <nl> backend -> mux -> chardev = g_strdup ( bid ); <nl> ret = qmp_chardev_add ( id , backend , errp ); <nl> - if ( error_is_set ( errp )) { <nl> - goto qapi_out ; <nl> - } <nl> + assert (! error_is_set ( errp )); <nl> } <nl>  <nl> chr = qemu_chr_find ( id ); <nl> CharDriverState * qemu_chr_new_from_opts ( QemuOpts * opts , <nl> qapi_out : <nl> qapi_free_ChardevBackend ( backend ); <nl> qapi_free_ChardevReturn ( ret ); <nl> + g_free ( bid ); <nl> return chr ; <nl> } <nl> 
static int vhost_user_cleanup ( struct vhost_dev * dev ) <nl>  <nl> u = dev -> opaque ; <nl> if ( u -> slave_fd >= 0 ) { <nl> + qemu_set_fd_handler ( u -> slave_fd , NULL , NULL , NULL ); <nl> close ( u -> slave_fd ); <nl> u -> slave_fd = - 1 ; <nl> }
int pci_bridge_initfn ( PCIDevice * dev ) <nl> br -> bus_name ); <nl> sec_bus -> parent_dev = dev ; <nl> sec_bus -> map_irq = br -> map_irq ; <nl> + /* TODO : use memory API to perform memory filtering . */ <nl> + sec_bus -> address_space_mem = parent -> address_space_mem ; <nl> + sec_bus -> address_space_io = parent -> address_space_io ; <nl>  <nl> QLIST_INIT (& sec_bus -> child ); <nl> QLIST_INSERT_HEAD (& parent -> child , sec_bus , sibling );
*/ <nl> # include < hw / hw . h > <nl> # include " dma . h " <nl> - <nl> +# include " qemu - error . h " <nl> # include < hw / ide / internal . h > <nl>  <nl> /* --------------------------------- */ <nl> static int ide_qdev_init ( DeviceState * qdev , DeviceInfo * base ) <nl> IDEBus * bus = DO_UPCAST ( IDEBus , qbus , qdev -> parent_bus ); <nl>  <nl> if (! dev -> conf . bs ) { <nl> - fprintf ( stderr , "% s : no drive specified \ n ", qdev -> info -> name ); <nl> + error_report (" No drive specified "); <nl> goto err ; <nl> } <nl> if ( dev -> unit == - 1 ) { <nl> static int ide_qdev_init ( DeviceState * qdev , DeviceInfo * base ) <nl> switch ( dev -> unit ) { <nl> case 0 : <nl> if ( bus -> master ) { <nl> - fprintf ( stderr , " ide : tried to assign master twice \ n "); <nl> + error_report (" IDE unit % d is in use ", dev -> unit ); <nl> goto err ; <nl> } <nl> bus -> master = dev ; <nl> break ; <nl> case 1 : <nl> if ( bus -> slave ) { <nl> - fprintf ( stderr , " ide : tried to assign slave twice \ n "); <nl> + error_report (" IDE unit % d is in use ", dev -> unit ); <nl> goto err ; <nl> } <nl> bus -> slave = dev ; <nl> break ; <nl> default : <nl> + error_report (" Invalid IDE unit % d ", dev -> unit ); <nl> goto err ; <nl> } <nl> return info -> init ( dev );
static int virtio_serial_load ( QEMUFile * f , void * opaque , int version_id ) <nl>  <nl> id = qemu_get_be32 ( f ); <nl> port = find_port_by_id ( s , id ); <nl> + if (! port ) { <nl> + return - EINVAL ; <nl> + } <nl>  <nl> port -> guest_connected = qemu_get_byte ( f ); <nl> host_connected = qemu_get_byte ( f );
typedef struct PIIX4PMState { <nl> # define SMBHSTDAT1 0x06 <nl> # define SMBBLKDAT 0x07 <nl>  <nl> - PIIX4PMState * pm_state ; <nl> + static PIIX4PMState * pm_state ; <nl>  <nl> static uint32_t get_pmtmr ( PIIX4PMState * s ) <nl> { <nl> i2c_bus * piix4_pm_init ( PCIBus * bus , int devfn , uint32_t smb_io_base , <nl> # if defined ( TARGET_I386 ) <nl> void qemu_system_powerdown ( void ) <nl> { <nl> - if ( pm_state -> pmen & PWRBTN_EN ) { <nl> + if (! pm_state ) { <nl> + qemu_system_shutdown_request (); <nl> + } else if ( pm_state -> pmen & PWRBTN_EN ) { <nl> pm_state -> pmsts |= PWRBTN_EN ; <nl> pm_update_sci ( pm_state ); <nl> }
void qmp_getfd ( const char * fdname , Error ** errp ) <nl> } <nl>  <nl> if ( qemu_isdigit ( fdname [ 0 ])) { <nl> + close ( fd ); <nl> error_set ( errp , QERR_INVALID_PARAMETER_VALUE , " fdname ", <nl> " a name not starting with a digit "); <nl> return ;
 <nl> static void acquire_privilege ( const char * name , Error ** errp ) <nl> { <nl> - HANDLE token ; <nl> + HANDLE token = NULL ; <nl> TOKEN_PRIVILEGES priv ; <nl> Error * local_err = NULL ; <nl>  <nl> static void acquire_privilege ( const char * name , Error ** errp ) <nl> goto out ; <nl> } <nl>  <nl> - CloseHandle ( token ); <nl> } else { <nl> error_set (& local_err , QERR_QGA_COMMAND_FAILED , <nl> " failed to open privilege token "); <nl> } <nl>  <nl> out : <nl> + if ( token ) { <nl> + CloseHandle ( token ); <nl> + } <nl> if ( local_err ) { <nl> error_propagate ( errp , local_err ); <nl> }
static void vnc_dpy_copy ( DisplayChangeListener * dcl , <nl> int i , x , y , pitch , inc , w_lim , s ; <nl> int cmp_bytes ; <nl>  <nl> + if (! vd -> server ) { <nl> + /* no client connected */ <nl> + return ; <nl> + } <nl> + <nl> vnc_refresh_server_surface ( vd ); <nl> QTAILQ_FOREACH_SAFE ( vs , & vd -> clients , next , vn ) { <nl> if ( vnc_has_feature ( vs , VNC_FEATURE_COPYRECT )) {
static int uhci_handle_td ( UHCIState * s , UHCIQueue * q , uint32_t qh_addr , <nl> if ( q == NULL ) { <nl> USBDevice * dev = uhci_find_device ( s , ( td -> token >> 8 ) & 0x7f ); <nl> USBEndpoint * ep = usb_ep_get ( dev , pid , ( td -> token >> 15 ) & 0xf ); <nl> + <nl> + if ( ep == NULL ) { <nl> + return uhci_handle_td_error ( s , td , td_addr , USB_RET_NODEV , <nl> + int_mask ); <nl> + } <nl> q = uhci_queue_new ( s , qh_addr , td , ep ); <nl> } <nl> async = uhci_async_alloc ( q , td_addr );
static void gen_cp0 ( CPUMIPSState * env , DisasContext * ctx , uint32_t opc , int rt , <nl> { <nl> const char * opn = " ldst "; <nl>  <nl> + check_cp0_enabled ( ctx ); <nl> switch ( opc ) { <nl> case OPC_MFC0 : <nl> if ( rt == 0 ) { <nl> static void gen_pool32axf ( CPUMIPSState * env , DisasContext * ctx , int rt , int rs , <nl> # ifndef CONFIG_USER_ONLY <nl> case MFC0 : <nl> case MFC0 + 32 : <nl> + check_cp0_enabled ( ctx ); <nl> if ( rt == 0 ) { <nl> /* Treat as NOP . */ <nl> break ; <nl> static void gen_pool32axf ( CPUMIPSState * env , DisasContext * ctx , int rt , int rs , <nl> break ; <nl> case MTC0 : <nl> case MTC0 + 32 : <nl> + check_cp0_enabled ( ctx ); <nl> { <nl> TCGv t0 = tcg_temp_new (); <nl>  <nl> static void gen_pool32axf ( CPUMIPSState * env , DisasContext * ctx , int rt , int rs , <nl> case 0x05 : <nl> switch ( minor ) { <nl> case RDPGPR : <nl> + check_cp0_enabled ( ctx ); <nl> check_insn ( env , ctx , ISA_MIPS32R2 ); <nl> gen_load_srsgpr ( rt , rs ); <nl> break ; <nl> case WRPGPR : <nl> + check_cp0_enabled ( ctx ); <nl> check_insn ( env , ctx , ISA_MIPS32R2 ); <nl> gen_store_srsgpr ( rt , rs ); <nl> break ; <nl> static void gen_pool32axf ( CPUMIPSState * env , DisasContext * ctx , int rt , int rs , <nl> case 0x1d : <nl> switch ( minor ) { <nl> case DI : <nl> + check_cp0_enabled ( ctx ); <nl> { <nl> TCGv t0 = tcg_temp_new (); <nl>  <nl> static void gen_pool32axf ( CPUMIPSState * env , DisasContext * ctx , int rt , int rs , <nl> } <nl> break ; <nl> case EI : <nl> + check_cp0_enabled ( ctx ); <nl> { <nl> TCGv t0 = tcg_temp_new (); <nl>  <nl> static void decode_micromips32_opc ( CPUMIPSState * env , DisasContext * ctx , <nl> minor = ( ctx -> opcode >> 12 ) & 0xf ; <nl> switch ( minor ) { <nl> case CACHE : <nl> + check_cp0_enabled ( ctx ); <nl> /* Treat as no - op . */ <nl> break ; <nl> case LWC2 : <nl> static void decode_opc ( CPUMIPSState * env , DisasContext * ctx , int * is_branch ) <nl> gen_st_cond ( ctx , op , rt , rs , imm ); <nl> break ; <nl> case OPC_CACHE : <nl> + check_cp0_enabled ( ctx ); <nl> check_insn ( env , ctx , ISA_MIPS3 | ISA_MIPS32 ); <nl> /* Treat as NOP . */ <nl> break ;
void os_set_proc_name ( const char * s ) <nl> char name [ 16 ]; <nl> if (! s ) <nl> return ; <nl> - name [ sizeof ( name ) - 1 ] = 0 ; <nl> - strncpy ( name , s , sizeof ( name )); <nl> + pstrcpy ( name , sizeof ( name ), s ); <nl> /* Could rewrite argv [ 0 ] too , but that ' s a bit more complicated . <nl> This simple way is enough for ` top '. */ <nl> if ( prctl ( PR_SET_NAME , name )) {
static void cleanup_unknown_header_ext ( BlockDriverState * bs ) <nl> } <nl> } <nl>  <nl> - static void report_unsupported ( BlockDriverState * bs , const char * fmt , ...) <nl> + static void GCC_FMT_ATTR ( 2 , 3 ) report_unsupported ( BlockDriverState * bs , <nl> + const char * fmt , ...) <nl> { <nl> char msg [ 64 ]; <nl> va_list ap ;
static int cow_create ( const char * filename , QemuOpts * opts , Error ** errp ) <nl> char * image_filename = NULL ; <nl> Error * local_err = NULL ; <nl> int ret ; <nl> - BlockDriverState * cow_bs ; <nl> + BlockDriverState * cow_bs = NULL ; <nl>  <nl> /* Read out options */ <nl> image_sectors = qemu_opt_get_size_del ( opts , BLOCK_OPT_SIZE , 0 ) / 512 ; <nl> static int cow_create ( const char * filename , QemuOpts * opts , Error ** errp ) <nl> goto exit ; <nl> } <nl>  <nl> - cow_bs = NULL ; <nl> ret = bdrv_open (& cow_bs , filename , NULL , NULL , <nl> BDRV_O_RDWR | BDRV_O_PROTOCOL , NULL , & local_err ); <nl> if ( ret < 0 ) { <nl> static int cow_create ( const char * filename , QemuOpts * opts , Error ** errp ) <nl>  <nl> exit : <nl> g_free ( image_filename ); <nl> - bdrv_unref ( cow_bs ); <nl> + if ( cow_bs ) { <nl> + bdrv_unref ( cow_bs ); <nl> + } <nl> return ret ; <nl> } <nl> 
static uint64_t msix_pba_mmio_read ( void * opaque , hwaddr addr , <nl> return pci_get_long ( dev -> msix_pba + addr ); <nl> } <nl>  <nl> + static void msix_pba_mmio_write ( void * opaque , hwaddr addr , <nl> + uint64_t val , unsigned size ) <nl> +{ <nl> +} <nl> + <nl> static const MemoryRegionOps msix_pba_mmio_ops = { <nl> . read = msix_pba_mmio_read , <nl> + . write = msix_pba_mmio_write , <nl> . endianness = DEVICE_LITTLE_ENDIAN , <nl> . valid = { <nl> . min_access_size = 4 ,
static void ncq_cb ( void * opaque , int ret ) <nl> NCQTransferState * ncq_tfs = ( NCQTransferState *) opaque ; <nl> IDEState * ide_state = & ncq_tfs -> drive -> port . ifs [ 0 ]; <nl>  <nl> + ncq_tfs -> aiocb = NULL ; <nl> if ( ret == - ECANCELED ) { <nl> return ; <nl> }
static int scsi_disk_emulate_inquiry ( SCSIRequest * req , uint8_t * outbuf ) <nl> } <nl>  <nl> l = strlen ( s -> serial ); <nl> - if ( l > 20 ) { <nl> - l = 20 ; <nl> + if ( l > 36 ) { <nl> + l = 36 ; <nl> } <nl>  <nl> DPRINTF (" Inquiry EVPD [ Serial number ] "
static void commit_complete ( BlockJob * job , void * opaque ) <nl> int ret = data -> ret ; <nl> bool remove_commit_top_bs = false ; <nl>  <nl> + /* Make sure overlay_bs and top stay around until bdrv_set_backing_hd () */ <nl> + bdrv_ref ( top ); <nl> + bdrv_ref ( overlay_bs ); <nl> + <nl> /* Remove base node parent that still uses BLK_PERM_WRITE / RESIZE before <nl> * the normal backing chain can be restored . */ <nl> blk_unref ( s -> base ); <nl> static void commit_complete ( BlockJob * job , void * opaque ) <nl> if ( remove_commit_top_bs ) { <nl> bdrv_set_backing_hd ( overlay_bs , top , & error_abort ); <nl> } <nl> + <nl> + bdrv_unref ( overlay_bs ); <nl> + bdrv_unref ( top ); <nl> } <nl>  <nl> static void coroutine_fn commit_run ( void * opaque )
static void tcg_out_op ( TCGContext * s , TCGOpcode opc , const TCGArg * args , <nl> break ; <nl>  <nl> case INDEX_op_ext32u_i64 : <nl> - tcg_out_rld ( s , RLDICR , args [ 0 ], args [ 1 ], 0 , 32 ); <nl> + tcg_out_rld ( s , RLDICL , args [ 0 ], args [ 1 ], 0 , 32 ); <nl> break ; <nl>  <nl> case INDEX_op_setcond_i32 :
static void write_target_close ( BlockDriverState * bs ) { <nl>  <nl> static BlockDriver vvfat_write_target = { <nl> . format_name = " vvfat_write_target ", <nl> + . instance_size = sizeof ( void *), <nl> . bdrv_co_pwritev = write_target_commit , <nl> . bdrv_close = write_target_close , <nl> }; <nl> static int enable_write_target ( BlockDriverState * bs , Error ** errp ) <nl> unlink ( s -> qcow_filename ); <nl> # endif <nl>  <nl> - backing = bdrv_new (); <nl> + backing = bdrv_new_open_driver (& vvfat_write_target , NULL , BDRV_O_ALLOW_RDWR , <nl> + & error_abort ); <nl> + *( void **) backing -> opaque = s ; <nl> + <nl> bdrv_set_backing_hd ( s -> bs , backing ); <nl> bdrv_unref ( backing ); <nl>  <nl> - s -> bs -> backing -> bs -> drv = & vvfat_write_target ; <nl> - s -> bs -> backing -> bs -> opaque = g_new ( void *, 1 ); <nl> - *( void **) s -> bs -> backing -> bs -> opaque = s ; <nl> - <nl> return 0 ; <nl>  <nl> err :
void pc_hot_add_cpu ( const int64_t id , Error ** errp ) <nl> DeviceState * icc_bridge ; <nl> int64_t apic_id = x86_cpu_apic_id_from_index ( id ); <nl>  <nl> + if ( id < 0 ) { <nl> + error_setg ( errp , " Invalid CPU id : %" PRIi64 , id ); <nl> + return ; <nl> + } <nl> + <nl> if ( cpu_exists ( apic_id )) { <nl> error_setg ( errp , " Unable to add CPU : %" PRIi64 <nl> ", it already exists ", id );
static void vncws_send_handshake_response ( VncState * vs , const char * key ) <nl> } <nl>  <nl> response = g_strdup_printf ( WS_HANDSHAKE , accept ); <nl> - vnc_write ( vs , response , strlen ( response )); <nl> - vnc_flush ( vs ); <nl> + vnc_client_write_buf ( vs , ( const uint8_t *) response , strlen ( response )); <nl>  <nl> g_free ( accept ); <nl> g_free ( response );
static void <nl> petalogix_ml605_init ( QEMUMachineInitArgs * args ) <nl> { <nl> ram_addr_t ram_size = args -> ram_size ; <nl> - const char * cpu_model = args -> cpu_model ; <nl> MemoryRegion * address_space_mem = get_system_memory (); <nl> DeviceState * dev , * dma , * eth0 ; <nl> Object * ds , * cs ; <nl> petalogix_ml605_init ( QEMUMachineInitArgs * args ) <nl> qemu_irq irq [ 32 ]; <nl>  <nl> /* init CPUs */ <nl> - if ( cpu_model == NULL ) { <nl> - cpu_model = " microblaze "; <nl> - } <nl> - cpu = cpu_mb_init ( cpu_model ); <nl> + cpu = MICROBLAZE_CPU ( object_new ( TYPE_MICROBLAZE_CPU )); <nl> + object_property_set_bool ( OBJECT ( cpu ), true , " realized ", & error_abort ); <nl>  <nl> /* Attach emulated BRAM through the LMB . */ <nl> memory_region_init_ram ( phys_lmb_bram , NULL , " petalogix_ml605 . lmb_bram ",
static Property virtio_crypto_properties [] = { <nl> static void virtio_crypto_get_config ( VirtIODevice * vdev , uint8_t * config ) <nl> { <nl> VirtIOCrypto * c = VIRTIO_CRYPTO ( vdev ); <nl> - struct virtio_crypto_config crypto_cfg ; <nl> + struct virtio_crypto_config crypto_cfg = {}; <nl>  <nl> /* <nl> * Virtio - crypto device conforms to VIRTIO 1 . 0 which is always LE ,
void memory_region_add_eventfd ( MemoryRegion * mr , <nl> }; <nl> unsigned i ; <nl>  <nl> - adjust_endianness ( mr , & mrfd . data , size ); <nl> + if ( size ) { <nl> + adjust_endianness ( mr , & mrfd . data , size ); <nl> + } <nl> memory_region_transaction_begin (); <nl> for ( i = 0 ; i < mr -> ioeventfd_nb ; ++ i ) { <nl> if ( memory_region_ioeventfd_before ( mrfd , mr -> ioeventfds [ i ])) { <nl> void memory_region_del_eventfd ( MemoryRegion * mr , <nl> }; <nl> unsigned i ; <nl>  <nl> - adjust_endianness ( mr , & mrfd . data , size ); <nl> + if ( size ) { <nl> + adjust_endianness ( mr , & mrfd . data , size ); <nl> + } <nl> memory_region_transaction_begin (); <nl> for ( i = 0 ; i < mr -> ioeventfd_nb ; ++ i ) { <nl> if ( memory_region_ioeventfd_equal ( mrfd , mr -> ioeventfds [ i ])) {
static int vvfat_write ( BlockDriverState * bs , int64_t sector_num , <nl>  <nl> DLOG ( checkpoint ()); <nl>  <nl> + /* Check if we ' re operating in read - only mode */ <nl> + if ( s -> qcow == NULL ) { <nl> + return - EACCES ; <nl> + } <nl> + <nl> vvfat_close_current_file ( s ); <nl>  <nl> /*
static int timebase_post_load ( void * opaque , int version_id ) <nl> host_ns = qemu_clock_get_ns ( QEMU_CLOCK_HOST ); <nl> ns_diff = MAX ( 0 , host_ns - tb_remote -> time_of_the_day_ns ); <nl> migration_duration_ns = MIN ( NANOSECONDS_PER_SECOND , ns_diff ); <nl> - migration_duration_tb = muldiv64 ( migration_duration_ns , freq , <nl> + migration_duration_tb = muldiv64 ( freq , migration_duration_ns , <nl> NANOSECONDS_PER_SECOND ); <nl> guest_tb = tb_remote -> guest_timebase + MIN ( 0 , migration_duration_tb ); <nl> 
static void assign_storage ( SCCB * sccb ) <nl> ( assign_addr >= mhd -> padded_ram_size )) { <nl> /* Re - use existing memory region if found */ <nl> mr = memory_region_find ( sysmem , assign_addr , 1 ). mr ; <nl> + memory_region_unref ( mr ); <nl> if (! mr ) { <nl>  <nl> MemoryRegion * standby_ram = g_new ( MemoryRegion , 1 ); <nl> static void assign_storage ( SCCB * sccb ) <nl> } <nl>  <nl> memory_region_init_ram ( standby_ram , NULL , id , this_subregion_size , & error_abort ); <nl> + /* This is a hack to make memory hotunplug work again . Once we have <nl> + * subdevices , we have to unparent them when unassigning memory , <nl> + * instead of doing it via the ref count of the MemoryRegion . */ <nl> + object_ref ( OBJECT ( standby_ram )); <nl> + object_unparent ( OBJECT ( standby_ram )); <nl> vmstate_register_ram_global ( standby_ram ); <nl> memory_region_add_subregion ( sysmem , offset , standby_ram ); <nl> } <nl> static void unassign_storage ( SCCB * sccb ) <nl>  <nl> /* find the specified memory region and destroy it */ <nl> mr = memory_region_find ( sysmem , unassign_addr , 1 ). mr ; <nl> + memory_region_unref ( mr ); <nl> if ( mr ) { <nl> int i ; <nl> int is_removable = 1 ; <nl> static void unassign_storage ( SCCB * sccb ) <nl> } <nl> if ( is_removable ) { <nl> memory_region_del_subregion ( sysmem , mr ); <nl> - object_unparent ( OBJECT ( mr )); <nl> - g_free ( mr ); <nl> + object_unref ( OBJECT ( mr )); <nl> } <nl> } <nl> }
static void build_pci_bus_end ( PCIBus * bus , void * bus_state ) <nl>  <nl> build_append_byte ( notify , 0x7B ); /* AndOp */ <nl> build_append_byte ( notify , 0x68 ); /* Arg0Op */ <nl> - build_append_int ( notify , 0x1 << i ); <nl> + build_append_int ( notify , 0x1U << i ); <nl> build_append_byte ( notify , 0x00 ); /* NullName */ <nl> build_append_byte ( notify , 0x86 ); /* NotifyOp */ <nl> build_append_nameseg ( notify , " S %. 02X_ ", PCI_DEVFN ( i , 0 ));
static void win_stdio_close ( CharDriverState * chr ) <nl> } <nl>  <nl> g_free ( chr -> opaque ); <nl> - g_free ( chr ); <nl> } <nl>  <nl> static CharDriverState * qemu_chr_open_stdio ( const char * id ,
static int ohci_bus_start ( OHCIState * ohci ) <nl> /* Stop sending SOF tokens on the bus */ <nl> static void ohci_bus_stop ( OHCIState * ohci ) <nl> { <nl> - if ( ohci -> eof_timer ) <nl> + if ( ohci -> eof_timer ) { <nl> timer_del ( ohci -> eof_timer ); <nl> + timer_free ( ohci -> eof_timer ); <nl> + } <nl> ohci -> eof_timer = NULL ; <nl> } <nl> 
static void slirp_smb_cleanup ( SlirpState * s ) <nl> static int slirp_smb ( SlirpState * s , const char * exported_dir , <nl> struct in_addr vserver_addr ) <nl> { <nl> - static int instance ; <nl> char smb_conf [ 128 ]; <nl> char smb_cmdline [ 128 ]; <nl> struct passwd * passwd ; <nl> static int slirp_smb ( SlirpState * s , const char * exported_dir , <nl> return - 1 ; <nl> } <nl>  <nl> - snprintf ( s -> smb_dir , sizeof ( s -> smb_dir ), "/ tmp / qemu - smb .% ld -% d ", <nl> - ( long ) getpid (), instance ++); <nl> - if ( mkdir ( s -> smb_dir , 0700 ) < 0 ) { <nl> + snprintf ( s -> smb_dir , sizeof ( s -> smb_dir ), "/ tmp / qemu - smb . XXXXXX "); <nl> + if (! mkdtemp ( s -> smb_dir )) { <nl> error_report (" could not create samba server dir '% s '", s -> smb_dir ); <nl> + s -> smb_dir [ 0 ] = 0 ; <nl> return - 1 ; <nl> } <nl> snprintf ( smb_conf , sizeof ( smb_conf ), "% s /% s ", s -> smb_dir , " smb . conf ");
static int local_name_to_path ( FsContext * ctx , V9fsPath * dir_path , <nl> { <nl> if ( dir_path ) { <nl> v9fs_path_sprintf ( target , "% s /% s ", dir_path -> data , name ); <nl> - } else { <nl> + } else if ( strcmp ( name , "/")) { <nl> v9fs_path_sprintf ( target , "% s ", name ); <nl> + } else { <nl> + /* We want the path of the export root to be relative , otherwise <nl> + * "* at ()" syscalls would treat it as "/" in the host . <nl> + */ <nl> + v9fs_path_sprintf ( target , "% s ", "."); <nl> } <nl> return 0 ; <nl> }
int load_vmstate ( const char * name ) <nl> void do_delvm ( Monitor * mon , const QDict * qdict ) <nl> { <nl> BlockDriverState * bs ; <nl> - Error * err = NULL ; <nl> + Error * err ; <nl> const char * name = qdict_get_str ( qdict , " name "); <nl>  <nl> if (! find_vmstate_bs ()) { <nl> void do_delvm ( Monitor * mon , const QDict * qdict ) <nl> bs = NULL ; <nl> while (( bs = bdrv_next ( bs ))) { <nl> if ( bdrv_can_snapshot ( bs )) { <nl> + err = NULL ; <nl> bdrv_snapshot_delete_by_id_or_name ( bs , name , & err ); <nl> if ( err ) { <nl> monitor_printf ( mon ,
static void virtio_net_guest_notifier_mask ( VirtIODevice * vdev , int idx , <nl> void virtio_net_set_config_size ( VirtIONet * n , uint32_t host_features ) <nl> { <nl> int i , config_size = 0 ; <nl> + host_features |= ( 1 << VIRTIO_NET_F_MAC ); <nl> for ( i = 0 ; feature_sizes [ i ]. flags != 0 ; i ++) { <nl> if ( host_features & feature_sizes [ i ]. flags ) { <nl> config_size = MAX ( feature_sizes [ i ]. end , config_size );
static void vfio_put_device ( VFIOPCIDevice * vdev ) <nl> { <nl> g_free ( vdev -> vbasedev . name ); <nl> if ( vdev -> msix ) { <nl> + object_unparent ( OBJECT (& vdev -> msix -> mmap_mem )); <nl> g_free ( vdev -> msix ); <nl> vdev -> msix = NULL ; <nl> }
int qemu_devtree_add_subnode ( void * fdt , const char * name ) <nl> int retval ; <nl>  <nl> if (! basename ) { <nl> + g_free ( dupname ); <nl> return - 1 ; <nl> } <nl> 
static void timer_enable ( struct xlx_timer * xt ) <nl> count = xt -> regs [ R_TLR ]; <nl> else <nl> count = ~ 0 - xt -> regs [ R_TLR ]; <nl> - ptimer_set_count ( xt -> ptimer , count ); <nl> + ptimer_set_limit ( xt -> ptimer , count , 1 ); <nl> ptimer_run ( xt -> ptimer , 1 ); <nl> } <nl> 
static void object_set_link_property ( Object * obj , Visitor * v , void * opaque , <nl>  <nl> target = object_resolve_path ( path , & ambiguous ); <nl> if ( target ) { <nl> - gchar * target_type ; <nl> - <nl> - target_type = g_strdup (& type [ 5 ]); <nl> - target_type [ strlen ( target_type ) - 2 ] = 0 ; <nl> - <nl> + /* Go from link < FOO > to FOO . */ <nl> + gchar * target_type = g_strndup (& type [ 5 ], strlen ( type ) - 6 ); <nl> if ( object_dynamic_cast ( target , target_type )) { <nl> object_ref ( target ); <nl> * child = target ;
static void numa_add ( const char * optarg ) <nl> if ( get_param_value ( option , 128 , " nodeid ", optarg ) == 0 ) { <nl> nodenr = nb_numa_nodes ; <nl> } else { <nl> - nodenr = strtoull ( option , NULL , 10 ); <nl> + if ( parse_uint_full ( option , & nodenr , 10 ) < 0 ) { <nl> + fprintf ( stderr , " qemu : Invalid NUMA nodeid : % s \ n ", option ); <nl> + exit ( 1 ); <nl> + } <nl> } <nl>  <nl> if ( nodenr >= MAX_NODES ) {
void ppc_set_compat ( PowerPCCPU * cpu , uint32_t compat_pvr , Error ** errp ) <nl>  <nl> cpu_synchronize_state ( CPU ( cpu )); <nl>  <nl> - cpu -> compat_pvr = compat_pvr ; <nl> - env -> spr [ SPR_PCR ] = pcr & pcc -> pcr_mask ; <nl> - <nl> - if ( kvm_enabled ()) { <nl> + if ( kvm_enabled () && cpu -> compat_pvr != compat_pvr ) { <nl> int ret = kvmppc_set_compat ( cpu , cpu -> compat_pvr ); <nl> if ( ret < 0 ) { <nl> error_setg_errno ( errp , - ret , <nl> " Unable to set CPU compatibility mode in KVM "); <nl> + return ; <nl> } <nl> } <nl> + <nl> + cpu -> compat_pvr = compat_pvr ; <nl> + env -> spr [ SPR_PCR ] = pcr & pcc -> pcr_mask ; <nl> } <nl>  <nl> typedef struct {
static void gen_sync ( DisasContext * ctx ) <nl> /* wait */ <nl> static void gen_wait ( DisasContext * ctx ) <nl> { <nl> - TCGv_i32 t0 = tcg_temp_new_i32 (); <nl> + TCGv_i32 t0 = tcg_const_i32 ( 1 ); <nl> tcg_gen_st_i32 ( t0 , cpu_env , <nl> - offsetof ( PowerPCCPU , env ) + offsetof ( CPUState , halted )); <nl> tcg_temp_free_i32 ( t0 );
DeviceState * qdev_device_add ( QemuOpts * opts ) <nl> } <nl> } <nl>  <nl> - if (! oc ) { <nl> + if (! object_class_dynamic_cast ( oc , TYPE_DEVICE )) { <nl> qerror_report ( QERR_INVALID_PARAMETER_VALUE , " driver ", " device type "); <nl> return NULL ; <nl> }
int main ( int argc , char ** argv , char ** envp ) <nl> exit ( 0 ); <nl> } <nl>  <nl> + if (! trace_init_backends ()) { <nl> + exit ( 1 ); <nl> + } <nl> trace_init_file ( trace_file ); <nl>  <nl> /* Open the logfile at this point and set the log mask if necessary . <nl> int main ( int argc , char ** argv , char ** envp ) <nl> qemu_set_log ( 0 ); <nl> } <nl>  <nl> - if (! trace_init_backends ()) { <nl> - exit ( 1 ); <nl> - } <nl> - <nl> /* If no data_dir is specified then try to find it relative to the <nl> executable path . */ <nl> if ( data_dir_idx < ARRAY_SIZE ( data_dir )) {
static const TypeInfo virtio_serial_port_type_info = { <nl> . class_init = virtio_serial_port_class_init , <nl> }; <nl>  <nl> - static int virtio_serial_device_exit ( DeviceState * dev ) <nl> + static void virtio_serial_device_exit ( VirtIODevice * vdev ) <nl> { <nl> - VirtIOSerial * vser = VIRTIO_SERIAL ( dev ); <nl> - VirtIODevice * vdev = VIRTIO_DEVICE ( dev ); <nl> + VirtIOSerial * vser = VIRTIO_SERIAL ( vdev ); <nl>  <nl> - unregister_savevm ( dev , " virtio - console ", vser ); <nl> + unregister_savevm ( DEVICE ( vdev ), " virtio - console ", vser ); <nl>  <nl> g_free ( vser -> ivqs ); <nl> g_free ( vser -> ovqs ); <nl> static int virtio_serial_device_exit ( DeviceState * dev ) <nl> g_free ( vser -> post_load ); <nl> } <nl> virtio_cleanup ( vdev ); <nl> - return 0 ; <nl> } <nl>  <nl> static Property virtio_serial_properties [] = { <nl> static void virtio_serial_class_init ( ObjectClass * klass , void * data ) <nl> { <nl> DeviceClass * dc = DEVICE_CLASS ( klass ); <nl> VirtioDeviceClass * vdc = VIRTIO_DEVICE_CLASS ( klass ); <nl> - dc -> exit = virtio_serial_device_exit ; <nl> dc -> props = virtio_serial_properties ; <nl> set_bit ( DEVICE_CATEGORY_INPUT , dc -> categories ); <nl> vdc -> init = virtio_serial_device_init ; <nl> + vdc -> exit = virtio_serial_device_exit ; <nl> vdc -> get_features = get_features ; <nl> vdc -> get_config = get_config ; <nl> vdc -> set_config = set_config ;
main ( <nl> GIOChannel * channel_stdin ; <nl> char * qemu_host ; <nl> char * qemu_port ; <nl> - VSCMsgHeader mhHeader ; <nl>  <nl> VCardEmulOptions * command_line_options = NULL ; <nl>  <nl> main ( <nl> . magic = VSCARD_MAGIC , <nl> . capabilities = { 0 } <nl> }; <nl> - send_msg ( VSC_Init , mhHeader . reader_id , & init , sizeof ( init )); <nl> + send_msg ( VSC_Init , 0 , & init , sizeof ( init )); <nl>  <nl> g_main_loop_run ( loop ); <nl> g_main_loop_unref ( loop );
static void realview_init ( MachineState * machine , <nl> CPUARMState * env ; <nl> ObjectClass * cpu_oc ; <nl> MemoryRegion * sysmem = get_system_memory (); <nl> - MemoryRegion * ram_lo = g_new ( MemoryRegion , 1 ); <nl> + MemoryRegion * ram_lo ; <nl> MemoryRegion * ram_hi = g_new ( MemoryRegion , 1 ); <nl> MemoryRegion * ram_alias = g_new ( MemoryRegion , 1 ); <nl> MemoryRegion * ram_hack = g_new ( MemoryRegion , 1 ); <nl> static void realview_init ( MachineState * machine , <nl>  <nl> if ( is_pb && ram_size > 0x20000000 ) { <nl> /* Core tile RAM . */ <nl> + ram_lo = g_new ( MemoryRegion , 1 ); <nl> low_ram_size = ram_size - 0x20000000 ; <nl> ram_size = 0x20000000 ; <nl> memory_region_init_ram ( ram_lo , NULL , " realview . lowmem ", low_ram_size ,
static void vscsi_got_payload ( VSCSIState * s , vscsi_crq * crq ) <nl> if ( crq -> s . IU_length > sizeof ( union viosrp_iu )) { <nl> fprintf ( stderr , " VSCSI : SRP IU too long (% d bytes ) !\ n ", <nl> crq -> s . IU_length ); <nl> + vscsi_put_req ( req ); <nl> return ; <nl> } <nl>  <nl> static void vscsi_got_payload ( VSCSIState * s , vscsi_crq * crq ) <nl> if ( spapr_tce_dma_read (& s -> vdev , crq -> s . IU_data_ptr , & req -> iu , <nl> crq -> s . IU_length )) { <nl> fprintf ( stderr , " vscsi_got_payload : DMA read failure !\ n "); <nl> - g_free ( req ); <nl> + vscsi_put_req ( req ); <nl> + return ; <nl> } <nl> memcpy (& req -> crq , crq , sizeof ( vscsi_crq )); <nl> 
static void * spapr_create_fdt_skel ( const char * cpu_model , <nl>  <nl> _FDT (( fdt_property ( fdt , " qemu , boot - kernel ", & kprop , sizeof ( kprop )))); <nl> } <nl> - _FDT (( fdt_property_string ( fdt , " qemu , boot - device ", boot_device ))); <nl> + if ( boot_device ) { <nl> + _FDT (( fdt_property_string ( fdt , " qemu , boot - device ", boot_device ))); <nl> + } <nl> _FDT (( fdt_property_cell ( fdt , " qemu , graphic - width ", graphic_width ))); <nl> _FDT (( fdt_property_cell ( fdt , " qemu , graphic - height ", graphic_height ))); <nl> _FDT (( fdt_property_cell ( fdt , " qemu , graphic - depth ", graphic_depth ))); <nl> static QEMUMachine spapr_machine = { <nl> . block_default_type = IF_SCSI , <nl> . max_cpus = MAX_CPUS , <nl> . no_parallel = 1 , <nl> - DEFAULT_MACHINE_OPTIONS , <nl> + . boot_order = NULL , <nl> }; <nl>  <nl> static void spapr_machine_init ( void )
static void entropy_available ( void * opaque ) <nl> ssize_t len ; <nl>  <nl> len = read ( s -> fd , buffer , s -> size ); <nl> + if ( len < 0 && errno == EAGAIN ) { <nl> + return ; <nl> + } <nl> g_assert ( len != - 1 ); <nl>  <nl> s -> receive_func ( s -> opaque , buffer , len );
static void tcg_liveness_analysis ( TCGContext * s ) <nl>  <nl> nb_ops = gen_opc_ptr - gen_opc_buf ; <nl>  <nl> - /* XXX : make it really dynamic */ <nl> - s -> op_dead_iargs = tcg_malloc ( OPC_BUF_SIZE * sizeof ( uint16_t )); <nl> + s -> op_dead_iargs = tcg_malloc ( nb_ops * sizeof ( uint16_t )); <nl>  <nl> dead_temps = tcg_malloc ( s -> nb_temps ); <nl> memset ( dead_temps , 1 , s -> nb_temps );
static int enable_write_target ( BDRVVVFATState * s , Error ** errp ) <nl> set_option_parameter ( options , BLOCK_OPT_BACKING_FILE , " fat :"); <nl>  <nl> ret = bdrv_create ( bdrv_qcow , s -> qcow_filename , options , errp ); <nl> + free_option_parameters ( options ); <nl> if ( ret < 0 ) { <nl> goto err ; <nl> }
static int socket_accept ( int sock ) <nl> setsockopt ( sock , SOL_SOCKET , SO_RCVTIMEO , ( void *)& timeout , <nl> sizeof ( timeout )); <nl>  <nl> - addrlen = sizeof ( addr ); <nl> do { <nl> + addrlen = sizeof ( addr ); <nl> ret = accept ( sock , ( struct sockaddr *)& addr , & addrlen ); <nl> } while ( ret == - 1 && errno == EINTR ); <nl> if ( ret == - 1 ) {
void qemu_spice_create_host_primary ( SimpleSpiceDisplay * ssd ) <nl> { <nl> QXLDevSurfaceCreate surface ; <nl>  <nl> + memset (& surface , 0 , sizeof ( surface )); <nl> + <nl> dprint ( 1 , "% s : % dx % d \ n ", __FUNCTION__ , <nl> ds_get_width ( ssd -> ds ), ds_get_height ( ssd -> ds )); <nl> 
static int qemu_rbd_open ( BlockDriverState * bs , QDict * options , int flags , <nl> name = qemu_opt_get ( opts , " image "); <nl> keypairs = qemu_opt_get ( opts , " keyvalue - pairs "); <nl>  <nl> + if (! pool || ! name ) { <nl> + error_setg ( errp , " Parameters ' pool ' and ' image ' are required "); <nl> + r = - EINVAL ; <nl> + goto failed_opts ; <nl> + } <nl> + <nl> r = rados_create (& s -> cluster , clientname ); <nl> if ( r < 0 ) { <nl> error_setg_errno ( errp , - r , " error initializing "); <nl> static int qemu_rbd_open ( BlockDriverState * bs , QDict * options , int flags , <nl> } <nl>  <nl> s -> snap = g_strdup ( snap ); <nl> - if ( name ) { <nl> - pstrcpy ( s -> name , RBD_MAX_IMAGE_NAME_SIZE , name ); <nl> - } <nl> + pstrcpy ( s -> name , RBD_MAX_IMAGE_NAME_SIZE , name ); <nl>  <nl> /* try default location when conf = NULL , but ignore failure */ <nl> r = rados_conf_read_file ( s -> cluster , conf );
static void cirrus_mem_writeb_mode4and5_8bpp ( CirrusVGAState * s , <nl> unsigned val = mem_value ; <nl> uint8_t * dst ; <nl>  <nl> - dst = s -> vga . vram_ptr + ( offset &= s -> cirrus_addr_mask ); <nl> for ( x = 0 ; x < 8 ; x ++) { <nl> + dst = s -> vga . vram_ptr + (( offset + x ) & s -> cirrus_addr_mask ); <nl> if ( val & 0x80 ) { <nl> * dst = s -> cirrus_shadow_gr1 ; <nl> } else if ( mode == 5 ) { <nl> * dst = s -> cirrus_shadow_gr0 ; <nl> } <nl> val <<= 1 ; <nl> - dst ++; <nl> } <nl> memory_region_set_dirty (& s -> vga . vram , offset , 8 ); <nl> } <nl> static void cirrus_mem_writeb_mode4and5_16bpp ( CirrusVGAState * s , <nl> unsigned val = mem_value ; <nl> uint8_t * dst ; <nl>  <nl> - dst = s -> vga . vram_ptr + ( offset &= s -> cirrus_addr_mask ); <nl> for ( x = 0 ; x < 8 ; x ++) { <nl> + dst = s -> vga . vram_ptr + (( offset + 2 * x ) & s -> cirrus_addr_mask & ~ 1 ); <nl> if ( val & 0x80 ) { <nl> * dst = s -> cirrus_shadow_gr1 ; <nl> *( dst + 1 ) = s -> vga . gr [ 0x11 ]; <nl> static void cirrus_mem_writeb_mode4and5_16bpp ( CirrusVGAState * s , <nl> *( dst + 1 ) = s -> vga . gr [ 0x10 ]; <nl> } <nl> val <<= 1 ; <nl> - dst += 2 ; <nl> } <nl> memory_region_set_dirty (& s -> vga . vram , offset , 16 ); <nl> }
static int virtio_scsi_parse_req ( VirtIOSCSIReq * req , <nl> * TODO : always disable this workaround for virtio 1 . 0 devices . <nl> */ <nl> if (! virtio_has_feature ( vdev , VIRTIO_F_ANY_LAYOUT )) { <nl> - req_size = req -> elem . out_sg [ 0 ]. iov_len ; <nl> - resp_size = req -> elem . in_sg [ 0 ]. iov_len ; <nl> + if ( req -> elem . out_num ) { <nl> + req_size = req -> elem . out_sg [ 0 ]. iov_len ; <nl> + } <nl> + if ( req -> elem . in_num ) { <nl> + resp_size = req -> elem . in_sg [ 0 ]. iov_len ; <nl> + } <nl> } <nl>  <nl> out_size = qemu_sgl_concat ( req , req -> elem . out_sg ,
static VncServerInfo * vnc_server_info_get ( VncDisplay * vd ) <nl> VncServerInfo * info ; <nl> Error * err = NULL ; <nl>  <nl> - info = g_malloc ( sizeof (* info )); <nl> + info = g_malloc0 ( sizeof (* info )); <nl> vnc_init_basic_info_from_server_addr ( vd -> lsock , <nl> qapi_VncServerInfo_base ( info ), & err ); <nl> info -> has_auth = true ;
void AUD_del_capture ( CaptureVoiceOut * cap , void * cb_opaque ) <nl> sw = sw1 ; <nl> } <nl> QLIST_REMOVE ( cap , entries ); <nl> + g_free ( cap -> hw . mix_buf ); <nl> + g_free ( cap -> buf ); <nl> g_free ( cap ); <nl> } <nl> return ;
static inline void softusb_read_dmem ( MilkymistSoftUsbState * s , <nl> if ( offset + len >= s -> dmem_size ) { <nl> error_report (" milkymist_softusb : read dmem out of bounds " <nl> " at offset 0x % x , len % d ", offset , len ); <nl> + memset ( buf , 0 , len ); <nl> return ; <nl> } <nl>  <nl> static inline void softusb_read_pmem ( MilkymistSoftUsbState * s , <nl> if ( offset + len >= s -> pmem_size ) { <nl> error_report (" milkymist_softusb : read pmem out of bounds " <nl> " at offset 0x % x , len % d ", offset , len ); <nl> + memset ( buf , 0 , len ); <nl> return ; <nl> } <nl> 
static void tmu2_start ( MilkymistTMU2State * s ) <nl> cpu_physical_memory_unmap ( mesh , mesh_len , 0 , mesh_len ); <nl>  <nl> /* Write back the OpenGL framebuffer to the QEMU framebuffer */ <nl> - fb_len = 2 * s -> regs [ R_DSTHRES ] * s -> regs [ R_DSTVRES ]; <nl> + fb_len = 2ULL * s -> regs [ R_DSTHRES ] * s -> regs [ R_DSTVRES ]; <nl> fb = cpu_physical_memory_map ( s -> regs [ R_DSTFBUF ], & fb_len , 1 ); <nl> if ( fb == NULL ) { <nl> glDeleteTextures ( 1 , & texture );
S390PCIBusDevice * s390_pci_find_dev_by_fh ( uint32_t fh ) <nl> static void s390_pci_generate_event ( uint8_t cc , uint16_t pec , uint32_t fh , <nl> uint32_t fid , uint64_t faddr , uint32_t e ) <nl> { <nl> - SeiContainer * sei_cont = g_malloc0 ( sizeof ( SeiContainer )); <nl> + SeiContainer * sei_cont ; <nl> S390pciState * s = S390_PCI_HOST_BRIDGE ( <nl> object_resolve_path ( TYPE_S390_PCI_HOST_BRIDGE , NULL )); <nl>  <nl> static void s390_pci_generate_event ( uint8_t cc , uint16_t pec , uint32_t fh , <nl> return ; <nl> } <nl>  <nl> + sei_cont = g_malloc0 ( sizeof ( SeiContainer )); <nl> sei_cont -> fh = fh ; <nl> sei_cont -> fid = fid ; <nl> sei_cont -> cc = cc ;
retry : <nl> goto retry ; <nl> } <nl> } <nl> + <nl> + /* Make sure that all offsets in the " allocated " range are representable <nl> + * in an int64_t */ <nl> + if ( s -> free_cluster_index - 1 > ( INT64_MAX >> s -> cluster_bits )) { <nl> + return - EFBIG ; <nl> + } <nl> + <nl> # ifdef DEBUG_ALLOC2 <nl> fprintf ( stderr , " alloc_clusters : size =%" PRId64 " -> %" PRId64 "\ n ", <nl> size ,
void qmp_drive_mirror ( const char * device , const char * target , <nl> if (! source && sync == MIRROR_SYNC_MODE_TOP ) { <nl> sync = MIRROR_SYNC_MODE_FULL ; <nl> } <nl> + if ( sync == MIRROR_SYNC_MODE_NONE ) { <nl> + source = bs ; <nl> + } <nl>  <nl> size = bdrv_getlength ( bs ); <nl> if ( size < 0 ) {
int net_init_vhost_user ( const NetClientOptions * opts , const char * name , <nl> } <nl>  <nl> queues = vhost_user_opts -> has_queues ? vhost_user_opts -> queues : 1 ; <nl> - if ( queues < 1 ) { <nl> + if ( queues < 1 || queues > MAX_QUEUE_NUM ) { <nl> error_setg ( errp , <nl> - " vhost - user number of queues must be bigger than zero "); <nl> + " vhost - user number of queues must be in range [ 1 , % d ]", <nl> + MAX_QUEUE_NUM ); <nl> return - 1 ; <nl> } <nl> 
static void spapr_core_release ( DeviceState * dev , void * opaque ) <nl> void spapr_core_unplug ( HotplugHandler * hotplug_dev , DeviceState * dev , <nl> Error ** errp ) <nl> { <nl> - sPAPRCPUCore * core = SPAPR_CPU_CORE ( OBJECT ( dev )); <nl> - PowerPCCPU * cpu = POWERPC_CPU ( core -> threads ); <nl> - int id = ppc_get_vcpu_dt_id ( cpu ); <nl> + CPUCore * cc = CPU_CORE ( dev ); <nl> sPAPRDRConnector * drc = <nl> - spapr_dr_connector_by_id ( SPAPR_DR_CONNECTOR_TYPE_CPU , id ); <nl> + spapr_dr_connector_by_id ( SPAPR_DR_CONNECTOR_TYPE_CPU , cc -> core_id ); <nl> sPAPRDRConnectorClass * drck ; <nl> Error * local_err = NULL ; <nl> 
static void pci_qdev_unrealize ( DeviceState * dev , Error ** errp ) <nl> pc -> exit ( pci_dev ); <nl> } <nl>  <nl> + pci_device_deassert_intx ( pci_dev ); <nl> do_pci_unregister_device ( pci_dev ); <nl> } <nl> 
static int img_bench ( int argc , char ** argv ) <nl> BlockBackend * blk = NULL ; <nl> BenchData data = {}; <nl> int flags = 0 ; <nl> - bool writethrough ; <nl> + bool writethrough = false ; <nl> struct timeval t1 , t2 ; <nl> int i ; <nl> 
pixman_format_code_t qemu_default_pixman_format ( int bpp , bool native_endian ) <nl> break ; <nl> } <nl> } <nl> - g_assert_not_reached (); <nl> + return 0 ; <nl> } <nl>  <nl> int qemu_pixman_get_type ( int rshift , int gshift , int bshift )
void HELPER ( mtspr )( CPUOpenRISCState * env , target_ulong spr , target_ulong rb ) <nl> } <nl> break ; <nl> case TO_SPR ( 9 , 0 ): /* PICMR */ <nl> - env -> picmr |= rb ; <nl> + env -> picmr = rb ; <nl> break ; <nl> case TO_SPR ( 9 , 2 ): /* PICSR */ <nl> env -> picsr &= ~ rb ;
static int vnc_refresh_lossy_rect ( VncDisplay * vd , int x , int y ) <nl>  <nl> static int vnc_update_stats ( VncDisplay * vd , struct timeval * tv ) <nl> { <nl> - int width = pixman_image_get_width ( vd -> guest . fb ); <nl> - int height = pixman_image_get_height ( vd -> guest . fb ); <nl> + int width = MIN ( pixman_image_get_width ( vd -> guest . fb ), <nl> + pixman_image_get_width ( vd -> server )); <nl> + int height = MIN ( pixman_image_get_height ( vd -> guest . fb ), <nl> + pixman_image_get_height ( vd -> server )); <nl> int x , y ; <nl> struct timeval res ; <nl> int has_dirty = 0 ;
static int get_S2prot ( CPUARMState * env , int s2ap , int xn ) <nl> prot |= PAGE_WRITE ; <nl> } <nl> if (! xn ) { <nl> - prot |= PAGE_EXEC ; <nl> + if ( arm_el_is_aa64 ( env , 2 ) || prot & PAGE_READ ) { <nl> + prot |= PAGE_EXEC ; <nl> + } <nl> } <nl> return prot ; <nl> }
static int pci_rocker_init ( PCIDevice * dev ) <nl> fprintf ( stderr , <nl> " rocker : name too long ; please shorten to at most % d chars \ n ", <nl> MAX_ROCKER_NAME_LEN ); <nl> - return - EINVAL ; <nl> + err = - EINVAL ; <nl> + goto err_name_too_long ; <nl> } <nl>  <nl> if ( memcmp (& r -> fp_start_macaddr , & zero , sizeof ( zero )) == 0 ) { <nl> static int pci_rocker_init ( PCIDevice * dev ) <nl>  <nl> return 0 ; <nl>  <nl> + err_name_too_long : <nl> err_duplicate : <nl> rocker_msix_uninit ( r ); <nl> err_msix_init :
build_ssdt ( GArray * table_data , GArray * linker , <nl>  <nl> patch_pci_windows ( pci , ssdt_ptr , sizeof ( ssdp_misc_aml )); <nl>  <nl> - *( uint16_t *)( ssdt_ptr + * ssdt_isa_pest ) = <nl> - cpu_to_le16 ( misc -> pvpanic_port ); <nl> + ACPI_BUILD_SET_LE ( ssdt_ptr , sizeof ( ssdp_misc_aml ), <nl> + ssdt_isa_pest [ 0 ], 16 , misc -> pvpanic_port ); <nl>  <nl> { <nl> GArray * sb_scope = build_alloc_array ();
static int qxl_track_command ( PCIQXLDevice * qxl , struct QXLCommandExt * ext ) <nl> return 1 ; <nl> } <nl> uint32_t id = le32_to_cpu ( cmd -> surface_id ); <nl> - PANIC_ON ( id >= NUM_SURFACES ); <nl> + <nl> + if ( id >= NUM_SURFACES ) { <nl> + qxl_guest_bug ( qxl , " QXL_CMD_SURFACE id % d >= % d ", id , NUM_SURFACES ); <nl> + return 1 ; <nl> + } <nl> qemu_mutex_lock (& qxl -> track_lock ); <nl> if ( cmd -> type == QXL_SURFACE_CMD_CREATE ) { <nl> qxl -> guest_surfaces . cmds [ id ] = ext -> cmd . data ;
int monitor_set_cpu ( int cpu_index ) <nl> CPUState * mon_get_cpu ( void ) <nl> { <nl> if (! cur_mon -> mon_cpu ) { <nl> - monitor_set_cpu ( 0 ); <nl> + monitor_set_cpu ( first_cpu -> cpu_index ); <nl> } <nl> cpu_synchronize_state ( cur_mon -> mon_cpu ); <nl> return cur_mon -> mon_cpu ;
static void virtio_net_set_status ( struct VirtIODevice * vdev , uint8_t status ) <nl> virtio_net_vhost_status ( n , status ); <nl>  <nl> for ( i = 0 ; i < n -> max_queues ; i ++) { <nl> + NetClientState * ncs = qemu_get_subqueue ( n -> nic , i ); <nl> + bool queue_started ; <nl> q = & n -> vqs [ i ]; <nl>  <nl> if ((! n -> multiqueue && i != 0 ) || i >= n -> curr_queues ) { <nl> static void virtio_net_set_status ( struct VirtIODevice * vdev , uint8_t status ) <nl> } else { <nl> queue_status = status ; <nl> } <nl> + queue_started = <nl> + virtio_net_started ( n , queue_status ) && ! n -> vhost_started ; <nl> + <nl> + if ( queue_started ) { <nl> + qemu_flush_queued_packets ( ncs ); <nl> + } <nl>  <nl> if (! q -> tx_waiting ) { <nl> continue ; <nl> } <nl>  <nl> - if ( virtio_net_started ( n , queue_status ) && ! n -> vhost_started ) { <nl> + if ( queue_started ) { <nl> if ( q -> tx_timer ) { <nl> timer_mod ( q -> tx_timer , <nl> qemu_clock_get_ns ( QEMU_CLOCK_VIRTUAL ) + n -> tx_timeout );
int qemu_poll_ns ( GPollFD * fds , guint nfds , int64_t timeout ) <nl> return ppoll (( struct pollfd *) fds , nfds , NULL , NULL ); <nl> } else { <nl> struct timespec ts ; <nl> - ts . tv_sec = timeout / 1000000000LL ; <nl> + int64_t tvsec = timeout / 1000000000LL ; <nl> + /* Avoid possibly overflowing and specifying a negative number of <nl> + * seconds , which would turn a very long timeout into a busy - wait . <nl> + */ <nl> + if ( tvsec > ( int64_t ) INT32_MAX ) { <nl> + tvsec = INT32_MAX ; <nl> + } <nl> + ts . tv_sec = tvsec ; <nl> ts . tv_nsec = timeout % 1000000000LL ; <nl> return ppoll (( struct pollfd *) fds , nfds , & ts , NULL ); <nl> }
static int do_slowtimo ; <nl> static TAILQ_HEAD ( slirp_instances , Slirp ) slirp_instances = <nl> TAILQ_HEAD_INITIALIZER ( slirp_instances ); <nl>  <nl> - struct in_addr dns_addr = { 0 }; <nl> - u_int dns_addr_time = 0 ; <nl> + static struct in_addr dns_addr ; <nl> + static u_int dns_addr_time ; <nl>  <nl> # ifdef _WIN32 <nl> 
static void breakpoint_invalidate ( CPUState * cpu , target_ulong pc ) <nl> # else <nl> static void breakpoint_invalidate ( CPUState * cpu , target_ulong pc ) <nl> { <nl> - tb_invalidate_phys_addr ( cpu_get_phys_page_debug ( cpu , pc ) | <nl> - ( pc & ~ TARGET_PAGE_MASK )); <nl> + hwaddr phys = cpu_get_phys_page_debug ( cpu , pc ); <nl> + if ( phys != - 1 ) { <nl> + tb_invalidate_phys_addr ( phys | ( pc & ~ TARGET_PAGE_MASK )); <nl> + } <nl> } <nl> # endif <nl> # endif /* TARGET_HAS_ICE */
static int qemu_signal_init ( void ) <nl> sigaddset (& set , SIGIO ); <nl> sigaddset (& set , SIGALRM ); <nl> sigaddset (& set , SIGBUS ); <nl> + sigaddset (& set , SIGINT ); <nl> + sigaddset (& set , SIGHUP ); <nl> + sigaddset (& set , SIGTERM ); <nl> pthread_sigmask ( SIG_BLOCK , & set , NULL ); <nl>  <nl> sigdelset (& set , SIG_IPI );
void ahci_realize ( AHCIState * s , DeviceState * qdev , AddressSpace * as , int ports ) <nl> ad -> port . dma -> ops = & ahci_dma_ops ; <nl> ide_register_restart_cb (& ad -> port ); <nl> } <nl> + g_free ( irqs ); <nl> } <nl>  <nl> void ahci_uninit ( AHCIState * s )
void pcie_aer_root_init ( PCIDevice * dev ) <nl> PCI_ERR_ROOT_CMD_EN_MASK ); <nl> pci_set_long ( dev -> w1cmask + pos + PCI_ERR_ROOT_STATUS , <nl> PCI_ERR_ROOT_STATUS_REPORT_MASK ); <nl> + /* PCI_ERR_ROOT_IRQ is RO but devices change it using a <nl> + * device - specific method . <nl> + */ <nl> + pci_set_long ( dev -> cmask + pos + PCI_ERR_ROOT_STATUS , <nl> + ~ PCI_ERR_ROOT_IRQ ); <nl> } <nl>  <nl> void pcie_aer_root_reset ( PCIDevice * dev )
static inline void tcg_out_shli64 ( TCGContext * s , TCGReg dst , TCGReg src , int c ) <nl> tcg_out_rld ( s , RLDICR , dst , src , c , 63 - c ); <nl> } <nl>  <nl> + static inline void tcg_out_shri64 ( TCGContext * s , TCGReg dst , TCGReg src , int c ) <nl> +{ <nl> + tcg_out_rld ( s , RLDICL , dst , src , 64 - c , c ); <nl> +} <nl> + <nl> static void tcg_out_movi32 ( TCGContext * s , TCGReg ret , int32_t arg ) <nl> { <nl> if ( arg == ( int16_t ) arg ) <nl> static void tcg_out_qemu_st ( TCGContext * s , const TCGArg * args , int opc ) <nl> if ( bswap ) { <nl> tcg_out32 ( s , STWBRX | SAB ( data_reg , rbase , r0 )); <nl> tcg_out32 ( s , ADDI | RT ( r1 ) | RA ( r0 ) | 4 ); <nl> - tcg_out_rld ( s , RLDICL , 0 , data_reg , 32 , 0 ); <nl> + tcg_out_shri64 ( s , 0 , data_reg , 32 ); <nl> tcg_out32 ( s , STWBRX | SAB ( 0 , rbase , r1 )); <nl> } <nl> else tcg_out32 ( s , STDX | SAB ( data_reg , rbase , r0 )); <nl> static void tcg_out_op ( TCGContext * s , TCGOpcode opc , const TCGArg * args , <nl> break ; <nl> case INDEX_op_shr_i64 : <nl> if ( const_args [ 2 ]) <nl> - tcg_out_rld ( s , RLDICL , args [ 0 ], args [ 1 ], 64 - args [ 2 ], args [ 2 ]); <nl> + tcg_out_shri64 ( s , args [ 0 ], args [ 1 ], args [ 2 ]); <nl> else <nl> tcg_out32 ( s , SRD | SAB ( args [ 1 ], args [ 0 ], args [ 2 ])); <nl> break ;
static void ioapic_class_init ( ObjectClass * klass , void * data ) <nl> DeviceClass * dc = DEVICE_CLASS ( klass ); <nl>  <nl> k -> realize = ioapic_realize ; <nl> + /* <nl> + * If APIC is in kernel , we need to update the kernel cache after <nl> + * migration , otherwise first 24 gsi routes will be invalid . <nl> + */ <nl> + k -> post_load = ioapic_update_kvm_routes ; <nl> dc -> reset = ioapic_reset_common ; <nl> dc -> props = ioapic_properties ; <nl> }
static int open_f ( BlockBackend * blk , int argc , char ** argv ) <nl> qemu_opts_reset (& empty_opts ); <nl>  <nl> if ( optind == argc - 1 ) { <nl> - return openfile ( argv [ optind ], flags , writethrough , force_share , opts ); <nl> + openfile ( argv [ optind ], flags , writethrough , force_share , opts ); <nl> } else if ( optind == argc ) { <nl> - return openfile ( NULL , flags , writethrough , force_share , opts ); <nl> + openfile ( NULL , flags , writethrough , force_share , opts ); <nl> } else { <nl> QDECREF ( opts ); <nl> - return qemuio_command_usage (& open_cmd ); <nl> + qemuio_command_usage (& open_cmd ); <nl> } <nl> + return 0 ; <nl> } <nl>  <nl> static int quit_f ( BlockBackend * blk , int argc , char ** argv )
static int aio_write_f ( int argc , char ** argv ) <nl> case ' P ': <nl> pattern = parse_pattern ( optarg ); <nl> if ( pattern < 0 ) { <nl> + free ( ctx ); <nl> return 0 ; <nl> } <nl> break ;
int qemu_create_pidfile ( const char * filename ) <nl> return - 1 ; <nl> } <nl> if ( lockf ( fd , F_TLOCK , 0 ) == - 1 ) { <nl> - fprintf ( stderr , " lock file '% s ' failed : % s \ n ", <nl> - filename , strerror ( errno )); <nl> close ( fd ); <nl> return - 1 ; <nl> }
void OPPROTO op_movl_drN_T0 ( void ) <nl>  <nl> void OPPROTO op_lmsw_T0 ( void ) <nl> { <nl> - /* only 4 lower bits of CR0 are modified */ <nl> - T0 = ( env -> cr [ 0 ] & ~ 0xf ) | ( T0 & 0xf ); <nl> + /* only 4 lower bits of CR0 are modified . PE cannot be set to zero <nl> + if already set to one . */ <nl> + T0 = ( env -> cr [ 0 ] & ~ 0xe ) | ( T0 & 0xf ); <nl> helper_movl_crN_T0 ( 0 ); <nl> } <nl> 
void apic_report_irq_delivered ( int delivered ) <nl>  <nl> void apic_reset_irq_delivered ( void ) <nl> { <nl> - trace_apic_reset_irq_delivered ( apic_irq_delivered ); <nl> + /* Copy this into a local variable to encourage gcc to emit a plain <nl> + * register for a sys / sdt . h marker . For details on this workaround , see : <nl> + * https :// sourceware . org / bugzilla / show_bug . cgi ? id = 13296 <nl> + */ <nl> + volatile int a_i_d = apic_irq_delivered ; <nl> + trace_apic_reset_irq_delivered ( a_i_d ); <nl>  <nl> apic_irq_delivered = 0 ; <nl> }
static uint64_t virtio_pci_common_read ( void * opaque , hwaddr addr , <nl> val = proxy -> gfselect ; <nl> break ; <nl> case VIRTIO_PCI_COMMON_GF : <nl> - if ( proxy -> gfselect <= ARRAY_SIZE ( proxy -> guest_features )) { <nl> + if ( proxy -> gfselect < ARRAY_SIZE ( proxy -> guest_features )) { <nl> val = proxy -> guest_features [ proxy -> gfselect ]; <nl> } <nl> break ; <nl> static void virtio_pci_common_write ( void * opaque , hwaddr addr , <nl> proxy -> gfselect = val ; <nl> break ; <nl> case VIRTIO_PCI_COMMON_GF : <nl> - if ( proxy -> gfselect <= ARRAY_SIZE ( proxy -> guest_features )) { <nl> + if ( proxy -> gfselect < ARRAY_SIZE ( proxy -> guest_features )) { <nl> proxy -> guest_features [ proxy -> gfselect ] = val ; <nl> virtio_set_features ( vdev , <nl> ((( uint64_t ) proxy -> guest_features [ 1 ]) << 32 ) |
void migrate_fd_put_notify ( void * opaque ) <nl>  <nl> qemu_set_fd_handler2 ( s -> fd , NULL , NULL , NULL , NULL ); <nl> qemu_file_put_notify ( s -> file ); <nl> + if ( qemu_file_has_error ( s -> file )) { <nl> + migrate_fd_error ( s ); <nl> + } <nl> } <nl>  <nl> ssize_t migrate_fd_put_buffer ( void * opaque , const void * data , size_t size ) <nl> ssize_t migrate_fd_put_buffer ( void * opaque , const void * data , size_t size ) <nl>  <nl> if ( ret == - EAGAIN ) { <nl> qemu_set_fd_handler2 ( s -> fd , NULL , NULL , migrate_fd_put_notify , s ); <nl> - } else if ( ret < 0 ) { <nl> - s -> state = MIG_STATE_ERROR ; <nl> - notifier_list_notify (& migration_state_notifiers , NULL ); <nl> } <nl>  <nl> return ret ;
static void acpi_dsdt_add_cpus ( Aml * scope , int smp_cpus ) <nl> uint16_t i ; <nl>  <nl> for ( i = 0 ; i < smp_cpus ; i ++) { <nl> - Aml * dev = aml_device (" C % 03x ", i ); <nl> + Aml * dev = aml_device (" C %. 03X ", i ); <nl> aml_append ( dev , aml_name_decl (" _HID ", aml_string (" ACPI0007 "))); <nl> aml_append ( dev , aml_name_decl (" _UID ", aml_int ( i ))); <nl> aml_append ( scope , dev );
qemu_irq * i8259_init ( ISABus * bus , qemu_irq parent_irq ) <nl> ISADevice * isadev ; <nl> int i ; <nl>  <nl> - irq_set = g_malloc ( ISA_NUM_IRQS * sizeof ( qemu_irq )); <nl> + irq_set = g_new0 ( qemu_irq , ISA_NUM_IRQS ); <nl>  <nl> isadev = i8259_init_chip ( TYPE_I8259 , bus , true ); <nl> dev = DEVICE ( isadev );
static int vhost_user_write ( struct vhost_dev * dev , VhostUserMsg * msg , <nl> return 0 ; <nl> } <nl>  <nl> - qemu_chr_fe_set_msgfds ( chr , fds , fd_num ); <nl> + if ( qemu_chr_fe_set_msgfds ( chr , fds , fd_num ) < 0 ) { <nl> + return - 1 ; <nl> + } <nl>  <nl> return qemu_chr_fe_write_all ( chr , ( const uint8_t *) msg , size ) == size ? <nl> 0 : - 1 ;
static void do_sdl_resize ( int width , int height , int bpp ) <nl> static void sdl_switch ( DisplayChangeListener * dcl , <nl> DisplaySurface * new_surface ) <nl> { <nl> - PixelFormat pf = qemu_pixelformat_from_pixman ( new_surface -> format ); <nl> + PixelFormat pf ; <nl>  <nl> /* temporary hack : allows to call sdl_switch to handle scaling changes */ <nl> if ( new_surface ) { <nl> surface = new_surface ; <nl> } <nl> + pf = qemu_pixelformat_from_pixman ( surface -> format ); <nl>  <nl> if (! scaling_active ) { <nl> do_sdl_resize ( surface_width ( surface ), surface_height ( surface ), 0 );
typedef struct { <nl> DebugFrameFDE fde ; <nl> } DebugFrame ; <nl>  <nl> -# if TCG_TARGET_REG_BITS == 64 <nl> +# if ! defined ( __ELF__ ) <nl> + /* Host machine without ELF . */ <nl> +# elif TCG_TARGET_REG_BITS == 64 <nl> # define ELF_HOST_MACHINE EM_X86_64 <nl> static DebugFrame debug_frame = { <nl> . cie . len = sizeof ( DebugFrameCIE )- 4 , /* length after . len member */ <nl> static DebugFrame debug_frame = { <nl> }; <nl> # endif <nl>  <nl> +# if defined ( ELF_HOST_MACHINE ) <nl> void tcg_register_jit ( void * buf , size_t buf_size ) <nl> { <nl> /* We ' re expecting a 2 byte uleb128 encoded value . */ <nl> void tcg_register_jit ( void * buf , size_t buf_size ) <nl>  <nl> tcg_register_jit_int ( buf , buf_size , & debug_frame , sizeof ( debug_frame )); <nl> } <nl> +# endif
enum vga_retrace_method { <nl>  <nl> extern enum vga_retrace_method vga_retrace_method ; <nl>  <nl> -# ifndef TARGET_SPARC <nl> +# if ! defined ( TARGET_SPARC ) || defined ( TARGET_SPARC64 ) <nl> # define VGA_RAM_SIZE ( 8192 * 1024 ) <nl> # else <nl> # define VGA_RAM_SIZE ( 9 * 1024 * 1024 )
coroutine_fn iscsi_co_write_zeroes ( BlockDriverState * bs , int64_t sector_num , <nl> nb_blocks = sector_qemu2lun ( nb_sectors , iscsilun ); <nl>  <nl> if ( iscsilun -> zeroblock == NULL ) { <nl> - iscsilun -> zeroblock = g_malloc0 ( iscsilun -> block_size ); <nl> + iscsilun -> zeroblock = g_try_malloc0 ( iscsilun -> block_size ); <nl> + if ( iscsilun -> zeroblock == NULL ) { <nl> + return - ENOMEM ; <nl> + } <nl> } <nl>  <nl> iscsi_co_init_iscsitask ( iscsilun , & iTask );
int qdev_device_help ( QemuOpts * opts ) <nl> return 0 ; <nl> } <nl>  <nl> - if (! object_class_by_name ( driver )) { <nl> - const char * typename = find_typename_by_alias ( driver ); <nl> - <nl> - if ( typename ) { <nl> - driver = typename ; <nl> - } <nl> + qdev_get_device_class (& driver , & local_err ); <nl> + if ( local_err ) { <nl> + goto error ; <nl> } <nl>  <nl> prop_list = qmp_device_list_properties ( driver , & local_err );
void monitor_flush ( Monitor * mon ) <nl>  <nl> if ( len && ! mon -> mux_out ) { <nl> rc = qemu_chr_fe_write ( mon -> chr , ( const uint8_t *) buf , len ); <nl> - if ( rc == len ) { <nl> - /* all flushed */ <nl> + if (( rc < 0 && errno != EAGAIN ) || ( rc == len )) { <nl> + /* all flushed or error */ <nl> QDECREF ( mon -> outbuf ); <nl> mon -> outbuf = qstring_new (); <nl> return ;
static int bdrv_check_byte_request ( BlockDriverState * bs , int64_t offset , <nl> static int bdrv_check_request ( BlockDriverState * bs , int64_t sector_num , <nl> int nb_sectors ) <nl> { <nl> + if ( nb_sectors > INT_MAX / BDRV_SECTOR_SIZE ) { <nl> + return - EIO ; <nl> + } <nl> + <nl> return bdrv_check_byte_request ( bs , sector_num * BDRV_SECTOR_SIZE , <nl> nb_sectors * BDRV_SECTOR_SIZE ); <nl> }
DisplayState * init_displaystate ( void ) <nl> gchar * name ; <nl> int i ; <nl>  <nl> - if (! display_state ) { <nl> - display_state = g_new0 ( DisplayState , 1 ); <nl> - } <nl> - <nl> + get_alloc_displaystate (); <nl> for ( i = 0 ; i < nb_consoles ; i ++) { <nl> if ( consoles [ i ]-> console_type != GRAPHIC_CONSOLE && <nl> consoles [ i ]-> ds == NULL ) {
static int vmdk_parse_extents ( const char * desc , BlockDriverState * bs , <nl> ret = vmdk_add_extent ( bs , extent_file , true , sectors , <nl> 0 , 0 , 0 , 0 , 0 , & extent , errp ); <nl> if ( ret < 0 ) { <nl> + bdrv_unref ( extent_file ); <nl> return ret ; <nl> } <nl> extent -> flat_start_offset = flat_offset << 9 ; <nl> static int vmdk_parse_extents ( const char * desc , BlockDriverState * bs , <nl> extent = & s -> extents [ s -> num_extents - 1 ]; <nl> } else { <nl> error_setg ( errp , " Unsupported extent type '% s '", type ); <nl> + bdrv_unref ( extent_file ); <nl> return - ENOTSUP ; <nl> } <nl> extent -> type = g_strdup ( type );
static FeatureWordInfo feature_word_info [ FEATURE_WORDS ] = { <nl> " ibpb ", NULL , NULL , NULL , <nl> NULL , NULL , NULL , NULL , <nl> NULL , NULL , NULL , NULL , <nl> - NULL , " virt - ssbd ", NULL , NULL , <nl> + " amd - ssbd ", " virt - ssbd ", NULL , NULL , <nl> NULL , NULL , NULL , NULL , <nl> }, <nl> . cpuid_eax = 0x80000008 ,
vga_bios_error : <nl> fprintf ( stderr , " qemu : could not load VGA BIOS '% s '\ n ", buf ); <nl> exit ( 1 ); <nl> } <nl> - } <nl>  <nl> - /* setup basic memory access */ <nl> - cpu_register_physical_memory ( 0xc0000 , 0x10000 , <nl> - vga_bios_offset | IO_MEM_ROM ); <nl> + /* setup basic memory access */ <nl> + cpu_register_physical_memory ( 0xc0000 , 0x10000 , <nl> + vga_bios_offset | IO_MEM_ROM ); <nl> + } <nl>  <nl> /* map the last 128KB of the BIOS in ISA space */ <nl> isa_bios_size = bios_size ;
static uint64_t pl011_read ( void * opaque , target_phys_addr_t offset , <nl> if ( s -> read_count == s -> read_trigger - 1 ) <nl> s -> int_level &= ~ PL011_INT_RX ; <nl> pl011_update ( s ); <nl> - qemu_chr_accept_input ( s -> chr ); <nl> + if ( s -> chr ) { <nl> + qemu_chr_accept_input ( s -> chr ); <nl> + } <nl> return c ; <nl> case 1 : /* UARTCR */ <nl> return 0 ;
static void cpu_common_unrealizefn ( DeviceState * dev , Error ** errp ) <nl>  <nl> static void cpu_common_initfn ( Object * obj ) <nl> { <nl> + uint32_t count ; <nl> CPUState * cpu = CPU ( obj ); <nl> CPUClass * cc = CPU_GET_CLASS ( obj ); <nl>  <nl> static void cpu_common_initfn ( Object * obj ) <nl> QTAILQ_INIT (& cpu -> breakpoints ); <nl> QTAILQ_INIT (& cpu -> watchpoints ); <nl>  <nl> - cpu -> trace_dstate = bitmap_new ( trace_get_vcpu_event_count ()); <nl> + count = trace_get_vcpu_event_count (); <nl> + if ( count ) { <nl> + cpu -> trace_dstate = bitmap_new ( count ); <nl> + } <nl>  <nl> cpu_exec_initfn ( cpu ); <nl> }
static int xen_pt_config_reg_init ( XenPCIPassthroughState * s , <nl> break ; <nl> case 4 : rc = xen_host_pci_get_long (& s -> real_device , offset , & val ); <nl> break ; <nl> - default : assert ( 1 ); <nl> + default : abort (); <nl> } <nl> if ( rc ) { <nl> /* Serious issues when we cannot read the host values ! */ <nl> static int xen_pt_config_reg_init ( XenPCIPassthroughState * s , <nl> break ; <nl> case 4 : pci_set_long ( s -> dev . config + offset , val ); <nl> break ; <nl> - default : assert ( 1 ); <nl> + default : abort (); <nl> } <nl> /* set register value pointer to the data . */ <nl> reg_entry -> ptr . byte = s -> dev . config + offset ;
static int kvm_put_msrs ( CPUState * env , int level ) <nl> kvm_msr_entry_set (& msrs [ n ++], MSR_IA32_SYSENTER_EIP , env -> sysenter_eip ); <nl> if ( kvm_has_msr_star ( env )) <nl> kvm_msr_entry_set (& msrs [ n ++], MSR_STAR , env -> star ); <nl> + kvm_msr_entry_set (& msrs [ n ++], MSR_VM_HSAVE_PA , env -> vm_hsave ); <nl> # ifdef TARGET_X86_64 <nl> /* FIXME if lm capable */ <nl> kvm_msr_entry_set (& msrs [ n ++], MSR_CSTAR , env -> cstar ); <nl> static int kvm_get_msrs ( CPUState * env ) <nl> msrs [ n ++]. index = MSR_IA32_SYSENTER_EIP ; <nl> if ( kvm_has_msr_star ( env )) <nl> msrs [ n ++]. index = MSR_STAR ; <nl> + msrs [ n ++]. index = MSR_VM_HSAVE_PA ; <nl> msrs [ n ++]. index = MSR_IA32_TSC ; <nl> # ifdef TARGET_X86_64 <nl> /* FIXME lm_capable_kernel */ <nl> static int kvm_get_msrs ( CPUState * env ) <nl> case MSR_IA32_TSC : <nl> env -> tsc = msrs [ i ]. data ; <nl> break ; <nl> + case MSR_VM_HSAVE_PA : <nl> + env -> vm_hsave = msrs [ i ]. data ; <nl> + break ; <nl> case MSR_KVM_SYSTEM_TIME : <nl> env -> system_time_msr = msrs [ i ]. data ; <nl> break ;
int net_init_tap ( const NetClientOptions * opts , const char * name , <nl> queues = tap -> has_queues ? tap -> queues : 1 ; <nl> vhostfdname = tap -> has_vhostfd ? tap -> vhostfd : NULL ; <nl>  <nl> + /* QEMU vlans does not support multiqueue tap , in this case peer is set . <nl> + * For - netdev , peer is always NULL . */ <nl> + if ( peer && ( tap -> has_queues || tap -> has_fds || tap -> has_vhostfds )) { <nl> + error_report (" Multiqueue tap cannnot be used with QEMU vlans "); <nl> + return - 1 ; <nl> + } <nl> + <nl> if ( tap -> has_fd ) { <nl> if ( tap -> has_ifname || tap -> has_script || tap -> has_downscript || <nl> tap -> has_vnet_hdr || tap -> has_helper || tap -> has_queues ||
static void usb_host_auto_check ( void * unused ) <nl> { <nl> struct USBHostDevice * s ; <nl> struct USBAutoFilter * f ; <nl> - libusb_device ** devs ; <nl> + libusb_device ** devs = NULL ; <nl> struct libusb_device_descriptor ddesc ; <nl> int unconnected = 0 ; <nl> int i , n ; <nl> static void usb_host_auto_check ( void * unused ) <nl>  <nl> void usb_host_info ( Monitor * mon , const QDict * qdict ) <nl> { <nl> - libusb_device ** devs ; <nl> + libusb_device ** devs = NULL ; <nl> struct libusb_device_descriptor ddesc ; <nl> char port [ 16 ]; <nl> int i , n ;
void helper_svm_check_intercept_param ( uint32_t type , uint64_t param ) <nl> switch (( uint32_t ) ECX ) { <nl> case 0 ... 0x1fff : <nl> t0 = ( ECX * 2 ) % 8 ; <nl> - t1 = ECX / 8 ; <nl> + t1 = ( ECX * 2 ) / 8 ; <nl> break ; <nl> case 0xc0000000 ... 0xc0001fff : <nl> t0 = ( 8192 + ECX - 0xc0000000 ) * 2 ;
static ssize_t virtio_net_receive ( NetClientState * nc , const uint8_t * buf , size_t <nl> * must have consumed the complete packet . <nl> * Otherwise , drop it . */ <nl> if (! n -> mergeable_rx_bufs && offset < size ) { <nl> -# if 0 <nl> - error_report (" virtio - net truncated non - mergeable packet : " <nl> - " i % zd mergeable % d offset % zd , size % zd , " <nl> - " guest hdr len % zd , host hdr len % zd ", <nl> - i , n -> mergeable_rx_bufs , <nl> - offset , size , n -> guest_hdr_len , n -> host_hdr_len ); <nl> -# endif <nl> + virtqueue_discard ( q -> rx_vq , & elem , total ); <nl> return size ; <nl> } <nl> 
static void i6300esb_restart_timer ( I6300State * d , int stage ) <nl> * multiply here can exceed 64 - bits , before we divide by 33MHz , so <nl> * we use a higher - precision intermediate result . <nl> */ <nl> - timeout = muldiv64 ( get_ticks_per_sec (), timeout , 33000000 ); <nl> + timeout = muldiv64 ( timeout , get_ticks_per_sec (), 33000000 ); <nl>  <nl> i6300esb_debug (" stage % d , timeout %" PRIi64 "\ n ", d -> stage , timeout ); <nl> 
static int vmdk_write_cid ( BlockDriverState * bs , uint32_t cid ) <nl> pstrcat ( desc , sizeof ( desc ), tmp_desc ); <nl> } <nl>  <nl> - if ( bdrv_pwrite ( bs -> file , 0x200 , desc , DESC_SIZE ) != DESC_SIZE ) <nl> + if ( bdrv_pwrite_sync ( bs -> file , 0x200 , desc , DESC_SIZE ) < 0 ) <nl> return - 1 ; <nl> return 0 ; <nl> } <nl> static int vmdk_L2update ( BlockDriverState * bs , VmdkMetaData * m_data ) <nl> BDRVVmdkState * s = bs -> opaque ; <nl>  <nl> /* update L2 table */ <nl> - if ( bdrv_pwrite ( bs -> file , (( int64_t ) m_data -> l2_offset * 512 ) + ( m_data -> l2_index * sizeof ( m_data -> offset )), <nl> - &( m_data -> offset ), sizeof ( m_data -> offset )) != sizeof ( m_data -> offset )) <nl> + if ( bdrv_pwrite_sync ( bs -> file , (( int64_t ) m_data -> l2_offset * 512 ) + ( m_data -> l2_index * sizeof ( m_data -> offset )), <nl> + &( m_data -> offset ), sizeof ( m_data -> offset )) < 0 ) <nl> return - 1 ; <nl> /* update backup L2 table */ <nl> if ( s -> l1_backup_table_offset != 0 ) { <nl> m_data -> l2_offset = s -> l1_backup_table [ m_data -> l1_index ]; <nl> - if ( bdrv_pwrite ( bs -> file , (( int64_t ) m_data -> l2_offset * 512 ) + ( m_data -> l2_index * sizeof ( m_data -> offset )), <nl> - &( m_data -> offset ), sizeof ( m_data -> offset )) != sizeof ( m_data -> offset )) <nl> + if ( bdrv_pwrite_sync ( bs -> file , (( int64_t ) m_data -> l2_offset * 512 ) + ( m_data -> l2_index * sizeof ( m_data -> offset )), <nl> + &( m_data -> offset ), sizeof ( m_data -> offset )) < 0 ) <nl> return - 1 ; <nl> } <nl> 
static void setup_frame ( int sig , struct target_sigaction * ka , <nl> /* moveq #, d0 ; trap # 0 */ <nl>  <nl> __put_user ( 0x70004e40 + ( TARGET_NR_sigreturn << 16 ), <nl> - ( long *)( frame -> retcode )); <nl> + ( uint32_t *)( frame -> retcode )); <nl>  <nl> /* Set up to return from userspace */ <nl>  <nl> static void setup_rt_frame ( int sig , struct target_sigaction * ka , <nl> /* moveq #, d0 ; notb d0 ; trap # 0 */ <nl>  <nl> __put_user ( 0x70004600 + (( TARGET_NR_rt_sigreturn ^ 0xff ) << 16 ), <nl> - ( long *)( frame -> retcode + 0 )); <nl> - __put_user ( 0x4e40 , ( short *)( frame -> retcode + 4 )); <nl> + ( uint32_t *)( frame -> retcode + 0 )); <nl> + __put_user ( 0x4e40 , ( uint16_t *)( frame -> retcode + 4 )); <nl>  <nl> if ( err ) <nl> goto give_sigsegv ;
void unregister_displaychangelistener ( DisplayChangeListener * dcl ) <nl> dcl -> con -> dcls --; <nl> } <nl> QLIST_REMOVE ( dcl , next ); <nl> + dcl -> ds = NULL ; <nl> gui_setup_refresh ( ds ); <nl> } <nl> 
static void v9fs_walk ( void * opaque ) <nl> goto out_nofid ; <nl> } <nl>  <nl> + v9fs_path_init (& dpath ); <nl> + v9fs_path_init (& path ); <nl> + <nl> err = fid_to_qid ( pdu , fidp , & qid ); <nl> if ( err < 0 ) { <nl> goto out ; <nl> } <nl>  <nl> - v9fs_path_init (& dpath ); <nl> - v9fs_path_init (& path ); <nl> /* <nl> * Both dpath and path initially poin to fidp . <nl> * Needed to handle request with nwnames == 0
static void assign_storage ( SCLPDevice * sclp , SCCB * sccb ) <nl> sccb -> h . response_code = cpu_to_be16 ( SCLP_RC_INVALID_SCLP_COMMAND ); <nl> return ; <nl> } <nl> - assign_addr = ( assign_info -> rn - 1 ) * mhd -> rzm ; <nl> + assign_addr = ( be16_to_cpu ( assign_info -> rn ) - 1 ) * mhd -> rzm ; <nl>  <nl> if (( assign_addr % MEM_SECTION_SIZE == 0 ) && <nl> ( assign_addr >= mhd -> padded_ram_size )) { <nl> static void unassign_storage ( SCLPDevice * sclp , SCCB * sccb ) <nl> sccb -> h . response_code = cpu_to_be16 ( SCLP_RC_INVALID_SCLP_COMMAND ); <nl> return ; <nl> } <nl> - unassign_addr = ( assign_info -> rn - 1 ) * mhd -> rzm ; <nl> + unassign_addr = ( be16_to_cpu ( assign_info -> rn ) - 1 ) * mhd -> rzm ; <nl>  <nl> /* if the addr is a multiple of 256 MB */ <nl> if (( unassign_addr % MEM_SECTION_SIZE == 0 ) &&
typedef struct BDRVRawState { <nl> int qemu_ftruncate64 ( int fd , int64_t length ) <nl> { <nl> LARGE_INTEGER li ; <nl> + DWORD dw ; <nl> LONG high ; <nl> HANDLE h ; <nl> BOOL res ; <nl> int qemu_ftruncate64 ( int fd , int64_t length ) <nl> /* get current position , ftruncate do not change position */ <nl> li . HighPart = 0 ; <nl> li . LowPart = SetFilePointer ( h , 0 , & li . HighPart , FILE_CURRENT ); <nl> - if ( li . LowPart == 0xffffffffUL && GetLastError () != NO_ERROR ) <nl> + if ( li . LowPart == INVALID_SET_FILE_POINTER && GetLastError () != NO_ERROR ) { <nl> return - 1 ; <nl> + } <nl>  <nl> high = length >> 32 ; <nl> - if (! SetFilePointer ( h , ( DWORD ) length , & high , FILE_BEGIN )) <nl> + dw = SetFilePointer ( h , ( DWORD ) length , & high , FILE_BEGIN ); <nl> + if ( dw == INVALID_SET_FILE_POINTER && GetLastError () != NO_ERROR ) { <nl> return - 1 ; <nl> + } <nl> res = SetEndOfFile ( h ); <nl>  <nl> /* back to old position */
int net_init_tap ( const NetClientOptions * opts , const char * name , <nl> if ( net_init_tap_one ( tap , peer , " bridge ", name , ifname , <nl> script , downscript , vhostfdname , <nl> vnet_hdr , fd )) { <nl> + close ( fd ); <nl> return - 1 ; <nl> } <nl> } else { <nl> int net_init_tap ( const NetClientOptions * opts , const char * name , <nl> if ( queues > 1 && i == 0 && ! tap -> has_ifname ) { <nl> if ( tap_fd_get_ifname ( fd , ifname )) { <nl> error_report (" Fail to get ifname "); <nl> + close ( fd ); <nl> return - 1 ; <nl> } <nl> } <nl> int net_init_tap ( const NetClientOptions * opts , const char * name , <nl> i >= 1 ? " no " : script , <nl> i >= 1 ? " no " : downscript , <nl> vhostfdname , vnet_hdr , fd )) { <nl> + close ( fd ); <nl> return - 1 ; <nl> } <nl> }
static inline void gen_op_arith_subf ( DisasContext * ctx , TCGv ret , TCGv arg1 , <nl> } <nl> tcg_gen_xor_tl ( t1 , arg2 , inv1 ); /* add without carry */ <nl> tcg_gen_add_tl ( t0 , t0 , inv1 ); <nl> + tcg_temp_free ( inv1 ); <nl> tcg_gen_xor_tl ( cpu_ca , t0 , t1 ); /* bits changes w / carry */ <nl> tcg_temp_free ( t1 ); <nl> tcg_gen_shri_tl ( cpu_ca , cpu_ca , 32 ); /* extract bit 32 */ <nl> static inline void gen_bcond ( DisasContext * ctx , int type ) <nl> gen_update_nip ( ctx , ctx -> nip ); <nl> tcg_gen_exit_tb ( 0 ); <nl> } <nl> + if ( type == BCOND_LR || type == BCOND_CTR ) { <nl> + tcg_temp_free ( target ); <nl> + } <nl> } <nl>  <nl> static void gen_bc ( DisasContext * ctx ) <nl> static void gen_mtmsr ( DisasContext * ctx ) <nl> tcg_gen_mov_tl ( msr , cpu_gpr [ rS ( ctx -> opcode )]); <nl> # endif <nl> gen_helper_store_msr ( cpu_env , msr ); <nl> + tcg_temp_free ( msr ); <nl> /* Must stop the translation as machine state ( may have ) changed */ <nl> /* Note that mtmsr is not always defined as context - synchronizing */ <nl> gen_stop_exception ( ctx ); <nl> static void gen_tlbsx_booke206 ( DisasContext * ctx ) <nl>  <nl> tcg_gen_add_tl ( t0 , t0 , cpu_gpr [ rB ( ctx -> opcode )]); <nl> gen_helper_booke206_tlbsx ( cpu_env , t0 ); <nl> + tcg_temp_free ( t0 ); <nl> # endif <nl> } <nl>  <nl> static void gen_tlbivax_booke206 ( DisasContext * ctx ) <nl> gen_addr_reg_index ( ctx , t0 ); <nl>  <nl> gen_helper_booke206_tlbivax ( cpu_env , t0 ); <nl> + tcg_temp_free ( t0 ); <nl> # endif <nl> } <nl> 
static int ohci_service_iso_td ( OHCIState * ohci , struct ohci_ed * ed , <nl> ed -> head & OHCI_DPTR_MASK , ed -> tail & OHCI_DPTR_MASK , <nl> iso_td . flags , iso_td . bp , iso_td . next , iso_td . be , <nl> ohci -> frame_number , starting_frame , <nl> - frame_count , relative_frame_number , <nl> - OHCI_BM ( iso_td . flags , TD_DI ), OHCI_BM ( iso_td . flags , TD_CC )); <nl> + frame_count , relative_frame_number ); <nl> trace_usb_ohci_iso_td_head_offset ( <nl> iso_td . offset [ 0 ], iso_td . offset [ 1 ], <nl> iso_td . offset [ 2 ], iso_td . offset [ 3 ],
static void pc_init_pci_no_kvmclock ( MachineState * machine ) <nl> has_pci_info = false ; <nl> has_acpi_build = false ; <nl> smbios_defaults = false ; <nl> + gigabyte_align = false ; <nl> + smbios_legacy_mode = true ; <nl> + has_reserved_memory = false ; <nl> + option_rom_has_mr = true ; <nl> + rom_file_has_mr = false ; <nl> x86_cpu_compat_disable_kvm_features ( FEAT_KVM , KVM_FEATURE_PV_EOI ); <nl> enable_compat_apic_id_mode (); <nl> pc_init1 ( machine , 1 , 0 ); <nl> static void pc_init_isa ( MachineState * machine ) <nl> has_pci_info = false ; <nl> has_acpi_build = false ; <nl> smbios_defaults = false ; <nl> + gigabyte_align = false ; <nl> + smbios_legacy_mode = true ; <nl> + has_reserved_memory = false ; <nl> + option_rom_has_mr = true ; <nl> + rom_file_has_mr = false ; <nl> if (! machine -> cpu_model ) { <nl> machine -> cpu_model = " 486 "; <nl> }
void kvm_set_phys_mem ( target_phys_addr_t start_addr , <nl>  <nl> mem = kvm_lookup_slot ( s , start_addr ); <nl> if ( mem ) { <nl> - if ( flags == IO_MEM_UNASSIGNED ) { <nl> + if (( flags == IO_MEM_UNASSIGNED ) || ( flags >= TLB_MMIO )) { <nl> mem -> memory_size = 0 ; <nl> mem -> guest_phys_addr = start_addr ; <nl> mem -> userspace_addr = 0 ;
static int vhost_user_read ( struct vhost_dev * dev , VhostUserMsg * msg ) <nl>  <nl> r = qemu_chr_fe_read_all ( chr , p , size ); <nl> if ( r != size ) { <nl> - error_report (" Failed to read msg header . Read % d instead of % d .", r , <nl> - size ); <nl> + error_report (" Failed to read msg header . Read % d instead of % d ." <nl> + " Original request % d .", r , size , msg -> request ); <nl> goto fail ; <nl> } <nl> 
static always_inline int translate_one ( DisasContext * ctx , uint32_t insn ) <nl> break ; <nl> # endif <nl> case 0x1A : <nl> - if ( ra != 31 ) <nl> - tcg_gen_movi_i64 ( cpu_ir [ ra ], ctx -> pc ); <nl> if ( rb != 31 ) <nl> tcg_gen_andi_i64 ( cpu_pc , cpu_ir [ rb ], ~ 3 ); <nl> else <nl> tcg_gen_movi_i64 ( cpu_pc , 0 ); <nl> + if ( ra != 31 ) <nl> + tcg_gen_movi_i64 ( cpu_ir [ ra ], ctx -> pc ); <nl> /* Those four jumps only differ by the branch prediction hint */ <nl> switch ( fn2 ) { <nl> case 0x0 :
static int bad_mode_switch ( CPUARMState * env , int mode , CPSRWriteType write_type ) <nl>  <nl> switch ( mode ) { <nl> case ARM_CPU_MODE_USR : <nl> + return 0 ; <nl> case ARM_CPU_MODE_SYS : <nl> case ARM_CPU_MODE_SVC : <nl> case ARM_CPU_MODE_ABT : <nl> static int bad_mode_switch ( CPUARMState * env , int mode , CPSRWriteType write_type ) <nl> /* Note that we don ' t implement the IMPDEF NSACR . RFR which in v7 <nl> * allows FIQ mode to be Secure - only . ( In v8 this doesn ' t exist .) <nl> */ <nl> + /* If HCR . TGE is set then changes from Monitor to NS PL1 via MSR <nl> + * and CPS are treated as illegal mode changes . <nl> + */ <nl> + if ( write_type == CPSRWriteByInstr && <nl> + ( env -> cp15 . hcr_el2 & HCR_TGE ) && <nl> + ( env -> uncached_cpsr & CPSR_M ) == ARM_CPU_MODE_MON && <nl> + ! arm_is_secure_below_el3 ( env )) { <nl> + return 1 ; <nl> + } <nl> return 0 ; <nl> case ARM_CPU_MODE_HYP : <nl> return ! arm_feature ( env , ARM_FEATURE_EL2 )
static void spapr_machine_reset ( void ) <nl> /* Check for unknown sysbus devices */ <nl> foreach_dynamic_sysbus_device ( find_unknown_sysbus_device , NULL ); <nl>  <nl> - if ( kvm_enabled () && kvmppc_has_cap_mmu_radix ()) { <nl> + first_ppc_cpu = POWERPC_CPU ( first_cpu ); <nl> + if ( kvm_enabled () && kvmppc_has_cap_mmu_radix () && <nl> + ppc_check_compat ( first_ppc_cpu , CPU_POWERPC_LOGICAL_3_00 , 0 , <nl> + spapr -> max_compat_pvr )) { <nl> /* If using KVM with radix mode available , VCPUs can be started <nl> * without a HPT because KVM will start them in radix mode . <nl> * Set the GR bit in PATB so that we know there is no HPT . */ <nl> static void spapr_machine_reset ( void ) <nl> g_free ( fdt ); <nl>  <nl> /* Set up the entry state */ <nl> - first_ppc_cpu = POWERPC_CPU ( first_cpu ); <nl> first_ppc_cpu -> env . gpr [ 3 ] = fdt_addr ; <nl> first_ppc_cpu -> env . gpr [ 5 ] = 0 ; <nl> first_cpu -> halted = 0 ;
static void disas_sparc_insn ( DisasContext * dc ) <nl> # endif <nl> } <nl> if ( xop < 4 || ( xop > 7 && xop < 0x14 && xop != 0x0e ) || \ <nl> - ( xop > 0x17 && xop < 0x1d ) || \ <nl> - ( xop > 0x2c && xop < 0x33 ) || xop == 0x1f ) { <nl> + ( xop > 0x17 && xop <= 0x1d ) || \ <nl> + ( xop > 0x2c && xop <= 0x33 ) || xop == 0x1f ) { <nl> switch ( xop ) { <nl> case 0x0 : /* load word */ <nl> gen_op_ldst ( ld );
static int raw_pread ( BlockDriverState * bs , int64_t offset , <nl> size = ALIGNED_BUFFER_SIZE ; <nl>  <nl> ret = raw_pread_aligned ( bs , offset , s -> aligned_buf , size ); <nl> - if ( ret < 0 ) <nl> + if ( ret < 0 ) { <nl> return ret ; <nl> + } else if ( ret == 0 ) { <nl> + fprintf ( stderr , " raw_pread : read beyond end of file \ n "); <nl> + abort (); <nl> + } <nl>  <nl> size = ret ; <nl> if ( size > count )
static int get_real_id ( const char * devpath , const char * idname , uint16_t * val ) <nl> if ( fscanf ( f , "% li \ n ", & id ) == 1 ) { <nl> * val = id ; <nl> } else { <nl> + fclose ( f ); <nl> return - 1 ; <nl> } <nl> fclose ( f );
static NetSocketState * net_socket_fd_init_dgram ( NetClientState * peer , <nl> net_socket_read_poll ( s , true ); <nl>  <nl> /* mcast : save bound address as dst */ <nl> - if ( is_connected ) { <nl> + if ( is_connected && mcast != NULL ) { <nl> s -> dgram_dst = saddr ; <nl> snprintf ( nc -> info_str , sizeof ( nc -> info_str ), <nl> " socket : fd =% d ( cloned mcast =% s :% d )",
void cpu_loop ( CPUMBState * env ) <nl> case EXCP_BREAK : <nl> /* Return address is 4 bytes after the call . */ <nl> env -> regs [ 14 ] += 4 ; <nl> + env -> sregs [ SR_PC ] = env -> regs [ 14 ]; <nl> ret = do_syscall ( env , <nl> env -> regs [ 12 ], <nl> env -> regs [ 5 ], <nl> void cpu_loop ( CPUMBState * env ) <nl> env -> regs [ 10 ], <nl> 0 , 0 ); <nl> env -> regs [ 3 ] = ret ; <nl> - env -> sregs [ SR_PC ] = env -> regs [ 14 ]; <nl> break ; <nl> case EXCP_HW_EXCP : <nl> env -> regs [ 17 ] = env -> sregs [ SR_PC ] + 4 ;
static BlockAIOCB * inject_error ( BlockDriverState * bs , <nl> int error = rule -> options . inject . error ; <nl> struct BlkdebugAIOCB * acb ; <nl> QEMUBH * bh ; <nl> + bool immediately = rule -> options . inject . immediately ; <nl>  <nl> if ( rule -> options . inject . once ) { <nl> - QSIMPLEQ_INIT (& s -> active_rules ); <nl> + QSIMPLEQ_REMOVE (& s -> active_rules , rule , BlkdebugRule , active_next ); <nl> + remove_rule ( rule ); <nl> } <nl>  <nl> - if ( rule -> options . inject . immediately ) { <nl> + if ( immediately ) { <nl> return NULL ; <nl> } <nl> 
static int protocol_client_vencrypt_auth ( VncState * vs , uint8_t * data , size_t len <nl> VNC_DEBUG (" Failed to complete TLS \ n "); <nl> return 0 ; <nl> } <nl> - <nl> - if ( vs -> wiremode == VNC_WIREMODE_TLS ) { <nl> - VNC_DEBUG (" Starting VeNCrypt subauth \ n "); <nl> - return start_auth_vencrypt_subauth ( vs ); <nl> - } else { <nl> - VNC_DEBUG (" TLS handshake blocked \ n "); <nl> - return 0 ; <nl> - } <nl> } <nl> return 0 ; <nl> }
END_TEST <nl>  <nl> START_TEST ( empty_input ) <nl> { <nl> - QObject * obj = qobject_from_json (""); <nl> + const char * empty = ""; <nl> + <nl> + QObject * obj = qobject_from_json ( empty ); <nl> fail_unless ( obj == NULL ); <nl> } <nl> END_TEST
static int parallels_open ( BlockDriverState * bs , QDict * options , int flags , <nl> ret = - EFBIG ; <nl> goto fail ; <nl> } <nl> - s -> catalog_bitmap = g_malloc ( s -> catalog_size * 4 ); <nl> + s -> catalog_bitmap = g_try_malloc ( s -> catalog_size * 4 ); <nl> + if ( s -> catalog_size && s -> catalog_bitmap == NULL ) { <nl> + ret = - ENOMEM ; <nl> + goto fail ; <nl> + } <nl>  <nl> ret = bdrv_pread ( bs -> file , 64 , s -> catalog_bitmap , s -> catalog_size * 4 ); <nl> if ( ret < 0 ) {
void do_device_add ( Monitor * mon , const QDict * qdict ) <nl>  <nl> opts = qemu_opts_parse (& qemu_device_opts , <nl> qdict_get_str ( qdict , " config "), " driver "); <nl> - if ( opts && ! qdev_device_help ( opts )) <nl> - qdev_device_add ( opts ); <nl> + if ( opts ) { <nl> + if ( qdev_device_help ( opts ) || qdev_device_add ( opts ) == NULL ) { <nl> + qemu_opts_del ( opts ); <nl> + } <nl> + } <nl> } <nl>  <nl> void do_device_del ( Monitor * mon , const QDict * qdict )
static int handle_primary_tcp_pkt ( NetFilterState * nf , <nl> /* handle packets to the secondary from the primary */ <nl> tcp_pkt -> th_ack = htonl ( ntohl ( tcp_pkt -> th_ack ) + conn -> offset ); <nl>  <nl> - net_checksum_calculate (( uint8_t *) pkt -> data , pkt -> size ); <nl> + net_checksum_calculate (( uint8_t *) pkt -> data + pkt -> vnet_hdr_len , <nl> + pkt -> size - pkt -> vnet_hdr_len ); <nl> } <nl> } <nl>  <nl> static int handle_secondary_tcp_pkt ( NetFilterState * nf , <nl> /* handle packets to the primary from the secondary */ <nl> tcp_pkt -> th_seq = htonl ( ntohl ( tcp_pkt -> th_seq ) - conn -> offset ); <nl>  <nl> - net_checksum_calculate (( uint8_t *) pkt -> data , pkt -> size ); <nl> + net_checksum_calculate (( uint8_t *) pkt -> data + pkt -> vnet_hdr_len , <nl> + pkt -> size - pkt -> vnet_hdr_len ); <nl> } <nl> } <nl> 
static bool get_phys_addr ( CPUARMState * env , target_ulong address , <nl> phys_ptr , prot , fsr ); <nl> qemu_log_mask ( CPU_LOG_MMU , " PMSAv7 MPU lookup for % s at 0x % 08 " PRIx32 <nl> " mmu_idx % u -> % s ( prot % c % c % c )\ n ", <nl> - access_type == 1 ? " reading " : <nl> - ( access_type == 2 ? " writing " : " execute "), <nl> + access_type == MMU_DATA_LOAD ? " reading " : <nl> + ( access_type == MMU_DATA_STORE ? " writing " : " execute "), <nl> ( uint32_t ) address , mmu_idx , <nl> ret ? " Miss " : " Hit ", <nl> * prot & PAGE_READ ? ' r ' : '-',
static int block_load ( QEMUFile * f , void * opaque , int version_id ) <nl> addr >>= BDRV_SECTOR_BITS ; <nl>  <nl> if ( flags & BLK_MIG_FLAG_DEVICE_BLOCK ) { <nl> + int ret ; <nl> /* get device name */ <nl> len = qemu_get_byte ( f ); <nl> qemu_get_buffer ( f , ( uint8_t *) device_name , len ); <nl> static int block_load ( QEMUFile * f , void * opaque , int version_id ) <nl> buf = qemu_malloc ( BLOCK_SIZE ); <nl>  <nl> qemu_get_buffer ( f , buf , BLOCK_SIZE ); <nl> - bdrv_write ( bs , addr , buf , BDRV_SECTORS_PER_DIRTY_CHUNK ); <nl> + ret = bdrv_write ( bs , addr , buf , BDRV_SECTORS_PER_DIRTY_CHUNK ); <nl>  <nl> qemu_free ( buf ); <nl> + if ( ret < 0 ) { <nl> + return ret ; <nl> + } <nl> } else if ( flags & BLK_MIG_FLAG_PROGRESS ) { <nl> if (! banner_printed ) { <nl> printf (" Receiving block device images \ n ");
static ssize_t nc_sendv_compat ( NetClientState * nc , const struct iovec * iov , <nl> buffer = iov [ 0 ]. iov_base ; <nl> offset = iov [ 0 ]. iov_len ; <nl> } else { <nl> - buf = g_new ( uint8_t , NET_BUFSIZE ); <nl> + offset = iov_size ( iov , iovcnt ); <nl> + if ( offset > NET_BUFSIZE ) { <nl> + return - 1 ; <nl> + } <nl> + buf = g_malloc ( offset ); <nl> buffer = buf ; <nl> - offset = iov_to_buf ( iov , iovcnt , 0 , buf , NET_BUFSIZE ); <nl> + offset = iov_to_buf ( iov , iovcnt , 0 , buf , offset ); <nl> } <nl>  <nl> if ( flags & QEMU_NET_PACKET_FLAG_RAW && nc -> info -> receive_raw ) {
static void slavio_check_interrupts ( SLAVIO_INTCTLState * s , int set_irqs ) <nl> pil_pending |= ( s -> slaves [ i ]. intreg_pending & CPU_SOFTIRQ_MASK ) >> 16 ; <nl>  <nl> if ( set_irqs ) { <nl> - for ( j = MAX_PILS ; j > 0 ; j --) { <nl> + /* Since there is not really an interrupt 0 ( and pil_pending <nl> + * and irl_out bit zero are thus always zero ) there is no need <nl> + * to do anything with cpu_irqs [ i ][ 0 ] and it is OK not to do <nl> + * the j = 0 iteration of this loop . <nl> + */ <nl> + for ( j = MAX_PILS - 1 ; j > 0 ; j --) { <nl> if ( pil_pending & ( 1 << j )) { <nl> if (!( s -> slaves [ i ]. irl_out & ( 1 << j ))) { <nl> qemu_irq_raise ( s -> cpu_irqs [ i ][ j ]);
static void dp8393x_realize ( DeviceState * dev , Error ** errp ) <nl> dp8393xState * s = DP8393X ( dev ); <nl> int i , checksum ; <nl> uint8_t * prom ; <nl> + Error * local_err = NULL ; <nl>  <nl> address_space_init (& s -> as , s -> dma_mr , " dp8393x "); <nl> memory_region_init_io (& s -> mmio , OBJECT ( dev ), & dp8393x_ops , s , <nl> static void dp8393x_realize ( DeviceState * dev , Error ** errp ) <nl> s -> watchdog = timer_new_ns ( QEMU_CLOCK_VIRTUAL , dp8393x_watchdog , s ); <nl> s -> regs [ SONIC_SR ] = 0x0004 ; /* only revision recognized by Linux */ <nl>  <nl> - memory_region_init_rom_device (& s -> prom , OBJECT ( dev ), NULL , NULL , <nl> - " dp8393x - prom ", SONIC_PROM_SIZE , NULL ); <nl> + memory_region_init_ram (& s -> prom , OBJECT ( dev ), <nl> + " dp8393x - prom ", SONIC_PROM_SIZE , & local_err ); <nl> + if ( local_err ) { <nl> + error_propagate ( errp , local_err ); <nl> + return ; <nl> + } <nl> + memory_region_set_readonly (& s -> prom , true ); <nl> prom = memory_region_get_ram_ptr (& s -> prom ); <nl> checksum = 0 ; <nl> for ( i = 0 ; i < 6 ; i ++) {
 <nl> static inline bool virtio_access_is_big_endian ( VirtIODevice * vdev ) <nl> { <nl> +# if defined ( TARGET_IS_BIENDIAN ) <nl> + return virtio_is_big_endian ( vdev ); <nl> +# elif defined ( TARGET_WORDS_BIGENDIAN ) <nl> if ( virtio_vdev_has_feature ( vdev , VIRTIO_F_VERSION_1 )) { <nl> /* Devices conforming to VIRTIO 1 . 0 or later are always LE . */ <nl> return false ; <nl> } <nl> -# if defined ( TARGET_IS_BIENDIAN ) <nl> - return virtio_is_big_endian ( vdev ); <nl> -# elif defined ( TARGET_WORDS_BIGENDIAN ) <nl> return true ; <nl> # else <nl> return false ;
int vmstate_register_with_alias_id ( DeviceState * dev , int instance_id , <nl>  <nl> return - 1 ; <nl> } <nl> + g_free ( id ); <nl>  <nl> se -> compat = g_new0 ( CompatEntry , 1 ); <nl> pstrcpy ( se -> compat -> idstr , sizeof ( se -> compat -> idstr ), vmsd -> name );
static AddrRange addrrange_shift ( AddrRange range , int64_t delta ) <nl>  <nl> static bool addrrange_intersects ( AddrRange r1 , AddrRange r2 ) <nl> { <nl> - return ( r1 . start >= r2 . start && r1 . start < r2 . start + r2 . size ) <nl> - || ( r2 . start >= r1 . start && r2 . start < r1 . start + r1 . size ); <nl> + return ( r1 . start >= r2 . start && ( r1 . start - r2 . start ) < r2 . size ) <nl> + || ( r2 . start >= r1 . start && ( r2 . start - r1 . start ) < r1 . size ); <nl> } <nl>  <nl> static AddrRange addrrange_intersection ( AddrRange r1 , AddrRange r2 )
if ( slirp_debug & DBG_CALL ) { fprintf ( dfd , fmt , ## __VA_ARGS__ ); fflush ( dfd ); } <nl> # define dprintf ( fmt , ...) <nl> # endif <nl>  <nl> - static BOOTPClient * get_new_addr ( struct in_addr * paddr ) <nl> + static BOOTPClient * get_new_addr ( struct in_addr * paddr , <nl> + const uint8_t * macaddr ) <nl> { <nl> BOOTPClient * bc ; <nl> int i ; <nl>  <nl> for ( i = 0 ; i < NB_ADDR ; i ++) { <nl> - if (! bootp_clients [ i ]. allocated ) <nl> + bc = & bootp_clients [ i ]; <nl> + if (! bc -> allocated || ! memcmp ( macaddr , bc -> macaddr , 6 )) <nl> goto found ; <nl> } <nl> return NULL ; <nl> static void bootp_reply ( const struct bootp_t * bp ) <nl> } <nl> if (! bc ) { <nl> new_addr : <nl> - bc = get_new_addr (& daddr . sin_addr ); <nl> + bc = get_new_addr (& daddr . sin_addr , client_ethaddr ); <nl> if (! bc ) { <nl> dprintf (" no address left \ n "); <nl> return ;
static int get_physical_address_data ( CPUState * env , <nl> # ifdef DEBUG_MMU <nl> printf (" DMISS at 0x %" PRIx64 "\ n ", address ); <nl> # endif <nl> + env -> dmmuregs [ 6 ] = ( address & ~ 0x1fffULL ) | ( env -> dmmuregs [ 1 ] & 0x1fff ); <nl> env -> exception_index = TT_DMISS ; <nl> return 1 ; <nl> } <nl> static int get_physical_address_code ( CPUState * env , <nl> # ifdef DEBUG_MMU <nl> printf (" TMISS at 0x %" PRIx64 "\ n ", address ); <nl> # endif <nl> + env -> immuregs [ 6 ] = ( address & ~ 0x1fffULL ) | ( env -> dmmuregs [ 1 ] & 0x1fff ); <nl> env -> exception_index = TT_TMISS ; <nl> return 1 ; <nl> }
static int blkverify_open ( BlockDriverState * bs , QDict * options , int flags , <nl>  <nl> ret = 0 ; <nl> fail : <nl> + qemu_opts_del ( opts ); <nl> return ret ; <nl> } <nl> 
static void stm32f2xx_timer_write ( void * opaque , hwaddr offset , <nl> return ; <nl> case TIM_PSC : <nl> timer_val = stm32f2xx_ns_to_ticks ( s , now ) - s -> tick_offset ; <nl> - s -> tim_psc = value ; <nl> + s -> tim_psc = value & 0xFFFF ; <nl> value = timer_val ; <nl> break ; <nl> case TIM_CNT :
static void spapr_phb_realize ( DeviceState * dev , Error ** errp ) <nl> } <nl> # endif <nl>  <nl> - memory_region_init_io (& sphb -> msiwindow , NULL , & spapr_msi_ops , spapr , <nl> + memory_region_init_io (& sphb -> msiwindow , OBJECT ( sphb ), & spapr_msi_ops , spapr , <nl> " msi ", msi_window_size ); <nl> memory_region_add_subregion (& sphb -> iommu_root , SPAPR_PCI_MSI_WINDOW , <nl> & sphb -> msiwindow );
static int find_and_clear_dirty_height ( VncState * vs , <nl> static int vnc_update_client ( VncState * vs , int has_dirty , bool sync ) <nl> { <nl> vs -> has_dirty += has_dirty ; <nl> - if ( vs -> need_update && vs -> ioc != NULL ) { <nl> + if ( vs -> need_update && ! vs -> disconnecting ) { <nl> VncDisplay * vd = vs -> vd ; <nl> VncJob * job ; <nl> int y ;
static void omap_rtc_write ( void * opaque , hwaddr addr , <nl> s -> ti += ti [ 1 ]; <nl> } else { <nl> /* A less accurate version */ <nl> - s -> ti -= ( s -> current_tm . tm_year % 100 ) * 31536000 ; <nl> - s -> ti += from_bcd ( value ) * 31536000 ; <nl> + s -> ti -= ( time_t )( s -> current_tm . tm_year % 100 ) * 31536000 ; <nl> + s -> ti += ( time_t ) from_bcd ( value ) * 31536000 ; <nl> } <nl> return ; <nl> 
static void * subpage_init ( target_phys_addr_t base , uint32_t * phys , <nl> need_subpage = 1 ; \ <nl> } \ <nl> \ <nl> - if ( end_addr - addr > TARGET_PAGE_SIZE ) \ <nl> + if (( start_addr + orig_size ) - addr >= TARGET_PAGE_SIZE ) \ <nl> end_addr2 = TARGET_PAGE_SIZE - 1 ; \ <nl> else { \ <nl> end_addr2 = ( start_addr + orig_size - 1 ) & ~ TARGET_PAGE_MASK ; \ <nl> void cpu_register_physical_memory ( target_phys_addr_t start_addr , <nl> unsigned long orig_size = size ; <nl> void * subpage ; <nl>  <nl> - end_addr = start_addr + ( target_phys_addr_t ) size ; <nl> size = ( size + TARGET_PAGE_SIZE - 1 ) & TARGET_PAGE_MASK ; <nl> - for ( addr = start_addr ; addr < end_addr ; addr += TARGET_PAGE_SIZE ) { <nl> + end_addr = start_addr + ( target_phys_addr_t ) size ; <nl> + for ( addr = start_addr ; addr != end_addr ; addr += TARGET_PAGE_SIZE ) { <nl> p = phys_page_find ( addr >> TARGET_PAGE_BITS ); <nl> if ( p && p -> phys_offset != IO_MEM_UNASSIGNED ) { <nl> unsigned long orig_memory = p -> phys_offset ;
static GIOStatus ga_channel_write ( GAChannel * c , const char * buf , size_t size , <nl> GIOStatus ga_channel_write_all ( GAChannel * c , const char * buf , size_t size ) <nl> { <nl> GIOStatus status = G_IO_STATUS_NORMAL ; <nl> - size_t count ; <nl> + size_t count = 0 ; <nl>  <nl> while ( size ) { <nl> status = ga_channel_write ( c , buf , size , & count );
static void spapr_core_pre_plug ( HotplugHandler * hotplug_dev , DeviceState * dev , <nl> * total vcpus not a multiple of threads - per - core . <nl> */ <nl> if ( mc -> has_hotpluggable_cpus && ( cc -> nr_threads != smp_threads )) { <nl> - error_setg ( errp , " invalid nr - threads % d , must be % d ", <nl> + error_setg (& local_err , " invalid nr - threads % d , must be % d ", <nl> cc -> nr_threads , smp_threads ); <nl> - return ; <nl> + goto out ; <nl> } <nl>  <nl> core_slot = spapr_find_cpu_slot ( MACHINE ( hotplug_dev ), cc -> core_id , & index );
PCIBus * pci_register_bus ( pci_set_irq_fn set_irq , pci_map_irq_fn map_irq , <nl> bus -> irq_opaque = pic ; <nl> bus -> devfn_min = devfn_min ; <nl> bus -> nirq = nirq ; <nl> + bus -> next = first_bus ; <nl> first_bus = bus ; <nl> register_savevm (" PCIBUS ", nbus ++, 1 , pcibus_save , pcibus_load , bus ); <nl> return bus ;
connect_to_qemu ( <nl> const char * port <nl> ) { <nl> struct addrinfo hints ; <nl> - struct addrinfo * server ; <nl> + struct addrinfo * server = NULL ; <nl> int ret , sock ; <nl>  <nl> sock = socket ( AF_INET , SOCK_STREAM , 0 ); <nl> connect_to_qemu ( <nl> if ( verbose ) { <nl> printf (" Connected ( sizeof Header =% zd )!\ n ", sizeof ( VSCMsgHeader )); <nl> } <nl> + <nl> + freeaddrinfo ( server ); <nl> return sock ; <nl>  <nl> cleanup_socket : <nl> + if ( server ) { <nl> + freeaddrinfo ( server ); <nl> + } <nl> closesocket ( sock ); <nl> return - 1 ; <nl> }
static void mptsas_fetch_request ( MPTSASState * s ) <nl> hwaddr addr ; <nl> int size ; <nl>  <nl> - if ( s -> state != MPI_IOC_STATE_OPERATIONAL ) { <nl> - mptsas_set_fault ( s , MPI_IOCSTATUS_INVALID_STATE ); <nl> - return ; <nl> - } <nl> - <nl> /* Read the message header from the guest first . */ <nl> addr = s -> host_mfa_high_addr | MPTSAS_FIFO_GET ( s , request_post ); <nl> pci_dma_read ( pci , addr , req , sizeof ( hdr )); <nl> static void mptsas_fetch_requests ( void * opaque ) <nl> { <nl> MPTSASState * s = opaque ; <nl>  <nl> + if ( s -> state != MPI_IOC_STATE_OPERATIONAL ) { <nl> + mptsas_set_fault ( s , MPI_IOCSTATUS_INVALID_STATE ); <nl> + return ; <nl> + } <nl> while (! MPTSAS_FIFO_EMPTY ( s , request_post )) { <nl> mptsas_fetch_request ( s ); <nl> }
struct PhysPageEntry { <nl> # define PHYS_MAP_NODE_NIL ((( uint32_t )~ 0 ) >> 6 ) <nl>  <nl> /* Size of the L2 ( and L3 , etc ) page tables . */ <nl> -# define ADDR_SPACE_BITS TARGET_PHYS_ADDR_SPACE_BITS <nl> +# define ADDR_SPACE_BITS 64 <nl>  <nl> # define P_L2_BITS 10 <nl> # define P_L2_SIZE ( 1 << P_L2_BITS ) <nl> static void memory_map_init ( void ) <nl> { <nl> system_memory = g_malloc ( sizeof (* system_memory )); <nl>  <nl> - assert ( ADDR_SPACE_BITS <= 64 ); <nl> - <nl> - memory_region_init ( system_memory , NULL , " system ", <nl> - ADDR_SPACE_BITS == 64 ? <nl> - UINT64_MAX : ( 0x1ULL << ADDR_SPACE_BITS )); <nl> + memory_region_init ( system_memory , NULL , " system ", UINT64_MAX ); <nl> address_space_init (& address_space_memory , system_memory , " memory "); <nl>  <nl> system_io = g_malloc ( sizeof (* system_io ));
static int exynos4210_combiner_init ( SysBusDevice * sbd ) <nl> qdev_init_gpio_in ( dev , exynos4210_combiner_handler , IIC_NIRQ ); <nl>  <nl> /* Connect SysBusDev irqs to device specific irqs */ <nl> - for ( i = 0 ; i < IIC_NIRQ ; i ++) { <nl> + for ( i = 0 ; i < IIC_NGRP ; i ++) { <nl> sysbus_init_irq ( sbd , & s -> output_irq [ i ]); <nl> } <nl> 
static void fsl_imx25_class_init ( ObjectClass * oc , void * data ) <nl> DeviceClass * dc = DEVICE_CLASS ( oc ); <nl>  <nl> dc -> realize = fsl_imx25_realize ; <nl> - <nl> dc -> desc = " i . MX25 SOC "; <nl> + /* <nl> + * Reason : uses serial_hds in realize and the imx25 board does not <nl> + * support multiple CPUs <nl> + */ <nl> + dc -> user_creatable = false ; <nl> } <nl>  <nl> static const TypeInfo fsl_imx25_type_info = {
static void qdict_crumple_test_recursive ( void ) <nl>  <nl> vnc = qdict_get_qdict ( dst , " vnc "); <nl> g_assert ( vnc ); <nl> + g_assert_cmpint ( qdict_size ( vnc ), ==, 3 ); <nl>  <nl> listen = qdict_get_qdict ( vnc , " listen "); <nl> g_assert ( listen ); <nl> + g_assert_cmpint ( qdict_size ( listen ), ==, 2 ); <nl> g_assert_cmpstr (" 127 . 0 . 0 . 1 ", ==, qdict_get_str ( listen , " addr ")); <nl> g_assert_cmpstr (" 5901 ", ==, qdict_get_str ( listen , " port ")); <nl>  <nl> acl = qdict_get_qdict ( vnc , " acl "); <nl> g_assert ( acl ); <nl> + g_assert_cmpint ( qdict_size ( acl ), ==, 3 ); <nl>  <nl> rules = qdict_get_qlist ( acl , " rules "); <nl> g_assert ( rules ); <nl> g_assert_cmpint ( qlist_size ( rules ), ==, 2 ); <nl>  <nl> rule = qobject_to_qdict ( qlist_pop ( rules )); <nl> + g_assert ( rule ); <nl> g_assert_cmpint ( qdict_size ( rule ), ==, 2 ); <nl> g_assert_cmpstr (" fred ", ==, qdict_get_str ( rule , " match ")); <nl> g_assert_cmpstr (" allow ", ==, qdict_get_str ( rule , " policy ")); <nl> QDECREF ( rule ); <nl>  <nl> rule = qobject_to_qdict ( qlist_pop ( rules )); <nl> + g_assert ( rule ); <nl> g_assert_cmpint ( qdict_size ( rule ), ==, 2 ); <nl> g_assert_cmpstr (" bob ", ==, qdict_get_str ( rule , " match ")); <nl> g_assert_cmpstr (" deny ", ==, qdict_get_str ( rule , " policy "));
static int nbd_errno_to_system_errno ( int err ) <nl> return ENOMEM ; <nl> case NBD_ENOSPC : <nl> return ENOSPC ; <nl> - case NBD_EINVAL : <nl> default : <nl> + TRACE (" Squashing unexpected error % d to EINVAL ", err ); <nl> + /* fallthrough */ <nl> + case NBD_EINVAL : <nl> return EINVAL ; <nl> } <nl> }
# ifndef BITMAP_H <nl> # define BITMAP_H <nl>  <nl> -# include " qemu - common . h " <nl> +# include < glib . h > <nl> +# include < string . h > <nl> +# include < stdlib . h > <nl> + <nl> +# include " qemu / osdep . h " <nl> # include " qemu / bitops . h " <nl>  <nl> /*
static void vhost_scsi_realize ( DeviceState * dev , Error ** errp ) <nl> s -> dev . nvqs = VHOST_SCSI_VQ_NUM_FIXED + vs -> conf . num_queues ; <nl> s -> dev . vqs = g_new ( struct vhost_virtqueue , s -> dev . nvqs ); <nl> s -> dev . vq_index = 0 ; <nl> + s -> dev . backend_features = 0 ; <nl>  <nl> ret = vhost_dev_init (& s -> dev , ( void *)( uintptr_t ) vhostfd , <nl> VHOST_BACKEND_TYPE_KERNEL , true ); <nl> static void vhost_scsi_realize ( DeviceState * dev , Error ** errp ) <nl> strerror (- ret )); <nl> return ; <nl> } <nl> - s -> dev . backend_features = 0 ; <nl>  <nl> error_setg (& s -> migration_blocker , <nl> " vhost - scsi does not support migration ");
static int pci_unregister_device ( DeviceState * dev ) <nl>  <nl> pci_unregister_io_regions ( pci_dev ); <nl> pci_del_option_rom ( pci_dev ); <nl> + qemu_free ( pci_dev -> romfile ); <nl> do_pci_unregister_device ( pci_dev ); <nl> return 0 ; <nl> }
static void handle_qmp_command ( JSONMessageParser * parser , GQueue * tokens ) <nl> QDict * qdict = NULL ; <nl> Monitor * mon = cur_mon ; <nl> Error * err = NULL ; <nl> + QString * req_json ; <nl>  <nl> req = json_parser_parse_err ( tokens , NULL , & err ); <nl> if (! req && ! err ) { <nl> static void handle_qmp_command ( JSONMessageParser * parser , GQueue * tokens ) <nl> qdict_del ( qdict , " id "); <nl> } /* else will fail qmp_dispatch () */ <nl>  <nl> + req_json = qobject_to_json ( req ); <nl> + trace_handle_qmp_command ( mon , qstring_get_str ( req_json )); <nl> + qobject_decref ( QOBJECT ( req_json )); <nl> + <nl> rsp = qmp_dispatch ( cur_mon -> qmp . commands , req ); <nl>  <nl> if ( mon -> qmp . commands == & qmp_cap_negotiation_commands ) {
void ide_exec_cmd ( IDEBus * bus , uint32_t val ) <nl> lba48 = 1 ; <nl> /* fall through */ <nl> case WIN_READ_NATIVE_MAX : <nl> + /* Refuse if no sectors are addressable ( e . g . medium not inserted ) */ <nl> + if ( s -> nb_sectors == 0 ) { <nl> + goto abort_cmd ; <nl> + } <nl> ide_cmd_lba48_transform ( s , lba48 ); <nl> ide_set_sector ( s , s -> nb_sectors - 1 ); <nl> s -> status = READY_STAT | SEEK_STAT ;
static void curses_refresh ( DisplayChangeListener * dcl ) <nl> qemu_input_event_send_key_delay ( 0 ); <nl> } <nl> } else { <nl> - keysym = curses2qemu [ chr ]; <nl> + keysym = - 1 ; <nl> + if ( chr < CURSES_KEYS ) { <nl> + keysym = curses2qemu [ chr ]; <nl> + } <nl> if ( keysym == - 1 ) <nl> keysym = chr ; <nl> 
DriveInfo * drive_init ( QemuOpts * all_opts , BlockInterfaceType block_default_type ) <nl>  <nl> /* Actual block device init : Functionality shared with blockdev - add */ <nl> dinfo = blockdev_init ( filename , bs_opts , & local_err ); <nl> + bs_opts = NULL ; <nl> if ( dinfo == NULL ) { <nl> if ( local_err ) { <nl> error_report ("% s ", error_get_pretty ( local_err )); <nl> DriveInfo * drive_init ( QemuOpts * all_opts , BlockInterfaceType block_default_type ) <nl>  <nl> fail : <nl> qemu_opts_del ( legacy_opts ); <nl> + QDECREF ( bs_opts ); <nl> return dinfo ; <nl> } <nl> 
void cmos_set_s3_resume ( void ) <nl> } <nl>  <nl> static QEMUMachine pc_machine = { <nl> - . name = " pc ", <nl> + . name = " pc - 0 . 11 ", <nl> + . alias = " pc ", <nl> . desc = " Standard PC ", <nl> . init = pc_init_pci , <nl> . max_cpus = 255 ,
static void ccid_handle_data ( USBDevice * dev , USBPacket * p ) <nl> " handle_data : int_in : notify_slot_change % X , " <nl> " requested len % zd \ n ", <nl> s -> bmSlotICCState , p -> iov . size ); <nl> + } else { <nl> + p -> status = USB_RET_NAK ; <nl> } <nl> break ; <nl> default :
static int kvm_physical_sync_dirty_bitmap ( MemoryRegionSection * section ) <nl> { <nl> KVMState * s = kvm_state ; <nl> unsigned long size , allocated_size = 0 ; <nl> - KVMDirtyLog d ; <nl> + KVMDirtyLog d = {}; <nl> KVMSlot * mem ; <nl> int ret = 0 ; <nl> hwaddr start_addr = section -> offset_within_address_space ;
 <nl> # elif defined ( USE_MPCxxx ) <nl>  <nl> -# define MAX_CPU 2 <nl> +# define MAX_CPU 15 <nl> # define MAX_IRQ 128 <nl> # define MAX_DBL 0 <nl> # define MAX_MBX 0 <nl> static inline void write_IRQreg ( openpic_t * opp , int n_IRQ , <nl> break ; <nl> case IRQ_IDE : <nl> tmp = val & 0xC0000000 ; <nl> - tmp |= val & (( 1 << MAX_CPU ) - 1 ); <nl> + tmp |= val & (( 1ULL << MAX_CPU ) - 1 ); <nl> opp -> src [ n_IRQ ]. ide = tmp ; <nl> DPRINTF (" Set IDE % d to 0x % 08x \ n ", n_IRQ , opp -> src [ n_IRQ ]. ide ); <nl> break ; <nl> static void mpic_reset ( void * opaque ) <nl>  <nl> mpp -> glbc = 0x80000000 ; <nl> /* Initialise controller registers */ <nl> - mpp -> frep = 0x004f0002 ; <nl> + mpp -> frep = 0x004f0002 | (( mpp -> nb_cpus - 1 ) << 8 ); <nl> mpp -> veni = VENI ; <nl> mpp -> pint = 0x00000000 ; <nl> mpp -> spve = 0x0000FFFF ; <nl> qemu_irq * mpic_init ( target_phys_addr_t base , int nb_cpus , <nl> { mpic_cpu_read , mpic_cpu_write , MPIC_CPU_REG_START , MPIC_CPU_REG_SIZE }, <nl> }; <nl>  <nl> - /* XXX : for now , only one CPU is supported */ <nl> - if ( nb_cpus != 1 ) <nl> - return NULL ; <nl> - <nl> mpp = g_malloc0 ( sizeof ( openpic_t )); <nl>  <nl> for ( i = 0 ; i < sizeof ( list )/ sizeof ( list [ 0 ]); i ++) {
static int img_snapshot ( int argc , char ** argv ) <nl> static int img_rebase ( int argc , char ** argv ) <nl> { <nl> BlockBackend * blk = NULL , * blk_old_backing = NULL , * blk_new_backing = NULL ; <nl> + uint8_t * buf_old = NULL ; <nl> + uint8_t * buf_new = NULL ; <nl> BlockDriverState * bs = NULL ; <nl> char * filename ; <nl> const char * fmt , * cache , * src_cache , * out_basefmt , * out_baseimg ; <nl> static int img_rebase ( int argc , char ** argv ) <nl> int64_t new_backing_num_sectors = 0 ; <nl> uint64_t sector ; <nl> int n ; <nl> - uint8_t * buf_old ; <nl> - uint8_t * buf_new ; <nl> float local_progress = 0 ; <nl>  <nl> buf_old = blk_blockalign ( blk , IO_BUF_SIZE ); <nl> static int img_rebase ( int argc , char ** argv ) <nl> } <nl> qemu_progress_print ( local_progress , 100 ); <nl> } <nl> - <nl> - qemu_vfree ( buf_old ); <nl> - qemu_vfree ( buf_new ); <nl> } <nl>  <nl> /* <nl> out : <nl> blk_unref ( blk_old_backing ); <nl> blk_unref ( blk_new_backing ); <nl> } <nl> + qemu_vfree ( buf_old ); <nl> + qemu_vfree ( buf_new ); <nl>  <nl> blk_unref ( blk ); <nl> if ( ret ) {
BlockStatsList * qmp_query_blockstats ( Error ** errp ) <nl>  <nl> while (( bs = bdrv_next ( bs ))) { <nl> BlockStatsList * info = g_malloc0 ( sizeof (* info )); <nl> + AioContext * ctx = bdrv_get_aio_context ( bs ); <nl> + <nl> + aio_context_acquire ( ctx ); <nl> info -> value = bdrv_query_stats ( bs ); <nl> + aio_context_release ( ctx ); <nl>  <nl> * p_next = info ; <nl> p_next = & info -> next ;
static void gen_rp_realize ( DeviceState * dev , Error ** errp ) <nl> PCIDevice * d = PCI_DEVICE ( dev ); <nl> GenPCIERootPort * grp = GEN_PCIE_ROOT_PORT ( d ); <nl> PCIERootPortClass * rpc = PCIE_ROOT_PORT_GET_CLASS ( d ); <nl> + Error * local_err = NULL ; <nl>  <nl> - rpc -> parent_realize ( dev , errp ); <nl> + rpc -> parent_realize ( dev , & local_err ); <nl> + if ( local_err ) { <nl> + error_propagate ( errp , local_err ); <nl> + return ; <nl> + } <nl>  <nl> int rc = pci_bridge_qemu_reserve_cap_init ( d , 0 , grp -> bus_reserve , <nl> grp -> io_reserve , grp -> mem_reserve , grp -> pref32_reserve ,
typedef struct QObject { <nl>  <nl> /* High - level interface for qobject_decref () */ <nl> # define QDECREF ( obj ) \ <nl> - qobject_decref ( QOBJECT ( obj )) <nl> + qobject_decref ( obj ? QOBJECT ( obj ) : NULL ) <nl>  <nl> /* Initialize an object to default values */ <nl> # define QOBJECT_INIT ( obj , qtype_type ) \
static void tcg_out_qemu_st ( TCGContext * s , const TCGArg * args , int opc ) <nl> # else <nl> tcg_out_mov ( s , TCG_TYPE_I32 , 3 , addr_reg2 ); <nl> tcg_out_mov ( s , TCG_TYPE_I32 , 4 , addr_reg ); <nl> -# ifdef TCG_TARGET_CALL_ALIGN_ARGS <nl> ir = 5 ; <nl> -# else <nl> - ir = 4 ; <nl> -# endif <nl> # endif <nl>  <nl> switch ( opc ) {
static void add_machine_test_cases ( void ) <nl> const QListEntry * p ; <nl> QObject * qobj ; <nl> QString * qstr ; <nl> - const char * mname , * path ; <nl> + const char * mname ; <nl>  <nl> qtest_start ("- machine none "); <nl> response = qmp ("{ ' execute ': ' query - machines ' }"); <nl> static void add_machine_test_cases ( void ) <nl> g_assert ( qstr ); <nl> mname = qstring_get_str ( qstr ); <nl> if (! is_blacklisted ( arch , mname )) { <nl> - path = g_strdup_printf (" qom /% s ", mname ); <nl> + char * path = g_strdup_printf (" qom /% s ", mname ); <nl> qtest_add_data_func ( path , g_strdup ( mname ), test_machine ); <nl> + g_free ( path ); <nl> } <nl> } <nl> 
static void print_block_info ( Monitor * mon , BlockInfo * info , <nl> inserted -> iops_size ); <nl> } <nl>  <nl> - if ( verbose ) { <nl> + /* TODO : inserted -> image should never be null */ <nl> + if ( verbose && inserted -> image ) { <nl> monitor_printf ( mon , "\ nImages :\ n "); <nl> image_info = inserted -> image ; <nl> while ( 1 ) {
static void do_sdl_resize ( int new_width , int new_height , int bpp ) <nl>  <nl> // printf (" resizing to % d % d \ n ", w , h ); <nl>  <nl> - flags = SDL_HWSURFACE | SDL_ASYNCBLIT | SDL_HWACCEL | SDL_RESIZABLE ; <nl> - if ( gui_fullscreen ) <nl> + flags = SDL_HWSURFACE | SDL_ASYNCBLIT | SDL_HWACCEL ; <nl> + if ( gui_fullscreen ) { <nl> flags |= SDL_FULLSCREEN ; <nl> + } else { <nl> + flags |= SDL_RESIZABLE ; <nl> + } <nl> if ( gui_noframe ) <nl> flags |= SDL_NOFRAME ; <nl> 
static void numa_add ( const char * optarg ) <nl>  <nl> value = endvalue = 0ULL ; <nl>  <nl> - optarg = get_opt_name ( option , 128 , optarg , ',') + 1 ; <nl> + optarg = get_opt_name ( option , 128 , optarg , ','); <nl> + if (* optarg == ',') { <nl> + optarg ++; <nl> + } <nl> if (! strcmp ( option , " node ")) { <nl> if ( get_param_value ( option , 128 , " nodeid ", optarg ) == 0 ) { <nl> nodenr = nb_numa_nodes ;
static gboolean fd_trampoline ( GIOChannel * chan , GIOCondition cond , gpointer opaq <nl> { <nl> IOTrampoline * tramp = opaque ; <nl>  <nl> - if ( tramp -> opaque == NULL ) { <nl> - return FALSE ; <nl> - } <nl> - <nl> if (( cond & G_IO_IN ) && tramp -> fd_read ) { <nl> tramp -> fd_read ( tramp -> opaque ); <nl> } <nl> int qemu_set_fd_handler ( int fd , <nl> if ( tramp -> tag != 0 ) { <nl> g_io_channel_unref ( tramp -> chan ); <nl> g_source_remove ( tramp -> tag ); <nl> + tramp -> tag = 0 ; <nl> } <nl>  <nl> - if ( opaque ) { <nl> + if ( fd_read || fd_write || opaque ) { <nl> GIOCondition cond = 0 ; <nl>  <nl> tramp -> fd_read = fd_read ;
# include " qapi / string - input - visitor . h " <nl> # include " qapi / string - output - visitor . h " <nl> # include " qapi / qmp / qerror . h " <nl> +# include " trace . h " <nl>  <nl> /* TODO : replace QObject with a simpler visitor to avoid a dependency <nl> * of the QOM core on QObject ? */ <nl> Object * object_dynamic_cast_assert ( Object * obj , const char * typename , <nl> { <nl> Object * inst ; <nl>  <nl> + trace_object_dynamic_cast_assert ( obj ? obj -> class -> type -> name : "( null )", <nl> + typename , file , line , func ); <nl> + <nl> inst = object_dynamic_cast ( obj , typename ); <nl>  <nl> if (! inst && obj ) { <nl> ObjectClass * object_class_dynamic_cast_assert ( ObjectClass * class , <nl> const char * file , int line , <nl> const char * func ) <nl> { <nl> - ObjectClass * ret = object_class_dynamic_cast ( class , typename ); <nl> + ObjectClass * ret ; <nl> + <nl> + trace_object_class_dynamic_cast_assert ( class ? class -> type -> name : "( null )", <nl> + typename , file , line , func ); <nl>  <nl> + ret = object_class_dynamic_cast ( class , typename ); <nl> if (! ret && class ) { <nl> fprintf ( stderr , "% s :% d :% s : Object % p is not an instance of type % s \ n ", <nl> file , line , func , class , typename );
static void grlib_gptimer_enable ( GPTimer * timer ) <nl> /* ptimer is triggered when the counter reach 0 but GPTimer is triggered at <nl> underflow . Set count + 1 to simulate the GPTimer behavior . */ <nl>  <nl> - trace_grlib_gptimer_enable ( timer -> id , timer -> counter + 1 ); <nl> + trace_grlib_gptimer_enable ( timer -> id , timer -> counter ); <nl>  <nl> - ptimer_set_count ( timer -> ptimer , timer -> counter + 1 ); <nl> + ptimer_set_count ( timer -> ptimer , ( uint64_t ) timer -> counter + 1 ); <nl> ptimer_run ( timer -> ptimer , 1 ); <nl> } <nl> 
# include " block / block . h " <nl> # include " qemu / queue . h " <nl> # include " qemu / sockets . h " <nl> -# ifdef CONFIG_EPOLL <nl> +# ifdef CONFIG_EPOLL_CREATE1 <nl> # include < sys / epoll . h > <nl> # endif <nl>  <nl> struct AioHandler <nl> QLIST_ENTRY ( AioHandler ) node ; <nl> }; <nl>  <nl> -# ifdef CONFIG_EPOLL <nl> +# ifdef CONFIG_EPOLL_CREATE1 <nl>  <nl> /* The fd number threashold to switch to epoll */ <nl> # define EPOLL_ENABLE_THRESHOLD 64 <nl> bool aio_poll ( AioContext * ctx , bool blocking ) <nl>  <nl> void aio_context_setup ( AioContext * ctx , Error ** errp ) <nl> { <nl> -# ifdef CONFIG_EPOLL <nl> +# ifdef CONFIG_EPOLL_CREATE1 <nl> assert (! ctx -> epollfd ); <nl> ctx -> epollfd = epoll_create1 ( EPOLL_CLOEXEC ); <nl> if ( ctx -> epollfd == - 1 ) {
static coroutine_fn int qcow2_handle_l2meta ( BlockDriverState * bs , <nl> while ( l2meta != NULL ) { <nl> QCowL2Meta * next ; <nl>  <nl> - if (! ret && link_l2 ) { <nl> + if ( link_l2 ) { <nl> ret = qcow2_alloc_cluster_link_l2 ( bs , l2meta ); <nl> if ( ret ) { <nl> goto out ;
* TODO lift the restriction <nl> * ' i ' 32 bit integer <nl> * ' l ' target long ( 32 or 64 bit ) <nl> - * ' M ' just like ' l ', except in user mode the value is <nl> - * multiplied by 2 ^ 20 ( think Mebibyte ) <nl> + * ' M ' Non - negative target long ( 32 or 64 bit ), in user mode the <nl> + * value is multiplied by 2 ^ 20 ( think Mebibyte ) <nl> * ' o ' octets ( aka bytes ) <nl> * user mode accepts an optional T , t , G , g , M , m , K , k <nl> * suffix , which multiplies the value by 2 ^ 40 for <nl> static const mon_cmd_t * monitor_parse_command ( Monitor * mon , <nl> monitor_printf ( mon , " integer is for 32 - bit values \ n "); <nl> goto fail ; <nl> } else if ( c == ' M ') { <nl> + if ( val < 0 ) { <nl> + monitor_printf ( mon , " enter a positive value \ n "); <nl> + goto fail ; <nl> + } <nl> val <<= 20 ; <nl> } <nl> qdict_put ( qdict , key , qint_from_int ( val ));
static int kvm_has_msr_star ( CPUState * env ) <nl> * save / restore */ <nl> msr_list . nmsrs = 0 ; <nl> ret = kvm_ioctl ( env -> kvm_state , KVM_GET_MSR_INDEX_LIST , & msr_list ); <nl> - if ( ret < 0 ) <nl> + if ( ret < 0 && ret != - E2BIG ) { <nl> return 0 ; <nl> - <nl> + } <nl> /* Old kernel modules had a bug and could write beyond the provided <nl> memory . Allocate at least a safe amount of 1K . */ <nl> kvm_msr_list = qemu_mallocz ( MAX ( 1024 , sizeof ( msr_list ) +
static int connect_to_ssh ( BDRVSSHState * s , QDict * options , <nl> /* Open the socket and connect . */ <nl> s -> sock = inet_connect ( s -> hostport , errp ); <nl> if ( s -> sock < 0 ) { <nl> - ret = - errno ; <nl> + ret = - EIO ; <nl> goto err ; <nl> } <nl> 
int nbd_client_co_pwritev ( BlockDriverState * bs , uint64_t offset , <nl> . len = bytes , <nl> }; <nl>  <nl> + assert (!( client -> info . flags & NBD_FLAG_READ_ONLY )); <nl> if ( flags & BDRV_REQ_FUA ) { <nl> assert ( client -> info . flags & NBD_FLAG_SEND_FUA ); <nl> request . flags |= NBD_CMD_FLAG_FUA ; <nl> int nbd_client_co_pwrite_zeroes ( BlockDriverState * bs , int64_t offset , <nl> . len = bytes , <nl> }; <nl>  <nl> + assert (!( client -> info . flags & NBD_FLAG_READ_ONLY )); <nl> if (!( client -> info . flags & NBD_FLAG_SEND_WRITE_ZEROES )) { <nl> return - ENOTSUP ; <nl> } <nl> int nbd_client_co_pdiscard ( BlockDriverState * bs , int64_t offset , int bytes ) <nl> . len = bytes , <nl> }; <nl>  <nl> + assert (!( client -> info . flags & NBD_FLAG_READ_ONLY )); <nl> if (!( client -> info . flags & NBD_FLAG_SEND_TRIM )) { <nl> return 0 ; <nl> } <nl> int nbd_client_init ( BlockDriverState * bs , <nl> logout (" Failed to negotiate with the NBD server \ n "); <nl> return ret ; <nl> } <nl> + if ( client -> info . flags & NBD_FLAG_READ_ONLY && <nl> + ! bdrv_is_read_only ( bs )) { <nl> + error_setg ( errp , <nl> + " request for write access conflicts with read - only export "); <nl> + return - EACCES ; <nl> + } <nl> if ( client -> info . flags & NBD_FLAG_SEND_FUA ) { <nl> bs -> supported_write_flags = BDRV_REQ_FUA ; <nl> bs -> supported_zero_flags |= BDRV_REQ_FUA ;
if_start ( void ) <nl> /* Encapsulate the packet for sending */ <nl> if_encap ( ifm -> m_data , ifm -> m_len ); <nl>  <nl> + m_free ( ifm ); <nl> + <nl> if ( if_queued ) <nl> goto again ; <nl> }
static struct scsi_task * iscsi_do_inquiry ( struct iscsi_context * iscsi , int lun , <nl> * inq = scsi_datain_unmarshall ( task ); <nl> if (* inq == NULL ) { <nl> error_setg ( errp , " iSCSI : failed to unmarshall inquiry datain blob "); <nl> - goto fail ; <nl> + goto fail_with_err ; <nl> } <nl>  <nl> return task ; <nl>  <nl> fail : <nl> - if (! error_is_set ( errp )) { <nl> - error_setg ( errp , " iSCSI : Inquiry command failed : % s ", <nl> - iscsi_get_error ( iscsi )); <nl> - } <nl> + error_setg ( errp , " iSCSI : Inquiry command failed : % s ", <nl> + iscsi_get_error ( iscsi )); <nl> + fail_with_err : <nl> if ( task != NULL ) { <nl> scsi_free_scsi_task ( task ); <nl> }
static inline void gdb_continue ( GDBState * s ) <nl> # ifdef CONFIG_USER_ONLY <nl> s -> running_state = 1 ; <nl> # else <nl> - if ( runstate_check ( RUN_STATE_DEBUG )) { <nl> + if (! runstate_needs_reset ()) { <nl> vm_start (); <nl> } <nl> # endif
int kvm_cpu_exec ( CPUState * cpu ) <nl> qemu_system_reset_request (); <nl> ret = EXCP_INTERRUPT ; <nl> break ; <nl> + case KVM_SYSTEM_EVENT_CRASH : <nl> + qemu_mutex_lock_iothread (); <nl> + qemu_system_guest_panicked (); <nl> + qemu_mutex_unlock_iothread (); <nl> + ret = 0 ; <nl> + break ; <nl> default : <nl> DPRINTF (" kvm_arch_handle_exit \ n "); <nl> ret = kvm_arch_handle_exit ( cpu , run );
static int cpudef_setfield ( const char * name , const char * str , void * opaque ) <nl> int err = 0 ; <nl>  <nl> if (! strcmp ( name , " name ")) { <nl> + g_free (( void *) def -> name ); <nl> def -> name = g_strdup ( str ); <nl> } else if (! strcmp ( name , " model_id ")) { <nl> strncpy ( def -> model_id , str , sizeof ( def -> model_id ));
int nbd_client ( int fd ) <nl> TRACE (" Doing NBD loop "); <nl>  <nl> ret = ioctl ( fd , NBD_DO_IT ); <nl> + if ( ret == - 1 && errno == EPIPE ) { <nl> + /* NBD_DO_IT normally returns EPIPE when someone has disconnected <nl> + * the socket via NBD_DISCONNECT . We do not want to return 1 in <nl> + * that case . <nl> + */ <nl> + ret = 0 ; <nl> + } <nl> serrno = errno ; <nl>  <nl> TRACE (" NBD loop returned % d : % s ", ret , strerror ( serrno ));
static int usb_device_post_load ( void * opaque , int version_id ) <nl> } else { <nl> dev -> attached = 1 ; <nl> } <nl> - if ( dev -> setup_index >= sizeof ( dev -> data_buf ) || <nl> + if ( dev -> setup_index < 0 || <nl> + dev -> setup_len < 0 || <nl> + dev -> setup_index >= sizeof ( dev -> data_buf ) || <nl> dev -> setup_len >= sizeof ( dev -> data_buf )) { <nl> return - EINVAL ; <nl> }
static void qxl_hw_text_update ( void * opaque , console_ch_t * chardata ) <nl>  <nl> static void qxl_dirty_surfaces ( PCIQXLDevice * qxl ) <nl> { <nl> - intptr_t vram_start ; <nl> + uintptr_t vram_start ; <nl> int i ; <nl>  <nl> if ( qxl -> mode != QXL_MODE_NATIVE && qxl -> mode != QXL_MODE_COMPAT ) { <nl> static void qxl_dirty_surfaces ( PCIQXLDevice * qxl ) <nl> qxl_set_dirty (& qxl -> vga . vram , qxl -> shadow_rom . draw_area_offset , <nl> qxl -> shadow_rom . surface0_area_size ); <nl>  <nl> - vram_start = ( intptr_t ) memory_region_get_ram_ptr (& qxl -> vram_bar ); <nl> + vram_start = ( uintptr_t ) memory_region_get_ram_ptr (& qxl -> vram_bar ); <nl>  <nl> /* dirty the off - screen surfaces */ <nl> for ( i = 0 ; i < qxl -> ssd . num_surfaces ; i ++) {
int load_snapshot ( const char * name , Error ** errp ) <nl>  <nl> aio_context_acquire ( aio_context ); <nl> ret = qemu_loadvm_state ( f ); <nl> - qemu_fclose ( f ); <nl> aio_context_release ( aio_context ); <nl>  <nl> migration_incoming_state_destroy ();
static void term_show_prompt ( void ) <nl> static void term_print_cmdline ( const char * cmdline ) <nl> { <nl> term_show_prompt (); <nl> - term_printf ( cmdline ); <nl> + term_printf ("% s ", cmdline ); <nl> term_flush (); <nl> } <nl>  <nl> static void term_up_char ( void ) <nl> } <nl> term_hist_entry --; <nl> if ( term_hist_entry >= 0 ) { <nl> - strcpy ( term_cmd_buf , term_history [ term_hist_entry ]); <nl> + pstrcpy ( term_cmd_buf , sizeof ( term_cmd_buf ), <nl> + term_history [ term_hist_entry ]); <nl> term_printf ("\ n "); <nl> term_print_cmdline ( term_cmd_buf ); <nl> term_cmd_buf_index = term_cmd_buf_size = strlen ( term_cmd_buf ); <nl> static void term_down_char ( void ) <nl> if ( term_hist_entry == TERM_MAX_CMDS - 1 || term_hist_entry == - 1 ) <nl> return ; <nl> if ( term_history [++ term_hist_entry ] != NULL ) { <nl> - strcpy ( term_cmd_buf , term_history [ term_hist_entry ]); <nl> + pstrcpy ( term_cmd_buf , sizeof ( term_cmd_buf ), <nl> + term_history [ term_hist_entry ]); <nl> } else { <nl> term_hist_entry = - 1 ; <nl> }
VirtIODevice * virtio_scsi_init ( DeviceState * dev , VirtIOSCSIConf * proxyconf ) <nl>  <nl> void virtio_scsi_exit ( VirtIODevice * vdev ) <nl> { <nl> + VirtIOSCSI * s = ( VirtIOSCSI *) vdev ; <nl> + unregister_savevm ( s -> qdev , " virtio - scsi ", s ); <nl> virtio_cleanup ( vdev ); <nl> }
static testdef_t tests [] = { <nl> static void check_guest_output ( const testdef_t * test , int fd ) <nl> { <nl> bool output_ok = false ; <nl> - int i , nbr , pos = 0 ; <nl> + int i , nbr , pos = 0 , ccnt ; <nl> char ch ; <nl>  <nl> /* Poll serial output ... Wait at most 60 seconds */ <nl> for ( i = 0 ; i < 6000 ; ++ i ) { <nl> - while (( nbr = read ( fd , & ch , 1 )) == 1 ) { <nl> + ccnt = 0 ; <nl> + while (( nbr = read ( fd , & ch , 1 )) == 1 && ccnt ++ < 512 ) { <nl> if ( ch == test -> expect [ pos ]) { <nl> pos += 1 ; <nl> if ( test -> expect [ pos ] == '\ 0 ') {
uint64_t pc_dimm_get_free_addr ( uint64_t address_space_start , <nl> uint64_t new_addr , ret = 0 ; <nl> uint64_t address_space_end = address_space_start + address_space_size ; <nl>  <nl> - assert ( address_space_end > address_space_size ); <nl> + if (! address_space_size ) { <nl> + error_setg ( errp , " memory hotplug is not enabled , " <nl> + " please add maxmem option "); <nl> + goto out ; <nl> + } <nl> + <nl> + assert ( address_space_end > address_space_start ); <nl> object_child_foreach ( qdev_get_machine (), pc_dimm_built_list , & list ); <nl>  <nl> if ( hint ) {
static KeyValue * copy_key_value ( KeyValue * src ) <nl> { <nl> KeyValue * dst = g_new ( KeyValue , 1 ); <nl> memcpy ( dst , src , sizeof (* src )); <nl> + if ( dst -> type == KEY_VALUE_KIND_NUMBER ) { <nl> + QKeyCode code = qemu_input_key_number_to_qcode ( dst -> u . number . data ); <nl> + dst -> type = KEY_VALUE_KIND_QCODE ; <nl> + dst -> u . qcode . data = code ; <nl> + } <nl> return dst ; <nl> } <nl> 
e1000e_init_msix ( E1000EState * s ) <nl> static void <nl> e1000e_cleanup_msix ( E1000EState * s ) <nl> { <nl> - if ( msix_enabled ( PCI_DEVICE ( s ))) { <nl> + if ( msix_present ( PCI_DEVICE ( s ))) { <nl> e1000e_unuse_msix_vectors ( s , E1000E_MSIX_VEC_NUM ); <nl> msix_uninit ( PCI_DEVICE ( s ), & s -> msix , & s -> msix ); <nl> }
static void vhost_scsi_stop ( VHostSCSI * s ) <nl> VirtioBusClass * k = VIRTIO_BUS_GET_CLASS ( qbus ); <nl> int ret = 0 ; <nl>  <nl> - if (! k -> set_guest_notifiers ) { <nl> + if ( k -> set_guest_notifiers ) { <nl> ret = k -> set_guest_notifiers ( qbus -> parent , s -> dev . nvqs , false ); <nl> if ( ret < 0 ) { <nl> error_report (" vhost guest notifier cleanup failed : % d \ n ", ret );
xmit_seg ( E1000State * s ) <nl> } else // UDP <nl> cpu_to_be16wu (( uint16_t *)( tp -> data + css + 4 ), len ); <nl> if ( tp -> sum_needed & E1000_TXD_POPTS_TXSM ) { <nl> + unsigned int phsum ; <nl> // add pseudo - header length before checksum calculation <nl> sp = ( uint16_t *)( tp -> data + tp -> tucso ); <nl> - cpu_to_be16wu ( sp , be16_to_cpup ( sp ) + len ); <nl> + phsum = be16_to_cpup ( sp ) + len ; <nl> + phsum = ( phsum >> 16 ) + ( phsum & 0xffff ); <nl> + cpu_to_be16wu ( sp , phsum ); <nl> } <nl> tp -> tso_frames ++; <nl> }
static int l2_load ( BlockDriverState * bs , uint64_t l2_offset , <nl> int qcow2_write_l1_entry ( BlockDriverState * bs , int l1_index ) <nl> { <nl> BDRVQcowState * s = bs -> opaque ; <nl> - uint64_t buf [ L1_ENTRIES_PER_SECTOR ]; <nl> + uint64_t buf [ L1_ENTRIES_PER_SECTOR ] = { 0 }; <nl> int l1_start_index ; <nl> int i , ret ; <nl>  <nl> l1_start_index = l1_index & ~( L1_ENTRIES_PER_SECTOR - 1 ); <nl> - for ( i = 0 ; i < L1_ENTRIES_PER_SECTOR ; i ++) { <nl> + for ( i = 0 ; i < L1_ENTRIES_PER_SECTOR && l1_start_index + i < s -> l1_size ; <nl> + i ++) <nl> + { <nl> buf [ i ] = cpu_to_be64 ( s -> l1_table [ l1_start_index + i ]); <nl> } <nl> 
static bool is_zero_cluster ( BlockDriverState * bs , int64_t start ) <nl> BlockDriverState * file ; <nl> int64_t res = bdrv_get_block_status_above ( bs , NULL , start , <nl> s -> cluster_sectors , & nr , & file ); <nl> - return res >= 0 && (( res & BDRV_BLOCK_ZERO ) || !( res & BDRV_BLOCK_DATA )); <nl> + return res >= 0 && ( res & BDRV_BLOCK_ZERO ); <nl> } <nl>  <nl> static bool is_zero_cluster_top_locked ( BlockDriverState * bs , int64_t start )
static void checkpoint ( void ) { <nl> return ; <nl> /* avoid compiler warnings : */ <nl> hexdump ( NULL , 100 ); <nl> - remove_mapping ( vvv , NULL ); <nl> + remove_mapping ( vvv , 0 ); <nl> print_mapping ( NULL ); <nl> print_direntry ( NULL ); <nl> }
void cache_insert ( PageCache * cache , uint64_t addr , uint8_t * pdata ) <nl> /* actual update of entry */ <nl> it = cache_get_by_addr ( cache , addr ); <nl>  <nl> + /* free old cached data if any */ <nl> + g_free ( it -> it_data ); <nl> + <nl> if (! it -> it_data ) { <nl> cache -> num_items ++; <nl> }
static void vga_draw_graphic ( VGACommonState * s , int full_update ) <nl> } else if ( is_buffer_shared ( surface ) && <nl> ( full_update || surface_data ( surface ) != s -> vram_ptr <nl> + ( s -> start_addr * 4 ))) { <nl> - DisplaySurface * surface ; <nl> surface = qemu_create_displaysurface_from ( disp_width , <nl> height , depth , s -> line_offset , <nl> s -> vram_ptr + ( s -> start_addr * 4 ), byteswap );
static int l2_allocate ( BlockDriverState * bs , int l1_index , uint64_t ** table ) <nl> { <nl> BDRVQcowState * s = bs -> opaque ; <nl> uint64_t old_l2_offset ; <nl> - uint64_t * l2_table ; <nl> + uint64_t * l2_table = NULL ; <nl> int64_t l2_offset ; <nl> int ret ; <nl>  <nl> static int l2_allocate ( BlockDriverState * bs , int l1_index , uint64_t ** table ) <nl>  <nl> fail : <nl> trace_qcow2_l2_allocate_done ( bs , l1_index , ret ); <nl> - qcow2_cache_put ( bs , s -> l2_table_cache , ( void **) table ); <nl> + if ( l2_table != NULL ) { <nl> + qcow2_cache_put ( bs , s -> l2_table_cache , ( void **) table ); <nl> + } <nl> s -> l1_table [ l1_index ] = old_l2_offset ; <nl> return ret ; <nl> }
static int check_directory_consistency ( BDRVVVFATState * s , <nl>  <nl> if ( s -> used_clusters [ cluster_num ] & USED_ANY ) { <nl> fprintf ( stderr , " cluster % d used more than once \ n ", ( int ) cluster_num ); <nl> - return 0 ; <nl> + goto fail ; <nl> } <nl> s -> used_clusters [ cluster_num ] = USED_DIRECTORY ; <nl> 
static void xio3130_downstream_realize ( PCIDevice * d , Error ** errp ) <nl> pcie_chassis_create ( s -> chassis ); <nl> rc = pcie_chassis_add_slot ( s ); <nl> if ( rc < 0 ) { <nl> + error_setg ( errp , " Can ' t add chassis slot , error % d ", rc ); <nl> goto err_pcie_cap ; <nl> } <nl> 
static int bdrv_qed_open ( BlockDriverState * bs , QDict * options , int flags , <nl> s -> l2_mask = s -> table_nelems - 1 ; <nl> s -> l1_shift = s -> l2_shift + ffs ( s -> table_nelems ) - 1 ; <nl>  <nl> + /* Header size calculation must not overflow uint32_t */ <nl> + if ( s -> header . header_size > UINT32_MAX / s -> header . cluster_size ) { <nl> + return - EINVAL ; <nl> + } <nl> + <nl> if (( s -> header . features & QED_F_BACKING_FILE )) { <nl> if (( uint64_t ) s -> header . backing_filename_offset + <nl> s -> header . backing_filename_size >
CPUState * cpu_gdbstub_get_env ( void * opaque ) <nl>  <nl> int main_loop ( void * opaque ) <nl> { <nl> - struct pollfd ufds [ 2 ], * pf , * serial_ufd , * net_ufd , * gdb_ufd ; <nl> - int ret , n , timeout ; <nl> + struct pollfd ufds [ 3 ], * pf , * serial_ufd , * net_ufd , * gdb_ufd ; <nl> + int ret , n , timeout , serial_ok ; <nl> uint8_t ch ; <nl> CPUState * env = global_env ; <nl>  <nl> int main_loop ( void * opaque ) <nl> term_init (); <nl> } <nl>  <nl> + serial_ok = 1 ; <nl> for (;;) { <nl> ret = cpu_x86_exec ( env ); <nl> if ( reset_requested ) <nl> int main_loop ( void * opaque ) <nl> /* poll any events */ <nl> serial_ufd = NULL ; <nl> pf = ufds ; <nl> - if (!( serial_ports [ 0 ]. lsr & UART_LSR_DR )) { <nl> + if ( serial_ok && !( serial_ports [ 0 ]. lsr & UART_LSR_DR )) { <nl> serial_ufd = pf ; <nl> pf -> fd = 0 ; <nl> pf -> events = POLLIN ; <nl> int main_loop ( void * opaque ) <nl> n = read ( 0 , & ch , 1 ); <nl> if ( n == 1 ) { <nl> serial_received_byte (& serial_ports [ 0 ], ch ); <nl> + } else { <nl> + /* Closed , stop polling . */ <nl> + serial_ok = 0 ; <nl> } <nl> } <nl> if ( net_ufd && ( net_ufd -> revents & POLLIN )) {
int socket_connect ( SocketAddress * addr , Error ** errp , <nl> case SOCKET_ADDRESS_KIND_FD : <nl> fd = monitor_get_fd ( cur_mon , addr -> fd -> str , errp ); <nl> if ( callback ) { <nl> + qemu_set_nonblock ( fd ); <nl> callback ( fd , opaque ); <nl> } <nl> break ;
static int l2_allocate ( BlockDriverState * bs , int l1_index , uint64_t ** table ) <nl>  <nl> l2_offset = qcow2_alloc_clusters ( bs , s -> l2_size * sizeof ( uint64_t )); <nl> if ( l2_offset < 0 ) { <nl> - return l2_offset ; <nl> + ret = l2_offset ; <nl> + goto fail ; <nl> } <nl>  <nl> ret = qcow2_cache_flush ( bs , s -> refcount_block_cache ); <nl> static int l2_allocate ( BlockDriverState * bs , int l1_index , uint64_t ** table ) <nl> trace_qcow2_l2_allocate_get_empty ( bs , l1_index ); <nl> ret = qcow2_cache_get_empty ( bs , s -> l2_table_cache , l2_offset , ( void **) table ); <nl> if ( ret < 0 ) { <nl> - return ret ; <nl> + goto fail ; <nl> } <nl>  <nl> l2_table = * table ;
static target_ulong h_rtas ( CPUState * env , sPAPREnvironment * spapr , <nl> nret , rtas_r3 + 12 + 4 * nargs ); <nl> } <nl>  <nl> - spapr_hcall_fn papr_hypercall_table [( MAX_HCALL_OPCODE / 4 ) + 1 ]; <nl> - spapr_hcall_fn kvmppc_hypercall_table [ KVMPPC_HCALL_MAX - KVMPPC_HCALL_BASE ]; <nl> + static spapr_hcall_fn papr_hypercall_table [( MAX_HCALL_OPCODE / 4 ) + 1 ]; <nl> + static spapr_hcall_fn kvmppc_hypercall_table [ KVMPPC_HCALL_MAX - KVMPPC_HCALL_BASE + 1 ]; <nl>  <nl> void spapr_register_hypercall ( target_ulong opcode , spapr_hcall_fn fn ) <nl> {
static int gicv3_gicd_no_migration_shift_bug_post_load ( void * opaque , <nl> return 0 ; <nl> } <nl>  <nl> + static bool needed_always ( void * opaque ) <nl> +{ <nl> + return true ; <nl> +} <nl> + <nl> const VMStateDescription vmstate_gicv3_gicd_no_migration_shift_bug = { <nl> . name = " arm_gicv3 / gicd_no_migration_shift_bug ", <nl> . version_id = 1 , <nl> . minimum_version_id = 1 , <nl> + . needed = needed_always , <nl> . pre_load = gicv3_gicd_no_migration_shift_bug_pre_load , <nl> . post_load = gicv3_gicd_no_migration_shift_bug_post_load , <nl> . fields = ( VMStateField []) {
static void curses_setup ( void ) <nl> nodelay ( stdscr , TRUE ); nonl (); keypad ( stdscr , TRUE ); <nl> start_color (); raw (); scrollok ( stdscr , FALSE ); <nl>  <nl> - for ( i = 0 ; i < 64 ; i ++) <nl> + for ( i = 0 ; i < 64 ; i ++) { <nl> init_pair ( i , colour_default [ i & 7 ], colour_default [ i >> 3 ]); <nl> + } <nl> + /* Set default color for more than 64 . ( monitor uses 0x74xx for example ) */ <nl> + for ( i = 64 ; i < COLOR_PAIRS ; i ++) { <nl> + init_pair ( i , COLOR_WHITE , COLOR_BLACK ); <nl> + } <nl> } <nl>  <nl> static void curses_keyboard_setup ( void )
void cpu_dump_state ( CPUCRISState * env , FILE * f , fprintf_function cpu_fprintf , <nl> } <nl> srs = env -> pregs [ PR_SRS ]; <nl> cpu_fprintf ( f , "\ nsupport function regs bank % x :\ n ", srs ); <nl> - if ( srs < 256 ) { <nl> + if ( srs < ARRAY_SIZE ( env -> sregs )) { <nl> for ( i = 0 ; i < 16 ; i ++) { <nl> cpu_fprintf ( f , " s % 2 . 2d =% 8 . 8x ", <nl> i , env -> sregs [ srs ][ i ]);
QPCIBus * qpci_init_spapr ( QGuestAllocator * alloc ) <nl> ret -> mmio . size = SPAPR_PCI_MMIO_WIN_SIZE ; <nl>  <nl> ret -> pci_hole_start = 0xC0000000 ; <nl> - ret -> pci_hole_size = SPAPR_PCI_MMIO_WIN_SIZE ; <nl> + ret -> pci_hole_size = <nl> + ret -> mmio . pci_base + ret -> mmio . size - ret -> pci_hole_start ; <nl> ret -> pci_hole_alloc = 0 ; <nl>  <nl> ret -> pci_iohole_start = 0xc000 ; <nl> - ret -> pci_iohole_size = SPAPR_PCI_IO_WIN_SIZE ; <nl> + ret -> pci_iohole_size = <nl> + ret -> pio . pci_base + ret -> pio . size - ret -> pci_iohole_start ; <nl> ret -> pci_iohole_alloc = 0 ; <nl>  <nl> return & ret -> bus ;
static TPMDriverOps const * be_drivers [ TPM_MAX_DRIVERS ] = { <nl> }; <nl>  <nl> static enum TpmModel tpm_models [ TPM_MAX_MODELS ] = { <nl> - - 1 , <nl> + TPM_MODEL_MAX , <nl> }; <nl>  <nl> int tpm_register_model ( enum TpmModel model ) <nl> int tpm_register_model ( enum TpmModel model ) <nl> int i ; <nl>  <nl> for ( i = 0 ; i < TPM_MAX_MODELS ; i ++) { <nl> - if ( tpm_models [ i ] == - 1 ) { <nl> + if ( tpm_models [ i ] == TPM_MODEL_MAX ) { <nl> tpm_models [ i ] = model ; <nl> return 0 ; <nl> }
static const cmdinfo_t map_cmd = { <nl>  <nl> static int close_f ( int argc , char ** argv ) <nl> { <nl> - bdrv_close ( bs ); <nl> + bdrv_delete ( bs ); <nl> bs = NULL ; <nl> return 0 ; <nl> } <nl> static int openfile ( char * name , int flags , int growable ) <nl>  <nl> if ( bdrv_open ( bs , name , flags , NULL ) < 0 ) { <nl> fprintf ( stderr , "% s : can ' t open device % s \ n ", progname , name ); <nl> + bdrv_delete ( bs ); <nl> bs = NULL ; <nl> return 1 ; <nl> } <nl> int main ( int argc , char ** argv ) <nl> qemu_aio_flush (); <nl>  <nl> if ( bs ) { <nl> - bdrv_close ( bs ); <nl> + bdrv_delete ( bs ); <nl> } <nl> return 0 ; <nl> }
static int connect_to_sdog ( const char * addr , const char * port ) <nl> if ( errno == EINTR ) { <nl> goto reconnect ; <nl> } <nl> + close ( fd ); <nl> break ; <nl> } <nl> 
# define MP_ETH_CRDP3 0x4AC <nl> # define MP_ETH_CTDP0 0x4E0 <nl> # define MP_ETH_CTDP1 0x4E4 <nl> -# define MP_ETH_CTDP2 0x4E8 <nl> -# define MP_ETH_CTDP3 0x4EC <nl>  <nl> /* MII PHY access */ <nl> # define MP_ETH_SMIR_DATA 0x0000FFFF <nl> static uint64_t mv88w8618_eth_read ( void * opaque , hwaddr offset , <nl> case MP_ETH_CRDP0 ... MP_ETH_CRDP3 : <nl> return s -> rx_queue [( offset - MP_ETH_CRDP0 )/ 4 ]; <nl>  <nl> - case MP_ETH_CTDP0 ... MP_ETH_CTDP3 : <nl> + case MP_ETH_CTDP0 ... MP_ETH_CTDP1 : <nl> return s -> tx_queue [( offset - MP_ETH_CTDP0 )/ 4 ]; <nl>  <nl> default : <nl> static void mv88w8618_eth_write ( void * opaque , hwaddr offset , <nl> s -> cur_rx [( offset - MP_ETH_CRDP0 )/ 4 ] = value ; <nl> break ; <nl>  <nl> - case MP_ETH_CTDP0 ... MP_ETH_CTDP3 : <nl> + case MP_ETH_CTDP0 ... MP_ETH_CTDP1 : <nl> s -> tx_queue [( offset - MP_ETH_CTDP0 )/ 4 ] = value ; <nl> break ; <nl> }
static inline int vfp_exceptbits_from_host ( int host_bits ) <nl> target_bits |= 8 ; <nl> if ( host_bits & float_flag_inexact ) <nl> target_bits |= 0x10 ; <nl> + if ( host_bits & float_flag_input_denormal ) <nl> + target_bits |= 0x80 ; <nl> return target_bits ; <nl> } <nl>  <nl> static inline int vfp_exceptbits_to_host ( int target_bits ) <nl> host_bits |= float_flag_underflow ; <nl> if ( target_bits & 0x10 ) <nl> host_bits |= float_flag_inexact ; <nl> + if ( target_bits & 0x80 ) <nl> + host_bits |= float_flag_input_denormal ; <nl> return host_bits ; <nl> } <nl>  <nl> void HELPER ( vfp_set_fpscr )( CPUState * env , uint32_t val ) <nl> } <nl> set_float_rounding_mode ( i , & env -> vfp . fp_status ); <nl> } <nl> - if ( changed & ( 1 << 24 )) <nl> + if ( changed & ( 1 << 24 )) { <nl> set_flush_to_zero (( val & ( 1 << 24 )) != 0 , & env -> vfp . fp_status ); <nl> + set_flush_inputs_to_zero (( val & ( 1 << 24 )) != 0 , & env -> vfp . fp_status ); <nl> + } <nl> if ( changed & ( 1 << 25 )) <nl> set_default_nan_mode (( val & ( 1 << 25 )) != 0 , & env -> vfp . fp_status ); <nl> 
static void spapr_rtc_class_init ( ObjectClass * oc , void * data ) <nl>  <nl> dc -> realize = spapr_rtc_realize ; <nl> dc -> vmsd = & vmstate_spapr_rtc ; <nl> + /* Reason : This is an internal device only for handling the hypercalls */ <nl> + dc -> user_creatable = false ; <nl>  <nl> spapr_rtas_register ( RTAS_GET_TIME_OF_DAY , " get - time - of - day ", <nl> rtas_get_time_of_day );
static void pciej_write ( void * opaque , uint32_t addr , uint32_t val ) <nl> BusState * bus = opaque ; <nl> DeviceState * qdev , * next ; <nl> PCIDevice * dev ; <nl> + PCIDeviceInfo * info ; <nl> int slot = ffs ( val ) - 1 ; <nl>  <nl> QLIST_FOREACH_SAFE ( qdev , & bus -> children , sibling , next ) { <nl> dev = DO_UPCAST ( PCIDevice , qdev , qdev ); <nl> - if ( PCI_SLOT ( dev -> devfn ) == slot ) { <nl> + info = container_of ( qdev -> info , PCIDeviceInfo , qdev ); <nl> + if ( PCI_SLOT ( dev -> devfn ) == slot && ! info -> no_hotplug ) { <nl> qdev_free ( qdev ); <nl> } <nl> }
static void ppc405cr_clk_setup ( ppc405cr_cpc_t * cpc ) <nl> D1 = ((( cpc -> pllmr >> 20 ) - 1 ) & 0xF ) + 1 ; /* FBDV */ <nl> D2 = 8 - (( cpc -> pllmr >> 16 ) & 0x7 ); /* FWDVA */ <nl> M = D0 * D1 * D2 ; <nl> - VCO_out = cpc -> sysclk * M ; <nl> + VCO_out = ( uint64_t ) cpc -> sysclk * M ; <nl> if ( VCO_out < 400000000 || VCO_out > 800000000 ) { <nl> /* PLL cannot lock */ <nl> cpc -> pllmr &= ~ 0x80000000 ; <nl> static void ppc405cr_clk_setup ( ppc405cr_cpc_t * cpc ) <nl> /* Bypass PLL */ <nl> bypass_pll : <nl> M = D0 ; <nl> - PLL_out = cpc -> sysclk * M ; <nl> + PLL_out = ( uint64_t ) cpc -> sysclk * M ; <nl> } <nl> CPU_clk = PLL_out ; <nl> if ( cpc -> cr1 & 0x00800000 ) <nl> static void ppc405ep_compute_clocks ( ppc405ep_cpc_t * cpc ) <nl> # ifdef DEBUG_CLOCKS_LL <nl> printf (" FWDA % 01 " PRIx32 " % d \ n ", ( cpc -> pllmr [ 1 ] >> 16 ) & 0x7 , D ); <nl> # endif <nl> - VCO_out = cpc -> sysclk * M * D ; <nl> + VCO_out = ( uint64_t ) cpc -> sysclk * M * D ; <nl> if ( VCO_out < 500000000UL || VCO_out > 1000000000UL ) { <nl> /* Error - unlock the PLL */ <nl> printf (" VCO out of range %" PRIu64 "\ n ", VCO_out );
static void curl_readv_bh_cb ( void * p ) <nl> state -> buf_start = start ; <nl> state -> buf_len = acb -> end + s -> readahead_size ; <nl> end = MIN ( start + state -> buf_len , s -> len ) - 1 ; <nl> - state -> orig_buf = g_malloc ( state -> buf_len ); <nl> + state -> orig_buf = g_try_malloc ( state -> buf_len ); <nl> + if ( state -> buf_len && state -> orig_buf == NULL ) { <nl> + curl_clean_state ( state ); <nl> + acb -> common . cb ( acb -> common . opaque , - ENOMEM ); <nl> + qemu_aio_release ( acb ); <nl> + return ; <nl> + } <nl> state -> acb [ 0 ] = acb ; <nl>  <nl> snprintf ( state -> range , 127 , "% zd -% zd ", start , end );
static MemTxResult address_space_write_continue ( AddressSpace * as , hwaddr addr , <nl> break ; <nl> case 4 : <nl> /* 32 bit write access */ <nl> - val = ldl_p ( buf ); <nl> + val = ( uint32_t ) ldl_p ( buf ); <nl> result |= memory_region_dispatch_write ( mr , addr1 , val , 4 , <nl> attrs ); <nl> break ;
static void pcnet_transmit ( PCNetState * s ) <nl> } <nl>  <nl> bcnt = 4096 - GET_FIELD ( tmd . length , TMDL , BCNT ); <nl> + <nl> + /* if multi - tmd packet outsizes s -> buffer then skip it silently . <nl> + Note : this is not what real hw does */ <nl> + if ( s -> xmit_pos + bcnt > sizeof ( s -> buffer )) { <nl> + s -> xmit_pos = - 1 ; <nl> + goto txdone ; <nl> + } <nl> + <nl> s -> phys_mem_read ( s -> dma_opaque , PHYSADDR ( s , tmd . tbadr ), <nl> s -> buffer + s -> xmit_pos , bcnt , CSR_BSWP ( s )); <nl> s -> xmit_pos += bcnt ;
int main ( int argc , char ** argv , char ** envp ) <nl> if ( dcl -> dpy_refresh != NULL ) { <nl> ds -> gui_timer = qemu_new_timer ( rt_clock , gui_update , ds ); <nl> qemu_mod_timer ( ds -> gui_timer , qemu_get_clock ( rt_clock )); <nl> + break ; <nl> } <nl> dcl = dcl -> next ; <nl> }
static int open_f ( BlockDriverState * bs , int argc , char ** argv ) <nl> flags |= BDRV_O_RDWR ; <nl> } <nl>  <nl> - if ( optind != argc - 1 ) { <nl> + if ( optind == argc - 1 ) { <nl> + return openfile ( argv [ optind ], flags , growable , opts ); <nl> + } else if ( optind == argc ) { <nl> + return openfile ( NULL , flags , growable , opts ); <nl> + } else { <nl> return qemuio_command_usage (& open_cmd ); <nl> } <nl> - <nl> - return openfile ( argv [ optind ], flags , growable , opts ); <nl> } <nl>  <nl> static int quit_f ( BlockDriverState * bs , int argc , char ** argv )
static void usbredir_handle_destroy ( USBDevice * udev ) <nl> USBRedirDevice * dev = DO_UPCAST ( USBRedirDevice , dev , udev ); <nl>  <nl> qemu_chr_delete ( dev -> cs ); <nl> + dev -> cs = NULL ; <nl> /* Note must be done after qemu_chr_close , as that causes a close event */ <nl> qemu_bh_delete ( dev -> chardev_close_bh ); <nl> 
static void report_unavailable_features ( FeatureWord w , uint32_t mask ) <nl> int i ; <nl>  <nl> for ( i = 0 ; i < 32 ; ++ i ) { <nl> - if ( 1 << i & mask ) { <nl> + if (( 1UL << i ) & mask ) { <nl> const char * reg = get_register_name_32 ( f -> cpuid_reg ); <nl> assert ( reg ); <nl> fprintf ( stderr , " warning : % s doesn ' t support requested feature : "
static void test_visitor_in_errors ( TestInputVisitorData * data , <nl> TestStruct * p = NULL ; <nl> Error * err = NULL ; <nl> Visitor * v ; <nl> + strList * q = NULL ; <nl>  <nl> - v = visitor_input_test_init ( data , "{ ' integer ': false , ' boolean ': ' foo ', ' string ': - 42 }"); <nl> + v = visitor_input_test_init ( data , "{ ' integer ': false , ' boolean ': ' foo ', " <nl> + "' string ': - 42 }"); <nl>  <nl> visit_type_TestStruct ( v , & p , NULL , & err ); <nl> error_free_or_abort (& err ); <nl> static void test_visitor_in_errors ( TestInputVisitorData * data , <nl>  <nl> g_free ( p -> string ); <nl> g_free ( p ); <nl> + <nl> + v = visitor_input_test_init ( data , "[ ' 1 ', ' 2 ', false , ' 3 ' ]"); <nl> + visit_type_strList ( v , & q , NULL , & err ); <nl> + error_free_or_abort (& err ); <nl> + assert ( q ); <nl> + qapi_free_strList ( q ); <nl> } <nl>  <nl> int main ( int argc , char ** argv )
static void nvdimm_realize ( PCDIMMDevice * dimm , Error ** errp ) <nl> " small to contain nvdimm label ( 0x %" PRIx64 ") and " <nl> " aligned PMEM ( 0x %" PRIx64 ")", <nl> path , memory_region_size ( mr ), nvdimm -> label_size , align ); <nl> + g_free ( path ); <nl> return ; <nl> } <nl> 
static void config_parse ( GAConfig * config , int argc , char ** argv ) <nl> { NULL , 0 , NULL , 0 } <nl> }; <nl>  <nl> - config -> log_level = G_LOG_LEVEL_ERROR | G_LOG_LEVEL_CRITICAL ; <nl> - <nl> while (( ch = getopt_long ( argc , argv , sopt , lopt , & opt_ind )) != - 1 ) { <nl> switch ( ch ) { <nl> case ' m ': <nl> int main ( int argc , char ** argv ) <nl> GAState * s = g_new0 ( GAState , 1 ); <nl> GAConfig * config = g_new0 ( GAConfig , 1 ); <nl>  <nl> + config -> log_level = G_LOG_LEVEL_ERROR | G_LOG_LEVEL_CRITICAL ; <nl> + <nl> module_call_init ( MODULE_INIT_QAPI ); <nl>  <nl> init_dfl_pathnames ();
static int pty_chr_write ( CharDriverState * chr , const uint8_t * buf , int len ) <nl> if (! s -> connected ) { <nl> /* guest sends data , check for ( re -) connect */ <nl> pty_chr_update_read_handler_locked ( chr ); <nl> - return 0 ; <nl> + if (! s -> connected ) { <nl> + return 0 ; <nl> + } <nl> } <nl> return io_channel_send ( s -> fd , buf , len ); <nl> }
static void pointer_event ( VncState * vs , int button_mask , int x , int y ) <nl> dz = 1 ; <nl>  <nl> if ( vs -> absolute ) { <nl> - kbd_mouse_event ( x * 0x7FFF / ( ds_get_width ( vs -> ds ) - 1 ), <nl> - y * 0x7FFF / ( ds_get_height ( vs -> ds ) - 1 ), <nl> + kbd_mouse_event ( ds_get_width ( vs -> ds ) > 1 ? <nl> + x * 0x7FFF / ( ds_get_width ( vs -> ds ) - 1 ) : 0x4000 , <nl> + ds_get_height ( vs -> ds ) > 1 ? <nl> + y * 0x7FFF / ( ds_get_height ( vs -> ds ) - 1 ) : 0x4000 , <nl> dz , buttons ); <nl> } else if ( vnc_has_feature ( vs , VNC_FEATURE_POINTER_TYPE_CHANGE )) { <nl> x -= 0x7FFF ;
static int spapr_fixup_cpu_smt_dt ( void * fdt , int offset , PowerPCCPU * cpu , <nl> int index = ppc_get_vcpu_dt_id ( cpu ); <nl>  <nl> if ( cpu -> cpu_version ) { <nl> - ret = fdt_setprop ( fdt , offset , " cpu - version ", <nl> - & cpu -> cpu_version , sizeof ( cpu -> cpu_version )); <nl> + ret = fdt_setprop_cell ( fdt , offset , " cpu - version ", cpu -> cpu_version ); <nl> if ( ret < 0 ) { <nl> return ret ; <nl> }
static void vfio_map_bar ( VFIOPCIDevice * vdev , int nr ) <nl> if ( vdev -> msix && vdev -> msix -> table_bar == nr ) { <nl> uint64_t start ; <nl>  <nl> - start = HOST_PAGE_ALIGN ( vdev -> msix -> table_offset + <nl> + start = HOST_PAGE_ALIGN (( uint64_t ) vdev -> msix -> table_offset + <nl> ( vdev -> msix -> entries * PCI_MSIX_ENTRY_SIZE )); <nl>  <nl> size = start < bar -> region . size ? bar -> region . size - start : 0 ;
static void gen_exception_cause ( DisasContext * dc , uint32_t cause ) <nl> gen_helper_exception_cause ( tpc , tcause ); <nl> tcg_temp_free ( tpc ); <nl> tcg_temp_free ( tcause ); <nl> + if ( cause == ILLEGAL_INSTRUCTION_CAUSE || <nl> + cause == SYSCALL_CAUSE ) { <nl> + dc -> is_jmp = DISAS_UPDATE ; <nl> + } <nl> } <nl>  <nl> static void gen_exception_cause_vaddr ( DisasContext * dc , uint32_t cause , <nl> static void gen_check_privilege ( DisasContext * dc ) <nl> { <nl> if ( dc -> cring ) { <nl> gen_exception_cause ( dc , PRIVILEGED_CAUSE ); <nl> + dc -> is_jmp = DISAS_UPDATE ; <nl> } <nl> } <nl>  <nl> static void disas_xtensa_insn ( DisasContext * dc ) <nl>  <nl> invalid_opcode : <nl> qemu_log (" INVALID ( pc = % 08x )\ n ", dc -> pc ); <nl> - dc -> pc = dc -> next_pc ; <nl> + gen_exception_cause ( dc , ILLEGAL_INSTRUCTION_CAUSE ); <nl> # undef HAS_OPTION <nl> } <nl> 
static glfs_t * glfs_find_preopened ( const char * volume ) <nl> static void glfs_clear_preopened ( glfs_t * fs ) <nl> { <nl> ListElement * entry = NULL ; <nl> + ListElement * next ; <nl>  <nl> if ( fs == NULL ) { <nl> return ; <nl> } <nl>  <nl> - QLIST_FOREACH ( entry , & glfs_list , list ) { <nl> + QLIST_FOREACH_SAFE ( entry , & glfs_list , list , next ) { <nl> if ( entry -> saved . fs == fs ) { <nl> if (-- entry -> saved . ref ) { <nl> return ;
static void page_flush_tb ( void ) <nl> /* XXX : tb_flush is currently not thread safe */ <nl> void tb_flush ( CPUState * cpu ) <nl> { <nl> + if (! tcg_enabled ()) { <nl> + return ; <nl> + } <nl> # if defined ( DEBUG_FLUSH ) <nl> printf (" qemu : flush code_size =% ld nb_tbs =% d avg_tb_size =% ld \ n ", <nl> ( unsigned long )( tcg_ctx . code_gen_ptr - tcg_ctx . code_gen_buffer ),
int main ( int argc , char ** argv , char ** envp ) <nl> ram_size = DEFAULT_RAM_SIZE * 1024 * 1024 ; <nl> } <nl>  <nl> + if ( qemu_opts_foreach ( qemu_find_opts (" device "), device_help_func , NULL , 0 ) <nl> + != 0 ) { <nl> + exit ( 0 ); <nl> + } <nl> + <nl> configure_accelerator (); <nl>  <nl> qemu_init_cpu_loop (); <nl> int main ( int argc , char ** argv , char ** envp ) <nl> } <nl> select_vgahw ( vga_model ); <nl>  <nl> - if ( qemu_opts_foreach ( qemu_find_opts (" device "), device_help_func , NULL , 0 ) != 0 ) <nl> - exit ( 0 ); <nl> - <nl> if ( watchdog ) { <nl> i = select_watchdog ( watchdog ); <nl> if ( i > 0 )
static void write_bootloader ( uint8_t * base , int64_t run_addr , <nl> stl_p ( p ++, 0x00000000 ); /* nop */ <nl> stl_p ( p ++, 0x0ff0021c ); /* jal 870 */ <nl> stl_p ( p ++, 0x00000000 ); /* nop */ <nl> - stl_p ( p ++, 0x08000205 ); /* j 814 */ <nl> + stl_p ( p ++, 0x1000fff9 ); /* b 814 */ <nl> stl_p ( p ++, 0x00000000 ); /* nop */ <nl> stl_p ( p ++, 0x01a00009 ); /* jalr t5 */ <nl> stl_p ( p ++, 0x01602021 ); /* move a0 , t3 */
static void virtio_net_save ( QEMUFile * f , void * opaque ) <nl>  <nl> qemu_put_buffer ( f , n -> mac , 6 ); <nl> qemu_put_be32 ( f , n -> tx_timer_active ); <nl> + qemu_put_be32 ( f , n -> mergeable_rx_bufs ); <nl> } <nl>  <nl> static int virtio_net_load ( QEMUFile * f , void * opaque , int version_id ) <nl> { <nl> VirtIONet * n = opaque ; <nl>  <nl> - if ( version_id != 1 ) <nl> + if ( version_id != 2 ) <nl> return - EINVAL ; <nl>  <nl> virtio_load (& n -> vdev , f ); <nl>  <nl> qemu_get_buffer ( f , n -> mac , 6 ); <nl> n -> tx_timer_active = qemu_get_be32 ( f ); <nl> + n -> mergeable_rx_bufs = qemu_get_be32 ( f ); <nl>  <nl> if ( n -> tx_timer_active ) { <nl> qemu_mod_timer ( n -> tx_timer , <nl> PCIDevice * virtio_net_init ( PCIBus * bus , NICInfo * nd , int devfn ) <nl> n -> tx_timer_active = 0 ; <nl> n -> mergeable_rx_bufs = 0 ; <nl>  <nl> - register_savevm (" virtio - net ", virtio_net_id ++, 1 , <nl> + register_savevm (" virtio - net ", virtio_net_id ++, 2 , <nl> virtio_net_save , virtio_net_load , n ); <nl>  <nl> return ( PCIDevice *) n ;
static void coroutine_fn v9fs_flush ( void * opaque ) <nl> * Wait for pdu to complete . <nl> */ <nl> qemu_co_queue_wait (& cancel_pdu -> complete , NULL ); <nl> - cancel_pdu -> cancelled = 0 ; <nl> - pdu_free ( cancel_pdu ); <nl> + if (! qemu_co_queue_next (& cancel_pdu -> complete )) { <nl> + cancel_pdu -> cancelled = 0 ; <nl> + pdu_free ( cancel_pdu ); <nl> + } <nl> } <nl> pdu_complete ( pdu , 7 ); <nl> }
GEN_HANDLER ( cntlzw , 0x1F , 0x1A , 0x00 , 0x00000000 , PPC_INTEGER ) <nl> { <nl> tcg_gen_helper_1_1 ( helper_cntlzw , cpu_gpr [ rA ( ctx -> opcode )], cpu_gpr [ rS ( ctx -> opcode )]); <nl> if ( unlikely ( Rc ( ctx -> opcode ) != 0 )) <nl> - gen_set_Rc0 ( ctx , cpu_gpr [ rS ( ctx -> opcode )]); <nl> + gen_set_Rc0 ( ctx , cpu_gpr [ rA ( ctx -> opcode )]); <nl> } <nl> /* eqv & eqv . */ <nl> GEN_LOGICAL2 ( eqv , tcg_gen_eqv_tl , 0x08 , PPC_INTEGER ); <nl> GEN_HANDLER ( name , 0x13 , 0x01 , opc , 0x00000001 , PPC_INTEGER ) \ <nl> else if ( sh < 0 ) \ <nl> tcg_gen_shli_i32 ( temp1 , cpu_crf [ crbA ( ctx -> opcode ) >> 2 ], - sh ); \ <nl> else \ <nl> - tcg_gen_mov_i32 ( temp1 , cpu_crf [ crbB ( ctx -> opcode ) >> 2 ]); \ <nl> + tcg_gen_mov_i32 ( temp1 , cpu_crf [ crbA ( ctx -> opcode ) >> 2 ]); \ <nl> temp2 = tcg_temp_new ( TCG_TYPE_I32 ); \ <nl> sh = ( crbD ( ctx -> opcode ) & 0x03 ) - ( crbB ( ctx -> opcode ) & 0x03 ); \ <nl> if ( sh > 0 ) \
static ram_addr_t qxl_rom_size ( void ) <nl> sizeof ( qxl_modes ); <nl> uint32_t rom_size = 8192 ; /* two pages */ <nl>  <nl> - required_rom_size = MAX ( required_rom_size , TARGET_PAGE_SIZE ); <nl> - required_rom_size = msb_mask ( required_rom_size * 2 - 1 ); <nl> - assert ( required_rom_size <= rom_size ); <nl> + QEMU_BUILD_BUG_ON ( required_rom_size > rom_size ); <nl> return rom_size ; <nl> } <nl> 
static void pty_chr_state ( CharDriverState * chr , int connected ) <nl> s -> timer_tag = 0 ; <nl> } <nl> if (! s -> connected ) { <nl> - qemu_chr_be_generic_open ( chr ); <nl> s -> connected = 1 ; <nl> + qemu_chr_be_generic_open ( chr ); <nl> s -> fd_tag = io_add_watch_poll ( s -> fd , pty_chr_read_poll , pty_chr_read , chr ); <nl> } <nl> }
static void msix_mmio_write ( void * opaque , target_phys_addr_t addr , <nl> PCIDevice * dev = opaque ; <nl> unsigned int offset = addr & ( MSIX_PAGE_SIZE - 1 ) & ~ 0x3 ; <nl> int vector = offset / PCI_MSIX_ENTRY_SIZE ; <nl> + <nl> + /* MSI - X page includes a read - only PBA and a writeable Vector Control . */ <nl> + if ( vector >= dev -> msix_entries_nr ) { <nl> + return ; <nl> + } <nl> + <nl> pci_set_long ( dev -> msix_table_page + offset , val ); <nl> msix_handle_mask_update ( dev , vector ); <nl> }
static int get_device_guid ( <nl> & len ); <nl>  <nl> if ( status != ERROR_SUCCESS || name_type != REG_SZ ) { <nl> - return - 1 ; <nl> + ++ i ; <nl> + continue ; <nl> } <nl> else { <nl> if ( is_tap_win32_dev ( enum_name )) {
static void v9fs_read ( void * opaque ) <nl> if ( len < 0 ) { <nl> /* IO error return the error */ <nl> err = len ; <nl> - goto out ; <nl> + goto out_free_iovec ; <nl> } <nl> } while ( count < max_count && len > 0 ); <nl> err = pdu_marshal ( pdu , offset , " d ", count ); <nl> if ( err < 0 ) { <nl> - goto out ; <nl> + goto out_free_iovec ; <nl> } <nl> err += offset + count ; <nl> + out_free_iovec : <nl> qemu_iovec_destroy (& qiov ); <nl> qemu_iovec_destroy (& qiov_full ); <nl> } else if ( fidp -> fid_type == P9_FID_XATTR ) {
World * rocker_get_world ( Rocker * r , enum rocker_world_type type ) <nl>  <nl> RockerSwitch * qmp_query_rocker ( const char * name , Error ** errp ) <nl> { <nl> - RockerSwitch * rocker = g_malloc0 ( sizeof (* rocker )); <nl> + RockerSwitch * rocker ; <nl> Rocker * r ; <nl>  <nl> r = rocker_find ( name ); <nl> RockerSwitch * qmp_query_rocker ( const char * name , Error ** errp ) <nl> return NULL ; <nl> } <nl>  <nl> + rocker = g_new0 ( RockerSwitch , 1 ); <nl> rocker -> name = g_strdup ( r -> name ); <nl> rocker -> id = r -> switch_id ; <nl> rocker -> ports = r -> fp_ports ;
static void schedule_mkdir ( BDRVVVFATState * s , uint32_t cluster , char * path ) <nl> } <nl>  <nl> typedef struct { <nl> - unsigned char name [ 1024 ]; <nl> + /* <nl> + * Since the sequence number is at most 0x3f , and the filename <nl> + * length is at most 13 times the sequence number , the maximal <nl> + * filename length is 0x3f * 13 bytes . <nl> + */ <nl> + unsigned char name [ 0x3f * 13 + 1 ]; <nl> int checksum , len ; <nl> int sequence_number ; <nl> } long_file_name ;
static QDict * qmp_dispatch_check_obj ( const QObject * request , Error ** errp ) <nl> return NULL ; <nl> } <nl> has_exec_key = true ; <nl> - } else if ( strcmp ( arg_name , " arguments ")) { <nl> + } else if (! strcmp ( arg_name , " arguments ")) { <nl> + if ( qobject_type ( arg_obj ) != QTYPE_QDICT ) { <nl> + error_setg ( errp , QERR_QMP_BAD_INPUT_OBJECT_MEMBER , <nl> + " arguments ", " object "); <nl> + return NULL ; <nl> + } <nl> + } else { <nl> error_setg ( errp , QERR_QMP_EXTRA_MEMBER , arg_name ); <nl> return NULL ; <nl> }
static void tgen_andi ( TCGContext * s , TCGType type , TCGReg dest , uint64_t val ) <nl> int msb , lsb ; <nl> if (( val & 0x8000000000000001ull ) == 0x8000000000000001ull ) { <nl> /* Achieve wraparound by swapping msb and lsb . */ <nl> - msb = 63 - ctz64 (~ val ); <nl> - lsb = clz64 (~ val ) + 1 ; <nl> + msb = 64 - ctz64 (~ val ); <nl> + lsb = clz64 (~ val ) - 1 ; <nl> } else { <nl> msb = clz64 ( val ); <nl> lsb = 63 - ctz64 ( val );
void xen_invalidate_map_cache_entry ( uint8_t * buffer ) <nl> target_phys_addr_t size ; <nl> int found = 0 ; <nl>  <nl> - if ( mapcache -> last_address_vaddr == buffer ) { <nl> - mapcache -> last_address_index = - 1 ; <nl> - } <nl> - <nl> QTAILQ_FOREACH ( reventry , & mapcache -> locked_entries , next ) { <nl> if ( reventry -> vaddr_req == buffer ) { <nl> paddr_index = reventry -> paddr_index ; <nl> void xen_invalidate_map_cache_entry ( uint8_t * buffer ) <nl> QTAILQ_REMOVE (& mapcache -> locked_entries , reventry , next ); <nl> g_free ( reventry ); <nl>  <nl> + if ( mapcache -> last_address_index == paddr_index ) { <nl> + mapcache -> last_address_index = - 1 ; <nl> + mapcache -> last_address_vaddr = NULL ; <nl> + } <nl> + <nl> entry = & mapcache -> entry [ paddr_index % mapcache -> nr_buckets ]; <nl> while ( entry && ( entry -> paddr_index != paddr_index || entry -> size != size )) { <nl> pentry = entry ;
static void virtio_gpu_resource_create_2d ( VirtIOGPU * g , <nl> qemu_log_mask ( LOG_GUEST_ERROR , <nl> "% s : host couldn ' t handle guest format % d \ n ", <nl> __func__ , c2d . format ); <nl> + g_free ( res ); <nl> cmd -> error = VIRTIO_GPU_RESP_ERR_INVALID_PARAMETER ; <nl> return ; <nl> }
static void memory_region_destructor_ram ( MemoryRegion * mr ) <nl> qemu_ram_free ( mr -> ram_addr ); <nl> } <nl>  <nl> - static void memory_region_destructor_alias ( MemoryRegion * mr ) <nl> -{ <nl> - memory_region_unref ( mr -> alias ); <nl> -} <nl> - <nl> static void memory_region_destructor_ram_from_ptr ( MemoryRegion * mr ) <nl> { <nl> qemu_ram_free_from_ptr ( mr -> ram_addr ); <nl> void memory_region_init_alias ( MemoryRegion * mr , <nl> uint64_t size ) <nl> { <nl> memory_region_init ( mr , owner , name , size ); <nl> - memory_region_ref ( orig ); <nl> - mr -> destructor = memory_region_destructor_alias ; <nl> mr -> alias = orig ; <nl> mr -> alias_offset = offset ; <nl> }
error : <nl> static void pl181_fifo_run ( pl181_state * s ) <nl> { <nl> uint32_t bits ; <nl> - uint32_t value ; <nl> + uint32_t value = 0 ; <nl> int n ; <nl> int is_read ; <nl>  <nl> static void pl181_fifo_run ( pl181_state * s ) <nl> && ! s -> linux_hack ) { <nl> if ( is_read ) { <nl> n = 0 ; <nl> - value = 0 ; <nl> while ( s -> datacnt && s -> fifo_len < PL181_FIFO_LEN ) { <nl> value |= ( uint32_t ) sd_read_data ( s -> card ) << ( n * 8 ); <nl> s -> datacnt --;
static void disas_arm_insn ( CPUARMState * env , DisasContext * s ) <nl> } <nl> ARCH ( 6 ); <nl> gen_srs ( s , ( insn & 0x1f ), ( insn >> 23 ) & 3 , insn & ( 1 << 21 )); <nl> + return ; <nl> } else if (( insn & 0x0e50ffe0 ) == 0x08100a00 ) { <nl> /* rfe */ <nl> int32_t offset ;
static unsigned hpte_page_shift ( const struct ppc_one_seg_page_size * sps , <nl>  <nl> mask = (( 1ULL << ps -> page_shift ) - 1 ) & HPTE64_R_RPN ; <nl>  <nl> - if (( pte1 & mask ) == ( ps -> pte_enc << HPTE64_R_RPN_SHIFT )) { <nl> + if (( pte1 & mask ) == (( uint64_t ) ps -> pte_enc << HPTE64_R_RPN_SHIFT )) { <nl> return ps -> page_shift ; <nl> } <nl> }
static target_ulong h_put_tce_indirect ( PowerPCCPU * cpu , <nl> ioba &= page_mask ; <nl>  <nl> for ( i = 0 ; i < npages ; ++ i , ioba += page_size ) { <nl> - target_ulong off = ( tce_list & ~ SPAPR_TCE_RW ) + <nl> - i * sizeof ( target_ulong ); <nl> - tce = ldq_be_phys ( cs -> as , off ); <nl> + tce = ldq_be_phys ( cs -> as , tce_list + i * sizeof ( target_ulong )); <nl>  <nl> ret = put_tce_emu ( tcet , ioba , tce ); <nl> if ( ret ) {
typedef struct ResetData { <nl> SPARCCPU * cpu ; <nl> uint32_t entry ; /* save kernel entry in case of reset */ <nl> + target_ulong sp ; /* initial stack pointer */ <nl> } ResetData ; <nl>  <nl> static void main_cpu_reset ( void * opaque ) <nl> static void main_cpu_reset ( void * opaque ) <nl> cpu -> halted = 0 ; <nl> env -> pc = s -> entry ; <nl> env -> npc = s -> entry + 4 ; <nl> + env -> regbase [ 6 ] = s -> sp ; <nl> } <nl>  <nl> void leon3_irq_ack ( void * irq_manager , int intno ) <nl> static void leon3_generic_hw_init ( QEMUMachineInitArgs * args ) <nl> /* Reset data */ <nl> reset_info = g_malloc0 ( sizeof ( ResetData )); <nl> reset_info -> cpu = cpu ; <nl> + reset_info -> sp = 0x40000000 + ram_size ; <nl> qemu_register_reset ( main_cpu_reset , reset_info ); <nl>  <nl> /* Allocate IRQ manager */
# include " qemu / error - report . h " <nl> # include " hw / hotplug . h " <nl> # include " hw / boards . h " <nl> +# include " hw / sysbus . h " <nl> # include " qapi - event . h " <nl>  <nl> int qdev_hotplug = 0 ; <nl> DeviceState * qdev_try_create ( BusState * bus , const char * type ) <nl> } <nl>  <nl> if (! bus ) { <nl> + /* Assert that the device really is a SysBusDevice before <nl> + * we put it onto the sysbus . Non - sysbus devices which aren ' t <nl> + * being put onto a bus should be created with object_new ( TYPE_FOO ), <nl> + * not qdev_create ( NULL , TYPE_FOO ). <nl> + */ <nl> + g_assert ( object_dynamic_cast ( OBJECT ( dev ), TYPE_SYS_BUS_DEVICE )); <nl> bus = sysbus_get_default (); <nl> } <nl> 
void machine_register_compat_props ( MachineState * machine ) <nl>  <nl> for ( i = 0 ; i < mc -> compat_props -> len ; i ++) { <nl> p = g_array_index ( mc -> compat_props , GlobalProperty *, i ); <nl> + /* Machine compat_props must never cause errors : */ <nl> + p -> errp = & error_abort ; <nl> qdev_prop_register_global ( p ); <nl> } <nl> }
static void nbd_trip ( void * opaque ) <nl> } <nl> } <nl>  <nl> - ret = blk_read ( exp -> blk , <nl> - ( request . from + exp -> dev_offset ) / BDRV_SECTOR_SIZE , <nl> - req -> data , request . len / BDRV_SECTOR_SIZE ); <nl> + ret = blk_pread ( exp -> blk , request . from + exp -> dev_offset , <nl> + req -> data , request . len ); <nl> if ( ret < 0 ) { <nl> LOG (" reading from file failed "); <nl> reply . error = - ret ; <nl> static void nbd_trip ( void * opaque ) <nl>  <nl> TRACE (" Writing to device "); <nl>  <nl> - ret = blk_write ( exp -> blk , <nl> - ( request . from + exp -> dev_offset ) / BDRV_SECTOR_SIZE , <nl> - req -> data , request . len / BDRV_SECTOR_SIZE ); <nl> + ret = blk_pwrite ( exp -> blk , request . from + exp -> dev_offset , <nl> + req -> data , request . len ); <nl> if ( ret < 0 ) { <nl> LOG (" writing to file failed "); <nl> reply . error = - ret ;
static void spapr_cpu_core_realize ( DeviceState * dev , Error ** errp ) <nl> if ( local_err ) { <nl> goto err ; <nl> } <nl> + object_unref ( obj ); <nl> } <nl> object_child_foreach ( OBJECT ( dev ), spapr_cpu_core_realize_child , & local_err ); <nl> if ( local_err ) {
static void ppc_spapr_init ( MachineState * machine ) <nl>  <nl> /* Set up Interrupt Controller before we create the VCPUs */ <nl> spapr -> icp = xics_system_init ( machine , <nl> - smp_cpus * kvmppc_smt_threads () / smp_threads , <nl> + DIV_ROUND_UP ( smp_cpus * kvmppc_smt_threads (), <nl> + smp_threads ), <nl> XICS_IRQS ); <nl>  <nl> /* init CPUs */
static void scsi_do_read ( void * opaque , int ret ) <nl> } <nl> } <nl>  <nl> + if ( r -> req . io_canceled ) { <nl> + return ; <nl> + } <nl> + <nl> + /* The request is used as the AIO opaque value , so add a ref . */ <nl> + scsi_req_ref (& r -> req ); <nl> + <nl> if ( r -> req . sg ) { <nl> dma_acct_start ( s -> qdev . conf . bs , & r -> acct , r -> req . sg , BDRV_ACCT_READ ); <nl> r -> req . resid -= r -> req . sg -> size ;
sofree ( struct socket * so ) <nl> if ( so -> so_next && so -> so_prev ) <nl> remque ( so ); /* crashes if so is not in a queue */ <nl>  <nl> + if ( so -> so_tcpcb ) { <nl> + free ( so -> so_tcpcb ); <nl> + } <nl> free ( so ); <nl> } <nl> 
static MemoryRegionIOMMUOps spapr_iommu_ops = { <nl> static int spapr_tce_table_realize ( DeviceState * dev ) <nl> { <nl> sPAPRTCETable * tcet = SPAPR_TCE_TABLE ( dev ); <nl> + uint64_t window_size = ( uint64_t ) tcet -> nb_table << tcet -> page_shift ; <nl>  <nl> - if ( kvm_enabled ()) { <nl> + if ( kvm_enabled () && !( window_size >> 32 )) { <nl> tcet -> table = kvmppc_create_spapr_tce ( tcet -> liobn , <nl> - tcet -> nb_table << <nl> - tcet -> page_shift , <nl> + window_size , <nl> & tcet -> fd , <nl> tcet -> vfio_accel ); <nl> }
void * pci_assign_dev_load_option_rom ( PCIDevice * dev , struct Object * owner , <nl> return NULL ; <nl> } <nl>  <nl> - if ( access ( rom_file , F_OK )) { <nl> - error_report (" pci - assign : Insufficient privileges for % s ", rom_file ); <nl> - return NULL ; <nl> - } <nl> - <nl> /* Write " 1 " to the ROM file to enable it */ <nl> fp = fopen ( rom_file , " r +"); <nl> if ( fp == NULL ) { <nl> + error_report (" pci - assign : Cannot open % s : % s ", rom_file , strerror ( errno )); <nl> return NULL ; <nl> } <nl> val = 1 ;
static int vpc_open ( BlockDriverState * bs , int flags ) <nl> struct vhd_dyndisk_header * dyndisk_header ; <nl> uint8_t buf [ HEADER_SIZE ]; <nl> uint32_t checksum ; <nl> + int err = - 1 ; <nl>  <nl> if ( bdrv_pread ( bs -> file , 0 , s -> footer_buf , HEADER_SIZE ) != HEADER_SIZE ) <nl> goto fail ; <nl> static int vpc_open ( BlockDriverState * bs , int flags ) <nl> bs -> total_sectors = ( int64_t ) <nl> be16_to_cpu ( footer -> cyls ) * footer -> heads * footer -> secs_per_cyl ; <nl>  <nl> + if ( bs -> total_sectors >= 65535 * 16 * 255 ) { <nl> + err = - EFBIG ; <nl> + goto fail ; <nl> + } <nl> + <nl> if ( bdrv_pread ( bs -> file , be64_to_cpu ( footer -> data_offset ), buf , HEADER_SIZE ) <nl> != HEADER_SIZE ) <nl> goto fail ; <nl> static int vpc_open ( BlockDriverState * bs , int flags ) <nl>  <nl> return 0 ; <nl> fail : <nl> - return - 1 ; <nl> + return err ; <nl> } <nl>  <nl> /*
void fw_cfg_add_file_callback ( FWCfgState * s , const char * filename , <nl> * index and " i - 1 " is the one being copied from , thus the <nl> * unusual start and end in the for statement . <nl> */ <nl> - for ( i = count + 1 ; i > index ; i --) { <nl> + for ( i = count ; i > index ; i --) { <nl> s -> files -> f [ i ] = s -> files -> f [ i - 1 ]; <nl> s -> files -> f [ i ]. select = cpu_to_be16 ( FW_CFG_FILE_FIRST + i ); <nl> s -> entries [ 0 ][ FW_CFG_FILE_FIRST + i ] = <nl> void * fw_cfg_modify_file ( FWCfgState * s , const char * filename , <nl> assert ( s -> files ); <nl>  <nl> index = be32_to_cpu ( s -> files -> count ); <nl> - assert ( index < fw_cfg_file_slots ( s )); <nl>  <nl> for ( i = 0 ; i < index ; i ++) { <nl> if ( strcmp ( filename , s -> files -> f [ i ]. name ) == 0 ) { <nl> void * fw_cfg_modify_file ( FWCfgState * s , const char * filename , <nl> return ptr ; <nl> } <nl> } <nl> + <nl> + assert ( index < fw_cfg_file_slots ( s )); <nl> + <nl> /* add new one */ <nl> fw_cfg_add_file_callback ( s , filename , NULL , NULL , NULL , data , len , true ); <nl> return NULL ;
static void tcg_out_movi ( TCGContext * s , TCGType type , <nl> { <nl> tcg_target_long hi , lo = ( int32_t ) arg ; <nl>  <nl> + /* Make sure we test 32 - bit constants for imm13 properly . */ <nl> + if ( type == TCG_TYPE_I32 ) { <nl> + arg = lo ; <nl> + } <nl> + <nl> /* A 13 - bit constant sign - extended to 64 - bits . */ <nl> if ( check_fit_tl ( arg , 13 )) { <nl> tcg_out_movi_imm13 ( s , ret , arg );
static int qxl_init_common ( PCIQXLDevice * qxl ) <nl>  <nl> qxl -> ssd . qxl . base . sif = & qxl_interface . base ; <nl> qxl -> ssd . qxl . id = qxl -> id ; <nl> - qemu_spice_add_interface (& qxl -> ssd . qxl . base ); <nl> + if ( qemu_spice_add_interface (& qxl -> ssd . qxl . base ) != 0 ) { <nl> + error_report (" qxl interface % d .% d not supported by spice - server \ n ", <nl> + SPICE_INTERFACE_QXL_MAJOR , SPICE_INTERFACE_QXL_MINOR ); <nl> + return - 1 ; <nl> + } <nl> qemu_add_vm_change_state_handler ( qxl_vm_change_state_handler , qxl ); <nl>  <nl> init_pipe_signaling ( qxl );
void qmp_memchar_write ( const char * device , const char * data , <nl>  <nl> ret = cirmem_chr_write ( chr , write_data , write_count ); <nl>  <nl> + if ( write_data != ( uint8_t *) data ) { <nl> + g_free (( void *) write_data ); <nl> + } <nl> + <nl> if ( ret < 0 ) { <nl> error_setg ( errp , " Failed to write to device % s ", device ); <nl> return ; <nl> char * qmp_memchar_read ( const char * device , int64_t size , <nl>  <nl> if ( has_format && ( format == DATA_FORMAT_BASE64 )) { <nl> data = g_base64_encode ( read_data , size ); <nl> + g_free ( read_data ); <nl> } else { <nl> data = ( char *) read_data ; <nl> }
static int object_set_property ( const char * name , const char * value , void * opaque <nl> StringInputVisitor * siv ; <nl> Error * local_err = NULL ; <nl>  <nl> - if ( strcmp ( name , " qom - type ") == 0 || strcmp ( name , " id ") == 0 ) { <nl> + if ( strcmp ( name , " qom - type ") == 0 || strcmp ( name , " id ") == 0 || <nl> + strcmp ( name , " type ") == 0 ) { <nl> return 0 ; <nl> } <nl> 
static void handle_qmp_command ( JSONMessageParser * parser , QList * tokens ) <nl> qobject_from_jsonf ("{ ' item ': % s }", info_item )); <nl> } else { <nl> cmd = monitor_find_command ( cmd_name ); <nl> - if (! cmd || ! monitor_handler_ported ( cmd ) <nl> - || monitor_cmd_user_only ( cmd )) { <nl> - qerror_report ( QERR_COMMAND_NOT_FOUND , cmd_name ); <nl> - goto err_out ; <nl> - } <nl> + } <nl> + <nl> + if (! cmd || ! monitor_handler_ported ( cmd ) || monitor_cmd_user_only ( cmd )) { <nl> + qerror_report ( QERR_COMMAND_NOT_FOUND , cmd_name ); <nl> + goto err_out ; <nl> } <nl>  <nl> obj = qdict_get ( input , " arguments ");
static void virtio_net_vhost_status ( VirtIONet * n , uint8_t status ) <nl> return ; <nl> } <nl>  <nl> - if (!! n -> vhost_started == virtio_net_started ( n , status ) && <nl> - ! nc -> peer -> link_down ) { <nl> + if (!! n -> vhost_started == <nl> + ( virtio_net_started ( n , status ) && ! nc -> peer -> link_down )) { <nl> return ; <nl> } <nl> if (! n -> vhost_started ) {
size_t mptsas_config_manufacturing_1 ( MPTSASState * s , uint8_t ** data , int address <nl> { <nl> /* VPD - all zeros */ <nl> return MPTSAS_CONFIG_PACK ( 1 , MPI_CONFIG_PAGETYPE_MANUFACTURING , 0x00 , <nl> - " s256 "); <nl> + "* s256 "); <nl> } <nl>  <nl> static <nl> size_t mptsas_config_ioc_0 ( MPTSASState * s , uint8_t ** data , int address ) <nl> return MPTSAS_CONFIG_PACK ( 0 , MPI_CONFIG_PAGETYPE_IOC , 0x01 , <nl> "* l * lwwb * b * b * blww ", <nl> pcic -> vendor_id , pcic -> device_id , pcic -> revision , <nl> - pcic -> subsystem_vendor_id , <nl> + pcic -> class_id , pcic -> subsystem_vendor_id , <nl> pcic -> subsystem_id ); <nl> } <nl> 
static int img_convert ( int argc , char ** argv ) <nl> goto out ; <nl> } <nl>  <nl> - out_bs = bdrv_new_open ( out_filename , out_fmt , BDRV_O_FLAGS | BDRV_O_RDWR ); <nl> + out_bs = bdrv_new_open ( out_filename , out_fmt , <nl> + BDRV_O_FLAGS | BDRV_O_RDWR | BDRV_O_NO_FLUSH ); <nl> if (! out_bs ) { <nl> ret = - 1 ; <nl> goto out ;
void vhost_dev_disable_notifiers ( struct vhost_dev * hdev , VirtIODevice * vdev ) <nl> int vhost_dev_start ( struct vhost_dev * hdev , VirtIODevice * vdev ) <nl> { <nl> int i , r ; <nl> + <nl> + hdev -> started = true ; <nl> + <nl> if (! vdev -> binding -> set_guest_notifiers ) { <nl> fprintf ( stderr , " binding does not support guest notifiers \ n "); <nl> r = - ENOSYS ; <nl> int vhost_dev_start ( struct vhost_dev * hdev , VirtIODevice * vdev ) <nl> } <nl> } <nl>  <nl> - hdev -> started = true ; <nl> - <nl> return 0 ; <nl> fail_log : <nl> fail_vq : <nl> fail_features : <nl> vdev -> binding -> set_guest_notifiers ( vdev -> binding_opaque , hdev -> nvqs , false ); <nl> fail_notifiers : <nl> fail : <nl> + <nl> + hdev -> started = false ; <nl> return r ; <nl> } <nl> 
static int qcow2_open ( BlockDriverState * bs , QDict * options , int flags , <nl> unsigned int len , i ; <nl> int ret = 0 ; <nl> QCowHeader header ; <nl> - QemuOpts * opts ; <nl> + QemuOpts * opts = NULL ; <nl> Error * local_err = NULL ; <nl> uint64_t ext_end ; <nl> uint64_t l1_vm_state_index ; <nl> static int qcow2_open ( BlockDriverState * bs , QDict * options , int flags , <nl> error_setg ( errp , " Unsupported value '% s ' for qcow2 option " <nl> "' overlap - check '. Allowed are either of the following : " <nl> " none , constant , cached , all ", opt_overlap_check ); <nl> - qemu_opts_del ( opts ); <nl> ret = - EINVAL ; <nl> goto fail ; <nl> } <nl> static int qcow2_open ( BlockDriverState * bs , QDict * options , int flags , <nl> } <nl>  <nl> qemu_opts_del ( opts ); <nl> + opts = NULL ; <nl>  <nl> if ( s -> use_lazy_refcounts && s -> qcow_version < 3 ) { <nl> error_setg ( errp , " Lazy refcounts require a qcow2 image with at least " <nl> static int qcow2_open ( BlockDriverState * bs , QDict * options , int flags , <nl> return ret ; <nl>  <nl> fail : <nl> + qemu_opts_del ( opts ); <nl> g_free ( s -> unknown_header_fields ); <nl> cleanup_unknown_header_ext ( bs ); <nl> qcow2_free_snapshots ( bs );
int do_drive_del ( Monitor * mon , const QDict * qdict , QObject ** ret_data ) <nl> */ <nl> if ( bdrv_get_attached_dev ( bs )) { <nl> bdrv_make_anon ( bs ); <nl> + <nl> + /* Further I / O must not pause the guest */ <nl> + bdrv_set_on_error ( bs , BLOCKDEV_ON_ERROR_REPORT , <nl> + BLOCKDEV_ON_ERROR_REPORT ); <nl> } else { <nl> drive_uninit ( drive_get_by_blockdev ( bs )); <nl> }
int main ( int argc , char ** argv ) { <nl> datalen = 0 ; <nl> } <nl> code = malloc ( strlen ( p )+ 1 ); <nl> + if (! code ) { <nl> + return 1 ; <nl> + } <nl> codelen = r_hex_str2bin ( p , code ); <nl> if (! arch ) arch = " x86 "; <nl> if (! bits ) bits = 32 ;
static int cmd_interpret ( void * data , const char * input ) { <nl> } else r_core_run_script ( core , "-"); <nl> break ; <nl> case ' ': <nl> - r_core_run_script ( core , input + 1 ); <nl> + if (! r_core_run_script ( core , input + 1 )) { <nl> + eprintf (" Cannot find '% s '\ n ", input + 1 ); <nl> + core -> num -> value = 1 ; <nl> + } else { <nl> + core -> num -> value = 0 ; <nl> + } <nl> break ; <nl> case '!': <nl> /* from command */
static int cmd_meta_hsdmf ( RCore * core , const char * input ) { <nl> // TODO : filter \ n and so on :) <nl> strncpy ( name , t , sizeof ( name )- 1 ); <nl> r_core_read_at ( core , addr , ( ut8 *) name , sizeof ( name )- 1 ); <nl> + if ( n < sizeof ( name )) <nl> + name [ n ] = '\ 0 '; <nl> break ; <nl> default : <nl> fi = r_flag_get_i ( core -> flags , addr );
static ut64 Elf_ ( get_import_addr )( struct Elf_ ( r_bin_elf_obj_t ) * bin , int sym ) { <nl> ( got_addr = Elf_ ( r_bin_elf_get_section_addr ) ( bin , ". got . plt ")) == - 1 ) <nl> return - 1 ; <nl> for ( i = 0 ; i < bin -> ehdr . e_shnum ; i ++) { <nl> + if ( bin -> shdr [ i ]. sh_name > bin -> shstrtab_section -> sh_size ) <nl> + continue ; <nl> if (! strcmp (& bin -> strtab [ bin -> shdr [ i ]. sh_name ], ". rel . plt ")) <nl> tsize = sizeof ( Elf_ ( Rel )); <nl> else if (! strcmp (& bin -> strtab [ bin -> shdr [ i ]. sh_name ], ". rela . plt "))
SDB_API void sdb_ns_free ( Sdb * s ) { <nl> SdbListIter next ; <nl> SdbListIter * it ; <nl> SdbNs * ns ; <nl> - // TODO : Implement and use ls_foreach_safe <nl> + if ( s ) <nl> ls_foreach ( s -> ns , it , ns ) { <nl> + // TODO : Implement and use ls_foreach_safe <nl> next . n = it -> n ; <nl> sdb_ns_free ( ns -> sdb ); <nl> sdb_free ( ns -> sdb );
R_API int r_cons_w32_print ( const ut8 * ptr , int len , int vmode ) { <nl> if ( linelen + ll > cols ) { <nl> // chop line if too long <nl> ll = ( cols - linelen )- 1 ; <nl> + if ( ll < 1 ) <nl> + continue ; <nl> } <nl> } <nl> write ( 1 , str , ll );
R_API int r_core_yank_to ( RCore * core , const char * _arg ) { <nl> pos = r_num_math ( core -> num , str + 1 ); <nl> str [ 0 ] = ' '; <nl> } <nl> - if ( len < 1 ) <nl> + if ( len < 1 ) { <nl> + free ( arg ); <nl> return res ; <nl> + } <nl> if (( str == NULL ) || ( pos == - 1 ) || ( len == 0 )) { <nl> eprintf (" Usage : yt [ len ] [ dst - addr ]\ n "); <nl> free ( arg );
static int cmd_write ( void * data , const char * input ) { <nl> r_file_dump ( tmpfile , ( ut8 *) out , strlen ( out )); <nl> r_core_patch ( core , tmpfile ); <nl> r_file_rm ( tmpfile ); <nl> + free ( out ); <nl> } <nl> - } else <nl> - if ( input [ 1 ]==' ' && input [ 2 ]) { <nl> - r_core_patch ( core , input + 2 ); <nl> } else { <nl> - eprintf (" Usage : wp [-| r2patch - file ]\ n " <nl> + if ( input [ 1 ]==' ' && input [ 2 ]) { <nl> + r_core_patch ( core , input + 2 ); <nl> + } else { <nl> + eprintf (" Usage : wp [-| r2patch - file ]\ n " <nl> " TODO : rapatch format documentation here \ n "); <nl> + } <nl> } <nl> break ; <nl> case ' u ':
R_API bool r_sign_save ( RAnal * a , const char * file ) { <nl> if (! a || ! file ) { <nl> return false ; <nl> } <nl> + <nl> + if ( sdb_count ( a -> sdb_zigns ) == 0 ) { <nl> + eprintf (" WARNING : no zignatures to save \ n "); <nl> + return false ; <nl> + } <nl>  <nl> Sdb * db = sdb_new ( NULL , file , 0 ); <nl> if (! db ) {
static int visual_help () { <nl> " Visual mode help :\ n " <nl> " ? show this help \ n " <nl> " ?? show the user - friendly hud \ n " <nl> + " $ toggle asm . pseudo \ n " <nl> " & rotate asm . bits between supported 8 , 16 , 32 , 64 \ n " <nl> " % in cursor mode finds matching pair , otherwise toggle autoblocksz \ n " <nl> " @ redraw screen every 1s ( multi - user view ), in cursor set position \ n " <nl> R_API int r_core_visual_cmd ( RCore * core , int ch ) { <nl> case ' O ': <nl> r_core_cmd0 ( core , " e ! asm . esil "); <nl> break ; <nl> + case '$': <nl> + r_core_cmd0 ( core , " e ! asm . pseudo "); <nl> + break ; <nl> case ' u ': <nl> { <nl> RIOUndos * undo = r_io_sundo ( core -> io , core -> offset );
static int replace ( int argc , const char * argv [], char * newstr ) { <nl> } else if ( letter == 4 && i == 32 ) { <nl> w = inv_mask64 ( argv [ 4 ], argv [ 3 ]); <nl> } else if ( letter == 4 && i >= 33 && i <= 35 ) { <nl> - w = cmask32 ( argv [ 4 ], argv [ 5 ]); <nl> + w = cmask32 ( argv [ 3 ], argv [ 4 ]); <nl> } else if ( letter == 1 && i >= 36 && i <= 43 ) { <nl> int to = atoi ( w ); <nl> switch ( to ) {
static int r_line_readchar_win ( int * vch ) { // this function handle the input in <nl> if ( I . zerosep ) { <nl> * vch = 0 ; <nl> buf [ 0 ] = 0 ; <nl> - read ( 0 , buf , 1 ); <nl> + if ( read ( 0 , buf , 1 ) != 1 ) <nl> + return - 1 ; <nl> return buf [ 0 ]; <nl> } <nl> 
RList * search_virtual_tables ( RCore * core ){ <nl> } <nl> ut64 startAddress ; <nl> ut64 endAddress ; <nl> - SdbListIter * iter ; <nl> - RIOSection * section ; <nl> + RListIter * iter ; <nl> + RBinSection * section ; <nl> + RList * sections = r_bin_get_sections ( core -> bin ); <nl> RList * vtables = r_list_newf (( RListFree ) free ); <nl> - if (! vtables ) { <nl> + if (! vtables || ! sections ) { <nl> return NULL ; <nl> } <nl> ut64 bits = r_config_get_i ( core -> config , " asm . bits "); <nl> int wordSize = bits / 8 ; <nl> - ls_foreach ( core -> io -> sections , iter , section ) { <nl> + r_list_foreach ( sections , iter , section ) { <nl> if (! strcmp ( section -> name , ". rodata ")) { <nl> ut8 * segBuff = calloc ( 1 , section -> size ); <nl> r_io_read_at ( core -> io , section -> vaddr , segBuff , section -> vsize );
free ( rf ); <nl> if ( r_debug_reg_sync ( core -> dbg , R_REG_TYPE_GPR , R_FALSE )) <nl> r_debug_reg_list ( core -> dbg , R_REG_TYPE_GPR , bits , '*', use_color ); <nl> break ; <nl> - case ' r ': <nl> + case ' r ': // " drr " <nl> { <nl> int bits = core -> assembler -> bits ; <nl> RList * list = r_reg_get_list ( core -> dbg -> reg , R_REG_TYPE_GPR ); <nl> free ( rf ); <nl> ut64 value = r_reg_get_value ( core -> dbg -> reg , r ); <nl> RFlagItem * fi = r_flag_get_i2 ( core -> flags , value ); <nl> ut64 type = r_core_anal_address ( core , value ); <nl> + if ( r -> size != bits ) <nl> + continue ; <nl> RAnalFunction * fcn = r_anal_get_fcn_in ( core -> anal , value , 0 ); <nl> if ( bits == 64 ) { <nl> r_cons_printf ("% 6s 0x % 016 " PFMT64x , r -> name , value );
R_API char * r_cons_hud_path ( const char * path , int dir ) { <nl> tmp = ret ; <nl> } <nl> } <nl> + r_list_free ( files ); <nl> } else eprintf (" No files found \ n "); <nl> if (! ret ) { <nl> free ( tmp );
R_API RCoreAnalStats * r_core_anal_get_stats ( RCore * core , ut64 from , ut64 to , ut6 <nl> int piece , as_size , blocks ; <nl> ut64 at ; <nl>  <nl> - if ( from == to ) { <nl> + if ( from == to || from == UT64_MAX || to == UT64_MAX ) { <nl> return NULL ; <nl> } <nl> as = R_NEW0 ( RCoreAnalStats );
static RList * r_debug_native_threads ( RDebug * dbg , int pid ) { <nl> close ( fd ); <nl> continue ; <nl> } <nl> - read ( fd , cmdline , sizeof ( cmdline )- 1 ); <nl> + ( void ) read ( fd , cmdline , sizeof ( cmdline )- 1 ); <nl> snprintf ( cmdline , sizeof ( cmdline ), " thread_ % d ", thid ++); <nl> cmdline [ sizeof ( cmdline )- 1 ] = '\ 0 '; <nl> r_list_append ( list , r_debug_pid_new ( cmdline , i , ' s ', 0 ));
static Sdb * store_versioninfo_gnu_verdef ( ELFOBJ * bin , Elf_ ( Shdr ) * shdr , int sz ) <nl> sdb_num_set ( sdb , " link ", shdr -> sh_link , 0 ); <nl> sdb_set ( sdb , " link_section_name ", link_section_name , 0 ); <nl>  <nl> - for ( cnt = 0 , i = 0 ; i >= 0 && cnt < shdr -> sh_info && (( char *) defs + i < end ); ++ cnt ) { <nl> + for ( cnt = 0 , i = 0 ; i >= 0 && cnt < shdr -> sh_info && ( end - ( char *) defs > i ); ++ cnt ) { <nl> Sdb * sdb_verdef = sdb_new0 (); <nl> char * vstart = (( char *) defs ) + i ; <nl> char key [ 32 ] = { 0 }; <nl> static Sdb * store_versioninfo_gnu_verdef ( ELFOBJ * bin , Elf_ ( Shdr ) * shdr , int sz ) <nl> verdef -> vd_aux = READ32 ( dfs , j ) <nl> verdef -> vd_next = READ32 ( dfs , j ) <nl> int vdaux = verdef -> vd_aux ; <nl> - if ( vdaux < 1 ) { <nl> + if ( vdaux < 1 || ( char *) UINTPTR_MAX - vstart < vdaux ) { <nl> sdb_free ( sdb_verdef ); <nl> goto out_error ; <nl> } <nl> vstart += vdaux ; <nl> - if ( vstart > end || vstart + sizeof ( Elf_ ( Verdaux )) > end ) { <nl> + if ( vstart > end || end - vstart < sizeof ( Elf_ ( Verdaux ))) { <nl> sdb_free ( sdb_verdef ); <nl> goto out_error ; <nl> } <nl> static Sdb * store_versioninfo_gnu_verdef ( ELFOBJ * bin , Elf_ ( Shdr ) * shdr , int sz ) <nl> Sdb * sdb_parent = sdb_new0 (); <nl> isum += aux . vda_next ; <nl> vstart += aux . vda_next ; <nl> - if ( vstart > end || vstart + sizeof ( Elf_ ( Verdaux )) > end ) { <nl> + if ( vstart > end || end - vstart < sizeof ( Elf_ ( Verdaux ))) { <nl> sdb_free ( sdb_verdef ); <nl> sdb_free ( sdb_parent ); <nl> goto out_error ;
R_API void r_reg_free_internal ( RReg * reg ) { <nl> int i ; <nl> for ( i = 0 ; i < R_REG_TYPE_LAST ; i ++) { <nl> r_list_purge ( reg -> regset [ i ]. regs ); <nl> + if ( reg -> name [ i ]) { <nl> + free ( reg -> name [ i ]); <nl> + reg -> name [ i ] = NULL ; <nl> + } <nl> reg -> regset [ i ]. regs = r_list_newf (( RListFree ) r_reg_item_free ); <nl> } <nl> } <nl> R_API RReg * r_reg_new () { <nl> reg -> iters = 0 ; <nl> reg -> profile = NULL ; <nl> reg -> reg_profile_str = NULL ; <nl> - for ( i = 0 ; i < R_REG_NAME_LAST ; i ++) <nl> - reg -> name [ i ] = NULL ; <nl> for ( i = 0 ; i < R_REG_TYPE_LAST ; i ++) { <nl> + reg -> name [ i ] = NULL ; <nl> arena = r_reg_arena_new ( 0 ); <nl> if (! arena ) { <nl> free ( reg );
static int string_scan_range ( RList * list , const ut8 * buf , int min , const ut64 f <nl> str_start = needle ; <nl>  <nl> /* Eat a whole C string */ <nl> - for ( rc = i = 0 ; i < sizeof ( tmp ) - 1 && needle < to ; i += rc ) { <nl> + for ( rc = i = 0 ; i < sizeof ( tmp ) - 2 && needle < to ; i += rc ) { <nl> RRune r ; <nl>  <nl> if ( str_type == R_STRING_TYPE_WIDE ) {
static void core_anal_bytes ( RCore * core , const ut8 * buf , int len , int nops , int <nl> r_cons_printf ("\" ophint \": \"% s \",", hint -> opcode ); <nl> } <nl> r_cons_printf ("\" prefix \": %" PFMT64d ",", op . prefix ); <nl> + r_cons_printf ("\" id \": % d ,", op . id ); <nl> r_cons_printf ("\" addr \": %" PFMT64d ",", core -> offset + idx ); <nl> r_cons_printf ("\" bytes \": \""); <nl> for ( j = 0 ; j < size ; j ++) { <nl> static void core_anal_bytes ( RCore * core , const ut8 * buf , int len , int nops , int <nl> printline (" addr ", " 0x % 08 " PFMT64x "\ n ", ( hint -> addr + idx )); <nl> } <nl> printline (" prefix ", "%" PFMT64d "\ n ", op . prefix ); <nl> + printline (" id ", "% d \ n ", op . id ); <nl> printline (" bytes ", NULL , 0 ); <nl> for ( j = 0 ; j < size ; j ++) { <nl> r_cons_printf ("% 02x ", buf [ j + idx ]);
static Sdb * store_versioninfo_gnu_verdef ( ELFOBJ * bin , Elf_ ( Shdr ) * shdr , int sz ) <nl> return false ; <nl> } <nl> link_shdr = & bin -> shdr [ shdr -> sh_link ]; <nl> - if ( shdr -> sh_size < 1 ) { <nl> + if ( shdr -> sh_size < 1 || shdr -> sh_size > SIZE_MAX ) { <nl> return false ; <nl> } <nl> Elf_ ( Verdef ) * defs = calloc ( shdr -> sh_size , sizeof ( char )); <nl> static Sdb * store_versioninfo_gnu_verneed ( ELFOBJ * bin , Elf_ ( Shdr ) * shdr , int sz ) <nl> if ( shdr -> sh_link > bin -> ehdr . e_shnum ) { <nl> return NULL ; <nl> } <nl> - if ( shdr -> sh_size < 1 ) { <nl> + if ( shdr -> sh_size < 1 || shdr -> sh_size > SIZE_MAX ) { <nl> return NULL ; <nl> } <nl> sdb = sdb_new0 ();
struct r_bin_zimg_obj_t * r_bin_zimg_new_buf ( RBuffer * buf ) { <nl> goto fail ; <nl> } <nl>  <nl> + if ( r_buf_size ( bin -> b ) < sizeof ( struct zimg_header_t )) { <nl> + goto fail ; <nl> + } <nl> bin -> header = (*( struct zimg_header_t *) bin -> b -> buf ); <nl>  <nl> return bin ;
static void handle_print_refptr_meta_infos ( RCore * core , RDisasmState * ds , ut64 <nl> r_cons_printf (" ( data )"); <nl> break ; <nl> default : <nl> - eprintf (" unknown type '% c '\ n ", mi2 -> type ); <nl> + r_cons_printf (" (% c ) % s ", mi2 -> type , mi2 -> str ); <nl> break ; <nl> } <nl> } else {
static void ds_print_esil_anal ( RDisasmState * ds ) { <nl> RCore * core = ds -> core ; <nl> RAnalEsil * esil = core -> anal -> esil ; <nl> const char * pc ; <nl> + int (* hook_mem_write )( RAnalEsil * esil , ut64 addr , const ut8 * buf , int len ) = NULL ; <nl> int i , nargs ; <nl> ut64 at = p2v ( ds , ds -> at ); <nl> RConfigHold * hc = r_config_hold_new ( core -> config ); <nl> static void ds_print_esil_anal ( RDisasmState * ds ) { <nl> r_reg_setv ( core -> anal -> reg , pc , at + ds -> analop . size ); <nl> esil -> cb . user = ds ; <nl> esil -> cb . hook_reg_write = myregwrite ; <nl> + hook_mem_write = esil -> cb . hook_mem_write ; <nl> if ( ds -> show_emu_write ) { <nl> esil -> cb . hook_mem_write = mymemwrite0 ; <nl> } else { <nl> static void ds_print_esil_anal ( RDisasmState * ds ) { <nl> r_anal_esil_stack_free ( esil ); <nl> hc = r_config_hold_new ( core -> config ); <nl> if (! hc ) { <nl> + if ( esil ) { <nl> + esil -> cb . hook_mem_write = hook_mem_write ; <nl> + } <nl> return ; <nl> } <nl> r_config_save_num ( hc , " io . cache ", NULL ); <nl> callfallback : <nl> break ; <nl> } <nl> beach : <nl> + if ( esil ) { <nl> + esil -> cb . hook_mem_write = hook_mem_write ; <nl> + } <nl> r_config_restore ( hc ); <nl> r_config_hold_free ( hc ); <nl> }
static int get_piece ( const char * p , char * chr ) { <nl> } <nl>  <nl> static char * prefixline ( RConsCanvas * c , int * left ) { <nl> - int x ; <nl> + int x , len ; <nl> char * p ; <nl> if (! c ) return NULL ; <nl> + if ( strlen ( c -> b ) < ( c -> y * c -> w )) return NULL ; <nl> p = c -> b + ( c -> y * c -> w ); <nl> - for ( x = 0 ; p [ x ] && x < c -> x ; x ++) { <nl> + len = strlen ( p )- 1 ; <nl> + for ( x = 0 ; ( p [ x ] && x < c -> x ) && x < len ; x ++) { <nl> if ( p [ x ] == '\ n ') <nl> p [ x ] = ' '; <nl> }
static void r_bin_file_free ( void /* RBinFile */ * bf_ ) { <nl> if ( a -> curxtr && a -> curxtr -> destroy ) <nl> a -> curxtr -> free_xtr (( void *) ( a -> xtr_obj )); <nl>  <nl> - r_bin_object_free ( a -> o ); <nl> + r_list_free ( a -> objs ); <nl> a -> o = NULL ; <nl> r_buf_free ( a -> buf ); <nl> // TODO : unset related sdb namespaces
struct r_bin_pe_lib_t * PE_ ( r_bin_pe_get_libs )( struct PE_ ( r_bin_pe_obj_t ) * bin ) { <nl> if ( r_buf_read_at ( bin -> b , PE_ ( r_bin_pe_rva_to_offset )( bin , bin -> import_directory [ i ]. Name ), <nl> ( ut8 *) libs [ j ]. name , PE_STRING_LENGTH ) == - 1 ) { <nl> eprintf (" Error : read ( libs - import dirs )\ n "); <nl> + free ( libs ); <nl> return NULL ; <nl> } <nl> if ( PE_ ( r_bin_pe_rva_to_offset )( bin , bin -> import_directory [ i ]. Characteristics ) == 0 &&
break ; <nl> fpos + sizeof ( struct ext2_dirent ), <nl> dirent . namelen , filename ); <nl> if ( grub_errno ) { <nl> - free ( filename ); <nl> + grub_free ( filename ); <nl> return 0 ; <nl> } <nl>  <nl> fdiro = grub_malloc ( sizeof ( struct grub_fshelp_node )); <nl> if (! fdiro ) { <nl> - free ( filename ); <nl> + grub_free ( filename ); <nl> return 0 ; <nl> } <nl>  <nl> break ; <nl> grub_le_to_cpu32 ( dirent . inode ), <nl> & fdiro -> inode ); <nl> if ( grub_errno ) { <nl> - free ( filename ); <nl> + grub_free ( filename ); <nl> grub_free ( fdiro ); <nl> return 0 ; <nl> } <nl> break ; <nl> } <nl>  <nl> if ( hook ( filename , type , fdiro , closure )) { <nl> - free ( filename ); <nl> + grub_free ( filename ); <nl> return 1 ; <nl> } <nl> - free ( filename ); <nl> + grub_free ( filename ); <nl> } <nl>  <nl> fpos += grub_le_to_cpu16 ( dirent . direntlen );
static bool parseOperands ( char * str , ArmOp * op ) { <nl> while ( token [ 0 ] == ' ') { <nl> token ++; <nl> } <nl> + if ( operand >= MAX_OPERANDS ) { <nl> + eprintf (" Too many operands \ n "); <nl> + return false ; <nl> + } <nl> op -> operands [ operand ]. type = ARM_NOTYPE ; <nl> op -> operands [ operand ]. reg_type = ARM_UNDEFINED ; <nl> op -> operands [ operand ]. shift = ARM_NO_SHIFT ;
int main ( int argc , char ** argv , char ** envp ) { <nl> if ( run_anal && threaded ) { <nl> // XXX : if no rabin2 in path that may fail <nl> rabin_cmd = r_str_newf (" rabin2 - rSIeMzisR % s % s ", <nl> - ( debug || r . io -> va )?" v ":"", r . file -> filename ); <nl> + ( debug || r . io -> va )?"":" p ", r . file -> filename ); <nl> /* TODO : only load data if no project is used */ <nl> lock = r_th_lock_new (); <nl> rabin_th = r_th_new (& rabin_delegate , lock , 0 );
static RList * entries ( RBinFile * arch ) { <nl> static RList * sections ( RBinFile * arch ) { <nl> RList * ret = NULL ; <nl> RBinSection * ptr = NULL ; <nl> + int big_endian = 0 ; <nl> ut64 textsize , datasize , symssize , spszsize , pcszsize ; <nl> - int big_endian = arch -> o -> info -> big_endian ; <nl> + if (! arch -> o -> info ) return NULL ; <nl> + big_endian = arch -> o -> info -> big_endian ; <nl>  <nl> if (!( ret = r_list_new ())) <nl> return NULL ; <nl> static int size ( RBinFile * arch ) { <nl> int big_endian ; <nl> if (! arch -> o -> info ) <nl> arch -> o -> info = info ( arch ); <nl> + if (! arch -> o -> info ) return 0 ; <nl> big_endian = arch -> o -> info -> big_endian ; <nl> // TODO : reuse section list <nl> text = r_mem_get_num ( arch -> buf -> buf + 4 , 4 , big_endian );
R_API bool r_core_bin_load ( RCore * r , const char * filenameuri , ut64 baddr ) { <nl> r_config_set_i ( r -> config , " io . va ", 0 ); <nl> } <nl> // workaround to map correctly malloc :// and raw binaries <nl> - if (! plugin || ! strcmp ( plugin -> name , " any ") || r_io_desc_is_dbg ( desc ) || ( obj && (! obj -> sections || ! va ))) { <nl> + if (! plugin || ! strcmp ( plugin -> name , " any ") || r_io_desc_is_dbg ( desc ) || ( obj && (! obj -> sections || ! va ))) { <nl> r_io_map_new ( r -> io , desc -> fd , desc -> flags , 0LL , laddr , r_io_desc_size ( desc ), true ); <nl> } <nl> return true ;
static int write_asm ( ut8 * data , Opcode * opcode_ptr , Operand * operands ) { <nl> if ( mod != 3 && rm == 4 ) <nl> data [ l ++] = make_SIB ( scale , index , base ); <nl>  <nl> - if ( regmem_op -> type & OT_MEMORY && ( mod > 0 || ( mod == 0 && rm == 5 ))) { <nl> + if ( regmem_op -> type & OT_MEMORY && <nl> + ( mod > 0 || ( mod == 0 && rm == 5 ) || ( mod == 0 && rm == 4 && base == 5 ))) { <nl> if ( mod == 1 ) { <nl> data [ l ++] = *( ut8 *)& regmem_op -> offset ; <nl> }
static int rabin_dump_symbols ( int len ) { <nl> else if ( symbol -> size == 0 && olen == 0 ) <nl> len = 32 ; <nl> else len = olen ; <nl> - <nl> - if (!( buf = malloc ( len )) || !( ret = malloc ( len * 2 + 1 ))) <nl> + if (!( buf = malloc ( len ))) { <nl> return R_FALSE ; <nl> + } <nl> + if (!( ret = malloc ( len * 2 + 1 ))) { <nl> + free ( buf ); <nl> + return R_FALSE ; <nl> + } <nl> r_buf_read_at ( bin -> cur . buf , symbol -> offset , buf , len ); <nl> r_hex_bin2str ( buf , len , ret ); <nl> printf ("% s % s \ n ", symbol -> name , ret );
if ( <nl>  <nl> if (( sym = ( Elf_ ( Sym ) *) malloc ( 1 + bin -> shdr [ i ]. sh_size )) == NULL ) { <nl> eprintf (" malloc ( syms )"); <nl> + free ( ret ); <nl> + free ( strtab ); <nl> return NULL ; <nl> } <nl> nsym = ( int )( bin -> shdr [ i ]. sh_size / sizeof ( Elf_ ( Sym )));
VRND_CryptoQuality ( void * ptr , size_t len ) <nl> ssize_t l ; <nl>  <nl> AN ( ptr ); <nl> - fd = open ("/ dev / random ", O_RDONLY ); <nl> + fd = open ("/ dev / urandom ", O_RDONLY ); <nl> if ( fd < 0 ) <nl> return (- 1 ); <nl> for ( p = ptr ; len > 0 ; len --, p ++) {
static int end_of_file = 0 ; <nl>  <nl> struct top { <nl> uint8_t tag ; <nl> - char * rec_data ; <nl> + const char * rec_data ; <nl> + char * rec_buf ; <nl> int clen ; <nl> unsigned hash ; <nl> VRB_ENTRY ( top ) e_order ; <nl> accumulate ( struct VSL_data * vsl , struct VSL_transaction * const pt [], <nl> t . hash = u ; <nl> t . tag = tag ; <nl> t . clen = len ; <nl> - t . rec_data = ( char *) VSL_CDATA ( tr -> c -> rec . ptr ); <nl> + t . rec_data = VSL_CDATA ( tr -> c -> rec . ptr ); <nl>  <nl> AZ ( pthread_mutex_lock (& mtx )); <nl> tp = VRB_FIND ( t_key , & h_key , & t ); <nl> accumulate ( struct VSL_data * vsl , struct VSL_transaction * const pt [], <nl> tp -> count = 1 . 0 ; <nl> tp -> clen = len ; <nl> tp -> tag = tag ; <nl> - tp -> rec_data = strdup ( t . rec_data ); <nl> + tp -> rec_buf = strdup ( t . rec_data ); <nl> + tp -> rec_data = tp -> rec_buf ; <nl> AN ( tp -> rec_data ); <nl> VRB_INSERT ( t_key , & h_key , tp ); <nl> VRB_INSERT ( t_order , & h_order , tp ); <nl> update ( int p ) <nl> if ( tp -> count * 10 < t || l > LINES * 10 ) { <nl> VRB_REMOVE ( t_key , & h_key , tp ); <nl> VRB_REMOVE ( t_order , & h_order , tp ); <nl> - free ( tp -> rec_data ); <nl> + free ( tp -> rec_buf ); <nl> free ( tp ); <nl> ntop --; <nl> }
void <nl> mgt_shm_atexit ( void ) <nl> { <nl>  <nl> + /* Do not let VCC kill our VSM */ <nl> + if ( getpid () != mgt_pid ) <nl> + return ; <nl> if ( heritage . vsm != NULL ) <nl> VSM_common_delete (& heritage . vsm ); <nl> }
main ( int argc , char * const * argv ) <nl> if ( b_arg != NULL && f_arg != NULL ) { <nl> fprintf ( stderr , " Only one of - b or - f can be specified \ n "); <nl> usage (); <nl> - } else if ( S_arg == NULL && T_arg == NULL ) { <nl> + } <nl> + if ( S_arg == NULL && T_arg == NULL && d_flag == 0 && b_arg == NULL && <nl> + f_arg == NULL ) { <nl> fprintf ( stderr , <nl> " At least one of - d , - b , - f , - S or - T must be specified \ n "); <nl> usage ();
h_ncsa ( void * priv , enum VSL_tag_e tag , unsigned fd , <nl> const char * p ; <nl> struct vsb * os ; <nl>  <nl> + /* XXX : Ignore fd ' s outside 65536 */ <nl> + if ( fd >= 65536 ) <nl> + return ( reopen ); <nl> + <nl> if ( fd >= nll ) { <nl> struct logline ** newll = ll ; <nl> size_t newnll = nll ;
EXP_Touch ( const struct object * o , double now ) <nl>  <nl> CHECK_OBJ_NOTNULL ( o , OBJECT_MAGIC ); <nl> oe = o -> objexp ; <nl> + if ( oe == NULL ) <nl> + return ; <nl> CHECK_OBJ_NOTNULL ( oe , OBJEXP_MAGIC ); <nl> if ( oe -> lru_stamp + params -> lru_timeout > now ) <nl> return ;
cli_backend_set_health ( struct cli * cli , const char * const * av , void * priv ) <nl>  <nl> static struct cli_proto backend_cmds [] = { <nl> { " backend . list ", " backend . list ", <nl> - "\ tList all backends \ n ", 0 , 1 , " d ", cli_backend_list }, <nl> + "\ tList all backends \ n ", 0 , 1 , "", cli_backend_list }, <nl> { " backend . set_health ", " backend . set_health matcher state ", <nl> - "\ tShow a backend \ n ", 2 , 2 , " d ", cli_backend_set_health }, <nl> + "\ tShow a backend \ n ", 2 , 2 , "", cli_backend_set_health }, <nl> { NULL } <nl> }; <nl> 
# endif <nl>  <nl> # include < sys / stat . h > <nl> +# include < sys / utsname . h > <nl> # include < stdio . h > <nl> # include < stdint . h > <nl> # include < stdlib . h > <nl> static void start_civetweb ( int argc , char * argv []) <nl> printf ("% s - Symbian \ n ", g_server_base_name ); <nl> # endif <nl> # else <nl> - struct utsname name = { 0 }; <nl> + struct utsname name ; <nl> + memset (& name , 0 , sizeof ( name )); <nl> uname (& name ); <nl> printf ("\ n % s \ n ", g_server_name ); <nl> printf ("% s - % s % s (% s ) - % s \ n ",
int main ( int argc , char * argv [], char * envp []) { <nl>  <nl> plugins_requested = getenv (" UWSGI_PLUGINS "); <nl> if ( plugins_requested ) { <nl> + plugins_requested = uwsgi_concat2 ( plugins_requested , ""); <nl> char * p = strtok ( plugins_requested , ","); <nl> while ( p != NULL ) { <nl> uwsgi_load_plugin (- 1 , p , NULL , 0 ); <nl> static int manage_base_opt ( int i , char * optarg ) { <nl> uwsgi . allowed_modifiers = optarg ; <nl> return 1 ; <nl> case LONG_ARGS_PLUGINS : <nl> - p = strtok ( optarg , ","); <nl> + p = strtok ( uwsgi_concat2 ( optarg , ""), ","); <nl> while ( p != NULL ) { <nl> # ifdef UWSGI_DEBUG <nl> uwsgi_debug (" loading plugin % s \ n ", p );
int http_parse ( struct http_session * h_session ) { <nl> hv = hv -> next ; <nl> } <nl>  <nl> + // security check <nl> + if ( c >= MAX_HTTP_VEC - 4 ) { <nl> + uwsgi_log (" too much headers in request . skipping it .\ n "); <nl> + return 0 ; <nl> + } <nl> + <nl> return c ; <nl>  <nl> }
public : <nl> size_t size () const { return lmap_ . size (); } <nl> size_t num_iters () const ; <nl>  <nl> + bool empty () const { return lmap_ . empty (); } <nl> + <nl> void clear ( bool force = false ); <nl>  <nl> /**
static bool localized_file_uptodate ( const std :: string & loc_file ) <nl> // First call , parse track index to collect fuzzy files by path . <nl> std :: string fsep = "\ xC2 \ xA6 "; // UTF - 8 for " broken bar " <nl> std :: string trackpath = filesystem :: get_binary_file_location ("", " l10n - track "); <nl> + <nl> + // l10n - track file not present . Assume image is up - to - date . <nl> + if ( trackpath . empty ()) { <nl> + return true ; <nl> + } <nl> + <nl> std :: string contents = filesystem :: read_file ( trackpath ); <nl>  <nl> for ( const std :: string & line : utils :: split ( contents , '\ n ')) {
bool ai_default_recruitment_stage :: recruit_usage ( const std :: string & usage ) <nl>  <nl> if ( imc != maximum_counts_ . end ()) { <nl> int count_active = 0 ; <nl> - for ( unit_map :: iterator u = get_info (). units . begin (); u != get_info (). units . end (); u ++) { <nl> + for ( unit_map :: iterator u = get_info (). units . begin (); u != get_info (). units . end (); ++ u ) { <nl> if (( u -> second . side ()== get_side ()) && (! u -> second . incapacitated ()) && ( u -> second . type_id () == name )) { <nl> - count_active ++; <nl> + ++ count_active ; <nl> } <nl> } <nl> 
void textbox :: set_text ( std :: string text ) <nl> { <nl> text_ = string_to_wstring ( text ); <nl> cursor_ = text_ . size (); <nl> + selstart_ = - 1 ; <nl> + selend_ = - 1 ; <nl> set_dirty ( true ); <nl> update_text_cache ( true ); <nl> } <nl> void textbox :: clear () <nl> cursor_ = 0 ; <nl> cursor_pos_ = 0 ; <nl> text_pos_ = 0 ; <nl> + selstart_ = - 1 ; <nl> + selend_ = - 1 ; <nl> set_dirty ( true ); <nl> update_text_cache ( true ); <nl> }
bool unit :: internal_matches_filter ( const vconfig & cfg , const gamemap :: location & <nl> std :: vector < std :: pair < int , int > >:: const_iterator range , range_end = ranges . end (); <nl> for ( range = ranges . begin (); range != range_end ; ++ range ) { <nl> for ( int i = range -> first ; i <= range -> second ; ++ i ) { <nl> - if ( i > 0 && i <= teams_ -> size ()) { <nl> + if ( i > 0 && static_cast < size_t >( i ) <= teams_ -> size ()) { <nl> viewers . insert ( i ); <nl> } <nl> } <nl> bool unit :: internal_matches_filter ( const vconfig & cfg , const gamemap :: location & <nl> } else { <nl> // if viewing_side is not defined , default to all enemies <nl> const team & my_team = (* teams_ )[ this -> side ()- 1 ]; <nl> - for ( int i = 1 ; i <= teams_ -> size (); ++ i ) { <nl> + for ( size_t i = 1 ; i <= teams_ -> size (); ++ i ) { <nl> if ( my_team . is_enemy ( i )) { <nl> viewers . insert ( i ); <nl> }
void unit_attack ( <nl> int swing , std :: string hit_text ) <nl> { <nl> game_display * disp = game_display :: get_singleton (); <nl> - if (! disp ) return ; <nl> + if (! disp || preferences :: show_combat () == false ) return ; <nl> unit_map & units = disp -> get_units (); <nl> disp -> select_hex ( gamemap :: location :: null_location ); <nl> - const bool hide = disp -> video (). update_locked () || disp -> fogged ( a ) && disp -> fogged ( b ) <nl> - || preferences :: show_combat () == false ; <nl> + const bool hide = disp -> video (). update_locked () || disp -> fogged ( a ) && disp -> fogged ( b ); <nl>  <nl> if (! hide ) { <nl> disp -> scroll_to_tiles ( a , b , game_display :: ONSCREEN ); <nl> void unit_attack ( <nl> } <nl> } <nl>  <nl> - <nl> - <nl> - <nl> - <nl> animator . start_animations (); <nl> animator . wait_for_end (); <nl> 
std :: string server :: process_command ( const std :: string & query ) { <nl> } else if ( command == " status ") { <nl> out << " STATUS REPORT \ n "; <nl> for ( player_map :: const_iterator pl = players_ . begin (); pl != players_ . end (); ++ pl ) { <nl> - if ( parameters == "" || utils :: wildcard_string_match ( pl -> second . name (), parameters )) { <nl> + if ( parameters == "" <nl> + || utils :: wildcard_string_match ( pl -> second . name (), parameters ) <nl> + || utils :: wildcard_string_match ( network :: ip_address ( pl -> first ), parameters )) { <nl> const network :: connection_stats & stats = network :: get_connection_stats ( pl -> first ); <nl> const int time_connected = stats . time_connected / 1000 ; <nl> const int seconds = time_connected % 60 ; <nl> std :: string server :: process_command ( const std :: string & query ) { <nl> } else { <nl> out << " Command '" << command << "' is not recognized .\ n "; <nl> out << " Available commands are : ( lobby ) msg < message >, motd [< message >]" <nl> - ", status [< nickmask >], metrics , ( k ) ban ( s ) [< mask >], unban < ipmask >" <nl> + ", status [< mask >], metrics , ( k ) ban ( s ) [< mask >], unban < ipmask >" <nl> ", kick < mask >"; <nl> } <nl> 
class grid : public widget <nl> public : <nl> explicit grid ( const unsigned rows = 0 , const unsigned cols = 0 ); <nl>  <nl> + /** Delete the copy constructor . */ <nl> + grid ( const grid &) = delete ; <nl> + <nl> + /** Delete the move assignment operator . */ <nl> + grid & operator =( const grid &) = delete ; <nl> + <nl> virtual ~ grid (); <nl>  <nl> /***** ***** ***** ***** LAYOUT FLAGS ***** ***** ***** *****/
namespace <nl> */ <nl> grid * row_grid = list . get_row_grid ( list . get_selected_row ()); <nl> if ( toggle_button * checkbox = find_widget < toggle_button >( row_grid , " checkbox ", false , false )) { <nl> - checkbox -> set_value_bool (! checkbox -> get_value_bool ()); <nl> + checkbox -> set_value_bool (! checkbox -> get_value_bool (), true ); <nl> } <nl> } <nl> 
void unit :: restart_animation ( const game_display & disp , int start_time ) { <nl> } <nl>  <nl> void unit :: set_facing ( gamemap :: location :: DIRECTION dir ) { <nl> - wassert ( dir != gamemap :: location :: NDIRECTIONS ); <nl> - facing_ = dir ; <nl> + if ( dir != gamemap :: location :: NDIRECTIONS ) { <nl> + facing_ = dir ; <nl> + } <nl> + // else look at yourself ( not available so continue to face the same direction ) <nl> } <nl>  <nl> void unit :: redraw_unit ( game_display & disp , const gamemap :: location & loc )
void room_manager :: load_config ( const config & cfg ) <nl> { <nl> filename_ = cfg [" room_save_file "]; <nl> compress_stored_rooms_ = utils :: string_bool ( cfg [" compress_stored_rooms "], true ); <nl> - new_room_policy_ = pp_from_string ( cfg [" new_room_policy "]); <nl> + PRIVILEGE_POLICY pp = pp_from_string ( cfg [" new_room_policy "]); <nl> + if ( pp != PP_COUNT ) new_room_policy_ = pp ; <nl> } <nl>  <nl> const std :: string & room_manager :: storage_filename () const
std :: vector < std :: string > get_text () { <nl> "- Michel Loos ", <nl> "- Renato Cunha ", <nl> "- Srgio de Miranda Costa ", <nl> + "- Tiago Souza ( Salvador )", <nl>  <nl> " _ " N_ ("+ Russian Translation "), <nl> "- Alexandr Menovchicov ",
int intf_set_dialog_callback ( lua_State * L ) <nl> if ( gui2 :: clickable_item * c = dynamic_cast < gui2 :: clickable_item *>( w )) { <nl> static dialog_callback_wrapper wrapper ; <nl> c -> connect_click_handler ( std :: bind (& dialog_callback_wrapper :: forward , wrapper , w )); <nl> - } else if ( gui2 :: selectable_item * s = dynamic_cast < gui2 :: selectable_item *>( w )) { <nl> - connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* s ), std :: bind ( dialog_callback , _1 )); <nl> - } else if ( gui2 :: integer_selector * s = dynamic_cast < gui2 :: integer_selector *>( w )) { <nl> - connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* s ), std :: bind ( dialog_callback , _1 )); <nl> + } else if ( gui2 :: selectable_item * si = dynamic_cast < gui2 :: selectable_item *>( w )) { <nl> + connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* si ), std :: bind ( dialog_callback , _1 )); <nl> + } else if ( gui2 :: integer_selector * is = dynamic_cast < gui2 :: integer_selector *>( w )) { <nl> + connect_signal_notify_modified ( dynamic_cast < gui2 :: widget &>(* is ), std :: bind ( dialog_callback , _1 )); <nl> } <nl> # ifdef GUI2_EXPERIMENTAL_LISTBOX <nl> else if ( gui2 :: list_view * l = dynamic_cast < gui2 :: list_view *>( w )) {
namespace { <nl> bool terrain_matches_filter ( const gamemap & map , const gamemap :: location & loc , const vconfig & cfg , <nl> const gamestatus & game_status , const unit_map & units , const bool flat_tod , <nl> const size_t max_loop ) <nl> -{ <nl> +{ <nl> + if (! map . on_board ( loc )) return false ; <nl> + <nl> // handle radius <nl> const size_t radius = minimum < size_t >( max_loop , <nl> lexical_cast_default < size_t >( cfg [" radius "], 0 ));
int battle_context :: choose_defender_weapon ( const unit & attacker , const unit & def <nl> choices . push_back ( i ); <nl> } <nl> } <nl> - if ( choices . size () == 0 ) <nl> + if ( choices . empty ()) <nl> return - 1 ; <nl> if ( choices . size () == 1 ) <nl> return choices [ 0 ]; <nl> int battle_context :: choose_attacker_weapon ( const unit & attacker , const unit & def <nl> choices . push_back ( i ); <nl> } <nl> } <nl> - if ( choices . size () == 0 ) <nl> + if ( choices . empty ()) <nl> return - 1 ; <nl> if ( choices . size () == 1 ) { <nl> * defender_weapon = choose_defender_weapon ( attacker , defender , choices [ 0 ], units , <nl> void calculate_healing ( int side , bool update_display ) <nl> healers . push_back ( units . find ( heal_loc -> loc )); <nl> } <nl>  <nl> - if ( healers . size () > 0 ) { <nl> + if (! healers . empty ()) { <nl> DBG_NG << " Unit has " << healers . size () << " potential healers \ n "; <nl> } <nl>  <nl> void calculate_healing ( int side , bool update_display ) <nl> healing = neg_max ; <nl> } <nl>  <nl> - if ( healers . size () > 0 ) { <nl> + if (! healers . empty ()) { <nl> DBG_NG << " Just before healing animations , unit has " << healers . size () << " potential healers \ n "; <nl> } <nl> 
void turn_info :: left_click ( const SDL_MouseButtonEvent & event ) <nl> enemy == units_ . end () && ! current_route_ . steps . empty () && <nl> current_route_ . steps . front () == selected_hex_ ) { <nl>  <nl> + const std :: vector < gamemap :: location > steps = current_route_ . steps ; <nl> const size_t moves = move_unit (& gui_ , gameinfo_ , status_ , map_ , units_ , teams_ , <nl> - current_route_ . steps ,& recorder ,& undo_stack_ ,& next_unit_ ); <nl> + steps ,& recorder ,& undo_stack_ ,& next_unit_ ); <nl>  <nl> cursor :: set ( cursor :: NORMAL ); <nl>  <nl> void turn_info :: left_click ( const SDL_MouseButtonEvent & event ) <nl>  <nl> redo_stack_ . clear (); <nl>  <nl> - assert ( moves <= current_route_ . steps . size ()); <nl> - const gamemap :: location & dst = current_route_ . steps [ moves - 1 ]; <nl> + assert ( moves <= steps . size ()); <nl> + const gamemap :: location & dst = steps [ moves - 1 ]; <nl> const unit_map :: const_iterator u = units_ . find ( dst ); <nl>  <nl> // u may be equal to units_ . end () in the case of e . g . a [ teleport ] <nl> if ( u != units_ . end ()) { <nl> // Reselect the unit if the move was interrupted <nl> - if ( dst != current_route_ . steps . back ()) { <nl> + if ( dst != steps . back ()) { <nl> selected_hex_ = dst ; <nl> gui_ . select_hex ( dst ); <nl> }
namespace events { <nl> } <nl> } else if ( cmd == " clear ") { <nl> gui_ -> clear_chat_messages (); <nl> - } else if ( cmd == " sunset ") { <nl> + } else if ( game_config :: debug && cmd == " sunset ") { <nl> int delay = lexical_cast_default < int >( data ); <nl> gui_ -> sunset ( delay ); <nl> } else if ( cmd == " w ") {
DECLAREreadFunc ( readContigTilesIntoBuffer ) <nl> uint32 colb = 0 ; <nl> uint32 col ; <nl>  <nl> - for ( col = 0 ; col < imagewidth ; col += tw ) { <nl> + for ( col = 0 ; col < imagewidth && colb < imagew ; col += tw ) { <nl> if ( TIFFReadTile ( in , tilebuf , col , row , 0 , 0 ) < 0 <nl> && ! ignore ) { <nl> TIFFError ( TIFFFileName ( in ), <nl> DECLAREwriteFunc ( writeBufferToContigTiles ) <nl> uint32 colb = 0 ; <nl> uint32 col ; <nl>  <nl> - for ( col = 0 ; col < imagewidth ; col += tw ) { <nl> + for ( col = 0 ; col < imagewidth && colb < imagew ; col += tw ) { <nl> /* <nl> * Tile is clipped horizontally . Calculate <nl> * visible portion and skewing factors .
static bool do_lxcapi_reboot ( struct lxc_container * c ) <nl> return false ; <nl> if ( c -> lxc_conf && c -> lxc_conf -> rebootsignal ) <nl> rebootsignal = c -> lxc_conf -> rebootsignal ; <nl> - if ( kill ( pid , rebootsignal ) < 0 ) <nl> + if ( kill ( pid , rebootsignal ) < 0 ) { <nl> + WARN (" Could not send signal % d to pid % d .", rebootsignal , pid ); <nl> return false ; <nl> + } <nl> return true ; <nl>  <nl> } <nl> static bool do_lxcapi_shutdown ( struct lxc_container * c , int timeout ) <nl>  <nl> INFO (" Using signal number '% d ' as halt signal .", haltsignal ); <nl>  <nl> - kill ( pid , haltsignal ); <nl> + if ( kill ( pid , haltsignal ) < 0 ) <nl> + WARN (" Could not send signal % d to pid % d .", haltsignal , pid ); <nl> + <nl> retv = do_lxcapi_wait ( c , " STOPPED ", timeout ); <nl> return retv ; <nl> }
static int unit_file_search ( <nl>  <nl> _cleanup_free_ char * template = NULL ; <nl> _cleanup_strv_free_ char ** dirs = NULL ; <nl> - _cleanup_free_ char ** files = NULL ; <nl> + _cleanup_strv_free_ char ** files = NULL ; <nl> const char * dropin_dir_name = NULL ; <nl> const char * dropin_template_dir_name = NULL ; <nl> 
int main ( int argc , char * argv [], char * envp []) <nl>  <nl> reload_config = 1 ; <nl> buf = malloc ( nbytes ); <nl> - if ( buf != NULL ) { <nl> + if ( buf == NULL ) { <nl> err (" error getting buffer for inotify , disable watching "); <nl> close ( inotify_fd ); <nl> inotify_fd = - 1 ;
const SyscallFilterSet syscall_filter_sets [ _SYSCALL_FILTER_SET_MAX ] = { <nl> " reboot \ 0 " <nl> }, <nl> [ SYSCALL_FILTER_SET_RESOURCES ] = { <nl> - /* Alter resource settings */ <nl> . name = "@ resources ", <nl> + . help = " Alter resource settings ", <nl> . value = <nl> " sched_setparam \ 0 " <nl> " sched_setscheduler \ 0 "
static void item_free ( Item * i ) { <nl> free ( i -> uid_path ); <nl> free ( i -> gid_path ); <nl> free ( i -> description ); <nl> + free ( i -> home ); <nl> free ( i ); <nl> } <nl> 
static int change_uid_gid ( char ** _home ) { <nl> } <nl>  <nl> r = mkdir_safe ( home , 0755 , uid , gid ); <nl> - if ( r < 0 ) { <nl> + if ( r < 0 && r != - EEXIST ) { <nl> log_error (" Failed to make home directory : % s ", strerror (- r )); <nl> return r ; <nl> }
static int service_dispatch_timer ( sd_event_source * source , usec_t usec , void * us <nl>  <nl> case SERVICE_RELOAD : <nl> log_unit_warning ( UNIT ( s ), " Reload operation timed out . Stopping ."); <nl> + service_unwatch_control_pid ( s ); <nl> + service_kill_control_processes ( s ); <nl> s -> reload_result = SERVICE_FAILURE_TIMEOUT ; <nl> service_enter_running ( s , SERVICE_SUCCESS ); <nl> break ;
static int link_get_handler ( sd_rtnl * rtnl , sd_rtnl_message * m , void * userdata ) { <nl> link_enter_failed ( link ); <nl> } <nl>  <nl> + link_update ( link , m ); <nl> + <nl> return 1 ; <nl> } <nl> 
static int parse_line ( const char * fname , unsigned line , const char * buffer , bool <nl> } <nl> } else { <nl> existing = new0 ( ItemArray , 1 ); <nl> + if (! existing ) <nl> + return log_oom (); <nl> + <nl> r = ordered_hashmap_put ( h , i . path , existing ); <nl> if ( r < 0 ) <nl> return log_oom ();
static int enable_unit ( DBusConnection * bus , char ** args ) { <nl> int r ; <nl> DBusError error ; <nl>  <nl> - dbus_error_init (& error ); <nl> - <nl> r = enable_sysv_units ( args ); <nl> if ( r < 0 ) <nl> return r ; <nl>  <nl> + if (! args [ 1 ]) <nl> + return 0 ; <nl> + <nl> + dbus_error_init (& error ); <nl> + <nl> if (! bus || avoid_bus ()) { <nl> if ( streq ( verb , " enable ")) { <nl> r = unit_file_enable ( arg_scope , arg_runtime , arg_root , args + 1 , arg_force , & changes , & n_changes );
static void service_set_state ( Service * s , ServiceState state ) { <nl> /* For remain_after_exit services , let ' s see if we can " release " the <nl> * hold on the console , since unit_notify () only does that in case of <nl> * change of state */ <nl> - if ( state == SERVICE_EXITED && s -> remain_after_exit && <nl> + if ( state == SERVICE_EXITED && <nl> + s -> remain_after_exit && <nl> UNIT ( s )-> manager -> n_on_console > 0 ) { <nl> - ExecContext * ec = unit_get_exec_context ( UNIT ( s )); <nl> + <nl> + ExecContext * ec ; <nl> + <nl> + ec = unit_get_exec_context ( UNIT ( s )); <nl> if ( ec && exec_context_may_touch_console ( ec )) { <nl> Manager * m = UNIT ( s )-> manager ; <nl> 
static int add_epoll ( int epoll_fd , int fd ) { <nl>  <nl> ev . data . fd = fd ; <nl> r = epoll_ctl ( epoll_fd , EPOLL_CTL_ADD , fd , & ev ); <nl> - if ( r < 0 ) <nl> - log_error (" Failed to add event on epoll fd :% d for fd :% d : % m ", <nl> - epoll_fd , fd ); <nl> - return - errno ; <nl> + if ( r < 0 ) { <nl> + log_error (" Failed to add event on epoll fd :% d for fd :% d : % m ", epoll_fd , fd ); <nl> + return - errno ; <nl> + } <nl> + <nl> + return 0 ; <nl> } <nl>  <nl> static int make_socket_fd ( const char * address , int flags ) {
int fstab_find_pri ( const char * options , int * ret ) { <nl> if ( r < 0 ) <nl> return r ; <nl>  <nl> + if (( int ) pri < 0 ) <nl> + return - ERANGE ; <nl> + <nl> * ret = ( int ) r ; <nl> return 1 ; <nl> }
int main ( int argc , char * argv []) { <nl> } <nl> } <nl>  <nl> + free ( arg_root_what ); <nl> + <nl> return r < 0 ? EXIT_FAILURE : EXIT_SUCCESS ; <nl> }
int machine_id_setup ( void ) { <nl>  <nl> m = umask ( 0000 ); <nl>  <nl> - if (( fd = open ("/ etc / machine - id ", O_RDWR | O_CREAT | O_CLOEXEC | O_NOCTTY , 0644 )) >= 0 ) <nl> + /* We create this 0444 , to indicate that this isn ' t really <nl> + * something you should ever modify . Of course , since the file <nl> + * will be owned by root it doesn ' t matter much , but maybe <nl> + * people look . */ <nl> + <nl> + if (( fd = open ("/ etc / machine - id ", O_RDWR | O_CREAT | O_CLOEXEC | O_NOCTTY , 0444 )) >= 0 ) <nl> writable = true ; <nl> else { <nl> if (( fd = open ("/ etc / machine - id ", O_RDONLY | O_CLOEXEC | O_NOCTTY )) < 0 ) {
static int parse_argv ( int argc , char * argv []) { <nl> return - EINVAL ; <nl> } <nl>  <nl> + if ( arg_userns && access ("/ proc / self / uid_map ", F_OK ) < 0 ) <nl> + return log_error_errno ( EOPNOTSUPP , "-- private - users = is not supported , kernel compiled without user namespace support ."); <nl> + <nl> arg_retain = ( arg_retain | plus | ( arg_private_network ? 1ULL << CAP_NET_ADMIN : 0 )) & ~ minus ; <nl>  <nl> if ( arg_boot && arg_kill_signal <= 0 )
void initialize_srand ( void ) { <nl>  <nl> auxv = ( void *) getauxval ( AT_RANDOM ); <nl> if ( auxv ) { <nl> - assert_cc ( sizeof ( x ) < 16 ); <nl> + assert_cc ( sizeof ( x ) <= 16 ); <nl> memcpy (& x , auxv , sizeof ( x )); <nl> } else <nl> # endif
int button_open ( Button * b ) { <nl> } <nl>  <nl> ( void ) button_set_mask ( b ); <nl> - <nl> + <nl> + b -> io_event_source = sd_event_source_unref ( b -> io_event_source ); <nl> r = sd_event_add_io ( b -> manager -> event , & b -> io_event_source , b -> fd , EPOLLIN , button_dispatch , b ); <nl> if ( r < 0 ) { <nl> log_error_errno ( r , " Failed to add button event : % m ");
static int add_rtattr ( sd_rtnl_message * m , unsigned short type , const void * data , <nl> uint32_t rta_length , message_length ; <nl> struct nlmsghdr * new_hdr ; <nl> struct rtattr * rta ; <nl> + char * padding ; <nl>  <nl> assert_return ( m , - EINVAL ); <nl> assert_return ( m -> hdr , - EINVAL ); <nl> static int add_rtattr ( sd_rtnl_message * m , unsigned short type , const void * data , <nl> assert_return ( data , - EINVAL ); <nl> assert_return ( data_length > 0 , - EINVAL ); <nl>  <nl> - /* get the size of the new rta attribute ( without padding at the end ) */ <nl> + /* get the size of the new rta attribute ( with padding at the end ) */ <nl> rta_length = RTA_LENGTH ( data_length ); <nl> - /* get the new message size ( with padding between the old message and the new attrib , <nl> - * but no padding after ) <nl> + /* get the new message size ( with padding at the end ) <nl> */ <nl> message_length = m -> hdr -> nlmsg_len + RTA_ALIGN ( rta_length ); <nl>  <nl> static int add_rtattr ( sd_rtnl_message * m , unsigned short type , const void * data , <nl> /* we don ' t deal with the case where the user lies about the type and gives us <nl> * too little data ( so don ' t do that ) <nl> */ <nl> - memcpy ( RTA_DATA ( rta ), data , data_length ); <nl> + padding = mempcpy ( RTA_DATA ( rta ), data , data_length ); <nl> + /* make sure also the padding at the end of the message is initialized */ <nl> + memset ( padding , '\ 0 ', ( unsigned char *) m -> hdr + m -> hdr -> nlmsg_len - ( unsigned char *) padding ); <nl>  <nl> return 0 ; <nl> }
static int handle_response ( sd_resolve * resolve , const Packet * packet , size_t len <nl>  <nl> if ( ni_resp -> hostlen > DNS_HOSTNAME_MAX || <nl> ni_resp -> servlen > DNS_HOSTNAME_MAX || <nl> - sizeof ( NameInfoResponse ) + ni_resp -> hostlen + ni_resp -> servlen > length + 2 ) <nl> + sizeof ( NameInfoResponse ) + ni_resp -> hostlen + ni_resp -> servlen > length ) <nl> ASSIGN_ERRNO ( q , EAI_SYSTEM , EIO , 0 ); <nl>  <nl> else {
int main ( int argc , char ** argv ) <nl> while ( dev != NULL && udev_device_get_sysattr_value ( dev , " capabilities / key ") == NULL ) <nl> dev = udev_device_get_parent ( dev ); <nl>  <nl> + /* not an " input " class device */ <nl> + if ( dev == NULL ) <nl> + return 0 ; <nl> + <nl> /* Use this as a flag that input devices were detected , so that this <nl> * program doesn ' t need to be called more than once per device */ <nl> puts (" ID_INPUT = 1 ");
static int sysv_chkconfig_order ( Service * s ) { <nl> if ( t -> sysv_start_priority < 0 ) <nl> continue ; <nl>  <nl> - if ( s -> sysv_has_lsb && t -> sysv_has_lsb ) <nl> + /* If both units have modern headers we don ' t care <nl> + * about the priorities */ <nl> + if ((! s -> sysv_path || s -> sysv_has_lsb ) && <nl> + (! t -> sysv_path || t -> sysv_has_lsb )) <nl> continue ; <nl>  <nl> if ( t -> sysv_start_priority < s -> sysv_start_priority )
gtkutil_file_req ( const char * title , void * callback , void * userdata , char * filte <nl>  <nl> g_free ( tokenbuffer ); <nl> gtk_file_chooser_set_filter ( GTK_FILE_CHOOSER ( dialog ), filefilter ); <nl> - g_free ( filefilter ); <nl> } <nl>  <nl> freq = malloc ( sizeof ( struct file_req ));
gtk_xtext_new ( GdkColor palette [], int separator ) <nl> } <nl>  <nl> static void <nl> - gtk_xtext_destroy ( GObject * object ) <nl> + gtk_xtext_destroy ( GtkObject * object ) <nl> { <nl> GtkXText * xtext = GTK_XTEXT ( object ); <nl>  <nl> gtk_xtext_scroll ( GtkWidget * widget , GdkEventScroll * event ) <nl> static void <nl> gtk_xtext_class_init ( GtkXTextClass * class ) <nl> { <nl> - GObjectClass * object_class ; <nl> + GtkObjectClass * object_class ; <nl> GtkWidgetClass * widget_class ; <nl> GtkXTextClass * xtext_class ; <nl>  <nl> gtk_xtext_class_init ( GtkXTextClass * class ) <nl> widget_class = ( GtkWidgetClass *) class ; <nl> xtext_class = ( GtkXTextClass *) class ; <nl>  <nl> - parent_class = g_type_class_peek ( g_object_get_type ()); <nl> + parent_class = g_type_class_peek ( gtk_widget_get_type ()); <nl>  <nl> xtext_signals [ WORD_CLICK ] = <nl> g_signal_new (" word_click ", <nl> gtk_xtext_class_init ( GtkXTextClass * class ) <nl> gtk_marshal_VOID__POINTER_POINTER , <nl> G_TYPE_NONE , <nl> 2 , G_TYPE_POINTER , G_TYPE_POINTER ); <nl> - object_class -> dispose = gtk_xtext_destroy ; <nl> + object_class -> destroy = gtk_xtext_destroy ; <nl>  <nl> widget_class -> realize = gtk_xtext_realize ; <nl> widget_class -> unrealize = gtk_xtext_unrealize ;
process_named_servermsg ( session * sess , char * buf , char * rawname , char * word_eol <nl> EMIT_SIGNAL ( XP_TE_SERVNOTICE , sess , buf , sess -> server -> servername , NULL , NULL , 0 ); <nl> return ; <nl> } <nl> + if (! strncmp ( buf , " AUTHENTICATE +", 14 )) /* omit SASL " empty " responses */ <nl> + { <nl> + return ; <nl> + } <nl>  <nl> EMIT_SIGNAL ( XP_TE_SERVTEXT , sess , buf , sess -> server -> servername , rawname , NULL , 0 ); <nl> }
void _logsys_log_printf ( <nl> subsysid = LOGSYS_MAX_SUBSYS_COUNT ; <nl> } <nl>  <nl> + if (( level > logsys_loggers [ subsysid ]. syslog_priority ) && <nl> + ( level > logsys_loggers [ subsysid ]. logfile_priority )) { <nl> + return ; <nl> + } <nl> + <nl> va_start ( ap , format ); <nl> len = vsprintf ( logsys_print_buffer , format , ap ); <nl> va_end ( ap );
void _logsys_log_vprintf ( <nl> } <nl>  <nl> if (( level > logsys_loggers [ subsysid ]. syslog_priority ) && <nl> - ( level > logsys_loggers [ subsysid ]. logfile_priority )) { <nl> + ( level > logsys_loggers [ subsysid ]. logfile_priority ) && <nl> + ( logsys_loggers [ subsysid ]. debug == 0 )) { <nl> return ; <nl> } <nl>  <nl> void _logsys_log_printf ( <nl> } <nl>  <nl> if (( level > logsys_loggers [ subsysid ]. syslog_priority ) && <nl> - ( level > logsys_loggers [ subsysid ]. logfile_priority )) { <nl> + ( level > logsys_loggers [ subsysid ]. logfile_priority ) && <nl> + ( logsys_loggers [ subsysid ]. debug == 0 )) { <nl> return ; <nl> } <nl> 
saEvtEventAttributesSet ( <nl> struct event_data_instance * edi ; <nl> int i ; <nl>  <nl> + if ( priority < SA_EVT_HIGHEST_PRIORITY || <nl> + priority > SA_EVT_LOWEST_PRIORITY ) { <nl> + return SA_AIS_ERR_INVALID_PARAM ; <nl> + } <nl> + <nl> error = saHandleInstanceGet (& event_handle_db , eventHandle , <nl> ( void *)& edi ); <nl> if ( error != SA_AIS_OK ) {
static void memb_state_gather_enter ( <nl>  <nl> instance -> memb_state = MEMB_STATE_GATHER ; <nl> instance -> stats . gather_entered ++; <nl> - instance -> stats . continuous_gather ++; <nl> + <nl> + if ( gather_from == 3 ) { <nl> + /* <nl> + * State 3 means gather , so we are continuously gathering . <nl> + */ <nl> + instance -> stats . continuous_gather ++; <nl> + } <nl>  <nl> if ( instance -> stats . continuous_gather > MAX_NO_CONT_GATHER ) { <nl> log_printf ( instance -> totemsrp_log_level_warning ,
ev_view_accessible_focus_changed ( GtkWidget * widget , <nl> g_return_val_if_fail ( EV_IS_VIEW ( widget ), FALSE ); <nl> g_return_val_if_fail ( EV_IS_VIEW_ACCESSIBLE ( self ), FALSE ); <nl>  <nl> - if ( self -> priv -> children == NULL ) <nl> + if ( self -> priv -> children == NULL || self -> priv -> children -> len == 0 ) <nl> return FALSE ; <nl>  <nl> page_accessible = g_ptr_array_index ( self -> priv -> children ,
ev_view_select_all ( EvView * view ) <nl> } <nl>  <nl> merge_selection_region ( view , g_list_reverse ( selections )); <nl> - gtk_widget_queue_draw ( GTK_WIDGET ( view )); <nl> } <nl>  <nl> gboolean
ev_window_save_job_cb ( EvJob * job , <nl> ev_window_error_message ( window , job -> error , <nl> _ (" The file could not be saved as % s ."), <nl> EV_JOB_SAVE ( job )-> uri ); <nl> + } else { <nl> + ev_window_add_recent ( window , EV_JOB_SAVE ( job )-> uri ); <nl> } <nl>  <nl> ev_window_clear_save_job ( window );
siox_cache_remove_fg ( gpointer key , <nl> * Initializes the SIOX segmentator . <nl> * Creates and returns a SioxState struct that has to be passed to all <nl> * function calls of this module as it maintaines the state . <nl> + * <nl> +'* Returns : a new siox state structure . <nl> */ <nl> SioxState * <nl> siox_init ( TileManager * pixels , <nl> siox_init ( TileManager * pixels , <nl> * a good value is : { 0 . 64 , 1 . 28 , 2 . 56 } <nl> * @ smoothness : boundary smoothness ( a good value is 3 ) <nl> * @ multiblob : allow multiple blobs ( true ) or only one ( false ) <nl> + * @ progress_callback : a progress callback <nl> + * @ progress_data : data passed to @ progress_callback <nl> * <nl> * Writes the resulting segmentation into @ mask . The region of <nl> * interest as specified using @ x1 , @ y1 , @ x2 and @ y2 defines the
ReadImage ( FILE * fd , <nl> } <nl>  <nl> if ( alpha_frame ) <nl> - dest = ( guchar *) g_malloc ( len * height * ( promote_to_rgb ? 4 : 2 )); <nl> + dest = ( guchar *) g_malloc (( gsize ) len * ( gsize ) height * ( promote_to_rgb ? 4 : 2 )); <nl> else <nl> - dest = ( guchar *) g_malloc ( len * height ); <nl> + dest = ( guchar *) g_malloc (( gsize ) len * ( gsize ) height ); <nl>  <nl> # ifdef GIFDEBUG <nl> g_print (" GIF : reading % d by % d % s GIF image , ncols =% d \ n ",
gimp_tile_backend_plugin_command ( GeglTileSource * tile_store , <nl> break ; <nl>  <nl> default : <nl> - g_assert ( command < GEGL_TILE_LAST_COMMAND && command >= 0 ); <nl> + /* g_assert ( command < GEGL_TILE_LAST_COMMAND && command >= 0 ); */ <nl> + break ; <nl> } <nl>  <nl> return result ;
metadata_message_dialog ( GtkMessageType type , <nl> { <nl> GtkWidget * dlg ; <nl>  <nl> - dlg = gtk_message_dialog_new ( parent , 0 , type , GTK_BUTTONS_OK , message ); <nl> + dlg = gtk_message_dialog_new ( parent , 0 , type , GTK_BUTTONS_OK , "% s ", message ); <nl>  <nl> if ( title ) <nl> gtk_window_set_title ( GTK_WINDOW ( dlg ), title );
gimp_histogram_view_notify ( GimpHistogram * histogram , <nl> static void <nl> gimp_histogram_view_update_bins ( GimpHistogramView * view ) <nl> { <nl> - gint new_bins ; <nl> + gint new_bins = 256 ; <nl>  <nl> if ( view -> histogram ) <nl> new_bins = gimp_histogram_n_bins ( view -> histogram );
gui_unique_win32_idle_open ( IdleOpenData * data ) <nl> if ( data -> file ) <nl> { <nl> file_open_from_command_line ( unique_gimp , data -> file , <nl> - data -> as_new , NULL , 0 ); <nl> + data -> as_new , NULL ); <nl> } <nl> else <nl> { <nl> gui_unique_quartz_idle_open ( GFile * file ) <nl>  <nl> if ( file ) <nl> { <nl> - file_open_from_command_line ( unique_gimp , file , FALSE , NULL , 0 ); <nl> + file_open_from_command_line ( unique_gimp , file , FALSE , NULL ); <nl> } <nl>  <nl> return FALSE ;
app_run ( const gchar * full_prog_name , <nl> /* change the locale if a language if specified */ <nl> language_init ( gimp -> config -> language ); <nl>  <nl> + /* initialize lowlevel stuff */ <nl> + gimp_gegl_init ( gimp ); <nl> + <nl> /* Connect our restore_after callback before gui_init () connects <nl> * theirs , so ours runs first and can grab the initial monitor <nl> * before the GUI ' s restore_after callback resets it . <nl> app_run ( const gchar * full_prog_name , <nl> if (! update_status_func ) <nl> update_status_func = app_init_update_noop ; <nl>  <nl> - /* initialize lowlevel stuff */ <nl> - gimp_gegl_init ( gimp ); <nl> - <nl> /* Create all members of the global Gimp instance which need an already <nl> * parsed gimprc , e . g . the data factories <nl> */
gimp_gegl_mask_bounds ( GeglBuffer * buffer , <nl> */ <nl> if ( data [ 0 ] && data [ iter -> length - 1 ]) <nl> { <nl> + /* " ex / ey - 1 " because the internal variables are the <nl> + * right / bottom pixel of the mask ' s contents , not one <nl> + * right / below it like the return values . <nl> + */ <nl> + <nl> if ( roi -> x < tx1 ) tx1 = roi -> x ; <nl> - if ( ex > tx2 ) tx2 = ex ; <nl> + if ( ex > tx2 ) tx2 = ex - 1 ; <nl>  <nl> if ( roi -> y < ty1 ) ty1 = roi -> y ; <nl> - if ( ey > ty2 ) ty2 = ey ; <nl> + if ( ey > ty2 ) ty2 = ey - 1 ; <nl> } <nl> else <nl> {
hb_ot_map_builder_t :: compile ( hb_ot_map_t & m ) <nl> for ( unsigned int table_index = 0 ; table_index < 2 ; table_index ++) <nl> { <nl> if ( required_feature_tag [ table_index ] == info -> tag ) <nl> - { <nl> required_feature_stage [ table_index ] = info -> stage [ table_index ]; <nl> - found = true ; <nl> - continue ; <nl> - } <nl> + <nl> found |= hb_ot_layout_language_find_feature ( face , <nl> table_tags [ table_index ], <nl> script_index [ table_index ],
_hb_ot_shape_normalize ( hb_font_t * font , hb_buffer_t * buffer , <nl> } <nl>  <nl> hb_codepoint_t composed , glyph ; <nl> - if (( buffer -> out_info [ buffer -> out_len - 1 ]. combining_class () < buffer -> info [ buffer -> idx ]. combining_class ()) && <nl> + if (( starter == buffer -> out_len - 1 || <nl> + buffer -> out_info [ buffer -> out_len - 1 ]. combining_class () < buffer -> info [ buffer -> idx ]. combining_class ()) && <nl> hb_unicode_compose ( buffer -> unicode , <nl> buffer -> out_info [ starter ]. codepoint , <nl> buffer -> info [ buffer -> idx ]. codepoint ,
class dmt { <nl> __attribute__ (( nonnull )) <nl> void rebalance ( subtree * const subtree ); <nl>  <nl> - __attribute__ (( nonnull )) <nl> + __attribute__ (( nonnull ( 3 ))) <nl> static void copyout ( uint32_t * const outlen , dmtdata_t * const out , const dmt_node * const n ); <nl>  <nl> - __attribute__ (( nonnull )) <nl> + __attribute__ (( nonnull ( 3 ))) <nl> static void copyout ( uint32_t * const outlen , dmtdata_t ** const out , dmt_node * const n ); <nl>  <nl> - __attribute__ (( nonnull )) <nl> + __attribute__ (( nonnull ( 4 ))) <nl> static void copyout ( uint32_t * const outlen , dmtdata_t * const out , const uint32_t len , const dmtdata_t * const stored_value_ptr ); <nl>  <nl> - __attribute__ (( nonnull )) <nl> + __attribute__ (( nonnull ( 4 ))) <nl> static void copyout ( uint32_t * const outlen , dmtdata_t ** const out , const uint32_t len , dmtdata_t * const stored_value_ptr ); <nl>  <nl> template < typename dmtcmp_t ,
row_scan_and_check_index ( <nl>  <nl> * n_rows = 0 ; <nl>  <nl> + if (! row_merge_is_index_usable ( prebuilt -> trx , index )) { <nl> + return ( is_ok ); <nl> + } <nl> + <nl> buf = mem_alloc ( UNIV_PAGE_SIZE ); <nl> heap = mem_heap_create ( 100 ); <nl>  <nl> row_scan_and_check_index ( <nl> in scanning the index entries */ <nl>  <nl> prebuilt -> index = index ; <nl> - prebuilt -> index_usable = row_merge_is_index_usable ( prebuilt -> trx , <nl> - index ); <nl> + prebuilt -> index_usable = TRUE ; <nl> prebuilt -> sql_stat_start = TRUE ; <nl> prebuilt -> template_type = ROW_MYSQL_DUMMY_TEMPLATE ; <nl> prebuilt -> n_template = 0 ;
referenced_xids_note_snapshot_txn_end_iter ( OMTVALUE live_xidv , u_int32_t UU ( inde <nl> if (-- tuple -> references == 0 ) { <nl> r = toku_omt_delete_at ( referenced_xids , idx ); <nl> lazy_assert_zero ( r ); <nl> + toku_free ( tuple ); <nl> } <nl> done : <nl> return 0 ;
void handler :: print_error ( int error , myf errflag ) <nl> { <nl> const char * engine = ha_get_storage_engine ( table -> db_type ); <nl> if ( temporary ) <nl> - my_error ( ER_GET_TEMPORARY_ERRMSG , error , msg , engine ); <nl> + my_error ( ER_GET_TEMPORARY_ERRMSG , MYF ( 0 ), error , msg , engine ); <nl> else <nl> - my_error ( ER_GET_ERRMSG , error , msg , engine ); <nl> + my_error ( ER_GET_ERRMSG , MYF ( 0 ), error , msg , engine ); <nl> } <nl> else <nl> my_error ( ER_GET_ERRNO , errflag , error );
static int connect_assisted_discovery ( handlerton *, THD * thd , <nl> break ; <nl> # if defined ( MONGO_SUPPORT ) <nl> case TAB_MONGO : <nl> + if (! topt -> tabname ) <nl> + topt -> tabname = tab ; <nl> + <nl> ok = true ; <nl> break ; <nl> # endif // MONGO_SUPPORT
_rl_fix_last_undo_of_type ( type , start , end ) <nl>  <nl> for ( rl = rl_undo_list ; rl ; rl = rl -> next ) <nl> { <nl> - if ( rl -> what == ( uint ) type ) <nl> + if ( rl -> what == ( unsigned int ) type ) <nl> { <nl> rl -> start = start ; <nl> rl -> end = end ;
FT_INFO * ft_init_boolean_search ( MI_INFO * info , uint keynr , byte * query , <nl> _ftb_parse_query ( ftb , & query , query + query_len , ftbe , 0 ); <nl> ftb -> list =( FTB_WORD **) alloc_root (& ftb -> mem_root , <nl> sizeof ( FTB_WORD *)* ftb -> queue . elements ); <nl> - memcpy ( ftb -> list , ftb -> queue . root , sizeof ( FTB_WORD *)* ftb -> queue . elements ); <nl> + memcpy ( ftb -> list , ftb -> queue . root + 1 , sizeof ( FTB_WORD *)* ftb -> queue . elements ); <nl> qsort2 ( ftb -> list , ftb -> queue . elements , sizeof ( FTB_WORD *), <nl> ( qsort2_cmp ) FTB_WORD_cmp_list , 0 ); <nl> if ( ftb -> queue . elements < 2 ) ftb -> with_scan = 0 ;
make_join_select ( JOIN * join , SQL_SELECT * select , COND * cond ) <nl> cond_tab -> select_cond -> quick_fix_field (); <nl> if ( cond_tab -> select ) <nl> cond_tab -> select -> cond = cond_tab -> select_cond ; <nl> - } <nl> + } <nl> + if ( tab == last_tab ) <nl> + break ; <nl> } <nl> first_inner_tab = first_inner_tab -> first_upper ; <nl> }
bool mysql_insert ( THD * thd , TABLE_LIST * table_list , <nl> error = 0 ; <nl> id = 0 ; <nl> thd -> proc_info =" update "; <nl> - if ( duplic != DUP_ERROR ) <nl> + if ( duplic != DUP_ERROR || ignore ) <nl> table -> file -> extra ( HA_EXTRA_IGNORE_DUP_KEY ); <nl> /* <nl> let ' s * try * to start bulk inserts . It won ' t necessary <nl> bool mysql_insert ( THD * thd , TABLE_LIST * table_list , <nl> table -> next_number_field = 0 ; <nl> thd -> count_cuted_fields = CHECK_FIELD_IGNORE ; <nl> thd -> next_insert_id = 0 ; // Reset this if wrongly used <nl> - if ( duplic != DUP_ERROR ) <nl> + if ( duplic != DUP_ERROR || ignore ) <nl> table -> file -> extra ( HA_EXTRA_NO_IGNORE_DUP_KEY ); <nl>  <nl> /* Reset value of LAST_INSERT_ID if no rows where inserted */ <nl> bool delayed_insert :: handle_inserts ( void ) <nl> info . ignore = row -> ignore ; <nl> info . handle_duplicates = row -> dup ; <nl> if ( info . ignore || <nl> - info . handle_duplicates == DUP_REPLACE ) <nl> + info . handle_duplicates != DUP_ERROR ) <nl> { <nl> table -> file -> extra ( HA_EXTRA_IGNORE_DUP_KEY ); <nl> using_ignore = 1 ; <nl> select_insert :: prepare ( List < Item > & values , SELECT_LEX_UNIT * u ) <nl> restore_record ( table , s -> default_values ); // Get empty record <nl> table -> next_number_field = table -> found_next_number_field ; <nl> thd -> cuted_fields = 0 ; <nl> - if ( info . ignore || info . handle_duplicates == DUP_REPLACE ) <nl> + if ( info . ignore || info . handle_duplicates != DUP_ERROR ) <nl> table -> file -> extra ( HA_EXTRA_IGNORE_DUP_KEY ); <nl> table -> file -> start_bulk_insert (( ha_rows ) 0 ); <nl> thd -> no_trans_update = 0 ; <nl> select_create :: prepare ( List < Item > & values , SELECT_LEX_UNIT * u ) <nl>  <nl> restore_record ( table , s -> default_values ); // Get empty record <nl> thd -> cuted_fields = 0 ; <nl> - if ( info . ignore || info . handle_duplicates == DUP_REPLACE ) <nl> + if ( info . ignore || info . handle_duplicates != DUP_ERROR ) <nl> table -> file -> extra ( HA_EXTRA_IGNORE_DUP_KEY ); <nl> table -> file -> start_bulk_insert (( ha_rows ) 0 ); <nl> thd -> no_trans_update = 0 ;
struct my_option my_long_options [] = <nl> " If set to 1 table names are stored in lowercase on disk and table names will be case - insensitive .", <nl> ( gptr *) & lower_case_table_names , <nl> ( gptr *) & lower_case_table_names , 0 , <nl> - GET_BOOL , REQUIRED_ARG , IF_WIN ( 1 , 0 ), 0 , 1 , 0 , 1 , 0 }, <nl> + GET_BOOL , NO_ARG , IF_WIN ( 1 , 0 ), 0 , 1 , 0 , 1 , 0 }, <nl> {" max_allowed_packet ", OPT_MAX_ALLOWED_PACKET , <nl> " Max packetlength to send / receive from to server .", <nl> ( gptr *) & global_system_variables . max_allowed_packet ,
bool login_connection ( THD * thd ) <nl> net -> no_send_error = 0 ; <nl>  <nl> /* Use " connect_timeout " value during connection phase */ <nl> - net_set_read_timeout ( net , connect_timeout ); <nl> - net_set_write_timeout ( net , connect_timeout ); <nl> + my_net_set_read_timeout ( net , connect_timeout ); <nl> + my_net_set_write_timeout ( net , connect_timeout ); <nl>  <nl> if (( error = check_connection ( thd ))) <nl> { // Wrong permissions <nl> bool login_connection ( THD * thd ) <nl> DBUG_RETURN ( 1 ); <nl> } <nl> /* Connect completed , set read / write timeouts back to default */ <nl> - net_set_read_timeout ( net , thd -> variables . net_read_timeout ); <nl> - net_set_write_timeout ( net , thd -> variables . net_write_timeout ); <nl> + my_net_set_read_timeout ( net , thd -> variables . net_read_timeout ); <nl> + my_net_set_write_timeout ( net , thd -> variables . net_write_timeout ); <nl> DBUG_RETURN ( 0 ); <nl> } <nl> 
sync_array_signal_object ( <nl>  <nl> if ( cell_count == cell_max_count ) { <nl> sync_cell_t ** old_cell_ptr = cell_ptr ; <nl> - size_t old_size = cell_max_count * <nl> + size_t old_size , new_size ; <nl> + <nl> + old_size = cell_max_count * <nl> sizeof ( sync_cell_t *); <nl> cell_max_count *= 2 ; <nl> - <nl> - size_t new_size = cell_max_count * <nl> + new_size = cell_max_count * <nl> sizeof ( sync_cell_t *); <nl>  <nl> cell_ptr = malloc ( new_size );
int ha_ndbcluster :: write_row ( byte * record ) <nl> /* <nl> * If IGNORE the ignore constraint violations on primary and unique keys <nl> */ <nl> - if ( m_ignore_dup_key ) <nl> + if (! m_use_write && m_ignore_dup_key ) <nl> { <nl> int peek_res = peek_indexed_rows ( record ); <nl> 
fil_mutex_enter_and_prepare_for_io ( <nl> fil_flush_file_spaces ( FIL_TYPE_TABLESPACE ); <nl>  <nl> count ++; <nl> + mutex_enter (& fil_system -> mutex ); <nl> continue ; <nl> } <nl> }
void Dbtc :: execDIGETPRIMCONF ( Signal * signal ) <nl> scanptr . i = scanFragptr . p -> scanRec ; <nl> ptrCheckGuard ( scanptr , cscanrecFileSize , scanRecord ); <nl>  <nl> - if ( ScanFragReq :: getReadCommittedFlag ( scanptr . p -> scanRequestInfo )) <nl> + /** <nl> + * This must be false as select count (*) otherwise <nl> + * can " pass " committing on backup fragments and <nl> + * get incorrect row count <nl> + */ <nl> + if ( false && ScanFragReq :: getReadCommittedFlag ( scanptr . p -> scanRequestInfo )) <nl> { <nl> jam (); <nl> Uint32 max = 3 + signal -> theData [ 6 ];
my_bool STDCALL mysql_stmt_attr_get ( MYSQL_STMT * stmt , <nl> { <nl> switch ( attr_type ) { <nl> case STMT_ATTR_UPDATE_MAX_LENGTH : <nl> - *( unsigned long *) value = stmt -> update_max_length ; <nl> + *( ulong *) value = stmt -> update_max_length ; <nl> break ; <nl> case STMT_ATTR_CURSOR_TYPE : <nl> - *( unsigned long *) value = stmt -> flags ; <nl> + *( ulong *) value = stmt -> flags ; <nl> break ; <nl> + case STMT_ATTR_PREFETCH_ROWS : <nl> + *( ulong *) value = stmt -> prefetch_rows ; <nl> + break ; <nl> default : <nl> return TRUE ; <nl> }
toku_minicron_change_period ( struct minicron * p , u_int32_t new_period ) <nl> int <nl> toku_minicron_shutdown ( struct minicron * p ) { <nl> int r = toku_pthread_mutex_lock (& p -> mutex ); assert ( r == 0 ); <nl> + assert (! p -> do_shutdown ); <nl> p -> do_shutdown = TRUE ; <nl> // printf ("% s :% d signalling \ n ", __FILE__ , __LINE__ ); <nl> r = toku_pthread_cond_signal (& p -> condvar ); assert ( r == 0 );
sp_head :: check_unresolved_goto () <nl> if ( m_backpatch_goto . elements > 0 ) <nl> { <nl> List_iterator_fast < bp_t > li ( m_backpatch_goto ); <nl> - bp_t * bp ; <nl> - while (( bp = li ++)) <nl> + while ( bp_t * bp = li ++) <nl> { <nl> - if (( bp -> instr_type == GOTO )) <nl> + if ( bp -> instr_type == GOTO ) <nl> { <nl> my_error ( ER_SP_LILABEL_MISMATCH , MYF ( 0 ), " GOTO ", bp -> lab -> name . str ); <nl> has_unresolved_label = true ;
class Field <nl> void operator =( Field &); <nl> public : <nl> static void * operator new ( size_t size ) { return ( void *) sql_alloc (( uint ) size ); } <nl> - static void operator delete ( void * ptr_arg , size_t size ) {} /* lint - e715 */ <nl> + static void operator delete ( void * ptr_arg , size_t size ) { <nl> +# ifdef PEDANTIC_SAFEMALLOC <nl> + bfill ( ptr_arg , size , 0x8F ); <nl> +# endif <nl> + } <nl>  <nl> char * ptr ; // Position to field in record <nl> uchar * null_ptr ; // Byte where null_bit is
buf_page_init_for_read ( <nl> uninitialized data . */ <nl> data = buf_buddy_alloc ( buf_pool , zip_size , & lru ); <nl>  <nl> - /* Initialize the buf_pool pointer . */ <nl> - bpage -> buf_pool_index = buf_pool_index ( buf_pool ); <nl> - <nl> /* If buf_buddy_alloc () allocated storage from the LRU list , <nl> it released and reacquired buf_pool -> mutex . Thus , we must <nl> check the page_hash again , as it may have been modified . */ <nl> buf_page_init_for_read ( <nl>  <nl> bpage = buf_page_alloc_descriptor (); <nl>  <nl> + /* Initialize the buf_pool pointer . */ <nl> + bpage -> buf_pool_index = buf_pool_index ( buf_pool ); <nl> + <nl> page_zip_des_init (& bpage -> zip ); <nl> page_zip_set_size (& bpage -> zip , zip_size ); <nl> bpage -> zip . data = data ;
int mysql_load ( THD * thd , sql_exchange * ex , TABLE_LIST * table_list , <nl> } <nl> else <nl> { <nl> + /* <nl> + As already explained above , we need to call end_io_cache () or the last <nl> + block will be logged only after Execute_load_log_event ( which is wrong ), <nl> + when read_info is destroyed . <nl> + */ <nl> read_info . end_io_cache (); <nl> if ( lf_info . wrote_create_file ) <nl> {
TRP_ROR_INTERSECT * get_best_ror_intersect ( const PARAM * param , SEL_TREE * tree , <nl> double min_cost = read_time ; <nl> DBUG_ENTER (" get_best_ror_intersect "); <nl>  <nl> - if ( tree -> n_ror_scans < 2 ) <nl> + if (( tree -> n_ror_scans < 2 ) || ! param -> table -> file -> records ) <nl> DBUG_RETURN ( NULL ); <nl>  <nl> /* <nl> TRP_ROR_INTERSECT * get_best_ror_intersect ( const PARAM * param , SEL_TREE * tree , <nl> min_cost = intersect -> total_cost ; <nl> best_rows = ( ha_rows )( intersect -> records_fract * <nl> rows2double ( param -> table -> file -> records )); <nl> + /* Prevent divisons by zero */ <nl> + if (! best_rows ) <nl> + best_rows = 1 ; <nl> is_best_covering = intersect -> is_covering ; <nl> intersect_scans_best = intersect_scans_end ; <nl> best_index_scan_costs = intersect -> index_scan_costs ; <nl> TRP_ROR_INTERSECT * get_best_ror_intersect ( const PARAM * param , SEL_TREE * tree , <nl> min_cost = intersect -> total_cost ; <nl> best_rows = ( ha_rows )( intersect -> records_fract * <nl> rows2double ( param -> table -> file -> records )); <nl> + /* Prevent divisons by zero */ <nl> + if (! best_rows ) <nl> + best_rows = 1 ; <nl> is_best_covering = intersect -> is_covering ; <nl> best_index_scan_costs = intersect -> index_scan_costs ; <nl> } <nl> TRP_ROR_INTERSECT * get_best_ror_intersect ( const PARAM * param , SEL_TREE * tree , <nl> trp -> last_scan = trp -> first_scan + best_num ; <nl> trp -> is_covering = is_best_covering ; <nl> trp -> read_cost = min_cost ; <nl> - trp -> records = best_rows ? best_rows : 1 ; <nl> + trp -> records = best_rows ; <nl> trp -> index_scan_costs = best_index_scan_costs ; <nl> trp -> cpk_scan = cpk_scan ; <nl> DBUG_PRINT (" info ",
enum tablespace_op_type <nl> e ||+-------------------------+ || <nl> V | neighbor | V | <nl> unit1 . 1 <+==================> unit1 . 2 unit2 . 1 <nl> - fake1 . 1 fake2 . 1 <nl> - select1 . 1 . 1 select 1 . 1 . 2 select1 . 2 . 1 select2 . 1 . 1 select2 . 1 . 2 <nl> + fake1 . 1 <nl> + select1 . 1 . 1 select 1 . 1 . 2 select1 . 2 . 1 select2 . 1 . 1 <nl> |^ <nl> || <nl> V |
my_decimal * Item_variance_field :: val_decimal ( my_decimal * dec_buf ) <nl> int simple_str_key_cmp ( void * arg , byte * key1 , byte * key2 ) <nl> { <nl> Field * f = ( Field *) arg ; <nl> - return f -> cmp ( key1 , key2 ); <nl> + return f -> cmp (( const char *) key1 , ( const char *) key2 ); <nl> } <nl>  <nl> /* <nl> int composite_key_cmp ( void * arg , byte * key1 , byte * key2 ) <nl> } <nl>  <nl>  <nl> - C_MODE_START <nl> - <nl> static int count_distinct_walk ( void * elem , unsigned int count , void * arg ) <nl> { <nl> (*(( ulonglong *) arg ))++; <nl> return 0 ; <nl> } <nl>  <nl> - C_MODE_END <nl> - <nl>  <nl> void Item_sum_count_distinct :: cleanup () <nl> {
ha_innobase :: check ( <nl> ( ulong ) n_rows , <nl> ( ulong ) n_rows_in_table ); <nl> is_ok = FALSE ; <nl> + row_mysql_lock_data_dictionary ( prebuilt -> trx ); <nl> + dict_set_corrupted ( index ); <nl> + row_mysql_unlock_data_dictionary ( prebuilt -> trx ); <nl> } <nl> } <nl> 
opj_bool j2k_read_sot_v2 ( <nl> opj_read_bytes ( p_header_data ,& l_tot_len , 4 ); /* Psot */ <nl> p_header_data += 4 ; <nl>  <nl> + /* PSot should be equal to zero or >= 14 or <= 2 ^ 32 - 1 */ <nl> + if (( l_tot_len != 0 ) && ( l_tot_len < 14 ) ) <nl> + { <nl> + opj_event_msg_v2 ( p_manager , EVT_ERROR , " Psot value (% d ) is not correct regards to the JPEG2000 norm !\ n ", l_tot_len ); <nl> + return OPJ_FALSE ; <nl> + } <nl> + <nl> + <nl> # ifdef USE_JPWL <nl> if ( l_cp -> correct ) { <nl> 
 <nl> # include < stdio . h > <nl> # include < stdlib . h > <nl> +# include < assert . h > <nl> # include " ihdrbox_manager . h " <nl>  <nl> ihdrbox_param_t * gene_ihdrbox ( metadatalist_param_t * metadatalist , Byte_t * jpipstream ) <nl> ihdrbox_param_t * gene_ihdrbox ( metadatalist_param_t * metadatalist , Byte_t * jpip <nl> ihdrbox_param_t * ihdrbox ; <nl> metadata_param_t * meta ; <nl> box_param_t * jp2h , * ihdr ; <nl> + int bpc_val ; <nl>  <nl> jp2h = NULL ; <nl> meta = metadatalist -> first ; <nl> ihdrbox_param_t * gene_ihdrbox ( metadatalist_param_t * metadatalist , Byte_t * jpip <nl> ihdrbox -> height = big4 ( jpipstream + get_DBoxoff ( ihdr )); <nl> ihdrbox -> width = big4 ( jpipstream + get_DBoxoff ( ihdr )+ 4 ); <nl> ihdrbox -> nc = big2 ( jpipstream + get_DBoxoff ( ihdr )+ 8 ); <nl> - ihdrbox -> bpc = *( jpipstream + get_DBoxoff ( ihdr )+ 10 )+ 1 ; <nl> + bpc_val = *( jpipstream + get_DBoxoff ( ihdr )+ 10 )+ 1 ; <nl> + assert ( bpc_val >= 0 && bpc_val <= 255 ); <nl> + ihdrbox -> bpc = ( Byte_t ) bpc_val ; <nl>  <nl> free ( ihdr ); <nl> 
buf_shrink_freelists ( int free_all ) <nl> -- n_to_free ; <nl> } <nl> tor_assert (! n_to_free ); <nl> - freelists [ i ]. lowest_length = freelists [ i ]. cur_length = n_to_skip ; <nl> + freelists [ i ]. cur_length = n_to_skip ; <nl> } <nl> + freelists [ i ]. lowest_length = freelists [ i ]. cur_length ; <nl> assert_freelist_ok (& freelists [ i ]); <nl> } <nl> }
entry_guards_update_primary ( guard_selection_t * gs ) <nl> * Return the number of seconds after the last attempt at which we should <nl> * retry a guard that has been failing since < b > failing_since </ b >. <nl> */ <nl> - static unsigned <nl> + static int <nl> get_retry_schedule ( time_t failing_since , time_t now , <nl> int is_primary ) <nl> { <nl> entry_guard_consider_retry ( entry_guard_t * guard ) <nl> return ; /* No retry needed . */ <nl>  <nl> const time_t now = approx_time (); <nl> - const unsigned delay = <nl> + const int delay = <nl> get_retry_schedule ( guard -> failing_since , now , guard -> is_primary ); <nl> const time_t last_attempt = guard -> last_tried_to_connect ; <nl> 
options_act ( or_options_t * old_options ) <nl> smartlist_t * sl = smartlist_create (); <nl> char * errmsg = NULL ; <nl> for ( cl = options -> RedirectExit ; cl ; cl = cl -> next ) { <nl> - if ( parse_redirect_line ( sl , cl , & errmsg )< 0 ) <nl> + if ( parse_redirect_line ( sl , cl , & errmsg )< 0 ) { <nl> log_warn ( LD_CONFIG , "% s ", errmsg ); <nl> tor_free ( errmsg ); <nl> return - 1 ; <nl> + } <nl> } <nl> set_exit_redirects ( sl ); <nl> }
client_likes_consensus ( const struct consensus_cache_entry_t * ent , <nl> int have = 0 ; <nl>  <nl> if ( consensus_cache_entry_get_voter_id_digests ( ent , voters ) != 0 ) { <nl> + smartlist_free ( voters ); <nl> return 1 ; // We don ' t know the voters ; assume the client won ' t mind . */ <nl> } <nl> 
hibernate_hard_limit_reached ( void ) <nl> * to send / receive this interval . */ <nl> static int hibernate_soft_limit_reached ( void ) <nl> { <nl> - uint64_t soft_limit = ( uint64_t ) (( get_options ()-> AccountingMax ) * . 99 ); <nl> + uint64_t soft_limit = ( uint64_t ) (( get_options ()-> AccountingMax ) * . 95 ); <nl> if (! soft_limit ) <nl> return 0 ; <nl> return n_bytes_read_in_interval >= soft_limit
static int parse_redirect_line ( or_options_t * options , <nl> tor_assert ( line ); <nl>  <nl> r = tor_malloc_zero ( sizeof ( exit_redirect_t )); <nl> + elements = smartlist_create (); <nl> smartlist_split_string ( elements , line -> value , " ", <nl> SPLIT_SKIP_SPACE | SPLIT_IGNORE_BLANK , 0 ); <nl> if ( smartlist_len ( elements ) != 2 ) {
get_recommended_software_from_directory ( const char * str ) <nl> /* We belong to a series with recommended members , and we are newer than <nl> * any recommended member . We ' re probably okay . */ <nl> if (! warned_too_new ) { <nl> - log ( LOG_WARN , " This version of Tor (% s ) is newer than any in the same series on the reccomended list (% s )", <nl> + log ( LOG_WARN , " This version of Tor (% s ) is newer than any in the same series on the recommended list (% s )", <nl> myversion , versionlist ); <nl> warned_too_new = 1 ; <nl> } <nl> get_recommended_software_from_directory ( const char * str ) <nl> /* We belong to a series with no recommended members , and it ' s <nl> * newer than any recommended series . We ' re probably okay . */ <nl> if (! warned_too_new ) { <nl> - log ( LOG_WARN , " This version of Tor (% s ) is newer than any on the reccomended list (% s )", <nl> + log ( LOG_WARN , " This version of Tor (% s ) is newer than any on the recommended list (% s )", <nl> myversion , versionlist ); <nl> warned_too_new = 1 ; <nl> }
handle_control_authenticate ( control_connection_t * conn , uint32_t len , <nl> int bad_cookie = 0 , bad_password = 0 ; <nl> smartlist_t * sl = NULL ; <nl>  <nl> - if (! len || TOR_ISSPACE ( body [ 0 ])) { <nl> + if (! len ) { <nl> password = tor_strdup (""); <nl> password_len = 0 ; <nl> } else if ( TOR_ISXDIGIT ( body [ 0 ])) { <nl> connection_control_process_inbuf ( control_connection_t * conn ) <nl> args = conn -> incoming_cmd + cmd_len + 1 ; <nl> tor_assert ( data_len >( size_t ) cmd_len ); <nl> data_len -= ( cmd_len + 1 ); /* skip the command and NUL we added after it */ <nl> - while (* args == ' ' || * args == '\ t ') { <nl> + while ( TOR_ISSPACE (* args )) { <nl> ++ args ; <nl> -- data_len ; <nl> }
namespace CryptoPP { } <nl> # define __USE_W32_SOCKETS <nl> # endif <nl>  <nl> - typedef unsigned char byte ; // put in global namespace to avoid ambiguity with other byte typedefs <nl> +// Originally in global namespace to avoid ambiguity with other byte typedefs . <nl> +// Moved to Crypto ++ namespace due to C ++ 17 , std :: byte and potential compile problems . Also see <nl> +// http :// www . cryptopp . com / wiki / std :: byte and http :// github . com / weidai11 / cryptopp / issues / 442 <nl> +// typedef unsigned char byte ; <nl> +# define CRYPTOPP_NO_GLOBAL_BYTE 1 <nl>  <nl> NAMESPACE_BEGIN ( CryptoPP ) <nl>  <nl> + typedef unsigned char byte ; <nl> typedef unsigned short word16 ; <nl> typedef unsigned int word32 ; <nl> 
public : <nl>  <nl> inline size_t Put ( const byte * begin , size_t length ) <nl> { <nl> + if (! begin || ! length ) return length ; <nl> size_t l = STDMIN ( length , MaxSize ()- m_tail ); <nl> if ( buf + m_tail != begin ) <nl> memcpy ( buf + m_tail , begin , l ); <nl> public : <nl>  <nl> inline size_t Peek ( byte * target , size_t copyMax ) const <nl> { <nl> + if (! target || ! copyMax ) return 0 ; <nl> size_t len = STDMIN ( copyMax , m_tail - m_head ); <nl> memcpy ( target , buf + m_head , len ); <nl> return len ;
size_t jsuGetFreeStack () { <nl> char ptr ; // this is on the stack <nl> extern void * STACK_BASE ; <nl> uint32_t count = ( uint32_t )(( size_t ) STACK_BASE - ( size_t )& ptr ); <nl> - return 1000000 - count ; // give it 1 megabyte of stack <nl> + const uint32_t max_stack = 1000000 ; // give it 1 megabyte of stack <nl> + if ( count > max_stack ) return 0 ; <nl> + return max_stack - count ; <nl> # else <nl> // stack depth seems pretty platform - specific :( Default to a value that disables it <nl> return 1000000 ; // no stack depth check on this platform
# include " src / api / slurm . h " <nl>  <nl> # include " src / srun / allocate . h " <nl> -# include " src / srun / attach . h " <nl> # include " src / srun / opt . h " <nl>  <nl> +# if HAVE_TOTALVIEW <nl> +# include " src / srun / attach . h " <nl> +# endif <nl> + <nl> # define MAX_RETRIES 10 <nl>  <nl> /*
static bool _validate_acct_policy ( job_desc_msg_t * job_desc , <nl> slurmdb_association_rec_t * assoc_ptr = assoc_in ; <nl> int parent = 0 ; <nl> int timelimit_set = 0 ; <nl> - char * user_name = assoc_ptr -> user ; <nl> + char * user_name = NULL ; <nl> bool rc = true ; <nl> bool limit_set_max_cpus = 0 ; <nl> assoc_mgr_lock_t locks = { READ_LOCK , NO_LOCK , <nl> static bool _validate_acct_policy ( job_desc_msg_t * job_desc , <nl> xassert ( limit_set_max_nodes ); <nl> //(* limit_set_max_nodes ) = 0 ; <nl>  <nl> + if (! assoc_ptr ) { <nl> + error (" _validate_acct_policy : no assoc_ptr given for job ."); <nl> + return false ; <nl> + } <nl> + <nl> + user_name = assoc_ptr -> user ; <nl> + <nl> assoc_mgr_lock (& locks ); <nl> if ( qos_ptr ) { <nl> /* for validation we don ' t need to look at
int slurm_step_launch ( slurm_step_ctx ctx , <nl> char ** env = NULL ; <nl>  <nl> debug (" Entering slurm_step_launch "); <nl> + memset (& launch , 0 , sizeof ( launch )); <nl> + <nl> if ( ctx == NULL || ctx -> magic != STEP_CTX_MAGIC ) { <nl> error (" Not a valid slurm_step_ctx !"); <nl> 
static void log_msg ( log_level_t level , const char * fmt , va_list args ) <nl>  <nl> if ( level > SYSLOG_LEVEL && <nl> level > LOGFILE_LEVEL && <nl> - level > STDERR_LEVEL ) <nl> + level > STDERR_LEVEL ) { <nl> + pthread_mutex_unlock (& log_lock ); <nl> return ; <nl> + } <nl>  <nl> if ( log -> opt . prefix_level || SYSLOG_LEVEL > level ) { <nl> switch ( level ) {
_unpack_network_callerid_msg ( network_callerid_msg_t ** msg_ptr , Buf buffer , <nl> unpack_error : <nl> info ("% s : error ", __func__ ); <nl> * msg_ptr = NULL ; <nl> + xfree ( charptr_tmp ); <nl> slurm_free_network_callerid_msg ( msg ); <nl> return SLURM_ERROR ; <nl> }
extern int configure_small_block ( bg_record_t * bg_record ) <nl> } <nl>  <nl>  <nl> + if (! bp_id ) { <nl> + error (" No BP ID was returned from database "); <nl> + continue ; <nl> + } <nl> + <nl> if (( rc = bridge_get_nodecards ( bp_id , & ncard_list )) <nl> != STATUS_OK ) { <nl> error (" bridge_get_nodecards (% s ): % d ", <nl> bp_id , rc ); <nl> - <nl> + free ( bp_id ); <nl> return SLURM_ERROR ; <nl> } <nl> - <nl> + free ( bp_id ); <nl> + <nl>  <nl> if (( rc = bridge_get_data ( ncard_list , RM_NodeCardListSize , & num )) <nl> != STATUS_OK ) {
extern void gres_plugin_node_state_log ( List gres_list , char * node_name ) <nl> ListIterator gres_iter ; <nl> gres_node_state_t * gres_ptr ; <nl>  <nl> + if ( gres_list == NULL ) <nl> + return ; <nl> + <nl> ( void ) gres_plugin_init (); <nl>  <nl> slurm_mutex_lock (& gres_context_lock );
static uint32_t _update_weighted_freq ( struct jobacctinfo * jobacct , <nl> jobacct -> current_weighted_freq = <nl> jobacct -> current_weighted_freq + <nl> ( uint32_t ) jobacct -> this_sampled_cputime * thisfreq ; <nl> - if ( jobacct -> tot_cpu ) { <nl> + if ( jobacct -> tot_cpu >= 1 ) { <nl> return ( jobacct -> current_weighted_freq / <nl> ( uint32_t ) jobacct -> tot_cpu ); <nl> } else
static void _purge_missing_jobs ( int node_inx , time_t now ) <nl> requeue = true ; <nl> info (" Batch JobId =% u missing from node 0 ", <nl> job_ptr -> job_id ); <nl> + job_ptr -> exit_code = 1 ; <nl> job_complete ( job_ptr -> job_id , 0 , requeue , true , NO_VAL ); <nl> } else { <nl> _notify_srun_missing_step ( job_ptr , node_inx ,
scontrol_parse_res_options ( int argc , char * argv [], const char * msg , <nl> strncasecmp ( tag , " CPUCount ", MAX ( taglen , 5 )) == 0 ) { <nl>  <nl> char * endptr = NULL , * core_cnt , * tok , * ptrptr = NULL ; <nl> + char * type = NULL ; <nl> int node_inx = 0 ; <nl>  <nl> + type = slurm_get_select_type (); <nl> + if (! strcasecmp ( type , " select / linear ")) { <nl> + error (" Invalid to use CoreCnt or CPUCnt with " <nl> + " SelectType = select / linear "); <nl> + xfree ( type ); <nl> + return - 1 ; <nl> + } <nl> + xfree ( type ); <nl> core_cnt = xstrdup ( val ); <nl> tok = strtok_r ( core_cnt , ",", & ptrptr ); <nl> while ( tok ) {
static void _slurm_rpc_reconfigure_controller ( slurm_msg_t * msg ) <nl> info (" _slurm_rpc_reconfigure_controller : completed % s ", <nl> TIME_STR ); <nl> slurm_send_rc_msg ( msg , SLURM_SUCCESS ); <nl> - schedule (); <nl> + schedule (); /* has its own locks */ <nl> save_all_state (); <nl> } <nl> }
extern List as_mysql_modify_clusters ( mysql_conn_t * mysql_conn , uint32_t uid , <nl> if ( debug_flags & DEBUG_FLAG_DB_ASSOC ) <nl> DB_DEBUG ( mysql_conn -> conn , <nl> " didn ' t effect anything \ n % s ", query ); <nl> + xfree ( name_char ); <nl> xfree ( vals ); <nl> xfree ( query ); <nl> return ret_list ;
static void _block_sync_core_bitmap ( struct job_record * job_ptr , <nl>  <nl> } <nl>  <nl> - if ( cpus > 0 ) <nl> + if ( cpus > 0 ) { <nl> /* cpu count should NEVER be greater than the number <nl> * of set bits in the core bitmap for a given node */ <nl> fatal (" cons_res : cpus computation error "); <nl> + } <nl>  <nl> /* adjust cpus count of the current node */ <nl> if (( alloc_cores || alloc_sockets ) &&
****************************************************************************** <nl> * <nl> * $ Log $ <nl> + * Revision 1 . 178 2005 / 04 / 12 23 : 56 : 44 sean <nl> + * change tmpId string to be non static in msTmpFile () ( bug 1312 ). <nl> + * <nl> * Revision 1 . 177 2005 / 04 / 07 17 : 23 : 16 assefa <nl> * Remove # ifdef USE_SVG . It was added during development . <nl> * <nl> char * msTmpFile ( const char * mappath , const char * tmppath , const char * ext ) <nl> char * tmpFname ; <nl> char szPath [ MS_MAXPATHLEN ]; <nl> const char * fullFname ; <nl> - static char tmpId [ 128 ]; /* big enough for time + pid + ext */ <nl> + char tmpId [ 128 ]; /* big enough for time + pid + ext */ <nl>  <nl> if ( ForcedTmpBase != NULL ) <nl> {
geocache_cfg * geocache_configuration_create ( apr_pool_t * pool ) { <nl> grid -> srs = apr_pstrdup ( pool ," epsg : 4326 "); <nl> grid -> unit = GEOCACHE_UNIT_DEGREES ; <nl> grid -> tile_sx = grid -> tile_sy = 256 ; <nl> - grid -> nlevels = 16 ; <nl> + grid -> nlevels = 19 ; <nl> grid -> extent [ 0 ] = wgs84_extent [ 0 ]; <nl> grid -> extent [ 1 ] = wgs84_extent [ 1 ]; <nl> grid -> extent [ 2 ] = wgs84_extent [ 2 ];
int msDrawLegendIcon ( mapObj * map , layerObj * lp , classObj * theclass , <nl> initTextSymbol (& ts ); <nl> msPopulateTextSymbolForLabelAndString (& ts , theclass -> labels [ 0 ], msStrdup (" Az "), lp -> scalefactor * image_draw -> resolutionfactor , image_draw -> resolutionfactor , duplicate_always ); <nl> ts . label -> size = height - 1 ; <nl> + ts . rotation = 0 ; <nl> ret = msComputeTextPath ( map ,& ts ); <nl> if ( UNLIKELY ( ret == MS_FAILURE )) goto legend_icon_cleanup ; <nl> textstartpt = get_metrics (& marker , MS_CC , ts . textpath , 0 , 0 , 0 , 0 , NULL );
styleObj * msRemoveStyle ( classObj * class , int nStyleIndex ) { <nl> return NULL ; <nl> } <nl> msCopyStyle ( style , &( class -> styles [ nStyleIndex ])); <nl> + style -> isachild = MS_FALSE ; <nl> for ( i = nStyleIndex ; i < class -> numstyles - 1 ; i ++) { <nl> msCopyStyle (& class -> styles [ i ], & class -> styles [ i + 1 ]); <nl> }
int msDumpLayer ( mapObj * map , layerObj * lp , int nVersion , const char * script_url_ <nl> free ( nestedGroups ); <nl> free ( numNestedGroups ); <nl> free ( isUsedInNestedGroup ); <nl> + free ( group_layers ); <nl> } <nl> } <nl> }
int msGetGDALGeoTransform ( GDALDatasetH hDS , mapObj * map , layerObj * layer , <nl> } <nl> /* fullPath has a filename included , so get the extension */ <nl> else { <nl> - fileExtension = strrchr ( szPath ,'.') + 1 ; <nl> + fileExtension = msStrdup ( strrchr ( szPath ,'.') + 1 ); <nl> } <nl> } <nl> /* common behaviour with worldfile generated from basename + . wld */
static gboolean wsq_tlskey_inited = FALSE ; <nl> void <nl> mono_wsq_init () <nl> { <nl> + if ( wsq_tlskey_inited ) <nl> + return ; <nl> + <nl> mono_native_tls_alloc ( wsq_tlskey , NULL ); <nl> + wsq_tlskey_inited = TRUE ; <nl> } <nl>  <nl> void
selector_thread ( gpointer data ) <nl>  <nl> updates_old = threadpool_io -> updates ; <nl>  <nl> - threadpool_io -> updates = mono_gc_alloc_fixed ( sizeof ( ThreadPoolIOUpdate ) * threadpool_io -> updates_capacity , NULL ); <nl> + threadpool_io -> updates = mono_gc_alloc_fixed ( sizeof ( ThreadPoolIOUpdate ) * threadpool_io -> updates_capacity , MONO_GC_DESCRIPTOR_NULL ); <nl> g_assert ( threadpool_io -> updates ); <nl>  <nl> mono_gc_free_fixed ( updates_old ); <nl> mono_threadpool_ms_io_add ( MonoAsyncResult * ares , MonoSocketAsyncResult * sockare <nl> updates_new_capacity = updates_old_capacity + 128 ; <nl>  <nl> updates_old = threadpool_io -> updates ; <nl> - updates_new = mono_gc_alloc_fixed ( sizeof ( ThreadPoolIOUpdate ) * updates_new_capacity , NULL ); <nl> + updates_new = mono_gc_alloc_fixed ( sizeof ( ThreadPoolIOUpdate ) * updates_new_capacity , MONO_GC_DESCRIPTOR_NULL ); <nl> g_assert ( updates_new ); <nl>  <nl> if ( updates_old )
read_pipes ( int outfd , gchar ** out_str , int errfd , gchar ** err_str ) <nl> err_closed = ( nread <= 0 ); <nl> } <nl> } <nl> - <nl> - } while ( res == - 1 && errno == EINTR ); <nl> + } while ( res > 0 || ( res == - 1 && errno == EINTR )); <nl>  <nl> g_free ( buffer ); <nl> if ( out_str )
mini_profiler_emit_instrumentation_call ( MonoCompile * cfg , void * func , gboolean <nl> { <nl> gboolean instrument , capture ; <nl>  <nl> + /* <nl> + * Do not instrument an inlined method - it becomes <nl> + * part of the current method . <nl> + */ <nl> + if ( cfg -> current_method != cfg -> method ) <nl> + return ; <nl> + <nl> if ( entry ) { <nl> instrument = cfg -> prof_flags & MONO_PROFILER_CALL_INSTRUMENTATION_PROLOGUE ; <nl> capture = cfg -> prof_flags & MONO_PROFILER_CALL_INSTRUMENTATION_PROLOGUE_CONTEXT ; <nl> mini_profiler_emit_instrumentation_call ( MonoCompile * cfg , void * func , gboolean <nl> if (! instrument ) <nl> return ; <nl>  <nl> - g_assert ( cfg -> current_method == cfg -> method ); <nl> - <nl> MonoInst * iargs [ 2 ]; <nl>  <nl> EMIT_NEW_METHODCONST ( cfg , iargs [ 0 ], cfg -> method );
ss_start ( SingleStepReq * ss_req , MonoMethod * method , SeqPoint * sp , MonoSeqPointI <nl> found_sp = mono_find_next_seq_point_for_native_offset ( frame -> domain , frame -> method , ( char *) ei -> handler_start - ( char *) jinfo -> code_start , NULL , & local_sp ); <nl> sp = ( found_sp )? & local_sp : NULL ; <nl>  <nl> - ss_bp_add_one ( ss_req , & ss_req_bp_count , & ss_req_bp_cache , frame -> method , sp -> il_offset ); <nl> + if ( found_sp ) <nl> + ss_bp_add_one ( ss_req , & ss_req_bp_count , & ss_req_bp_cache , frame -> method , sp -> il_offset ); <nl> } <nl> } <nl> }
coverage_filter ( MonoProfiler * prof , MonoMethod * method ) <nl> MonoLockFreeQueue * image_methods , * class_methods ; <nl> MonoLockFreeQueueNode * node ; <nl>  <nl> - if (! coverage_initialized ) <nl> - return FALSE ; <nl> + g_assert ( coverage_initialized && " Why are we being asked for coverage filter info when we ' re not doing coverage ?"); <nl>  <nl> COVERAGE_DEBUG ( fprintf ( stderr , " Coverage filter for % s \ n ", mono_method_get_name ( method ));) <nl> 
do_newobj ( VerifyContext * ctx , int token ) <nl> return ; <nl> } <nl>  <nl> + if (! sig -> hasthis ) { <nl> + ADD_VERIFY_ERROR ( ctx , g_strdup_printf (" Invalid constructor signature missing hasthis at 0x % 04x ", ctx -> ip_offset )); <nl> + return ; <nl> + } <nl> + <nl> if (! check_underflow ( ctx , sig -> param_count )) <nl> return ; <nl> 
mini_method_compile ( MonoMethod * method , guint32 opts , MonoDomain * domain , JitFl <nl> // g_free ( nm ); <nl> } <nl> if ( cfg -> llvm_only ) { <nl> + g_free ( cfg -> exception_message ); <nl> cfg -> disable_aot = TRUE ; <nl> return cfg ; <nl> }
seq_point_info_add_seq_point ( MonoSeqPointInfo * info , SeqPoint * sp , SeqPoint * la <nl> guint8 buffer [ 4 ]; <nl> guint8 len ; <nl>  <nl> + if (! info -> has_debug_data && <nl> + ( sp -> il_offset == METHOD_ENTRY_IL_OFFSET || sp -> il_offset == METHOD_EXIT_IL_OFFSET )) <nl> + return FALSE ; <nl> + <nl> /* check that data can be added to the arrays */ <nl> g_assert ( info -> alloc_arrays ); <nl> 
mini_emit_inst_for_method ( MonoCompile * cfg , MonoMethod * cmethod , MonoMethodSign <nl> ( strcmp ( cmethod -> klass -> name_space , " System . Reflection ") == 0 ) && <nl> ( strcmp ( cmethod -> klass -> name , " Assembly ") == 0 )) { <nl> if ( cfg -> llvm_only && ! strcmp ( cmethod -> name , " GetExecutingAssembly ")) { <nl> - /* No stack walks are current available , so implement this as an intrinsic */ <nl> + /* No stack walks are currently available , so implement this as an intrinsic */ <nl> MonoInst * assembly_ins ; <nl>  <nl> EMIT_NEW_AOTCONST ( cfg , assembly_ins , MONO_PATCH_INFO_IMAGE , cfg -> method -> klass -> image ); <nl> mini_emit_inst_for_method ( MonoCompile * cfg , MonoMethod * cmethod , MonoMethodSign <nl> if ( cfg -> backend -> have_objc_get_selector && <nl> ! strcmp ( cmethod -> name , " GetHandle ") && fsig -> param_count == 1 && <nl> ( args [ 0 ]-> opcode == OP_GOT_ENTRY || args [ 0 ]-> opcode == OP_AOTCONST ) && <nl> - cfg -> compile_aot ) { <nl> + cfg -> compile_aot && ! cfg -> llvm_only ) { <nl> MonoInst * pi ; <nl> MonoJumpInfoToken * ji ; <nl> MonoString * s ; <nl>  <nl> + // FIXME : llvmonly <nl> + <nl> cfg -> exception_message = g_strdup (" GetHandle "); <nl> cfg -> disable_llvm = TRUE ; <nl> 
int PacketHandler :: processUpdate ( DNSPacket * p ) { <nl> di . backend -> lookup ( QType ( QType :: ANY ), rr -> d_name ); <nl> while ( di . backend -> get ( rec )) { <nl> if ( rec . qtype != QType :: CNAME && rec . qtype != QType :: RRSIG ) { <nl> + // leave database handle in a consistent state <nl> + while ( di . backend -> get ( rec )) <nl> + ; <nl> g_log << Logger :: Warning << msgPrefix <<" Refusing update for " << rr -> d_name << "/" << QType ( rr -> d_type ). getName () << ": Data other than CNAME exists for the same name "<< endl ; <nl> di . backend -> abortTransaction (); <nl> return RCode :: Refused ; <nl> int PacketHandler :: processUpdate ( DNSPacket * p ) { <nl> di . backend -> lookup ( QType ( QType :: CNAME ), rr -> d_name ); <nl> while ( di . backend -> get ( rec )) { <nl> if ( rec . qtype == QType :: CNAME && rr -> d_type != QType :: RRSIG ) { <nl> + // leave database handle in a consistent state <nl> + while ( di . backend -> get ( rec )) <nl> + ; <nl> g_log << Logger :: Warning << msgPrefix <<" Refusing update for " << rr -> d_name << "/" << QType ( rr -> d_type ). getName () << ": CNAME exists for the same name "<< endl ; <nl> di . backend -> abortTransaction (); <nl> return RCode :: Refused ;
int PacketHandler :: doChaosRequest ( DNSPacket * p , DNSPacket * r , DNSName & target ) <nl> return 0 ; <nl> } <nl> string tid = id ; <nl> - if (! tid . empty () && tid [ 0 ]!='"') // see # 6010 however <nl> - tid = "\"" + tid + "\""; <nl> + if (! tid . empty () && tid [ 0 ]!='"') { // see # 6010 however <nl> + tid = "\"" + tid + "\""; <nl> + } <nl> rr . dr . d_content = DNSRecordContent :: mastermake ( QType :: TXT , 1 , tid ); <nl> } <nl> else {
bool isEDNSOptionInOpt ( const std :: string & packet , const size_t optStart , const s <nl> size_t p = optStart + 9 ; <nl> uint16_t rdLen = ( 0x100 * packet . at ( p ) + packet . at ( p + 1 )); <nl> p += sizeof ( rdLen ); <nl> - if ( 11 + rdLen > optLen ) { <nl> + if ( rdLen > ( optLen - 11 )) { <nl> return false ; <nl> } <nl> 
# include " config . h " <nl> # endif <nl> # include " geoipbackend . hh " <nl> +# include " pdns / dns_random . hh " <nl> # include < sstream > <nl> # include < regex . h > <nl> # include < glob . h > <nl> GeoIPBackend ::~ GeoIPBackend () { <nl> bool GeoIPBackend :: lookup_static ( const GeoIPDomain & dom , const DNSName & search , const QType & qtype , const DNSName & qdomain , const std :: string & ip , GeoIPLookup & gl , bool v6 ) { <nl> const auto i = dom . records . find ( search ); <nl> int cumul_probability = 0 ; <nl> - int probability_rnd = 1 +( random () % 1000 ); // setting probability = 0 means it never is used <nl> + int probability_rnd = 1 +( dns_random ( 1000 )); // setting probability = 0 means it never is used <nl>  <nl> if ( i != dom . records . end ()) { // return static value <nl> for ( const auto & rr : i -> second ) {
string * doProcessUDPQuestion ( const std :: string & question , const ComboAddress & fr <nl> SyncRes :: s_queries ++; <nl> ageDNSPacket ( response , age ); <nl> sendto ( fd , response . c_str (), response . length (), 0 , ( struct sockaddr *) & fromaddr , fromaddr . getSocklen ()); <nl> - if ( response . length () >= sizeof ( struct dnsheader )) <nl> - updateRcodeStats ((( struct dnsheader *) response . c_str ())-> rcode ); <nl> + if ( response . length () >= sizeof ( struct dnsheader )) { <nl> + struct dnsheader dh ; <nl> + memcpy (& dh , response . c_str (), sizeof ( dh )); <nl> + updateRcodeStats ( dh . rcode ); <nl> + } <nl> g_stats . avgLatencyUsec =( uint64_t )(( 1 - 0 . 0001 )* g_stats . avgLatencyUsec + 0 ); // we assume 0 usec <nl> return 0 ; <nl> }
try <nl> cerr <<" generate - zone - key zsk | ksk [ bits ] [ algorithm ]\ n "; <nl> cerr <<" Generate a ZSK or KSK to stdout with specified algo & bits \ n "; <nl> cerr <<" hash - zone - record ZONE RNAME Calculate the NSEC3 hash for RNAME in ZONE \ n "; <nl> - cerr <<" increase - serial ZONE Increases the SOA - serial by 1 . Uses SOA - EDIT \ n "; <nl> + cerr <<" increase - serial ZONE Increases the SOA - serial by 1 . Uses SOA - EDIT \ n "; <nl> cerr <<" import - zone - key ZONE FILE Import from a file a private key , ZSK or KSK \ n "; <nl> cerr <<" [ ksk | zsk ] Defaults to KSK \ n "; <nl> cerr <<" rectify - zone ZONE [ ZONE ..] Fix up DNSSEC fields ( order , auth )\ n ";
char * oracle_cb_rewrite_indexname ( M_sql_connpool_t * pool , const char * index_name <nl> for ( max_sect_len = 6 ; max_sect_len >= 2 ; max_sect_len --) { <nl> size_t i ; <nl> /* Don ' t need position 0 as it is always just " i " for index . truncate from end . */ <nl> - for ( i = num_sects - 1 ; i > 0 ; i ++) { <nl> + for ( i = num_sects - 1 ; i > 0 ; i --) { <nl> M_buf_truncate ( buf , 0 ); <nl> oracle_cb_rewrite_indexname_int ( buf , sects , num_sects , max_sect_len , i ); <nl> if ( M_buf_len ( buf ) <= 30 )
static M_sql_error_t mysql_bind_params ( M_sql_driver_stmt_t * driver_stmt , M_sql_s <nl> M_sql_error_t err = M_SQL_ERROR_SUCCESS ; <nl> unsigned int merr ; <nl> size_t num_cols = M_sql_driver_stmt_bind_cnt ( stmt ); <nl> - size_t num_rows = mysql_num_process_rows ( M_sql_driver_stmt_bind_rows ( stmt ), num_cols ); <nl> + size_t num_rows = mysql_num_process_rows ( num_cols , M_sql_driver_stmt_bind_rows ( stmt )); <nl> size_t row ; <nl> size_t i ; <nl>  <nl> static M_sql_error_t mysql_cb_execute ( M_sql_conn_t * conn , M_sql_stmt_t * stmt , si <nl>  <nl> /* Get number of rows that are processed at once , supports <nl> * comma - delimited values for inserting multiple rows . */ <nl> - * rows_executed = mysql_num_process_rows ( M_sql_driver_stmt_bind_rows ( stmt ), M_sql_driver_stmt_bind_cnt ( stmt )); <nl> + * rows_executed = mysql_num_process_rows ( M_sql_driver_stmt_bind_cnt ( stmt ), M_sql_driver_stmt_bind_rows ( stmt ); <nl>  <nl> if ( mysql_stmt_execute ( driver_stmt -> stmt ) != 0 ) { <nl> unsigned int merr = mysql_stmt_errno ( driver_stmt -> stmt );
M_bool M_hash_u64u64_get ( const M_hash_u64u64_t * h , M_uint64 key , M_uint64 * value <nl>  <nl> retval = M_hashtable_get (( const M_hashtable_t *) h , & key , & outval ); <nl>  <nl> - if ( value != NULL ) <nl> + if ( retval && value != NULL ) <nl> * value = *( M_uint64 *) outval ; <nl>  <nl> return retval ; <nl> M_bool M_hash_u64u64_multi_get ( const M_hash_u64u64_t * h , M_uint64 key , size_t id <nl>  <nl> retval = M_hashtable_multi_get (( const M_hashtable_t *) h , & key , idx , & outval ); <nl>  <nl> - if ( value != NULL ) <nl> + if ( retval && value != NULL ) <nl> * value = *( M_uint64 *) outval ; <nl>  <nl> return retval ;
int MySQLDB :: exec_sql_query ( MYSQL * conn , char * sql , <nl> // than a simple 0 <nl> if (( result = mysql_store_result (& mysql )) == NULL ) <nl> rc = 0 ; // unable to retrieve the result but still the query succeded <nl> - else <nl> + else { <nl> + mysql_free_result ( result ); <nl> rc = mysql_num_rows ( result ); <nl> + } <nl> } <nl>  <nl> if ( doLock && m ) m -> unlock ( __FILE__ , __LINE__ );
static int ssl_parse_server_key_exchange ( mbedtls_ssl_context * ssl ) <nl> /* <nl> * Read signature <nl> */ <nl> + <nl> + if ( p > end - 2 ) <nl> + { <nl> + MBEDTLS_SSL_DEBUG_MSG ( 1 , ( " bad server key exchange message " ) ); <nl> + mbedtls_ssl_send_alert_message ( ssl , MBEDTLS_SSL_ALERT_LEVEL_FATAL , <nl> + MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR ); <nl> + return ( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE ); <nl> + } <nl> sig_len = ( p [ 0 ] << 8 ) | p [ 1 ]; <nl> p += 2 ; <nl> 
int ssl_set_psk ( ssl_context * ssl , const unsigned char * psk , size_t psk_len , <nl> ssl -> psk = polarssl_malloc ( ssl -> psk_len ); <nl> ssl -> psk_identity = polarssl_malloc ( ssl -> psk_identity_len ); <nl>  <nl> - if ( ssl -> psk == NULL || ssl -> psk_identity == NULL ) <nl> + if ( ssl -> psk == NULL ) <nl> return ( POLARSSL_ERR_SSL_MALLOC_FAILED ); <nl> + if ( ssl -> psk_identity == NULL ) <nl> + { <nl> + polarssl_free ( ssl -> psk ); <nl> + return ( POLARSSL_ERR_SSL_MALLOC_FAILED ); <nl> + } <nl>  <nl> memcpy ( ssl -> psk , psk , ssl -> psk_len ); <nl> memcpy ( ssl -> psk_identity , psk_identity , ssl -> psk_identity_len );
int ctr_drbg_update_internal ( ctr_drbg_context * ctx , <nl> /* <nl> * Increase counter <nl> */ <nl> - for ( i = CTR_DRBG_BLOCKSIZE ; i >= 0 ; i -- ) <nl> + for ( i = CTR_DRBG_BLOCKSIZE ; i > 0 ; i -- ) <nl> if ( ++ ctx -> counter [ i - 1 ] != 0 ) <nl> break ; <nl> 
real_sync_title ( NautilusWindow * window , <nl> notebook = NAUTILUS_NOTEBOOK ( NAUTILUS_NAVIGATION_WINDOW_PANE ( slot -> pane )-> notebook ); <nl> nautilus_notebook_sync_tab_label ( notebook , slot ); <nl>  <nl> - nautilus_navigation_window_pane_sync_tab_menu_title ( NAUTILUS_NAVIGATION_WINDOW_PANE ( nautilus_window_get_pane_from_slot ( window , slot )), slot ); <nl> + if ( slot -> pane -> is_active ) { <nl> + nautilus_navigation_window_pane_sync_tab_menu_title ( NAUTILUS_NAVIGATION_WINDOW_PANE ( slot -> pane ), slot ); <nl> + } <nl> } <nl>  <nl> static NautilusIconInfo *
nautilus_icon_container_receive_dropped_icons ( NautilusIconContainer * container , <nl> GdkDragContext * context , <nl> int x , int y ) <nl> { <nl> - char * drop_target ; <nl> + char * drop_target , * container_uri ; <nl> gboolean local_move_only ; <nl> double world_x , world_y ; <nl> gboolean icon_hit ; <nl> nautilus_icon_container_receive_dropped_icons ( NautilusIconContainer * container , <nl> action = GDK_ACTION_MOVE ; <nl> } else { <nl> action = GDK_ACTION_MOVE | GDK_ACTION_COPY | GDK_ACTION_LINK ; <nl> + container_uri = get_container_uri ( container ); <nl>  <nl> - if ( selection_is_image_file ( container -> details -> dnd_info -> drag_info . selection_list )) { <nl> + if ( eel_uri_is_desktop ( container_uri ) && <nl> + selection_is_image_file ( container -> details -> dnd_info -> drag_info . selection_list )) { <nl> action |= NAUTILUS_DND_ACTION_SET_AS_BACKGROUND ; <nl> } <nl> + <nl> + g_free ( container_uri ); <nl> } <nl> real_action = nautilus_drag_drop_action_ask <nl> ( GTK_WIDGET ( container ), action );
location_cell_data_func ( GtkTreeViewColumn * column , <nl> NAUTILUS_LIST_MODEL_FILE_COLUMN , & file , <nl> - 1 ); <nl>  <nl> + /* The file might be NULL if we just toggled an expander <nl> + * and we ' re still loading the subdirectory . <nl> + */ <nl> + if ( file == NULL ) { <nl> + return ; <nl> + } <nl> + <nl> if ( show_trash_orig && nautilus_file_is_in_trash ( file )) { <nl> NautilusFile * orig_file ; <nl> 
nautilus_entry_new_with_max_length ( guint16 max ) <nl> GtkWidget * widget ; <nl>  <nl> widget = gtk_widget_new ( NAUTILUS_TYPE_ENTRY , NULL ); <nl> - GTK_ENTRY ( widget )-> text_max_length = max ; <nl> + gtk_entry_set_max_length ( GTK_ENTRY ( widget ), max ); <nl>  <nl> return widget ; <nl> } <nl> nautilus_entry_selection_clear ( GtkWidget * widget , <nl> { <nl> g_assert ( NAUTILUS_IS_ENTRY ( widget )); <nl>  <nl> - if ( gdk_selection_owner_get ( event -> selection ) == widget -> window ) { <nl> + if ( gdk_selection_owner_get ( event -> selection ) == gtk_widget_get_window ( widget )) { <nl> return FALSE ; <nl> } <nl> 
nautilus_window_slot_content_view_matches ( NautilusWindowSlot * self , <nl> return FALSE ; <nl> } <nl>  <nl> - if ( id != NAUTILUS_VIEW_INVALID_ID && NAUTILUS_IS_FILES_VIEW ( priv -> content_view )){ <nl> + if ( id != NAUTILUS_VIEW_INVALID_ID && NAUTILUS_IS_FILES_VIEW ( priv -> content_view )) { <nl> return nautilus_files_view_get_view_id ( NAUTILUS_FILES_VIEW ( priv -> content_view )) == id ; <nl> } else { <nl> return FALSE ;
# include < libnautilus - private / nautilus - icon - names . h > <nl> # include < libnautilus - private / nautilus - program - choosing . h > <nl> # include < libnautilus - private / nautilus - tree - view - drag - dest . h > <nl> -# include < libnautilus - private / nautilus - cell - renderer - pixbuf - emblem . h > <nl> # include < libnautilus - private / nautilus - sidebar - provider . h > <nl> # include < libnautilus - private / nautilus - module . h > <nl> # include < libnautilus - private / nautilus - window - info . h > <nl> create_tree ( FMTreeView * view ) <nl> /* Create column */ <nl> column = gtk_tree_view_column_new (); <nl>  <nl> - cell = nautilus_cell_renderer_pixbuf_emblem_new (); <nl> + cell = gtk_cell_renderer_pixbuf_new (); <nl> gtk_tree_view_column_pack_start ( column , cell , FALSE ); <nl> gtk_tree_view_column_set_attributes ( column , cell , <nl> " pixbuf ", FM_TREE_MODEL_CLOSED_PIXBUF_COLUMN , <nl> " pixbuf_expander_closed ", FM_TREE_MODEL_CLOSED_PIXBUF_COLUMN , <nl> " pixbuf_expander_open ", FM_TREE_MODEL_OPEN_PIXBUF_COLUMN , <nl> - " pixbuf_emblem ", FM_TREE_MODEL_EMBLEM_PIXBUF_COLUMN , <nl> NULL ); <nl>  <nl> cell = gtk_cell_renderer_text_new ();
create_basic_page ( NautilusPropertiesWindow * window ) <nl> FALSE ); <nl> } <nl>  <nl> - if ( should_show_free_space ( window )) { <nl> + if ( should_show_free_space ( window ) <nl> + && ! should_show_volume_usage ( window )) { <nl> append_blank_row ( grid ); <nl>  <nl> append_title_value_pair ( window , grid , _ (" Free space :"),
static void TraverseCustomTexture ( GF_Node * node , void * rs , Bool is_destroy ) <nl>  <nl> static void CustomTexture_update ( GF_TextureHandler * txh ) <nl> { <nl> +# ifndef GPAC_DISABLE_3D <nl> char data [ 12 ]; <nl> +# endif <nl> CustomTextureStack * stack = gf_node_get_private ( txh -> owner ); <nl> // texture not setup , do it <nl> if (! txh -> tx_io ) {
static GF_Err ft_set_font ( GF_FontReader * dr , const char * OrigFontName , u32 style <nl> opt = gf_modules_get_option (( GF_BaseInterface *) dr , " FontEngine ", fname ); <nl>  <nl> if ( opt ) { <nl> - gf_free ( fname ); <nl> FT_Face face ; <nl> + gf_free ( fname ); <nl> if ( FT_New_Face ( ftpriv -> library , opt , 0 , & face )) return GF_IO_ERR ; <nl> if (! face ) return GF_IO_ERR ; <nl> gf_list_add ( ftpriv -> loaded_fonts , face );
static void VR_write_yv12_to_yuv ( GF_VideoSurface * vs , unsigned char * src , u32 s <nl> u32 src_width , u32 src_height , const GF_Window * src_wnd ) <nl> { <nl> unsigned char * pY , * pU , * pV ; <nl> + u32 start_y ; <nl> pY = src ; <nl> pU = src + src_stride * src_height ; <nl> pV = src + 5 * src_stride * src_height / 4 ; <nl>  <nl> + start_y = src_wnd -> y ; <nl> + /* because of U and V downsampling by 2x2 , working with odd Y offset will lead to a half - line shift between Y and UV components . We <nl> + therefore force an even Y offset for U and V planes .*/ <nl> + if ( start_y % 2 ) start_y --; <nl> + <nl> pY = pY + src_stride * src_wnd -> y + src_wnd -> x ; <nl> - pU = pU + ( src_stride * src_wnd -> y / 2 + src_wnd -> x ) / 2 ; <nl> - pV = pV + ( src_stride * src_wnd -> y / 2 + src_wnd -> x ) / 2 ; <nl> + pU = pU + (( src_stride * start_y ) / 2 + src_wnd -> x ) / 2 ; <nl> + pV = pV + (( src_stride * start_y ) / 2 + src_wnd -> x ) / 2 ; <nl>  <nl>  <nl> if ( is_planar_yuv ( vs -> pixel_format )) {
common : <nl> txh -> tx_io -> conv_format = dst . pixel_format = GF_PIXEL_RGB_24 ; <nl> /* stretch and flip */ <nl> gf_stretch_bits (& dst , & src , NULL , NULL , 0xFF , 1 , NULL , NULL ); <nl> + txh -> flags |= GF_SR_TEXTURE_NO_GL_FLIP ; <nl> break ; <nl> case GF_PIXEL_YUVD : <nl> if (( txh -> compositor -> depth_gl_type == GF_SC_DEPTH_GL_NONE ) || ( txh -> compositor -> depth_gl_type == GF_SC_DEPTH_GL_VBO )) {
static GF_Glyph * ft_load_glyph ( GF_FontReader * dr , u32 glyph_name ) <nl>  <nl> glyph_idx = FT_Get_Char_Index ( ftpriv -> active_face , glyph_name ); <nl> /* missing glyph */ <nl> - if (! glyph_idx ) return NULL ; <nl> + if (! glyph_idx ) { <nl> + GF_LOG ( GF_LOG_WARNING , GF_LOG_PARSER , ("[ FreeType ] Glyph not found for char % d in font % s ( style % s )\ n ", glyph_name , ftpriv -> active_face -> family_name , ftpriv -> active_face -> style_name )); <nl> + return NULL ; <nl> + } <nl>  <nl> /* work in design units */ <nl> FT_Load_Glyph ( ftpriv -> active_face , glyph_idx , FT_LOAD_NO_SCALE | FT_LOAD_NO_BITMAP );
GF_Err SDLVid_ResizeWindow ( GF_VideoOutput * dr , u32 width , u32 height ) <nl> u32 flags , nb_bits ; <nl> const char * opt ; <nl>  <nl> - if (( ctx -> width == width ) && ( ctx -> height == height ) ) { <nl> + if ( ctx -> screen && ( ctx -> width == width ) && ( ctx -> height == height ) ) { <nl> gf_mx_v ( ctx -> evt_mx ); <nl> return GF_OK ; <nl> } <nl> GF_Err SDLVid_ResizeWindow ( GF_VideoOutput * dr , u32 width , u32 height ) <nl> # else <nl> hw_reset = GF_TRUE ; <nl> ctx -> screen = SDL_SetVideoMode ( width , height , 0 , flags ); <nl> + if (! ctx -> screen ) { <nl> + GF_LOG ( GF_LOG_ERROR , GF_LOG_MMIO , ("[ SDL ] Cannot create window : % s \ n ", SDL_GetError ())); <nl> + gf_mx_v ( ctx -> evt_mx ); <nl> + return GF_IO_ERR ; <nl> + } <nl> # endif <nl> - assert ( ctx -> screen ); <nl> ctx -> width = width ; <nl> ctx -> height = height ; <nl> memset (& evt , 0 , sizeof ( GF_Event ));
static Bool netctrl_process ( GF_TermExt * termext , u32 action , void * param ) <nl> event . mouse . x = ( 1 - gaze_x ) * netctrl -> term -> compositor -> display_width ; <nl> event . mouse . y = ( 1 - gaze_y ) * netctrl -> term -> compositor -> display_height ; <nl>  <nl> - if (! netctrl -> mouse_down ){ <nl> + if (! netctrl -> mouse_down ) { <nl> + // don ' t grab if mouse is down <nl> + if ( netctrl -> term -> compositor -> navigation_state ) break ; <nl> netctrl -> mouse_down = GF_TRUE ; <nl> event . type = GF_EVENT_MOUSEDOWN ; <nl> netctrl -> term -> compositor -> video_out -> on_event ( netctrl -> term -> compositor -> video_out -> evt_cbk_hdl , & event );
s32 AVC_ReadSeqInfo ( char * sps_data , u32 sps_size , AVCState * avc , u32 subseq_sps , <nl>  <nl> pcomp = gf_bs_read_int ( bs , 8 ); <nl> /* sanity checks */ <nl> - if ( pcomp && 0x3 ) <nl> - goto exit ; <nl> + // JLF commented - breaks SVC import and no time to investigate <nl> +// if ( pcomp && 0x3 ) goto exit ; <nl>  <nl> level_idc = gf_bs_read_int ( bs , 8 ); <nl> 
void gf_log ( const char * fmt , ...) <nl> va_start ( vl , fmt ); <nl> log_cbk ( user_log_cbk , call_lev , call_tool , fmt , vl ); <nl> va_end ( vl ); <nl> - if ( log_exit_on_error && call_lev == GF_LOG_ERROR ) <nl> + if ( log_exit_on_error && ( call_lev == GF_LOG_ERROR ) && ( call_tool != GF_LOG_MEMORY )) { <nl> exit ( 1 ); <nl> + } <nl> } <nl>  <nl> GF_EXPORT
GF_Err dinf_Read ( GF_Box * s , GF_BitStream * bs ) <nl> return e ; <nl> } <nl> if (!(( GF_DataInformationBox *) s )-> dref ) { <nl> + GF_Box * dref ; <nl> GF_LOG ( GF_LOG_ERROR , GF_LOG_CONTAINER , ("[ iso file ] Missing dref box in dinf \ n ")); <nl> - (( GF_DataInformationBox *) s )-> dref = ( GF_DataReferenceBox *) gf_isom_box_new ( GF_ISOM_BOX_TYPE_DREF ); <nl> + dref = gf_isom_box_new ( GF_ISOM_BOX_TYPE_DREF ); <nl> + (( GF_DataInformationBox *) s )-> dref = ( GF_DataReferenceBox *) dref ; <nl> + gf_isom_box_add_for_dump_mode ( s , dref ); <nl> } <nl> return GF_OK ; <nl> }
static DownloadGroupStatus dash_download_group_download ( GF_DashClient * dash , GF_ <nl> /* At this stage , there are some segments left to be downloaded */ <nl> e = gf_dash_resolve_url ( dash -> mpd , rep , group , dash -> base_url , GF_MPD_RESOLVE_URL_MEDIA , group -> download_segment_index , & new_base_seg_url , & start_range , & end_range , & group -> current_downloaded_segment_duration , NULL , & key_url , & key_iv , NULL ); <nl> gf_mx_v ( dash -> dl_mutex ); <nl> - if ( e ) { <nl> + if ( e || ! new_base_seg_url ) { <nl> /* do something !!*/ <nl> return GF_DASH_DownloadCancel ; <nl> }
static int infocamere_1200_init ( sc_pkcs15_card_t * p15card ) <nl>  <nl> if ( r != SC_SUCCESS || file -> size > 255 ) { <nl> /* Not EF . GDO */ <nl> + if ( file ) <nl> + sc_file_free ( file ); <nl> return SC_ERROR_WRONG_CARD ; <nl> } <nl>  <nl> static int infocamere_1200_init ( sc_pkcs15_card_t * p15card ) <nl>  <nl> if ( ef_gdo [ 0 ] != 0x5A || file -> size < 3 ) { <nl> /* Not EF . GDO */ <nl> + sc_file_free ( file ); <nl> return SC_ERROR_WRONG_CARD ; <nl> } <nl>  <nl> static int infocamere_1200_init ( sc_pkcs15_card_t * p15card ) <nl>  <nl> if ( file -> size < ( size_t ) ( len_iccsn + 5 )) { <nl> /* Not CHN */ <nl> + sc_file_free ( file ); <nl> return SC_ERROR_WRONG_CARD ; <nl> } <nl> + sc_file_free ( file ); <nl>  <nl> if (! <nl> ( ef_gdo [ len_iccsn + 2 ] == 0x5F
sign_verify ( CK_SLOT_ID slot , CK_SESSION_HANDLE session , CK_OBJECT_HANDLE priv_ke <nl> CK_ULONG signat_len ; <nl> int j , errors = 0 ; <nl>  <nl> + memcpy ( buf , "\ x00 \ x01 \ xFF \ xFF \ xFF \ xFF \ xFF \ xFF \ xFF \ xFF \ x00 ", 11 ); <nl> + <nl> for ( j = 0 , mech_type = mech_types ; * mech_type != 0xffffff ; mech_type ++, j ++) { <nl> CK_MECHANISM mech = {* mech_type , NULL , 0 }; <nl> 
parse_dir_record ( sc_card_t * card , u8 ** buf , size_t * buflen , int rec_nr ) <nl> else <nl> app -> label = NULL ; <nl>  <nl> - if ( asn1_dirrecord [ 2 ]. flags & SC_ASN1_PRESENT ) { <nl> + if ( asn1_dirrecord [ 2 ]. flags & SC_ASN1_PRESENT && path_len > 0 ) { <nl> /* application path present : ignore AID */ <nl> if ( path_len > SC_MAX_PATH_SIZE ) { <nl> free ( app );
static CK_RV pkcs15_gen_keypair ( struct sc_pkcs11_card * p11card , <nl> & keytype , NULL ); <nl> if ( rv != CKR_OK && pMechanism -> mechanism == CKM_RSA_PKCS_KEY_PAIR_GEN ) <nl> keytype = CKK_RSA ; <nl> - if ( rv != CKR_OK && pMechanism -> mechanism == CKM_EC_KEY_PAIR_GEN ) <nl> + else if ( rv != CKR_OK && pMechanism -> mechanism == CKM_EC_KEY_PAIR_GEN ) <nl> keytype = CKK_EC ; <nl> else if ( rv != CKR_OK ) <nl> goto kpgen_done ; <nl> + <nl> if ( keytype == CKK_GOSTR3410 ) { <nl> keygen_args . prkey_args . key . algorithm = SC_ALGORITHM_GOSTR3410 ; <nl> pub_args . key . algorithm = SC_ALGORITHM_GOSTR3410 ;
static int iso7816_process_fci ( sc_card_t * card , sc_file_t * file , <nl> sc_hex_dump ( ctx , SC_LOG_DEBUG_NORMAL , <nl> file -> name , file -> namelen , tbuf , sizeof ( tbuf )); <nl> sc_debug ( ctx , SC_LOG_DEBUG_NORMAL , " File name : % s \ n ", tbuf ); <nl> + if (! file -> type ) <nl> + file -> type = SC_FILE_TYPE_DF ; <nl> } <nl> tag = sc_asn1_find_tag ( ctx , p , len , 0x85 , & taglen ); <nl> if ( tag != NULL && taglen ) {
do_read_private_key ( const char * filename , const char * format , <nl> char * passphrase = NULL ; <nl> int r ; <nl>  <nl> + if ( opt_passphrase ) <nl> + passphrase = opt_passphrase ; <nl> + <nl> while ( 1 ) { <nl> if (! format || ! strcasecmp ( format , " pem ")) { <nl> r = do_read_pem_private_key ( filename , passphrase , pk ); <nl> do_read_private_key ( const char * filename , const char * format , <nl>  <nl> if ( r >= 0 || passphrase ) <nl> break ; <nl> - if (( passphrase = opt_passphrase ) != 0 ) <nl> - continue ; <nl> + /* second try ... */ <nl> passphrase = getpass (" Please enter passphrase " <nl> " to unlock secret key : "); <nl> if (! passphrase )
static int test_signature ( CK_SESSION_HANDLE sess ) <nl>  <nl> /* Fill in data [ 0 ] and dataLens [ 0 ] */ <nl> dataLen = modLenBytes ; <nl> + data [ 0 ] = 0x00 ; <nl> data [ 1 ] = 0x01 ; <nl> memset ( data + 2 , 0xFF , dataLen - 3 - dataLens [ 1 ]); <nl> data [ dataLen - 36 ] = 0x00 ;
static int asn1_encode_path ( struct sc_context * ctx , const struct sc_path * path , <nl>  <nl> static const struct sc_asn1_entry c_asn1_com_obj_attr [ 6 ] = { <nl> { " label ", SC_ASN1_UTF8STRING , ASN1_UTF8STRING , SC_ASN1_OPTIONAL , NULL }, <nl> - { " flags ", SC_ASN1_BIT_STRING , ASN1_BIT_STRING , SC_ASN1_OPTIONAL , NULL }, <nl> + { " flags ", SC_ASN1_BIT_FIELD , ASN1_BIT_STRING , SC_ASN1_OPTIONAL , NULL }, <nl> { " authId ", SC_ASN1_PKCS15_ID , ASN1_OCTET_STRING , SC_ASN1_OPTIONAL , NULL }, <nl> { " userConsent ", SC_ASN1_INTEGER , ASN1_INTEGER , SC_ASN1_OPTIONAL , NULL }, <nl> { " accessControlRules ", SC_ASN1_STRUCT , ASN1_SEQUENCE | SC_ASN1_CONS , SC_ASN1_OPTIONAL , NULL },
static int iso7816_select_file ( sc_card_t * card , <nl> if ( file == NULL ) <nl> SC_FUNC_RETURN ( card -> ctx , 0 , SC_ERROR_OUT_OF_MEMORY ); <nl> file -> path = * in_path ; <nl> - if ( card -> ops -> process_fci == NULL ) <nl> + if ( card -> ops -> process_fci == NULL ) { <nl> + sc_file_free ( file ); <nl> SC_FUNC_RETURN ( card -> ctx , 2 , SC_ERROR_NOT_SUPPORTED ); <nl> + } <nl> if ( apdu . resp [ 1 ] <= apdu . resplen ) <nl> card -> ops -> process_fci ( card , file , apdu . resp + 2 , apdu . resp [ 1 ]); <nl> * file_out = file ;
int sc_connect_card ( sc_reader_t * reader , int slot_id , <nl> sc_context_t * ctx = reader -> ctx ; <nl> sc_slot_info_t * slot = _sc_get_slot_info ( reader , slot_id ); <nl> struct sc_card_driver * driver ; <nl> - int i , r = 0 , idx ; <nl> + int i , r = 0 , idx , connected = 0 ; <nl>  <nl> assert ( card_out != NULL ); <nl> SC_FUNC_CALLED ( ctx , 1 ); <nl> int sc_connect_card ( sc_reader_t * reader , int slot_id , <nl> if ( r ) <nl> goto err ; <nl>  <nl> + connected = 1 ; <nl> card -> reader = reader ; <nl> card -> slot = slot ; <nl> card -> ctx = ctx ; <nl> int sc_connect_card ( sc_reader_t * reader , int slot_id , <nl> sc_debug ( ctx , " card info : % s , % i , 0x % X \ n ", card -> name , card -> type , card -> flags ); <nl> SC_FUNC_RETURN ( ctx , 1 , 0 ); <nl> err : <nl> + if ( connected ) <nl> + reader -> ops -> disconnect ( reader , slot , 0 ); <nl> if ( card != NULL ) <nl> sc_card_free ( card ); <nl> SC_FUNC_RETURN ( ctx , 1 , r );
/* ----------------------------------------------------------------------- <nl> * formatting . c <nl> * <nl> - * $ Header : / cvsroot / pgsql / src / backend / utils / adt / formatting . c , v 1 . 62 2003 / 03 / 27 17 : 10 : 55 momjian Exp $ <nl> + * $ Header : / cvsroot / pgsql / src / backend / utils / adt / formatting . c , v 1 . 63 2003 / 04 / 02 02 : 33 : 52 tgl Exp $ <nl> * <nl> * <nl> * Portions Copyright ( c ) 1999 - 2002 , PostgreSQL Global Development Group <nl> NUM_processor ( FormatNode * node , NUMDesc * Num , char * inout , char * number , <nl> NUMProc _Np , <nl> * Np = & _Np ; <nl>  <nl> + MemSet ( Np , 0 , sizeof ( NUMProc )); <nl> + <nl> Np -> Num = Num ; <nl> Np -> type = type ; <nl> Np -> number = number ; <nl> NUM_processor ( FormatNode * node , NUMDesc * Num , char * inout , char * number , <nl> if ( IS_PLUS ( Np -> Num ) || IS_MINUS ( Np -> Num )) <nl> { <nl> if ( IS_PLUS ( Np -> Num ) && IS_MINUS ( Np -> Num )== FALSE ) <nl> - Np -> sign_wrote = FALSE ; <nl> + Np -> sign_wrote = FALSE ; /* need sign */ <nl> + else <nl> + Np -> sign_wrote = TRUE ; /* needn ' t sign */ <nl> } <nl> else <nl> {
SyncRepUpdateConfig ( void ) <nl> */ <nl> syncrep_scanner_init ( SyncRepStandbyNames ); <nl> parse_rc = syncrep_yyparse (); <nl> - Assert ( parse_rc == 0 ); <nl> syncrep_scanner_finish (); <nl>  <nl> + if ( parse_rc != 0 ) <nl> + ereport ( ERROR , <nl> + ( errcode ( ERRCODE_SYNTAX_ERROR ), <nl> + errmsg_internal (" synchronous_standby_names parser returned % d ", <nl> + parse_rc ))); <nl> + <nl> SyncRepConfig = syncrep_parse_result ; <nl> syncrep_parse_result = NULL ; <nl> }
print_aligned_vertical ( const printTableContent * cont , FILE * fout ) <nl> if ( cont -> cells [ 0 ] == NULL && cont -> opt -> start_table && <nl> cont -> opt -> stop_table ) <nl> { <nl> - if (! opt_tuples_only ) <nl> + if (! opt_tuples_only && cont -> opt -> default_footer ) <nl> fprintf ( fout , _ ("( No rows )\ n ")); <nl> return ; <nl> }
* <nl> * <nl> * IDENTIFICATION <nl> - * $ Header : / cvsroot / pgsql / src / bin / pg_dump / common . c , v 1 . 41 2000 / 04 / 12 17 : 16 : 14 momjian Exp $ <nl> + * $ Header : / cvsroot / pgsql / src / bin / pg_dump / common . c , v 1 . 42 2000 / 05 / 19 23 : 00 : 00 tgl Exp $ <nl> * <nl> * Modifications - 6 / 12 / 96 - dave @ bensoft . com - version 1 . 13 . dhb . 2 <nl> * <nl> parseNumericArray ( const char * str , char ** array , int arraysize ) <nl> } <nl> else <nl> { <nl> - if (! isdigit ( s ) || j >= sizeof ( temp ) - 1 ) <nl> + if (!( isdigit ( s ) || s == '-') || j >= sizeof ( temp ) - 1 ) <nl> { <nl> fprintf ( stderr , " parseNumericArray : bogus number \ n "); <nl> exit ( 2 );
* <nl> * <nl> * IDENTIFICATION <nl> - * $ Header : / cvsroot / pgsql / src / backend / executor / execQual . c , v 1 . 48 1999 / 03 / 14 20 : 01 : 14 momjian Exp $ <nl> + * $ Header : / cvsroot / pgsql / src / backend / executor / execQual . c , v 1 . 49 1999 / 03 / 19 22 : 31 : 39 momjian Exp $ <nl> * <nl> *------------------------------------------------------------------------- <nl> */ <nl> ExecTargetList ( List * targetlist , <nl> * free the nulls array if we allocated one .. <nl> */ <nl> if ( nodomains > 64 ) <nl> + { <nl> pfree ( null_head ); <nl> - <nl> + pfree ( fjIsNull ); <nl> + } <nl> + <nl> return newTuple ; <nl> } <nl> 
* <nl> * Copyright ( c ) 2000 - 2008 , PostgreSQL Global Development Group <nl> * <nl> - * $ PostgreSQL : pgsql / src / bin / psql / describe . c , v 1 . 167 2008 / 04 / 14 15 : 04 : 20 alvherre Exp $ <nl> + * $ PostgreSQL : pgsql / src / bin / psql / describe . c , v 1 . 168 2008 / 05 / 02 10 : 16 : 16 heikki Exp $ <nl> */ <nl> # include " postgres_fe . h " <nl> # include " describe . h " <nl> listTables ( const char * tabtypes , const char * pattern , bool verbose ) <nl> gettext_noop (" Table ")); <nl>  <nl> if ( verbose ) <nl> + { <nl> + appendPQExpBuffer (& buf , <nl> + ",\ n pg_catalog . pg_size_pretty ( pg_catalog . pg_relation_size ( c . oid )) as \"% s \"", <nl> + gettext_noop (" Size ")); <nl> appendPQExpBuffer (& buf , <nl> ",\ n pg_catalog . obj_description ( c . oid , ' pg_class ') as \"% s \"", <nl> gettext_noop (" Description ")); <nl> + } <nl>  <nl> appendPQExpBuffer (& buf , <nl> "\ nFROM pg_catalog . pg_class c "
create_internal ( void * place , size_t size , <nl> area -> mapping_pinned = false ; <nl> memset ( area -> segment_maps , 0 , sizeof ( dsa_segment_map ) * DSA_MAX_SEGMENTS ); <nl> area -> high_segment_index = 0 ; <nl> + area -> freed_segment_counter = 0 ; <nl> LWLockInitialize (& control -> lock , control -> lwlock_tranche_id ); <nl> for ( i = 0 ; i < DSA_NUM_SIZE_CLASSES ; ++ i ) <nl> LWLockInitialize ( DSA_SCLASS_LOCK ( area , i ), <nl> attach_internal ( void * place , dsm_segment * segment , dsa_handle handle ) <nl> errmsg (" could not attach to dynamic shared area "))); <nl> } <nl> ++ control -> refcnt ; <nl> + area -> freed_segment_counter = area -> control -> freed_segment_counter ; <nl> LWLockRelease ( DSA_AREA_LOCK ( area )); <nl>  <nl> return area ;
add_json ( Datum val , bool is_null , StringInfo result , Oid val_type , bool key_scal <nl> tcategory = TYPCATEGORY_ARRAY ; <nl> else if ( val_type == RECORDOID ) <nl> tcategory = TYPCATEGORY_COMPOSITE ; <nl> - else if ( val_type == JSONOID ) <nl> + else if ( val_type == JSONOID || val_type == JSONBOID ) <nl> tcategory = TYPCATEGORY_JSON ; <nl> else <nl> tcategory = TypeCategory ( val_type );
* ENHANCEMENTS , OR MODIFICATIONS . <nl> * <nl> * IDENTIFICATION <nl> - * $ Header : / cvsroot / pgsql / src / pl / plperl / plperl . c , v 1 . 39 2003 / 08 / 04 00 : 43 : 33 momjian Exp $ <nl> + * $ Header : / cvsroot / pgsql / src / pl / plperl / plperl . c , v 1 . 40 2003 / 09 / 04 15 : 16 : 39 tgl Exp $ <nl> * <nl> **********************************************************************/ <nl>  <nl> plperl_build_tuple_argument ( HeapTuple tuple , TupleDesc tupdesc ) <nl>  <nl> for ( i = 0 ; i < tupdesc -> natts ; i ++) <nl> { <nl> + /* ignore dropped attributes */ <nl> + if ( tupdesc -> attrs [ i ]-> attisdropped ) <nl> + continue ; <nl> + <nl> /************************************************************ <nl> * Get the attribute name <nl> ************************************************************/
* Portions Copyright ( c ) 1996 - 2001 , PostgreSQL Global Development Group <nl> * Portions Copyright ( c ) 1994 , Regents of the University of California <nl> * <nl> - * $ Header : / cvsroot / pgsql / src / backend / access / transam / xlog . c , v 1 . 92 2002 / 04 / 21 19 : 08 : 02 thomas Exp $ <nl> + * $ Header : / cvsroot / pgsql / src / backend / access / transam / xlog . c , v 1 . 93 2002 / 04 / 24 01 : 54 : 43 momjian Exp $ <nl> * <nl> *------------------------------------------------------------------------- <nl> */ <nl> InstallXLogFileSegment ( uint32 log , uint32 seg , char * tmppath , <nl> * overwrite an existing logfile . However , there shouldn ' t be one , so <nl> * rename () is an acceptable substitute except for the truly paranoid . <nl> */ <nl> -# ifndef __BEOS__ <nl> +# if ! defined ( __BEOS__ ) && ! defined ( N_PLAT_NLM ) <nl> if ( link ( tmppath , path ) < 0 ) <nl> elog ( PANIC , " link from % s to % s ( initialization of log file % u , segment % u ) failed : % m ", <nl> tmppath , path , log , seg );
lazy_scan_heap ( Relation onerel , LVRelStats * vacrelstats , <nl> if (! lazy_check_needs_freeze ( buf )) <nl> { <nl> UnlockReleaseBuffer ( buf ); <nl> + vacrelstats -> scanned_pages ++; <nl> continue ; <nl> } <nl> LockBuffer ( buf , BUFFER_LOCK_UNLOCK );
parse_hba_line ( List * line , int line_num , HbaLine * parsedline ) <nl> token = lfirst ( line_item ); <nl> if ( strcmp ( token , " local ") == 0 ) <nl> { <nl> +# ifdef HAVE_UNIX_SOCKETS <nl> parsedline -> conntype = ctLocal ; <nl> +# else <nl> + ereport ( LOG , <nl> + ( errcode ( ERRCODE_CONFIG_FILE_ERROR ), <nl> + errmsg (" local connections are not supported by this build "), <nl> + errcontext (" line % d of configuration file \"% s \"", <nl> + line_num , HbaFileName ))); <nl> + return false ; <nl> +# endif <nl> } <nl> else if ( strcmp ( token , " host ") == 0 <nl> || strcmp ( token , " hostssl ") == 0
* <nl> * <nl> * IDENTIFICATION <nl> - * $ PostgreSQL : pgsql / src / backend / executor / execMain . c , v 1 . 340 2010 / 01 / 06 03 : 04 : 01 momjian Exp $ <nl> + * $ PostgreSQL : pgsql / src / backend / executor / execMain . c , v 1 . 341 2010 / 01 / 08 02 : 44 : 00 tgl Exp $ <nl> * <nl> *------------------------------------------------------------------------- <nl> */ <nl> EvalPlanQualFetch ( EState * estate , Relation relation , int lockmode , <nl> { <nl> /* it was updated , so look at the updated version */ <nl> tuple . t_self = update_ctid ; <nl> + /* updated row should have xmin matching this xmax */ <nl> + priorXmax = update_xmax ; <nl> continue ; <nl> } <nl> /* tuple was deleted , so give up */
* Portions Copyright ( c ) 1996 - 2008 , PostgreSQL Global Development Group <nl> * <nl> * IDENTIFICATION <nl> - * $ PostgreSQL : pgsql / src / timezone / pgtz . c , v 1 . 60 2008 / 07 / 01 03 : 40 : 55 tgl Exp $ <nl> + * $ PostgreSQL : pgsql / src / timezone / pgtz . c , v 1 . 61 2008 / 11 / 13 20 : 49 : 38 tgl Exp $ <nl> * <nl> *------------------------------------------------------------------------- <nl> */ <nl> pg_tzenumerate_next ( pg_tzenum * dir ) <nl> continue ; <nl> } <nl>  <nl> + if (! tz_acceptable (& dir -> tz )) <nl> + { <nl> + /* Ignore leap - second zones */ <nl> + continue ; <nl> + } <nl> + <nl> /* Timezone loaded OK . */ <nl> return & dir -> tz ; <nl> }
* Portions Copyright ( c ) 1994 , Regents of the University of California <nl> * <nl> * IDENTIFICATION <nl> - * $ Header : / cvsroot / pgsql / src / backend / nodes / copyfuncs . c , v 1 . 121 2000 / 09 / 12 21 : 06 : 49 tgl Exp $ <nl> + * $ Header : / cvsroot / pgsql / src / backend / nodes / copyfuncs . c , v 1 . 122 2000 / 09 / 20 15 : 28 : 01 tgl Exp $ <nl> * <nl> *------------------------------------------------------------------------- <nl> */ <nl> _copyCommentStmt ( CommentStmt * from ) <nl>  <nl> newnode -> objtype = from -> objtype ; <nl> newnode -> objname = pstrdup ( from -> objname ); <nl> - newnode -> objproperty = pstrdup ( from -> objproperty ); <nl> + if ( from -> objproperty ) <nl> + newnode -> objproperty = pstrdup ( from -> objproperty ); <nl> Node_Copy ( from , newnode , objlist ); <nl> newnode -> comment = pstrdup ( from -> comment ); <nl> 
bool ZipFile :: seek ( int64_t offset , int whence /* = SEEK_SET */) { <nl> setWritePosition ( 0 ); <nl> setReadPosition ( 0 ); <nl> setEof ( false ); <nl> + gzclearerr ( m_gzFile ); <nl> flush (); <nl> off_t result = gzseek ( m_gzFile , offset , whence ); <nl> setPosition ( result );
void Instance :: cloneSet ( ObjectData * clone ) { <nl> tvRefcountedDecRef (& iclonePropVec [ i ]); <nl> tvDupFlattenVars (& propVec ()[ i ], & iclonePropVec [ i ], NULL ); <nl> } <nl> - iclone -> initDynProps (); <nl> if ( o_properties . get () != NULL ) { <nl> + iclone -> initDynProps (); <nl> ssize_t iter = o_properties . get ()-> iter_begin (); <nl> while ( iter != HphpArray :: ElmIndEmpty ) { <nl> auto props = static_cast < HphpArray *>( o_properties . get ());
struct SimpleParser { <nl> case ' u ': { <nl> if ( UNLIKELY ( is_tsimplejson )) { <nl> auto const ch1 = * p ++; <nl> + if ( UNLIKELY ( ch1 != ' 0 ')) return false ; <nl> auto const ch2 = * p ++; <nl> + if ( UNLIKELY ( ch2 != ' 0 ')) return false ; <nl> auto const dch3 = dehexchar (* p ++); <nl> + if ( UNLIKELY ( dch3 < 0 )) return false ; <nl> auto const dch4 = dehexchar (* p ++); <nl> - if ( UNLIKELY ( ch1 != ' 0 ' || ch2 != ' 0 ' || dch3 < 0 || dch4 < 0 )) { <nl> - return false ; <nl> - } <nl> + if ( UNLIKELY ( dch4 < 0 )) return false ; <nl> out = ( dch3 << 4 ) | dch4 ; <nl> return true ; <nl> } else {
private : <nl> void eraseNoCompact ( ssize_t pos ); <nl> void erase ( ssize_t pos ) { <nl> eraseNoCompact ( pos ); <nl> - if ( m_size < m_used / 2 ) { <nl> + if ( m_size <= m_used / 2 ) { <nl> // Compact in order to keep elms from being overly sparse . <nl> compact ( false ); <nl> }
static const pcre_cache_entry * pcre_get_compiled_regex_cache ( CStrRef regex ) { <nl> } <nl> } <nl>  <nl> + /* We ' ve reached a null byte , now check if we ' re actually at the end of the <nl> + string . If not this is a bad expression , and a potential security hole . */ <nl> + if ( regex . length () != ( pp - regex . data ())) { <nl> + raise_error (" Error : Null byte found in pattern "); <nl> + } <nl> + <nl> /* Compile pattern and display a warning if compilation failed . */ <nl> const char * error ; <nl> int erroffset ;
bool JSON_parser ( Variant & z , const char * p , int length , bool const assoc , <nl> // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread <nl> // is explicitly flushed ( e . g ., due to being idle ). <nl> json -> initSb ( length ); <nl> + if ( depth <= 0 ) { <nl> + json -> error_code = json_error_codes :: JSON_ERROR_DEPTH ; <nl> + return false ; <nl> + } <nl> SCOPE_EXIT { <nl> constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024 ; <nl> if ( json -> sb_cap > kMaxPersistentStringBufferCapacity ) json -> flushSb ();
Variant HHVM_FUNCTION ( socket_select , <nl> except = empty_array (); <nl> } <nl> read = hasData ; <nl> + free ( fds ); <nl> return hasData . size (); <nl> } <nl> }
void FastCGITransport :: onHeader ( std :: unique_ptr < folly :: IOBuf > key_chain , <nl> Cursor keyCur ( key_chain . get ()); <nl> auto key = keyCur . readFixedString ( key_chain -> computeChainDataLength ()); <nl>  <nl> + // Don ' t allow requests to inject an HTTP_PROXY environment variable by <nl> + // sending a Proxy header . <nl> + if ( strcasecmp ( key . c_str (), " HTTP_PROXY ") == 0 ) return ; <nl> + <nl> Cursor valCur ( value_chain . get ()); <nl> auto value = valCur . readFixedString ( value_chain -> computeChainDataLength ()); <nl> 
struct Resumable { <nl> static void * Create ( const ActRec * fp , size_t numSlots , jit :: TCA resumeAddr , <nl> Offset resumeOffset , size_t objSize ) { <nl> assert ( fp ); <nl> + assert ( fp -> resumed () == clone ); <nl> DEBUG_ONLY auto const func = fp -> func (); <nl> assert ( func ); <nl> assert ( func -> isResumable ()); <nl> struct Resumable { <nl> auto src = ( void *)(( uintptr_t ) fp - frameSize ); <nl> memcpy ( mem , src , frameSize + sizeof ( ActRec )); <nl>  <nl> + // Set resumed flag . <nl> + actRec -> setResumed (); <nl> + <nl> // Suspend VarEnv if needed <nl> if ( UNLIKELY ( fp -> hasVarEnv ())) { <nl> fp -> getVarEnv ()-> suspend ( fp , actRec ); <nl> struct Resumable { <nl> memcpy ( actRec , fp , sizeof ( ActRec )); <nl> } <nl>  <nl> - // Set resumed flag . <nl> - actRec -> setResumed (); <nl> - <nl> // Populate Resumable . <nl> resumable -> m_resumeAddr = resumeAddr ; <nl> resumable -> m_resumeOffset = resumeOffset ;
bool LightProcess :: initShadow ( const std :: string & prefix , int id , <nl> socklen_t addrlen ; <nl> m_afdt_fd = accept ( m_afdt_lfd , & addr , & addrlen ); <nl> if ( m_afdt_fd < 0 ) { <nl> - Logger :: Warning (" Unable to establish afdt connection "); <nl> + char buf [ 1024 ]; <nl> + Logger :: Warning (" Unable to establish afdt connection : % s ", <nl> + strerror_r ( errno , buf , sizeof ( buf ))); <nl> closeShadow (); <nl> return false ; <nl> }
bool RequestEvalState :: includeFile ( Variant & res , CStrRef path , bool once , <nl> } <nl> efile = it -> second ; <nl> } else { <nl> - char * rpath = realpath ( spath . c_str (), 0 ); <nl> - if ( rpath && rpath != spath ) { <nl> + char * rpath = ( char *) malloc ( PATH_MAX ); <nl> + if ( rpath == NULL ) { <nl> + return false ; <nl> + } <nl> + if ( realpath ( spath . c_str (), rpath ) && rpath != spath ) { <nl> it = self -> m_evaledFiles . find ( rpath ); <nl> if ( it != self -> m_evaledFiles . end ()) { <nl> self -> m_evaledFiles [ spath ] = efile = it -> second ;
void LightProcess :: SigChldHandler ( int sig , siginfo_t * info , void * ctx ) { <nl> } <nl> pid_t pid = info -> si_pid ; <nl> for ( int i = 0 ; i < g_procsCount ; ++ i ) { <nl> - if ( g_procs [ i ]. m_shadowProcess == pid ) { <nl> + if ( g_procs && g_procs [ i ]. m_shadowProcess == pid ) { <nl> // The exited process was a light process . Notify the callback , if any . <nl> if ( s_lostChildHandler ) { <nl> s_lostChildHandler ( pid );
int PDOMySqlConnection :: handleError ( const char * file , int line , <nl> strcpy (* pdo_err , mysql_sqlstate ( m_server )); <nl> } <nl>  <nl> - pdo_raise_impl_error ( stmt -> dbh , NULL , pdo_err [ 0 ], einfo -> errmsg ); <nl> - <nl> + if ( stmt && stmt -> stmt ()) { <nl> + pdo_raise_impl_error ( stmt -> dbh , NULL , pdo_err [ 0 ], einfo -> errmsg ); <nl> + } else { <nl> + throw_pdo_exception ( null , null , " SQLSTATE [% s ] [% d ] % s ", <nl> + pdo_err [ 0 ], einfo -> errcode , einfo -> errmsg ); <nl> + } <nl> return einfo -> errcode ; <nl> } <nl> 
String string_number_format ( double d , int dec , <nl> d = php_math_round ( d , dec ); <nl>  <nl> // departure from PHP : we got rid of dependencies on spprintf () here . <nl> + // This actually means 63 bytes for characters + 1 byte for '\ 0 ' <nl> String tmpstr ( 63 , ReserveString ); <nl> tmpbuf = tmpstr . mutableData (); <nl> tmplen = snprintf ( tmpbuf , 64 , "%.* F ", dec , d ); <nl> + // From the man page of snprintf , the return value is : <nl> + // The number of characters that would have been written if n had been <nl> + // sufficiently large , not counting the terminating null character . <nl> if ( tmplen < 0 ) return empty_string (); <nl> - if ( tmpbuf == nullptr || ! isdigit (( int ) tmpbuf [ 0 ])) { <nl> + if ( tmplen < 64 && ( tmpbuf == nullptr || ! isdigit (( int ) tmpbuf [ 0 ]))) { <nl> tmpstr . setSize ( tmplen ); <nl> return tmpstr ; <nl> }
TranslatorX64 :: smash ( X64Assembler & a , TCA src , TCA dest , bool isCall ) { <nl> */ <nl> CodeCursor cg ( a , src ); <nl> assert ( isSmashable ( a . code . frontier , kJmpLen )); <nl> - if ( dest > src && dest - src <= 7 ) { <nl> + if ( dest > src && dest - src <= kJmpLen ) { <nl> assert (! isCall ); <nl> a . emitNop ( dest - src ); <nl> } else if (! isCall ) {
* Copyright ( C ) 1991 - 1997 , Thomas G . Lane . <nl> * Modified 2009 by Bill Allombert , Guido Vollbeding . <nl> * libjpeg - turbo Modifications : <nl> - * Copyright ( C ) 2015 - 2017 , D . R . Commander . <nl> + * Copyright ( C ) 2015 - 2017 , 2020 , D . R . Commander . <nl> * For conditions of distribution and use , see the accompanying README . ijg <nl> * file . <nl> * <nl> start_input_ppm ( j_compress_ptr cinfo , cjpeg_source_ptr sinfo ) <nl> /* On 16 - bit - int machines we have to be careful of maxval = 65535 */ <nl> source -> rescale = ( JSAMPLE *) <nl> (* cinfo -> mem -> alloc_small ) (( j_common_ptr ) cinfo , JPOOL_IMAGE , <nl> - ( size_t )((( long ) maxval + 1L ) * <nl> + ( size_t )((( long ) MAX ( maxval , 255 ) + 1L ) * <nl> sizeof ( JSAMPLE ))); <nl> half_maxval = maxval / 2 ; <nl> for ( val = 0 ; val <= ( long ) maxval ; val ++) {
* <nl> * $ RCSfile : dp_gui_cmdenv . h , v $ <nl> * <nl> - * $ Revision : 1 . 12 $ <nl> + * $ Revision : 1 . 13 $ <nl> * <nl> - * last change : $ Author : obo $ $ Date : 2008 - 02 - 27 10 : 21 : 22 $ <nl> + * last change : $ Author : kz $ $ Date : 2008 - 03 - 07 11 : 02 : 47 $ <nl> * <nl> * The Contents of this file are made available subject to <nl> * the terms of GNU Lesser General Public License Version 2 . 1 . <nl> class ProgressCommandEnv <nl> sal_Int32 m_currentProgressSection ; <nl> sal_Int32 m_progressSections ; <nl> void updateProgress ( :: rtl :: OUString const & text = :: rtl :: OUString () ); <nl> + void syncProgress (:: rtl :: OUString const & text ); <nl> :: com :: sun :: star :: uno :: Reference < :: com :: sun :: star :: task :: XAbortChannel > m_xAbortChannel ; <nl> bool m_aborted ; <nl> 
void HWPFile :: TagsRead () <nl> return ; <nl> } <nl>  <nl> + _hwpInfo . back_info . data . clear (); <nl> + <nl> // read potentially compressed data in blocks as its more <nl> // likely large values are simply broken and we ' ll run out <nl> // of data before we need to realloc
* <nl> * $ RCSfile : thread . c , v $ <nl> * <nl> - * $ Revision : 1 . 15 $ <nl> + * $ Revision : 1 . 16 $ <nl> * <nl> - * last change : $ Author : obr $ $ Date : 2001 - 06 - 14 14 : 02 : 18 $ <nl> + * last change : $ Author : vg $ $ Date : 2003 - 04 - 01 14 : 14 : 29 $ <nl> * <nl> * The Contents of this file are made available subject to the terms of <nl> * either of the following licenses <nl> # include < rtl / alloc . h > <nl> # include < osl / time . h > <nl> # include < osl / interlck . h > <nl> +# include < rtl / tencinfo . h > <nl>  <nl> /* <nl> Thread - data structure hidden behind oslThread : <nl> typedef HRESULT ( WINAPI * CoInitializeEx_PROC )( LPVOID pvReserved , DWORD dwCoInit ) <nl>  <nl> CoInitializeEx_PROC _CoInitializeEx = osl_CoInitializeEx ; <nl>  <nl> -/* implemented in nlsupport . c */ <nl> - rtl_TextEncoding GetTextEncodingFromCodePage ( UINT ); <nl> - <nl> /*****************************************************************************/ <nl> /* oslWorkerWrapperFunction */ <nl> /*****************************************************************************/ <nl> rtl_TextEncoding SAL_CALL osl_getThreadTextEncoding () <nl> if ( NULL != ( pszEncoding = getenv ( " SOLAR_USER_RTL_TEXTENCODING " )) ) <nl> _encoding = atoi ( pszEncoding ); <nl> else <nl> - _encoding = GetTextEncodingFromCodePage ( GetACP () ); <nl> + _encoding = rtl_getTextEncodingFromWindowsCodePage ( GetACP () ); <nl>  <nl> TlsSetValue ( g_dwTLSTextEncodingIndex , ( LPVOID ) MAKELONG ( _encoding , TRUE ) ); <nl> }
int XrdHttpReq :: PostProcessHTTPReq ( bool final_ ) { <nl>  <nl> } else <nl> for ( int i = 0 ; i < iovN ; i ++) { <nl> - prot -> SendData (( char *) iovP [ i ]. iov_base , iovP [ i ]. iov_len ); <nl> + if ( prot -> SendData (( char *) iovP [ i ]. iov_base , iovP [ i ]. iov_len )) return 1 ; <nl> writtenbytes += iovP [ i ]. iov_len ; <nl> } <nl> 
XReqErrorType XrdClientConn :: GoBackToRedirector () { <nl> // redirections . Used typically for stat and similar functions <nl> Disconnect ( false ); <nl> if ( fGlobalRedirCnt ) fGlobalRedirCnt --; <nl> - return GoToAnotherServer (* fLBSUrl ); <nl> + return ( fLBSUrl ? GoToAnotherServer (* fLBSUrl ) : kOK ); <nl> } <nl>  <nl> // _____________________________________________________________________________
char * strshare_get ( const char * str ) <nl> { <nl> strshare_t * ss ; <nl>  <nl> + if ( str == NULL ) <nl> + return NULL ; <nl> + <nl> ss = mowgli_patricia_retrieve ( strshare_dict , str ); <nl> if ( ss != NULL ) <nl> ss -> refcount ++; <nl> void strshare_unref ( char * str ) <nl> { <nl> strshare_t * ss ; <nl>  <nl> + if ( str == NULL ) <nl> + return NULL ; <nl> + <nl> ss = ( strshare_t *) str - 1 ; <nl> ss -> refcount --; <nl> if ( ss -> refcount == 0 )
static void do_chanuser_sync ( mychan_t * mc , chanuser_t * cu , chanacs_t * ca , <nl> } <nl>  <nl> try_kick ( chansvs . me -> me , mc -> chan , cu -> user , " You are not authorized to be on this channel "); <nl> + return ; <nl> } <nl> if ( fl & CA_AKICK && !( fl & CA_EXEMPT )) <nl> {
void write_accounts ( void ) <nl> for ( i = 0 ; i < 1024 ; i ++) { <nl> for ( nc = nclists [ i ]; nc ; nc = nc -> next ) { <nl> athemeflags = 0 ; <nl> + if ( nc -> aliases . count == 0 ) <nl> + continue ; <nl> na = nc -> aliases . list [ 0 ]; <nl> registered = na -> time_registered ; <nl> for ( ii = 1 ; ii < nc -> aliases . count ; ii ++)
static void mygroup_delete ( mygroup_t * mg ) <nl> } <nl>  <nl> metadata_delete_all ( mg ); <nl> + BlockHeapFree ( mygroup_heap , mg ); <nl> } <nl>  <nl> mygroup_t * mygroup_add ( const char * name ) <nl> mygroup_t * mygroup_find ( const char * name ) <nl> static void groupacs_des ( groupacs_t * ga ) <nl> { <nl> metadata_delete_all ( ga ); <nl> - /* XXX nothing */ <nl> + BlockHeapFree ( groupacs_heap , ga ); <nl> } <nl>  <nl> groupacs_t * groupacs_add ( mygroup_t * mg , myuser_t * mu , unsigned int flags )
static void cs_cmd_activate ( sourceinfo_t * si , int parc , char * parv []) <nl> } <nl>  <nl> csreq_destroy ( cs ); <nl> + /* Check if GUARD is enabled by default and if so , ChanServ should join even <nl> + * if the founder is no longer present or identified . -- siniStar <nl> + */ <nl> + if ( mc -> flags & MC_GUARD ) <nl> + join ( mc -> name , chansvs . nick ); <nl> logcommand ( si , CMDLOG_ADMIN , " ACTIVATE : \ 2 % s \ 2 ", parv [ 0 ]); <nl> } <nl> 
static void sasl_newuser ( hook_user_nick_t * data ) <nl>  <nl> if ( is_soper ( mu )) <nl> { <nl> - logcommand ( si , CMDLOG_ADMIN , " SOPER : \ 2 % s \ 2 as \ 2 % s \ 2 ", u -> nick , mu -> name ); <nl> + slog ( LG_INFO , " SOPER : \ 2 % s \ 2 as \ 2 % s \ 2 ", u -> nick , mu -> name ); <nl> } <nl>  <nl> myuser_notice ( saslsvs . nick , mu , "% s !% s @% s has just authenticated as you (% s )", u -> nick , u -> user , u -> vhost , mu -> name );
swConnection * swReactor_get ( swReactor * reactor , int fd ) <nl> } <nl> else <nl> { <nl> - int max_socket = reactor -> max_socket * 2 ; <nl> + int max_socket = fd * 2 ; <nl> if ( max_socket > SwooleG . max_sockets ) <nl> { <nl> max_socket = SwooleG . max_sockets + 1 ; <nl> } <nl> reactor -> sockets = sw_realloc ( reactor -> sockets , max_socket * sizeof ( swConnection )); <nl> + if ( reactor -> sockets ) <nl> + bzero (( void *) reactor -> sockets + reactor -> max_socket * sizeof ( swConnection ),( max_socket - reactor -> max_socket )* sizeof ( swConnection )); <nl> + <nl> reactor -> max_socket = max_socket ; <nl> } <nl> 
int sw_coro_create ( zend_fcall_info_cache * fci_cache , zval ** argv , int argc , zval <nl> COROG . current_coro = ( coro_task *) EG ( vm_stack_top ); <nl> zend_execute_data * call = ( zend_execute_data *)( EG ( vm_stack_top )); <nl> EG ( vm_stack_top ) = ( zval *)(( char *) call + TASK_SLOT * sizeof ( zval )); <nl> - object = ( func -> common . fn_flags | ZEND_ACC_STATIC ) ? NULL : fci_cache -> object ; <nl> + object = ( func -> common . fn_flags & ZEND_ACC_STATIC ) ? NULL : fci_cache -> object ; <nl> call = zend_vm_stack_push_call_frame ( ZEND_CALL_TOP_FUNCTION | ZEND_CALL_ALLOCATED , fci_cache -> function_handler , argc , fci_cache -> called_scope , object ); <nl>  <nl> # if PHP_MINOR_VERSION < 1
* the resulting executable , without including the source code for OpenSSL in <nl> * the source distribution . <nl> * <nl> - * $ Id : mod_sql . c , v 1 . 193 2010 - 12 - 17 04 : 23 : 15 castaglia Exp $ <nl> + * $ Id : mod_sql . c , v 1 . 194 2010 - 12 - 18 18 : 33 : 13 castaglia Exp $ <nl> */ <nl>  <nl> # include " conf . h " <nl> MODRET info_master ( cmd_rec * cmd ) { <nl>  <nl> c = find_config ( main_server -> conf , CONF_PARAM , name , FALSE ); <nl> while ( c ) { <nl> - size_t arglen , outs_remain = sizeof ( outs )- 1 ; <nl> + size_t arglen = 0 , outs_remain = sizeof ( outs )- 1 ; <nl>  <nl> sql_log ( DEBUG_FUNC , ">>> info_master (% s )", name ); <nl>  <nl> MODRET info_master ( cmd_rec * cmd ) { <nl>  <nl> c = find_config ( main_server -> conf , CONF_PARAM , name , FALSE ); <nl> while ( c ) { <nl> - size_t arglen , outs_remain = sizeof ( outs )- 1 ; <nl> + size_t arglen = 0 , outs_remain = sizeof ( outs )- 1 ; <nl>  <nl> sql_log ( DEBUG_FUNC , ">>> info_master (% s )", name ); <nl>  <nl> MODRET errinfo_master ( cmd_rec * cmd ) { <nl>  <nl> c = find_config ( main_server -> conf , CONF_PARAM , name , FALSE ); <nl> while ( c ) { <nl> - size_t arglen , outs_remain = sizeof ( outs )- 1 ; <nl> + size_t arglen = 0 , outs_remain = sizeof ( outs )- 1 ; <nl>  <nl> sql_log ( DEBUG_FUNC , ">>> errinfo_master (% s )", name ); <nl>  <nl> MODRET errinfo_master ( cmd_rec * cmd ) { <nl>  <nl> c = find_config ( main_server -> conf , CONF_PARAM , name , FALSE ); <nl> while ( c ) { <nl> - size_t arglen , outs_remain = sizeof ( outs )- 1 ; <nl> + size_t arglen = 0 , outs_remain = sizeof ( outs )- 1 ; <nl>  <nl> sql_log ( DEBUG_FUNC , ">>> errinfo_master (% s )", name ); <nl> 
static void sftp_exit_ev ( const void * event_data , void * user_data ) { <nl> # if defined ( PR_SHARED_MODULE ) <nl> static void sftp_mod_unload_ev ( const void * event_data , void * user_data ) { <nl> if ( strcmp (" mod_sftp . c ", ( const char *) event_data ) == 0 ) { <nl> + /* Unregister ourselves from all events . */ <nl> + pr_event_unregister (& sftp_module , NULL , NULL ); <nl> + <nl> + sftp_keys_free (); <nl> pr_response_block ( FALSE ); <nl> sftp_utf8_free (); <nl> 
static int fs_getsize ( int fd , char * path , off_t * fs_size ) { <nl> * we ' ll use typecasting . <nl> */ <nl> if ( sizeof ( fs . f_bavail ) > 4 || <nl> - sizeof ( fs . f_frsize ) > 4 ) { <nl> + sizeof ( fs . f_bsize ) > 4 ) { <nl>  <nl> /* In order to return a size in KB , as get_fs_size () does , we need <nl> * to divide by 1024 . <nl> */ <nl> - * fs_size = ((( off_t ) fs . f_bavail * ( off_t ) fs . f_frsize ) / 1024 ); <nl> + * fs_size = ((( off_t ) fs . f_bavail * ( off_t ) fs . f_bsize ) / 1024 ); <nl>  <nl> } else { <nl> - * fs_size = get_fs_size ( fs . f_bavail , fs . f_frsize ); <nl> + * fs_size = get_fs_size ( fs . f_bavail , fs . f_bsize ); <nl> } <nl>  <nl> res = 0 ; <nl> static int fs_getsize ( int fd , char * path , off_t * fs_size ) { <nl> /* In order to return a size in KB , as get_fs_size () does , we need <nl> * to divide by 1024 . <nl> */ <nl> - * fs_size = ((( off_t ) fs . f_bavail * ( off_t ) fs . f_frsize ) / 1024 ); <nl> + * fs_size = ((( off_t ) fs . f_bavail * ( off_t ) fs . f_bsize ) / 1024 ); <nl>  <nl> } else { <nl> * fs_size = get_fs_size ( fs . f_bavail , fs . f_bsize ); <nl> static int fs_getsize ( int fd , char * path , off_t * fs_size ) { <nl> /* In order to return a size in KB , as get_fs_size () does , we need <nl> * to divide by 1024 . <nl> */ <nl> - * fs_size = ((( off_t ) fs . f_bavail * ( off_t ) fs . f_frsize ) / 1024 ); <nl> + * fs_size = ((( off_t ) fs . f_bavail * ( off_t ) fs . f_bsize ) / 1024 ); <nl>  <nl> } else { <nl> * fs_size = get_fs_size ( fs . f_bavail , fs . f_bsize );
int pr_netio_write_async ( pr_netio_stream_t * nstrm , char * buf , size_t buflen ) { <nl>  <nl> if ( bwritten < 0 ) { <nl> nstrm -> strm_errno = errno ; <nl> - fcntl ( nstrm -> strm_fd , F_SETFL , flags ); <nl> + ( void ) fcntl ( nstrm -> strm_fd , F_SETFL , flags ); <nl>  <nl> - if ( nstrm -> strm_errno == EWOULDBLOCK ) <nl> + if ( nstrm -> strm_errno == EWOULDBLOCK ) { <nl> /* Give up ... */ <nl> return total ; <nl> + } <nl>  <nl> return - 1 ; <nl> }
class ModuleIdent : public Module <nl> { <nl> int * fd ; <nl> if ( user -> GetExt (" ident_socket_fd ", fd ) && ( ServerInstance -> SE -> GetRef (* fd ) == isock )) <nl> + { <nl> + user -> Shrink (" ident_socket_fd "); <nl> + delete fd ; <nl> isock -> Close (); <nl> + } <nl> } <nl> } <nl> } <nl> class ModuleIdent : public Module <nl> { <nl> int * fd ; <nl> if ( user -> GetExt (" ident_socket_fd ", fd ) && ( ServerInstance -> SE -> GetRef (* fd ) == isock )) <nl> + { <nl> + user -> Shrink (" ident_socket_fd "); <nl> + delete fd ; <nl> isock -> Close (); <nl> + } <nl> } <nl> } <nl> };
class ModuleSSLGnuTLS : public Module <nl> // once a day , once a week or once a month . Depending on the <nl> // security requirements . <nl>  <nl> + if (! dh_alloc ) <nl> + return ; <nl> + <nl> int ret ; <nl>  <nl> if (( ret = gnutls_dh_params_generate2 ( dh_params , dh_bits )) < 0 )
class cmd_shun : public Command <nl>  <nl> if ( pcnt == 1 ) <nl> { <nl> - if ( ServerInstance -> XLines -> DelLine ( parameters [ 0 ], " S ", user )) <nl> + if ( ServerInstance -> XLines -> DelLine ( parameters [ 0 ], " SHUN ", user )) <nl> { <nl> ServerInstance -> SNO -> WriteToSnoMask (' x ',"% s Removed shun on % s .", user -> nick , parameters [ 0 ]); <nl> }
void ModeParser :: DisplayCurrentModes ( userrec * user , userrec * targetuser , chanrec <nl> } <nl> else if ( targetuser ) <nl> { <nl> + if ( targetuser -> Visibility && ! targetuser -> Visibility -> VisibleTo ( user )) <nl> + { <nl> + user -> WriteServ (" 401 % s % s : No such nick / channel ", user -> nick , text ); <nl> + return ; <nl> + } <nl> + <nl> if (( targetuser == user ) || (* user -> oper )) <nl> { <nl> /* Display user ' s current mode string */
class ModuleDenyChannels : public Module <nl>  <nl> virtual int OnUserPreJoin ( userrec * user , chanrec * chan , const char * cname ) <nl> { <nl> - bool isoper = strchr ( user -> modes ,' o ') ? true : false ; <nl> - <nl> for ( int j = 0 ; j < Conf -> Enumerate (" badchan "); j ++) <nl> { <nl> irc :: string cn = Conf -> ReadValue (" badchan "," name ", j ). c_str (); <nl> irc :: string thischan = cname ; <nl> if ( thischan == cn ) <nl> { <nl> - if (( Conf -> ReadFlag (" badchan "," allowopers ", j )) && isoper == true ) <nl> + if (( Conf -> ReadFlag (" badchan "," allowopers ", j )) && * user -> oper ) <nl> { <nl> return 0 ; <nl> }
ModuleSQL :: ModuleSQL () <nl>  <nl> void ModuleSQL :: init () <nl> { <nl> + if ( mysql_library_init ( 0 , NULL , NULL )) <nl> + throw ModuleException (" Unable to initialise the MySQL library !"); <nl> + <nl> Dispatcher = new DispatcherThread ( this ); <nl> ServerInstance -> Threads -> Start ( Dispatcher ); <nl>  <nl> ModuleSQL ::~ ModuleSQL () <nl> Dispatcher -> OnNotify (); <nl> delete Dispatcher ; <nl> } <nl> + <nl> for ( ConnMap :: iterator i = connections . begin (); i != connections . end (); i ++) <nl> { <nl> delete i -> second ; <nl> } <nl> + <nl> + mysql_library_end (); <nl> } <nl>  <nl> void ModuleSQL :: OnRehash ( User * user )
void TreeSocket :: OnTimeout () <nl>  <nl> void TreeSocket :: Close () <nl> { <nl> - if ( fd != - 1 ) <nl> - ServerInstance -> GlobalCulls . AddItem ( this ); <nl> + if ( fd < 0 ) <nl> + return ; <nl> + <nl> + ServerInstance -> GlobalCulls . AddItem ( this ); <nl> this -> BufferedSocket :: Close (); <nl> SetError (" Remote host closed connection "); <nl> 
void MainDelegate :: InitializeResourceBundle () { <nl> path = pak_dir . Append ( FILE_PATH_LITERAL (" content_shell . pak ")); <nl> # endif <nl>  <nl> - ui :: ResourceBundle :: InitSharedInstanceWithLocale ("", NULL , <nl> + ui :: ResourceBundle :: InitSharedInstanceWithLocale ("", nullptr , <nl> ui :: ResourceBundle :: DO_NOT_LOAD_COMMON_RESOURCES ); <nl> - ui :: ResourceBundle :: GetSharedInstance (). AddDataPackFromPath ( path , ui :: SCALE_FACTOR_100P ); <nl> + ui :: ResourceBundle :: GetSharedInstance (). AddDataPackFromPath ( <nl> + path , ui :: GetSupportedScaleFactors ()[ 0 ]); <nl> AddDataPackFromPath (& ui :: ResourceBundle :: GetSharedInstance (), path . DirName ()); <nl> } <nl> 
MenuBar :: MenuBar ( views :: View * window ) <nl> : background_color_ ( kDefaultColor ), window_ ( window ) { <nl> RefreshColorCache (); <nl> UpdateViewColors (); <nl> - SetLayoutManager ( new views :: BoxLayout ( views :: BoxLayout :: kHorizontal )); <nl> + SetLayoutManager ( std :: make_unique < views :: BoxLayout >( <nl> + views :: BoxLayout :: kHorizontal )); <nl> window_ -> GetFocusManager ()-> AddFocusChangeListener ( this ); <nl> } <nl> 
gfx :: Image Clipboard :: ReadImage ( mate :: Arguments * args ) { <nl> void Clipboard :: WriteImage ( const gfx :: Image & image , mate :: Arguments * args ) { <nl> ui :: ScopedClipboardWriter writer ( GetClipboardType ( args )); <nl> SkBitmap bmp ; <nl> + // TODO ( ferreus ): Replace with sk_tools_utils :: copy_to ( chrome60 ) <nl> if ( image . AsBitmap (). deepCopyTo (& bmp )) { <nl> writer . WriteImage ( bmp ); <nl> } else {
void InspectableWebContentsImpl :: ShowDevTools () { <nl> Observe ( devtools_web_contents_ . get ()); <nl> devtools_web_contents_ -> SetDelegate ( this ); <nl>  <nl> - AttachTo ( std :: move ( <nl> - content :: DevToolsAgentHost :: GetOrCreateFor ( web_contents_ . get ()))); <nl> + AttachTo ( content :: DevToolsAgentHost :: GetOrCreateFor ( web_contents_ . get ())); <nl>  <nl> devtools_web_contents_ -> GetController (). LoadURL ( <nl> GetDevToolsURL ( can_dock_ ), <nl> void InspectableWebContentsImpl :: AttachTo ( <nl> scoped_refptr < content :: DevToolsAgentHost > host ) { <nl> if ( agent_host_ . get ()) <nl> Detach (); <nl> - agent_host_ = host ; <nl> + agent_host_ = std :: move ( host ); <nl> // Terminate existing debugging connections and start debugging . <nl> agent_host_ -> ForceAttachClient ( this ); <nl> }
setup ( int argc , char ** argv ) <nl>  <nl> /* memmove is defined here because some vendors don ' t provide it at <nl> all and others do a terrible job ( like calling malloc ) */ <nl> +// -- ouch , that hurts -- ln <nl> +# ifdef memmove <nl> +# undef memmove <nl> +# endif <nl> void * <nl> memmove ( void * dp , const void * sp , size_t n ) <nl> {
void G_ShutdownGame ( int restart ) { <nl> G_LogPrintf (" ShutdownGame :\ n " ); <nl> G_LogPrintf ("------------------------------------------------------------\ n " ); <nl> trap_FS_FCloseFile ( level . logFile ); <nl> + level . logFile = 0 ; <nl> } <nl>  <nl> // write all the client session data so we can get it back
void S_UpdateBackgroundTrack ( void ) { <nl> // decide how much data needs to be read from the file <nl> fileSamples = bufferSamples * s_backgroundStream -> info . rate / dma . speed ; <nl>  <nl> + if (! fileSamples ) <nl> + return ; <nl> + <nl> // our max buffer size <nl> fileBytes = fileSamples * ( s_backgroundStream -> info . width * s_backgroundStream -> info . channels ); <nl> if ( fileBytes > sizeof ( raw ) ) {
int __nagios_object_structure_version = CURRENT_OBJECT_STRUCTURE_VERSION ; <nl> int read_object_config_data ( char * main_config_file , int options , int cache , int precache ) { <nl> int result = OK ; <nl>  <nl> + /* reset object counts */ <nl> + memset (& num_objects , 0 , sizeof ( num_objects )); <nl> + <nl> /********* IMPLEMENTATION - SPECIFIC INPUT FUNCTION ********/ <nl> # ifdef USE_XODTEMPLATE <nl> /* read in data from all text host config files ( template - based ) */
void compute_subject_downtime_times ( time_t start_time , time_t end_time , avail_su <nl> } <nl> saved_status = temp_as -> entry_type ; <nl> saved_stamp = temp_as -> time_stamp ; <nl> + <nl> + /* check if first time is before schedule downtime */ <nl> + if ( saved_stamp < start_time ) <nl> + saved_stamp = start_time ; <nl> + <nl> } <nl> } <nl> 
static int cancel_channel_subscription ( struct nerd_channel * chan , int sd ) <nl> if ( subscr -> sd == sd ) { <nl> cancelled ++; <nl> free ( list ); <nl> + free ( subscr ); <nl> if ( prev ) { <nl> prev -> next = next ; <nl> } else {
static int wproc_is_alive ( worker_process * wp ) <nl>  <nl> int wproc_destroy ( worker_process * wp , int flags ) <nl> { <nl> - int i = 0 , destroyed = 0 , force = 0 , self ; <nl> + int i = 0 , force = 0 , self ; <nl>  <nl> if (! wp ) <nl> return 0 ; <nl> int wproc_destroy ( worker_process * wp , int flags ) <nl> wp -> ioc = NULL ; <nl> my_free ( wp -> source_name ); <nl> if ( wp -> jobs ) { <nl> - for ( i = 0 ; i < wp -> max_jobs ; i ++) { <nl> + for ( i = 0 ; i < wp -> max_jobs && wp -> jobs_running ; i ++) { <nl> if (! wp -> jobs [ i ]) <nl> continue ; <nl>  <nl> destroy_job ( wp , wp -> jobs [ i ]); <nl> - /* we can ( often ) break out early */ <nl> - if (++ destroyed >= wp -> jobs_running ) <nl> - break ; <nl> } <nl>  <nl> free ( wp -> jobs );
static const char * init_root ( const char * root0 ) { <nl> if ( root0 == NULL ) <nl> root0 = "/"; <nl> root = strdup ( root0 ); <nl> + if ( root == NULL ) <nl> + return NULL ; <nl> if ( root [ strlen ( root )- 1 ] != SEP ) { <nl> if ( REALLOC_N ( root , strlen ( root ) + 2 ) == - 1 ) { <nl> FREE ( root );
struct parsed_source_t { <nl> parsed_source_t & operator =( parsed_source_t &&) = default ; <nl> }; <nl> /// Return a shared pointer to parsed_source_t , or null on failure . <nl> - using parsed_source_ref_t = std :: shared_ptr < parsed_source_t >; <nl> + using parsed_source_ref_t = std :: shared_ptr < const parsed_source_t >; <nl> parsed_source_ref_t parse_source ( wcstring src , parse_tree_flags_t flags , parse_error_list_t * errors , <nl> parse_token_type_t goal = symbol_job_list ); <nl> 
void completer_t :: complete_cmd_desc ( const wcstring & str ) { <nl> wcstring cmd ; <nl> size_t pos = str . find_last_of ( L '/'); <nl> if ( pos != std :: string :: npos ) { <nl> - cmd = wcstring ( str , pos ); <nl> + if ( pos + 1 > str . length ()) return ; <nl> + cmd = wcstring ( str , pos + 1 ); <nl> } else { <nl> cmd = str ; <nl> }
void mrb_define_const ( mrb_state *, struct RClass *, const char * name , mrb_value ); <nl> void mrb_undef_method ( mrb_state *, struct RClass *, const char *); <nl> void mrb_undef_class_method ( mrb_state *, struct RClass *, const char *); <nl> mrb_value mrb_obj_new ( mrb_state * mrb , struct RClass * c , int argc , mrb_value * argv ); <nl> +# define mrb_class_new_instance ( mrb , argc , argv , c ) mrb_obj_new ( mrb , c , argc , argv ) <nl> + mrb_value mrb_class_obj_new ( mrb_state * mrb , struct RClass * c , int argc , mrb_value * argv ); <nl> mrb_value mrb_instance_new ( mrb_state * mrb , mrb_value cv ); <nl> struct RClass * mrb_class_new ( mrb_state * mrb , struct RClass * super ); <nl> struct RClass * mrb_module_new ( mrb_state * mrb );
MRB_API void mrb_undef_class_method ( mrb_state *, struct RClass *, const char *); <nl> MRB_API mrb_value mrb_obj_new ( mrb_state * mrb , struct RClass * c , mrb_int argc , const mrb_value * argv ); <nl>  <nl> /** See @ ref mrb_obj_new */ <nl> - MRB_INLINE mrb_value mrb_class_new_instance ( mrb_state * mrb , struct RClass * c , mrb_int argc , const mrb_value * argv ) <nl> + MRB_INLINE mrb_value mrb_class_new_instance ( mrb_state * mrb , mrb_int argc , const mrb_value * argv , struct RClass * c ) <nl> { <nl> return mrb_obj_new ( mrb , c , argc , argv ); <nl> }
mrb_remove_method ( mrb_state * mrb , struct RClass * c , mrb_sym mid ) <nl> MRB_CLASS_ORIGIN ( c ); <nl> h = c -> mt ; <nl>  <nl> - if ( h && mt_del ( mrb , h , mid )) return ; <nl> + if ( h && mt_del ( mrb , h , mid )) { <nl> + mrb_mc_clear_by_class ( mrb , c ); <nl> + return ; <nl> + } <nl> mrb_name_error ( mrb , mid , " method '% n ' not defined in % C ", mid , c ); <nl> } <nl> 
mrb_close ( mrb_state * mrb ) <nl> mrb_free ( mrb , mrb -> irep [ i ]); <nl> } <nl> mrb_free ( mrb , mrb -> irep ); <nl> + mrb_free ( mrb , mrb -> rescue ); <nl> + mrb_free ( mrb , mrb -> ensure ); <nl> mrb_free_symtbl ( mrb ); <nl> mrb_free_heap ( mrb ); <nl> mrb_alloca_free ( mrb );
main ( int argc , char ** argv ) <nl> char_index = 0 ; <nl> while (( last_char = getchar ()) != '\ n ') { <nl> if ( last_char == EOF ) break ; <nl> - if ( char_index > sizeof ( last_code_line )- 2 ) { <nl> + if ( char_index >= sizeof ( last_code_line )- 2 ) { <nl> fputs (" input string too long \ n ", stderr ); <nl> continue ; <nl> }
mrb_include_module ( mrb_state * mrb , struct RClass * c , struct RClass * m ) <nl> struct RClass * p = c , * ic ; <nl> int superclass_seen = 0 ; <nl>  <nl> - if ( c -> mt == m -> mt ) { <nl> + if ( c -> mt && c -> mt == m -> mt ) { <nl> mrb_raise ( mrb , E_ARGUMENT_ERROR , " cyclic include detected "); <nl> } <nl> while ( p ) {
mrb_ary_shift ( mrb_state * mrb , mrb_value self ) <nl> static mrb_value <nl> mrb_ary_shift_m ( mrb_state * mrb , mrb_value self ) <nl> { <nl> - struct RArray * a = mrb_ary_ptr ( self ); <nl> - mrb_int len = ARY_LEN ( a ); <nl> mrb_int n ; <nl> - mrb_value val ; <nl>  <nl> if ( mrb_get_args ( mrb , "| i ", & n ) == 0 ) { <nl> return mrb_ary_shift ( mrb , self ); <nl> - }; <nl> + } <nl> + <nl> + struct RArray * a = mrb_ary_ptr ( self ); <nl> + mrb_int len = ARY_LEN ( a ); <nl> + mrb_value val ; <nl> + <nl> ary_modify_check ( mrb , a ); <nl> if ( len == 0 || n == 0 ) return mrb_ary_new ( mrb ); <nl> if ( n < 0 ) mrb_raise ( mrb , E_ARGUMENT_ERROR , " negative array shift ");
RETRY_TRY_BLOCK : <nl>  <nl> p = mrb_closure_new ( mrb , irep -> reps [ GETARG_Bx ( i )]); <nl> /* push ensure_stack */ <nl> - if ( mrb -> c -> esize <= mrb -> c -> ci -> eidx ) { <nl> + if ( mrb -> c -> esize <= mrb -> c -> ci -> eidx + 1 ) { <nl> if ( mrb -> c -> esize == 0 ) mrb -> c -> esize = 16 ; <nl> else mrb -> c -> esize *= 2 ; <nl> mrb -> c -> ensure = ( struct RProc **) mrb_realloc ( mrb , mrb -> c -> ensure , sizeof ( struct RProc *) * mrb -> c -> esize );
initiate_ondemand_body ( struct find_oppo_bundle * b <nl>  <nl> /* otherwise , there is some kind of static conn that can handle <nl> * this connection , so we initiate it */ <nl> - if ( c -> kind == CK_PERMANENT && USE_NETKEY ) <nl> + if ( c -> kind == CK_PERMANENT && kern_interface == USE_NETKEY ) <nl> { <nl> /* there is already a tunnel and with netkey we need to ignore */ <nl> return 0 ;
route_owner ( struct connection * c <nl> continue ; <nl> if ( src -> that . port != srd -> that . port ) <nl> continue ; <nl> + <nl> + /* with old eroutes / routing , we could not do this . This <nl> + * allows a host with two IP ' s to talk to 1 oter host <nl> + * with both IP ' s using two different tunnels . <nl> + */ <nl> + if (! sameaddr (& src -> this . host_addr , & srd -> this . host_addr )) <nl> + continue ; <nl> + <nl> passert ( oriented (* d )); <nl> if ( srd -> routing > best_routing ) <nl> {
dpd_timeout ( struct state * st ) <nl> case DPD_ACTION_RESTART : <nl> /** dpdaction = restart - immediate renegotiate the connection . */ <nl> openswan_log (" DPD : Restarting Connection "); <nl> + delete_states_by_connection ( c , TRUE ); <nl>  <nl> + if ( c -> kind == CK_INSTANCE ) { <nl> + /* If this is a template ( eg : right =% any ) we won ' t be able to reinitiate , the peer <nl> + has probably changed IP addresses , or isn ' t available anymore . So remove the routes <nl> + too */ <nl> + unroute_connection ( c ); /* -- unroute */ <nl> + } <nl> /* we replace the SA so that we do it in a rational place */ <nl> delete_event ( st ); <nl> event_schedule ( EVENT_SA_REPLACE , 0 , st );
main ( int argc , char ** argv ) <nl>  <nl> # ifdef HAVE_LIBNSS <nl> char buf [ 100 ]; <nl> - snprintf ( buf , sizeof ( buf ), " sql :% s ", oco -> confddir ); <nl> + snprintf ( buf , sizeof ( buf ), "% s ", oco -> confddir ); <nl> loglog ( RC_LOG_SERIOUS ," nss directory plutomain : % s ", buf ); <nl> SECStatus nss_init_status = NSS_InitReadWrite ( buf ); <nl> if ( nss_init_status != SECSuccess ) {
cupsdCreateProfile ( int job_id , /* I - Job ID or 0 for none */ <nl> " #\"^/ usr / bin /\"" /* / usr / bin /... */ <nl> " #\"^/ usr / libexec / cups $\"" /* / usr / libexec / cups */ <nl> " #\"^/ usr / libexec / cups /\"" /* / usr / libexec / cups /... */ <nl> + " #\"^/ usr / libexec / fax $\"" /* / usr / libexec / fax */ <nl> + " #\"^/ usr / libexec / fax /\"" /* / usr / libexec / fax /... */ <nl> " #\"^/ usr / sbin $\"" /* / usr / sbin */ <nl> " #\"^/ usr / sbin /\"" /* / usr / sbin /... */ <nl> " #\"^/ Library / Application Support $\"" <nl> cupsdCreateProfile ( int job_id , /* I - Job ID or 0 for none */ <nl> " #\"^/ usr / sbin /\"" /* / usr / sbin /... */ <nl> " #\"^% s /\"" /* ServerBin /... */ <nl> " #\"^/ Library / Printers /.*/\"" <nl> + " #\"^/ System / Library / Frameworks / Python . framework /\"" <nl> "))\ n ", <nl> bin ); <nl> if ( RunUser && getenv (" CUPS_TESTROOT "))
valid_host ( cupsd_client_t * con ) /* I - Client connection */ <nl>  <nl> return (! _cups_strcasecmp ( con -> clientname , " localhost ") || <nl> ! _cups_strcasecmp ( con -> clientname , " localhost .") || <nl> -# ifdef __linux <nl> - ! _cups_strcasecmp ( con -> clientname , " localhost . localdomain ") || <nl> -# endif /* __linux */ <nl> ! strcmp ( con -> clientname , " 127 . 0 . 0 . 1 ") || <nl> ! strcmp ( con -> clientname , "[:: 1 ]")); <nl> }
quote_string ( const char * s , /* I - String */ <nl> { <nl> if (* s == '\\' || * s == '\"' || * s == '\'') <nl> { <nl> - if ( q < ( qend - 4 )) <nl> + if ( qptr < ( qend - 4 )) <nl> { <nl> * qptr ++ = '\\'; <nl> * qptr ++ = '\\';
parse ( cherokee_handler_ssi_t * hdl , <nl>  <nl> ret = parse ( hdl , & file_content , out ); <nl> if ( unlikely ( ret != ret_ok )) { <nl> + cherokee_buffer_mrproper (& file_content ); <nl> return ret_error ; <nl> } <nl> 
TEST ( signal , rt_tgsigqueueinfo ) { <nl> "* https :// git . kernel . org / cgit / linux / kernel / git / torvalds / linux . git / commit /? id = 66dd34ad31e5963d72a700ec3f2449291d322921 \ n "; <nl> static siginfo received ; <nl>  <nl> - struct sigaction handler = {}; <nl> + struct sigaction handler ; <nl> + memset (& handler , 0 , sizeof ( handler )); <nl> handler . sa_sigaction = []( int , siginfo_t * siginfo , void *) { received = * siginfo ; }; <nl> handler . sa_flags = SA_SIGINFO ; <nl>  <nl> ASSERT_EQ ( 0 , sigaction ( SIGUSR1 , & handler , nullptr )); <nl>  <nl> - siginfo sent = {}; <nl> + siginfo sent ; <nl> + memset (& sent , 0 , sizeof ( sent )); <nl>  <nl> sent . si_code = SI_TKILL ; <nl> ASSERT_EQ ( 0 , syscall ( SYS_rt_tgsigqueueinfo , getpid (), gettid (), SIGUSR1 , & sent ))
frexpf ( float x , int * eptr ) <nl> } <nl> * eptr += ( ix >> 23 )- 126 ; <nl> hx = ( hx & 0x807fffff )| 0x3f000000 ; <nl> - *( int *)& x = hx ; <nl> + SET_FLOAT_WORD ( x , hx ); <nl> return x ; <nl> }
extern " C " pid_t __getpid (); <nl> pid_t getpid () { <nl> pthread_internal_t * self = __get_thread (); <nl>  <nl> - // Do we have a valid cached pid ? <nl> - pid_t cached_pid ; <nl> - if ( __predict_true ( self -> get_cached_pid (& cached_pid ))) { <nl> - return cached_pid ; <nl> + if ( __predict_true ( self )) { <nl> + // Do we have a valid cached pid ? <nl> + pid_t cached_pid ; <nl> + if ( __predict_true ( self -> get_cached_pid (& cached_pid ))) { <nl> + return cached_pid ; <nl> + } <nl> } <nl>  <nl> // We ' re still in the dynamic linker or we ' re in the middle of forking , so ask the kernel .
TEST ( pthread , pthread_attr_getstack_18908062 ) { <nl> } <nl>  <nl> # if defined ( __BIONIC__ ) <nl> + static pthread_mutex_t gettid_mutex ; <nl> static void * pthread_gettid_np_helper ( void * arg ) { <nl> + pthread_mutex_lock (& gettid_mutex ); <nl> * reinterpret_cast < pid_t *>( arg ) = gettid (); <nl> + pthread_mutex_unlock (& gettid_mutex ); <nl> return NULL ; <nl> } <nl> # endif <nl> TEST ( pthread , pthread_gettid_np ) { <nl>  <nl> pid_t t_gettid_result ; <nl> pthread_t t ; <nl> + pthread_mutex_init (& gettid_mutex , NULL ); <nl> + pthread_mutex_lock (& gettid_mutex ); <nl> pthread_create (& t , NULL , pthread_gettid_np_helper , & t_gettid_result ); <nl>  <nl> pid_t t_pthread_gettid_np_result = pthread_gettid_np ( t ); <nl> + pthread_mutex_unlock (& gettid_mutex ); <nl>  <nl> pthread_join ( t , NULL ); <nl> + pthread_mutex_destroy (& gettid_mutex ); <nl>  <nl> ASSERT_EQ ( t_gettid_result , t_pthread_gettid_np_result ); <nl> # else
void * memmove ( void * dst , const void * src , size_t n ) <nl> { <nl> const char * p = src ; <nl> char * q = dst ; <nl> - /* We can use the optimized memcpy if the destination is below the <nl> - * source ( i . e . q < p ), or if it is completely over it ( i . e . q >= p + n ). <nl> + /* We can use the optimized memcpy if the source and destination <nl> + * don ' t overlap . <nl> */ <nl> - if ( __builtin_expect (( q < p ) || (( size_t )( q - p ) >= n ), 1 )) { <nl> + if ( __builtin_expect ((( q < p ) && (( size_t )( p - q ) >= n )) <nl> + || (( p < q ) && (( size_t )( q - p ) >= n )), 1 )) { <nl> return memcpy ( dst , src , n ); <nl> } else { <nl> bcopy ( src , dst , n );
namespace Js <nl> bindRefChunkBegin ( nullptr ), <nl> bindRefChunkCurrent ( nullptr ), <nl> bindRefChunkEnd ( nullptr ), <nl> - dynamicFunctionReference ( nullptr ) <nl> + dynamicFunctionReference ( nullptr ), <nl> + toStringTagCache ( nullptr ) <nl> + <nl> { <nl> this -> globalObject = globalObject ; <nl> }
namespace Js <nl>  <nl> bool JavascriptArray :: IsMissingItem ( uint32 index ) <nl> { <nl> + if ( this -> length <= index ) <nl> + { <nl> + return false ; <nl> + } <nl> + <nl> bool isIntArray = false , isFloatArray = false ; <nl> this -> GetArrayTypeAndConvert (& isIntArray , & isFloatArray ); <nl>  <nl> namespace Js <nl> // Prototype lookup for missing elements <nl> if (! pArr -> HasNoMissingValues ()) <nl> { <nl> - for ( uint32 i = 0 ; i < newLen ; i ++) <nl> + for ( uint32 i = 0 ; i < newLen && ( i + start ) < pArr -> length ; i ++) <nl> { <nl> // array type might be changed in the below call to DirectGetItemAtFull <nl> // need recheck array type before checking array item [ i + start ]
TagLib :: uint String :: length () const <nl>  <nl> bool String :: isEmpty () const <nl> { <nl> - return d -> data . size () == 0 ; <nl> + return d -> data . empty (); <nl> } <nl>  <nl> bool String :: isNull () const
static QString parse ( const QByteArray & data , const QStringList & handlers ) <nl> return parsePlaylist ( data , QLatin1String (" Ref "), handlers ); <nl> } else if ( data . length ()> 5 && ! strncasecmp ( data . constData (), "<? xml ", 5 )) { <nl> return parseXml ( data , handlers ); <nl> + } else if ( (- 1 == data . indexOf ("< html ") && - 1 != data . indexOf (" http :/")) || // flat list ? <nl> + (- 1 != data . indexOf ("# EXTM3U ")) ) { // m3u with comments ? <nl> + return parseExt3Mu ( data , handlers ); <nl> } <nl>  <nl> return QString ();
raptor_rss10_build_items ( raptor_rss10_serializer_context * rss_serializer ) <nl> s =( raptor_statement *) raptor_sequence_get_at ( rss_serializer -> triples , i ); <nl> if (! s ) <nl> continue ; <nl> + <nl> + /* skip triples that are not ? ? < uri > */ <nl> + if ( s -> object_type != RAPTOR_IDENTIFIER_TYPE_RESOURCE ) <nl> + continue ; <nl>  <nl> if ( s -> subject_type == RAPTOR_IDENTIFIER_TYPE_ANONYMOUS ) <nl> fake_uri = raptor_new_uri (( unsigned char *) s -> subject ); <nl> raptor_rss10_build_items ( raptor_rss10_serializer_context * rss_serializer ) <nl> fake_uri = raptor_uri_copy (( raptor_uri *) s -> subject ); <nl>  <nl> if ( raptor_uri_equals ( fake_uri , rss_serializer -> seq_uri )) { <nl> + /* found < seq URI > < some predicate > < some URI > triple */ <nl> + <nl> if ( s -> predicate_type == RAPTOR_IDENTIFIER_TYPE_ORDINAL ) <nl> ordinal = *(( int *) s -> predicate ); <nl> else { /* predicate is a resource */
raptor_unicode_utf8_string_put_char ( raptor_unichar c , <nl>  <nl> /* when no buffer given , return size */ <nl> if (! output ) <nl> - return size ; <nl> + return ( int ) size ; /* ok since size is in range 1 .. 6 */ <nl>  <nl> if ( size > length ) <nl> return - 1 ; <nl> raptor_unicode_utf8_string_put_char ( raptor_unichar c , <nl> output [ 0 ] = ( unsigned char ) c ; <nl> } <nl>  <nl> - return size ; <nl> + return ( int ) size ; /* ok since size is in range 1 .. 6 */ <nl> } <nl>  <nl>  <nl> raptor_unicode_utf8_string_get_char ( const unsigned char * input , size_t length , <nl>  <nl>  <nl> if (! output ) <nl> - return size ; <nl> + return ( int ) size ; /* ok since size is in range 1 .. 6 */ <nl>  <nl> if ( length < size ) <nl> return - 1 ; <nl> raptor_unicode_utf8_string_get_char ( const unsigned char * input , size_t length , <nl> if ( c > raptor_unicode_max_codepoint ) <nl> return - 4 ; <nl>  <nl> - return size ; <nl> + return ( int ) size ; /* ok since size is in range 1 .. 6 */ <nl> } <nl>  <nl> 
static void end_element ( void * parser_context , const char * name , <nl> } <nl>  <nl> /* update the plain literal if the XML Literal is an empty string */ <nl> - if ( strlen ( context -> xml_literal ) == 0 ) <nl> + if ( context -> xml_literal != NULL && strlen ( context -> xml_literal ) == 0 ) <nl> { <nl> context -> plain_literal = <nl> rdfa_replace_string ( context -> plain_literal , "");
struct raptor_parser_factory_s { <nl> /* parse a chunk of memory */ <nl> int (* chunk )( raptor_parser * parser , const unsigned char * buffer , size_t len , int is_end ); <nl>  <nl> + /* finish the parser factory */ <nl> + int (* finish_factory )( raptor_parser_factory * factory ); <nl> + <nl> }; <nl>  <nl>  <nl> void raptor_init_parser_ntriples ( void ); <nl> void raptor_init_parser_n3 ( void ); <nl> void raptor_init_parser_rss ( void ); <nl>  <nl> - void raptor_terminate_parser_rdfxml ( void ); <nl> - <nl>  <nl> /* raptor_utf8 . c */ <nl> int raptor_unicode_char_to_utf8 ( unsigned long c , unsigned char * output );
static Image * ReadTIFFImage ( const ImageInfo * image_info , <nl> /* <nl> Convert stripped TIFF image . <nl> */ <nl> - extent = 4 * MagickMax ( image -> columns *( samples_per_pixel + extra_samples )* <nl> - ( image -> depth + 7 )/ 8 ,( size_t ) TIFFStripSize ( tiff )); <nl> + extent = MagickMax ( sizeof ( uint32 ),( samples_per_pixel + extra_samples )* <nl> + ( image -> depth + 7 )/ 8 )* image -> columns * rows_per_strip ; <nl> strip_pixels =( unsigned char *) AcquireQuantumMemory ( extent , <nl> sizeof (* strip_pixels )); <nl> if ( strip_pixels == ( unsigned char *) NULL )
MagickExport ResizeFilter * AcquireResizeFilter ( const Image * image , <nl> if ( resize_filter -> filter == SincFast ) filter_type = SincFastFilter ; <nl> if ( resize_filter -> filter == Jinc ) filter_type = JincFilter ; <nl> if ( resize_filter -> filter == CubicBC ) filter_type = CubicFilter ; <nl> - if ( resize_filter -> filter == Box ) window_type = BoxFilter ; <nl> + if ( resize_filter -> window == Box ) window_type = BoxFilter ; <nl> if ( resize_filter -> window == Sinc ) window_type = SincFilter ; <nl> if ( resize_filter -> window == SincFast ) window_type = SincFastFilter ; <nl> - if ( resize_filter -> filter == Jinc ) window_type = JincFilter ; <nl> + if ( resize_filter -> window == Jinc ) window_type = JincFilter ; <nl> if ( resize_filter -> window == CubicBC ) window_type = CubicFilter ; <nl> /* <nl> Report Filter Details .
static void CL_API_CALL DestroyMagickCLCacheInfoAndPixels ( <nl> } <nl> } <nl> pixels = info -> pixels ; <nl> + RelinquishMagickResource ( MemoryResource , info -> length ); <nl> DestroyMagickCLCacheInfo ( info ); <nl> ( void ) RelinquishAlignedMemory ( pixels ); <nl> }
static Image * ReadPWPImage ( const ImageInfo * image_info , ExceptionInfo * exception ) <nl> ( void ) close ( unique_file ); <nl> ( void ) RelinquishUniqueFileResource ( read_info -> filename ); <nl> read_info = DestroyImageInfo ( read_info ); <nl> - ( void ) CloseBlob ( pwp_image ); <nl> - pwp_image = DestroyImage ( pwp_image ); <nl> if ( EOFBlob ( image ) != MagickFalse ) <nl> { <nl> char
static Image * ReadTIFFImage ( const ImageInfo * image_info , <nl> extent += image -> columns * sizeof ( uint32 ); <nl> # endif <nl> strip_pixels =( unsigned char *) AcquireQuantumMemory ( extent , <nl> - sizeof (* strip_pixels )); <nl> + 2 * sizeof (* strip_pixels )); <nl> if ( strip_pixels == ( unsigned char *) NULL ) <nl> ThrowTIFFException ( ResourceLimitError ," MemoryAllocationFailed "); <nl> ( void ) memset ( strip_pixels , 0 , extent * sizeof (* strip_pixels ));
public : <nl> string message (" Cannot connect to Unix socket '"); <nl> message . append ( listenSocketName ); <nl> message . append ("' on the abstract namespace "); <nl> + do { <nl> + ret = close ( fd ); <nl> + } while ( ret == - 1 && errno == EINTR ); <nl> throw SystemException ( message , e ); <nl> } <nl> 
 <nl> # include < game / client / gameclient . h > <nl>  <nl> +# include < game / client / components / motd . h > <nl> # include < game / client / components / scoreboard . h > <nl>  <nl> # include " broadcast . h " <nl> void CBroadcast :: OnReset () <nl>  <nl> void CBroadcast :: OnRender () <nl> { <nl> - if ( m_pClient -> m_pScoreboard -> Active ()) <nl> + if ( m_pClient -> m_pScoreboard -> Active () || m_pClient -> m_pMotd -> IsActive ()) <nl> return ; <nl>  <nl> Graphics ()-> MapScreen ( 0 , 0 , 300 * Graphics ()-> ScreenAspect (), 300 );
public : <nl> str_format ( aPath , sizeof ( aPath ), "% s /% s ", Data . pPath , pName ); <nl> Data . pPath = aPath ; <nl> fs_listdir ( Data . pStorage -> GetPath ( Type , aPath , aBuf , sizeof ( aBuf )), FindFileCallback , Type , & Data ); <nl> + if ( Data . pBuffer [ 0 ]) <nl> + return 1 ; <nl> } <nl> else if (! str_comp ( pName , Data . pFilename )) <nl> { <nl> public : <nl> { <nl> // search within all available directories <nl> for ( int i = 0 ; i < m_NumPaths ; ++ i ) <nl> + { <nl> fs_listdir ( GetPath ( i , pPath , aBuf , sizeof ( aBuf )), FindFileCallback , i , & Data ); <nl> + if ( pBuffer [ 0 ]) <nl> + return true ; <nl> + } <nl> } <nl> else if ( Type >= 0 && Type < m_NumPaths ) <nl> {
int CServer :: SendMsg ( CMsgPacker * pMsg , int Flags , int ClientID ) <nl> if (! pMsg ) <nl> return - 1 ; <nl>  <nl> - // drop packet to dummy client <nl> - if ( 0 <= ClientID && ClientID < MAX_CLIENTS && GameServer ()-> IsClientBot ( ClientID )) <nl> + // drop invalid packet <nl> + if ( ClientID != - 1 && ( ClientID < 0 || ClientID >= MAX_CLIENTS || m_aClients [ ClientID ]. m_State == CClient :: STATE_EMPTY || m_aClients [ ClientID ]. m_Quitting )) <nl> return 0 ; <nl>  <nl> mem_zero (& Packet , sizeof ( CNetChunk ));
void CCountryFlags :: OnInit () <nl> CCountryFlag DummyEntry ; <nl> DummyEntry . m_CountryCode = - 1 ; <nl> DummyEntry . m_Texture = - 1 ; <nl> + mem_zero ( DummyEntry . m_aCountryCodeString , sizeof ( DummyEntry . m_aCountryCodeString )); <nl> m_aCountryFlags . add ( DummyEntry ); <nl> } <nl> }
new_accepting_socket ( struct evconnlistener_iocp * lev , int family ) <nl> res -> family = family ; <nl>  <nl> event_deferred_cb_init_ (& res -> deferred , <nl> - event_base_get_npriorities ( base ) / 2 , <nl> + event_base_get_npriorities ( lev -> event_base ) / 2 , <nl> accepted_socket_invoke_user_cb , res ); <nl>  <nl> InitializeCriticalSectionAndSpinCount (& res -> lock , 1000 );
evbuffer_peek ( struct evbuffer * buffer , ev_ssize_t len , <nl> if ( n_vec == 0 && len < 0 ) { <nl> /* If no vectors are provided and they asked for " everything ", <nl> * pretend they asked for the actual available amount . */ <nl> - len = buffer -> total_len - len_so_far ; <nl> + len = buffer -> total_len ; <nl> + if ( start_at ) { <nl> + len -= start_at -> pos ; <nl> + } <nl> } <nl>  <nl> while ( chain ) {
kq_dispatch ( void * arg , struct timeval * tv ) <nl> if (! which ) <nl> continue ; <nl>  <nl> - if (!( ev -> ev_events & EV_PERSIST )) <nl> + if (!( ev -> ev_events & EV_PERSIST )) { <nl> + ev -> ev_flags &= ~ EVLIST_X_KQINKERNEL ; <nl> event_del ( ev ); <nl> + } <nl>  <nl> event_active ( ev , which , <nl> ev -> ev_events & EV_SIGNAL ? events [ i ]. data : 1 );
_win32_read_file ( void * state , void * data , zip_uint64_t len , zip_source_cmd_t cmd <nl> zip_error_set (& ctx -> error , ZIP_ER_RENAME , _zip_set_win32_error ( GetLastError (), & ctx -> win32err )); <nl> return - 1 ; <nl> } <nl> + free ( ctx -> tmpname ); <nl> + ctx -> tmpname = NULL ; <nl> return 0 ; <nl> } <nl> 
_zip_guess_encoding ( const zip_uint8_t * const name , zip_uint32_t len ) <nl>  <nl> ret = ZIP_ENCODING_ASCII ; <nl> for ( i = 0 ; i < len ; i ++) { <nl> - if ( name [ i ] < 128 ) <nl> + if ( name [ i ] > 31 && name [ i ] < 128 ) <nl> continue ; <nl>  <nl> ret = ZIP_ENCODING_UTF8 ;
int MK_EXPORT _mkp_network_io_create_socket ( int domain , int type , int protocol ); <nl> int MK_EXPORT _mkp_network_io_bind ( int socket_fd , const struct sockaddr * addr , <nl> socklen_t addrlen , int backlog ); <nl> int MK_EXPORT _mkp_network_io_server ( int port , char * listen_addr , int reuse_port ); <nl> + int MK_EXPORT _mkp_network_io_buffer_size (); <nl> int MK_EXPORT _mkp_event_read ( int sockfd ); <nl> int MK_EXPORT _mkp_event_write ( int sockfd ); <nl> int MK_EXPORT _mkp_event_error ( int sockfd );
static void mk_signal_exit () <nl> { <nl> int i ; <nl> + int n ; <nl> uint64_t val ; <nl>  <nl> /* ignore future signals to properly handle the cleanup */ <nl> static void mk_signal_exit () <nl> /* Distribute worker signals to stop working */ <nl> val = MK_SCHEDULER_SIGNAL_FREE_ALL ; <nl> for ( i = 0 ; i < config -> workers ; i ++) { <nl> - write ( sched_list [ i ]. signal_channel , & val , sizeof ( val )); <nl> + n = write ( sched_list [ i ]. signal_channel , & val , sizeof ( val )); <nl> + if ( n < 0 ) { <nl> + perror (" write "); <nl> + } <nl> } <nl>  <nl> /* Wait for workers to finish */
int mk_http_init ( struct client_request * cr , struct request * sr ) <nl> } <nl> } <nl>  <nl> - /* read permission */ <nl> - if ( sr -> file_info -> read_access == MK_FILE_FALSE ){ <nl> + /* read permissions and check file */ <nl> + if ( sr -> file_info -> read_access == MK_FILE_FALSE || <nl> + sr -> file_info -> is_directory == MK_FILE_TRUE ){ <nl> mk_request_error ( M_CLIENT_FORBIDDEN , cr , sr , 1 , sr -> log ); <nl> return - 1 ; <nl> }
int mk_sched_check_timeouts ( struct sched_list_node * sched ) <nl>  <nl> mk_sched_remove_client ( sched , cs_node -> socket ); <nl> mk_session_remove ( cs_node -> socket ); <nl> + <nl> + /* This removal invalidated our iterator . Start over from the beginning . */ <nl> + node = rb_first ( cs_list ); <nl> + if (! node ) break ; <nl> } <nl> } <nl> }
static inline void mk_stream_set ( struct mk_stream * stream , int type , <nl> * performance and aim to make things easier . The COPYBUF type is not <nl> * used by Monkey core , at the moment the only caller is the CGI plugin . <nl> */ <nl> - if (! stream && type == MK_STREAM_COPYBUF ) { <nl> + if ( type == MK_STREAM_COPYBUF ) { <nl> stream = mk_mem_malloc ( sizeof ( struct mk_stream )); <nl> } <nl> 
NPP_New ( NPMIMEType mimetype , <nl> data = g_slice_new ( PluginData ); <nl> instance -> pdata = data ; <nl>  <nl> - /* set windowless mode */ <nl> - funcs . setvalue ( instance , NPPVpluginWindowBool , NULL ); <nl> - <nl> data -> proxy = g_dbus_proxy_new_for_bus_sync ( G_BUS_TYPE_SESSION , <nl> G_DBUS_PROXY_FLAGS_NONE , <nl> NULL , /* interface info */ <nl> NPP_GetValue ( NPP instance , <nl> *( NPObject **) value = funcs . createobject ( instance , & plugin_class ); <nl> break ; <nl>  <nl> + case NPPVpluginNeedsXEmbed : <nl> + *( bool *) value = TRUE ; <nl> + break ; <nl> + <nl> default : <nl> ; <nl> }
_shell_app_remove_window ( ShellApp * app , <nl> g_object_unref ( window ); <nl> app -> windows = g_slist_remove ( app -> windows , window ); <nl>  <nl> + g_signal_emit ( app , shell_app_signals [ WINDOWS_CHANGED ], 0 ); <nl> + <nl> if ( app -> windows == NULL ) <nl> disconnect_workspace_switch ( app ); <nl> }
void StreamTcpReassembleMemuseCounter ( ThreadVars * tv , TcpReassemblyThreadCtx * rt <nl> * \ retval 0 if not in bounds <nl> */ <nl> int StreamTcpReassembleCheckMemcap ( uint32_t size ) { <nl> - if ( stream_config . reassembly_memcap == 0 || size + SC_ATOMIC_GET ( ra_memuse ) <= stream_config . reassembly_memcap ) <nl> + if ( stream_config . reassembly_memcap == 0 || <nl> + ( uint64_t )(( uint64_t ) size + SC_ATOMIC_GET ( ra_memuse )) <= stream_config . reassembly_memcap ) <nl> return 1 ; <nl> return 0 ; <nl> }
int HTPParserTest07 ( void ) { <nl> if ( r != 0 ) { <nl> printf (" toserver chunk %" PRIu32 " returned %" PRId32 ", expected " <nl> " 0 : ", u , r ); <nl> - result = 0 ; <nl> goto end ; <nl> } <nl> } <nl> int HTPParserTest07 ( void ) { <nl> htp_state = f . aldata [ AlpGetStateIdx ( ALPROTO_HTTP )]; <nl> if ( htp_state == NULL ) { <nl> printf (" no http state : "); <nl> - result = 0 ; <nl> goto end ; <nl> } <nl>  <nl> int HTPParserTest07 ( void ) { <nl> htp_tx_t * tx = list_get ( htp_state -> connp -> conn -> transactions , 0 ); <nl> if ( tx != NULL && tx -> request_uri_normalized != NULL ) { <nl> if ( reflen != bstr_size ( tx -> request_uri_normalized )) { <nl> + printf (" normalized uri len should be %" PRIuMAX ", is %" PRIuMAX , <nl> + ( uintmax_t ) reflen , <nl> + ( uintmax_t ) bstr_size ( tx -> request_uri_normalized )); <nl> goto end ; <nl> } <nl>  <nl> if ( memcmp ( bstr_ptr ( tx -> request_uri_normalized ), ref , <nl> bstr_size ( tx -> request_uri_normalized )) != 0 ) <nl> { <nl> + printf (" normalized uri \""); <nl> + PrintRawUriFp ( stdout , ( uint8_t *) bstr_ptr ( tx -> request_uri_normalized ), bstr_size ( tx -> request_uri_normalized )); <nl> + printf ("\" != \""); <nl> + PrintRawUriFp ( stdout , ref , reflen ); <nl> + printf ("\": "); <nl> goto end ; <nl> } <nl> }
int AFPRunModeIsIPS () <nl>  <nl> for ( ldev = 0 ; ldev < nlive ; ldev ++) { <nl> char * live_dev = LiveGetDeviceName ( ldev ); <nl> + if ( live_dev == NULL ) { <nl> + SCLogError ( SC_ERR_INVALID_VALUE , " Problem with config file "); <nl> + return 0 ; <nl> + } <nl> char * copymodestr = NULL ; <nl> if_root = ConfNodeLookupKeyValue ( af_packet_node , " interface ", live_dev ); <nl>  <nl> int AFPRunModeIsIPS () <nl> SCLogInfo (" AF_PACKET mode using IPS and IDS mode "); <nl> for ( ldev = 0 ; ldev < nlive ; ldev ++) { <nl> char * live_dev = LiveGetDeviceName ( ldev ); <nl> + if ( live_dev == NULL ) { <nl> + SCLogError ( SC_ERR_INVALID_VALUE , " Problem with config file "); <nl> + return 0 ; <nl> + } <nl> if_root = ConfNodeLookupKeyValue ( af_packet_node , " interface ", live_dev ); <nl> char * copymodestr = NULL ; <nl> 
int DeStateDetectStartDetection ( ThreadVars * tv , DetectEngineCtx * de_ctx , <nl>  <nl> /* if continue detection already inspected this rule for this tx , <nl> * continue with the first not - inspected tx */ <nl> - uint8_t offset = det_ctx -> de_state_sig_array [ s -> num ] & 0xef ; <nl> + uint8_t offset = det_ctx -> de_state_sig_array [ s -> num ] & 0x7f ; <nl> uint64_t tx_id = AppLayerParserGetTransactionInspectId ( f -> alparser , flags ); <nl> if ( offset > 0 ) { <nl> SCLogDebug (" using stored_tx_id %" PRIu64 " instead of %" PRIu64 , tx_id + offset , tx_id );
int SMTPParserTest14 ( void ) <nl> SCMutexUnlock (& f . m ); <nl> goto end ; <nl> } <nl> + <nl> + if (( smtp_state -> curr_tx -> mail_from_len != 14 ) || <nl> + strncmp (" asdff @ asdf . com ", ( char *) smtp_state -> curr_tx -> mail_from , 14 )) { <nl> + printf (" incorrect parsing of MAIL FROM field '% s ' (% d )\ n ", <nl> + smtp_state -> curr_tx -> mail_from , <nl> + smtp_state -> curr_tx -> mail_from_len ); <nl> + SCMutexUnlock (& f . m ); <nl> + goto end ; <nl> + } <nl> + <nl> SCMutexUnlock (& f . m ); <nl> if ( smtp_state -> input_len != 0 || <nl> smtp_state -> cmds_cnt != 0 ||
int DetectIsdataatSetup ( DetectEngineCtx * de_ctx , Signature * s , char * isdataatst <nl> SigMatchAppendSMToList ( s , sm , DETECT_SM_LIST_PMATCH ); <nl> } <nl> } else { <nl> - int list_type ; <nl> + int list_type = - 1 ; <nl> if ( pm -> type == DETECT_PCRE || pm -> type == DETECT_BYTEJUMP ) { <nl> list_type = SigMatchListSMBelongsTo ( s , pm ); <nl> - if ( list_type == - 1 ) { <nl> - goto error ; <nl> - } <nl> } else { <nl> switch ( pm -> type ) { <nl> case DETECT_CONTENT : <nl> int DetectIsdataatSetup ( DetectEngineCtx * de_ctx , Signature * s , char * isdataatst <nl> break ; <nl> } /* switch */ <nl> } /* else */ <nl> + if ( list_type == - 1 ) { <nl> + goto error ; <nl> + } <nl>  <nl> SigMatchAppendSMToList ( s , sm , list_type ); <nl> } /* else - if ( pm == NULL ) */
void free_term ( TERM * term ) <nl>  <nl> free_term ((( TERM_STRING *) term )-> offset ); <nl> break ; <nl> + <nl> + case TERM_TYPE_STRING_OFFSET : <nl> + <nl> + free_term ((( TERM_STRING *) term )-> index ); <nl> + break ; <nl>  <nl> case TERM_TYPE_STRING_IN_RANGE : <nl> 
bool compile_files ( <nl> { <nl> for ( int i = 0 ; i < argc - 1 ; i ++) <nl> { <nl> + FILE * rule_file ; <nl> const char * ns ; <nl> const char * file_name ; <nl> char * colon = ( char *) strchr ( argv [ i ], ':'); <nl> bool compile_files ( <nl> ns = NULL ; <nl> } <nl>  <nl> - FILE * rule_file = fopen ( file_name , " r "); <nl> + if ( strcmp ( file_name , "-") == 0 ) <nl> + rule_file = stdin ; <nl> + else <nl> + rule_file = fopen ( file_name , " r "); <nl>  <nl> if ( rule_file == NULL ) <nl> {
ivec_reserve ( rust_task * task , type_desc * ty , rust_ivec * v , size_t n_elems ) <nl> } else { <nl> // On heap ; resize . <nl> heap_part = ( rust_ivec_heap *) task -> realloc ( v -> payload . ptr , <nl> - new_alloc ); <nl> + new_alloc + sizeof ( size_t )); <nl> v -> payload . ptr = heap_part ; <nl> } <nl> 
void BasicWriter < Char >:: write_double ( <nl> spec . width () > static_cast < unsigned >( n )) { <nl> width = spec . width (); <nl> CharPtr p = grow_buffer ( width ); <nl> - std :: memmove ( p + ( width - n ) / 2 , p , n * sizeof ( Char )); <nl> + std :: memmove ( get ( p ) + ( width - n ) / 2 , get ( p ), n * sizeof ( Char )); <nl> fill_padding ( p , spec . width (), n , fill ); <nl> return ; <nl> }
CURLcode Curl_readwrite ( struct connectdata * conn , <nl> time_t secs = time ( NULL ); <nl> k -> timeofdoc = curl_getdate ( k -> p + strlen (" Last - Modified :"), <nl> & secs ); <nl> - if ( data -> set . get_filetime >= 0 ) <nl> + if ( data -> set . get_filetime ) <nl> data -> info . filetime = k -> timeofdoc ; <nl> } <nl> else if (( k -> httpcode >= 300 && k -> httpcode < 400 ) &&
static CURLMcode multi_runsingle ( struct Curl_multi * multi , <nl>  <nl> case CURLM_STATE_TOOFAST : /* limit - rate exceeded in either direction */ <nl> /* if both rates are within spec , resume transfer */ <nl> + Curl_pgrsUpdate ( easy -> easy_conn ); <nl> if ( ( ( data -> set . max_send_speed == 0 ) || <nl> ( data -> progress . ulspeed < data -> set . max_send_speed )) && <nl> ( ( data -> set . max_recv_speed == 0 ) ||
static bool imap_endofresp ( struct connectdata * conn , char * line , size_t len , <nl> wordlen ++; <nl>  <nl> /* Does the server support the STARTTLS capability ? */ <nl> - if ( len >= 8 && ! memcmp ( line , " STARTTLS ", 8 )) <nl> + if ( wordlen >= 8 && ! memcmp ( line , " STARTTLS ", 8 )) <nl> imapc -> tls_supported = TRUE ; <nl>  <nl> /* Has the server explicitly disabled clear text authentication ? */
int fwrite_xattr ( CURL * curl , int fd ) <nl> char * value = NULL ; <nl> CURLcode rc = curl_easy_getinfo ( curl , mappings [ i ]. info , & value ); <nl> if ( rc == CURLE_OK && value ) { <nl> +# ifdef HAVE_FSETXATTR_6 <nl> + err = fsetxattr ( fd , mappings [ i ]. attr , value , strlen ( value ), 0 , 0 ); <nl> +# elif defined ( HAVE_FSETXATTR_5 ) <nl> err = fsetxattr ( fd , mappings [ i ]. attr , value , strlen ( value ), 0 ); <nl> +# endif <nl> } <nl> i ++; <nl> }
CURL * curl_easy_duphandle ( CURL * incurl ) <nl> outcurl -> progress . flags = data -> progress . flags ; <nl> outcurl -> progress . callback = data -> progress . callback ; <nl>  <nl> + if ( data -> cookies ) <nl> + /* If cookies are enabled in the parent handle , we enable them <nl> + in the clone as well ! */ <nl> + outcurl -> cookies = Curl_cookie_init ( data -> cookies -> filename , <nl> + outcurl -> cookies ); <nl> + <nl> /* duplicate all values in ' change ' */ <nl> if ( data -> change . url ) { <nl> outcurl -> change . url = strdup ( data -> change . url );
static CURLcode smtp_mail ( struct connectdata * conn ) <nl> struct SessionHandle * data = conn -> data ; <nl>  <nl> /* send MAIL FROM */ <nl> - if ( data -> set . str [ STRING_MAIL_FROM ][ 0 ] == '<') <nl> + if (! data -> set . str [ STRING_MAIL_FROM ]) <nl> + /* null reverse - path , RFC - 2821 , sect . 3 . 7 */ <nl> + result = Curl_pp_sendf (& conn -> proto . smtpc . pp , " MAIL FROM :<>"); <nl> + <nl> + else if ( data -> set . str [ STRING_MAIL_FROM ][ 0 ] == '<') <nl> result = Curl_pp_sendf (& conn -> proto . smtpc . pp , " MAIL FROM :% s ", <nl> data -> set . str [ STRING_MAIL_FROM ]); <nl> else
static bool init_resolve_thread ( struct connectdata * conn , <nl>  <nl> conn -> async . os_specific = ( void *) td ; <nl> if (! td ) <nl> - goto err_exit ; <nl> + goto errno_exit ; <nl>  <nl> conn -> async . port = port ; <nl> conn -> async . done = FALSE ; <nl> static bool init_resolve_thread ( struct connectdata * conn , <nl> conn -> async . dns = NULL ; <nl> td -> thread_hnd = curl_thread_t_null ; <nl>  <nl> - if (! init_thread_sync_data ( td , hostname , port , hints )) <nl> - goto err_exit ; <nl> + if (! init_thread_sync_data ( td , hostname , port , hints )) { <nl> + conn -> async . os_specific = NULL ; <nl> + free ( td ); <nl> + goto errno_exit ; <nl> + } <nl>  <nl> free ( conn -> async . hostname ); <nl> conn -> async . hostname = strdup ( hostname ); <nl> static bool init_resolve_thread ( struct connectdata * conn , <nl> err_exit : <nl> destroy_async_data (& conn -> async ); <nl>  <nl> + errno_exit : <nl> errno = err ; <nl> return FALSE ; <nl> }
CURLcode Curl_input_ntlm ( struct connectdata * conn , <nl> header ++; <nl>  <nl> if (* header ) { <nl> - result = Curl_ntlm_decode_type2_message ( conn -> data , header , ntlm ); <nl> + result = Curl_sasl_decode_ntlm_type2_message ( conn -> data , header , ntlm ); <nl> if ( result ) <nl> return result ; <nl>  <nl> CURLcode Curl_output_ntlm ( struct connectdata * conn , bool proxy ) <nl> case NTLMSTATE_TYPE1 : <nl> default : /* for the weird cases we ( re ) start here */ <nl> /* Create a type - 1 message */ <nl> - result = Curl_ntlm_create_type1_message ( userp , passwdp , ntlm , & base64 , <nl> - & len ); <nl> + result = Curl_sasl_create_ntlm_type1_message ( userp , passwdp , ntlm , & base64 , <nl> + & len ); <nl> if ( result ) <nl> return result ; <nl>  <nl> CURLcode Curl_output_ntlm ( struct connectdata * conn , bool proxy ) <nl>  <nl> case NTLMSTATE_TYPE2 : <nl> /* We already received the type - 2 message , create a type - 3 message */ <nl> - result = Curl_ntlm_create_type3_message ( conn -> data , userp , passwdp , <nl> - ntlm , & base64 , & len ); <nl> + result = Curl_sasl_create_ntlm_type3_message ( conn -> data , userp , passwdp , <nl> + ntlm , & base64 , & len ); <nl> if ( result ) <nl> return result ; <nl> 
static GlobCode glob_range ( URLGlob * glob , char ** patternp , <nl> } <nl> else <nl> step_n = 1 ; <nl> - if (* endp == ']') { <nl> + if ( endp && (* endp == ']')) { <nl> pattern = endp + 1 ; <nl> } <nl> else
typedef int sig_atomic_t ; <nl> * ( or equivalent ) on this platform to hide platform details to code using it . <nl> */ <nl>  <nl> -# ifdef WIN32 <nl> +# if defined ( WIN32 ) && ! defined ( USE_LWIPSOCK ) <nl> # define ERRNO (( int ) GetLastError ()) <nl> # define SET_ERRNO ( x ) ( SetLastError (( DWORD )( x ))) <nl> # else
static void G_AddBot ( const char * name , float skill , const char * team , int delay <nl> // get the botinfo from bots . txt <nl> botinfo = G_GetBotInfoByName ( name ); <nl> if ( ! botinfo ) { <nl> + trap -> BotFreeClient ( clientNum ); <nl> trap -> Print ( S_COLOR_RED " Error : Bot '% s ' not defined \ n ", name ); <nl> return ; <nl> }
static void GLimp_InitExtensions ( void ) <nl> // Find out how many general combiners they have . <nl> # define GL_MAX_GENERAL_COMBINERS_NV 0x854D <nl> GLint iNumGeneralCombiners = 0 ; <nl> - qglGetIntegerv ( GL_MAX_GENERAL_COMBINERS_NV , & iNumGeneralCombiners ); <nl> + if ( bNVRegisterCombiners ) <nl> + qglGetIntegerv ( GL_MAX_GENERAL_COMBINERS_NV , & iNumGeneralCombiners ); <nl>  <nl> // Only allow dynamic glows / flares if they have the hardware <nl> if ( bTexRectSupported && bARBVertexProgram && qglActiveTextureARB && glConfig . maxActiveTextures >= 4 &&
vm_block_handler_type ( VALUE block_handler ) <nl> } <nl>  <nl> static inline void <nl> - vm_block_handler_verify ( VALUE block_handler ) <nl> + vm_block_handler_verify ( MAYBE_UNUSED ( VALUE block_handler )) <nl> { <nl> VM_ASSERT ( block_handler == VM_BLOCK_HANDLER_NONE || <nl> ( vm_block_handler_type ( block_handler ), 1 ));
cbsubst_table_setup ( argc , argv , self ) <nl> for ( idx = 0 ; idx < len ; idx ++) { <nl> inf = RARRAY_PTR ( proc_inf )[ idx ]; <nl> if (! RB_TYPE_P ( inf , T_ARRAY )) continue ; <nl> + if ( RARRAY_LEN ( inf ) < 2 ) continue ; <nl> rb_hash_aset ( subst_inf -> proc , <nl> ( RB_TYPE_P ( RARRAY_PTR ( inf )[ 0 ], T_STRING )? <nl> INT2FIX (*( RSTRING_PTR ( RARRAY_PTR ( inf )[ 0 ]))) :
zstream_run_func ( void * ptr ) <nl> struct zstream * z = args -> z ; <nl> uInt n ; <nl>  <nl> + err = Z_OK ; <nl> while (! args -> interrupt ) { <nl> n = z -> stream . avail_out ; <nl> err = z -> func -> run (& z -> stream , flush );
rb_objspace_free ( rb_objspace_t * objspace ) <nl> # define REQUIRED_SIZE_BY_MALLOC ( sizeof ( size_t ) * 5 ) <nl> # define HEAP_SIZE ( HEAP_ALIGN - REQUIRED_SIZE_BY_MALLOC ) <nl>  <nl> -# define HEAP_OBJ_LIMIT ( HEAP_SIZE /( unsigned int ) sizeof ( struct RVALUE ) - ( unsigned int )( sizeof ( struct heaps_slot )/ sizeof ( struct RVALUE )+ 1 )) <nl> +# define HEAP_OBJ_LIMIT ( unsigned int )( HEAP_SIZE / sizeof ( struct RVALUE ) - ( sizeof ( struct heaps_slot )/ sizeof ( struct RVALUE )+ 1 )) <nl> # define HEAP_BITMAP_LIMIT ( HEAP_OBJ_LIMIT / sizeof ( uintptr_t )+ 1 ) <nl>  <nl> # define GET_HEAP_HEADER ( x ) ( HEAP_HEADER ((( uintptr_t ) x ) & ~( HEAP_ALIGN_MASK )))
st_insert2 ( st_table * tab , st_data_t key , st_data_t value , <nl> if ( tab -> bins == NULL ) { <nl> bin = find_entry ( tab , hash_value , key ); <nl> new_p = bin == UNDEFINED_ENTRY_IND ; <nl> + if ( new_p ) <nl> + tab -> num_entries ++; <nl> bin_ind = UNDEFINED_BIN_IND ; <nl> } <nl> else {
valid_hostname ( const char * hostname ) <nl> if ( hostname == NULL ) <nl> return NO ; <nl>  <nl> + if (! strcmp ( hostname , " localhost ")) <nl> + return YES ; <nl> + <nl> if ('.' == * p || ':' == * p || '/' == * p ) <nl> return NO ; <nl> 
int match_cidr ( const char * s1 , const char * s2 ) <nl> * len ++ = '\ 0 '; <nl>  <nl> cidrlen = atoi ( len ); <nl> - if ( cidrlen == 0 ) <nl> + if ( cidrlen <= 0 ) <nl> return 0 ; <nl>  <nl> # ifdef RB_IPV6 <nl> if ( strchr ( ip , ':') && strchr ( ipmask , ':')) <nl> { <nl> + if ( cidrlen > 128 ) <nl> + return 0 ; <nl> + <nl> aftype = AF_INET6 ; <nl> ipptr = &(( struct sockaddr_in6 *)& ipaddr )-> sin6_addr ; <nl> maskptr = &(( struct sockaddr_in6 *)& maskaddr )-> sin6_addr ; <nl> int match_cidr ( const char * s1 , const char * s2 ) <nl> # endif <nl> if (! strchr ( ip , ':') && ! strchr ( ipmask , ':')) <nl> { <nl> + if ( cidrlen > 32 ) <nl> + return 0 ; <nl> + <nl> aftype = AF_INET ; <nl> ipptr = &(( struct sockaddr_in *)& ipaddr )-> sin_addr ; <nl> maskptr = &(( struct sockaddr_in *)& maskaddr )-> sin_addr ;
int CloseUnreal ( HWND hWnd ) <nl> return 0 ; <nl> else <nl> { <nl> - DestroyWindow ( hWnd ); <nl> - exit ( 0 ); <nl> + DestroyWindow ( hWnd ); <nl> + TerminateProcess ( GetCurrentProcess (), 0 ); <nl> + exit ( 0 ); /* in case previous fails ( possible ?) */ <nl> } <nl> } <nl> 
opj_pi_iterator_t * opj_pi_create_decode ( opj_image_t * p_image , <nl> l_current_pi -> include = 00 ; <nl> if ( l_step_l <= ( SIZE_MAX / ( l_tcp -> numlayers + 1U ))) <nl> { <nl> - l_current_pi -> include = ( OPJ_INT16 *) opj_calloc (( l_tcp -> numlayers + 1 ) * l_step_l , sizeof ( OPJ_INT16 )); <nl> + l_current_pi -> include = ( OPJ_INT16 *) opj_calloc (( size_t )( l_tcp -> numlayers + 1U ) * l_step_l , sizeof ( OPJ_INT16 )); <nl> } <nl>  <nl> if
int main ( int argc , char ** argv ) <nl>  <nl> /* Remove the temporary files */ <nl> /* -------------------------- */ <nl> - if ( cp . decod_format != PGX_CFMT ) { /* PNM PGM PPM or BMP */ <nl> + if ( cp . decod_format != PGX_DFMT ) { /* PNM PGM PPM or BMP */ <nl> for ( i = 0 ; i < img . numcomps ; i ++) { <nl> char tmp ; <nl> sprintf (& tmp , " Compo % d ", i );
void my_debug ( void * ctx , int level , const char * str ) <nl>  <nl> int main ( int argc , char * argv [] ) <nl> { <nl> - int ret , len , server_fd ; <nl> + int ret = 0 , len , server_fd ; <nl> unsigned char buf [ 1024 ]; <nl> havege_state hs ; <nl> ssl_context ssl ;
static int ssl_parse_server_key_exchange ( mbedtls_ssl_context * ssl ) <nl> sig_len = ( p [ 0 ] << 8 ) | p [ 1 ]; <nl> p += 2 ; <nl>  <nl> - if ( end != p + sig_len ) <nl> + if ( p != end - sig_len ) <nl> { <nl> MBEDTLS_SSL_DEBUG_MSG ( 1 , ( " bad server key exchange message " ) ); <nl> mbedtls_ssl_send_alert_message ( ssl , MBEDTLS_SSL_ALERT_LEVEL_FATAL ,
int ssl_session_reset ( ssl_context * ssl ) <nl> ssl -> out_msglen = 0 ; <nl> ssl -> out_left = 0 ; <nl>  <nl> + ssl -> mfl_code = SSL_MAX_FRAG_LEN_NONE ; <nl> + ssl -> max_frag_len = SSL_MAX_CONTENT_LEN ; <nl> + <nl> ssl -> transform_in = NULL ; <nl> ssl -> transform_out = NULL ; <nl> 
static int ssl_parse_server_psk_hint ( mbedtls_ssl_context * ssl , <nl> * <nl> * opaque psk_identity_hint < 0 .. 2 ^ 16 - 1 >; <nl> */ <nl> + if ( (* p ) > end - 2 ) <nl> + { <nl> + MBEDTLS_SSL_DEBUG_MSG ( 1 , ( " bad server key exchange message " <nl> + "( psk_identity_hint length )" ) ); <nl> + return ( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE ); <nl> + } <nl> len = (* p )[ 0 ] << 8 | (* p )[ 1 ]; <nl> * p += 2 ; <nl> 
append_to_command_line_from_file ( const char * file_name , <nl> } <nl> if (( argv_tmp = realloc (* argv_p , ( sizeof arg ) * <nl> (( size_t ) * argc_p + 1 ))) == NULL ) { <nl> + free ( arg ); <nl> fclose ( fp ); <nl> return - 1 ; <nl> }
void dostor ( char * name , const int append , const int autorename ) <nl> if ( quota_update (& quota , 0LL , 0LL , & overflow ) == 0 && <nl> ( overflow > 0 || quota . files >= user_quota_files || <nl> quota . size > user_quota_size || <nl> - ( max_filesize >= ( off_t ) 0 && <nl> - ( max_filesize = user_quota_size - quota . size ) < ( off_t ) 0 ))) { <nl> + ( max_filesize = user_quota_size - quota . size ) < ( off_t ) 0 )) { <nl> overflow = 1 ; <nl> ( void ) close ( f ); <nl> goto afterquota ;
struct WireHelpers { <nl> WirePointer * ref , word * refTarget , SegmentBuilder * segment , <nl> const void * defaultValue , ByteCount defaultSize )) { <nl> if ( ref -> isNull ()) { <nl> + useDefault : <nl> if ( defaultSize == 0 * BYTES ) { <nl> return nullptr ; <nl> } else { <nl> struct WireHelpers { <nl> } <nl> } else { <nl> word * ptr = followFars ( ref , refTarget , segment ); <nl> + char * cptr = reinterpret_cast < char *>( ptr ); <nl>  <nl> KJ_REQUIRE ( ref -> kind () == WirePointer :: LIST , <nl> " Called getText { Field , Element }() but existing pointer is not a list ."); <nl> KJ_REQUIRE ( ref -> listRef . elementSize () == ElementSize :: BYTE , <nl> " Called getText { Field , Element }() but existing list pointer is not byte - sized ."); <nl>  <nl> - // Subtract 1 from the size for the NUL terminator . <nl> - return Text :: Builder ( reinterpret_cast < char *>( ptr ), ref -> listRef . elementCount () / ELEMENTS - 1 ); <nl> + size_t size = ref -> listRef . elementCount () / ELEMENTS ; <nl> + KJ_REQUIRE ( size > 0 && cptr [ size - 1 ] == '\ 0 ', " Text blob missing NUL terminator .") { <nl> + goto useDefault ; <nl> + } <nl> + <nl> + return Text :: Builder ( cptr , size - 1 ); <nl> } <nl> } <nl> 
foptoas ( int op , Type * t , int flg ) <nl> { <nl> int et , a ; <nl>  <nl> + a = AGOK ; <nl> et = simtype [ t -> etype ]; <nl>  <nl> if ( use_sse )
int ossl_policy_cache_set_mapping ( X509 * x , POLICY_MAPPINGS * maps ) <nl>  <nl> ret = 1 ; <nl> bad_mapping : <nl> - if ( ret == - 1 && CRYPTO_THREAD_write_lock ( x -> lock )) { <nl> - x -> ex_flags |= EXFLAG_INVALID_POLICY ; <nl> - CRYPTO_THREAD_unlock ( x -> lock ); <nl> - } <nl> sk_POLICY_MAPPING_pop_free ( maps , POLICY_MAPPING_free ); <nl> return ret ; <nl> 
int dsa_builtin_paramgen2 ( DSA * ret , size_t L , size_t N , <nl> } else { <nl> p = BN_CTX_get ( ctx ); <nl> q = BN_CTX_get ( ctx ); <nl> + if ( q == NULL ) <nl> + goto err ; <nl> } <nl>  <nl> if (! BN_lshift ( test , BN_value_one (), L - 1 ))
static int rsa_item_verify ( EVP_MD_CTX * ctx , const ASN1_ITEM * it , void * asn , <nl> RSAerr ( RSA_F_RSA_ITEM_VERIFY , RSA_R_UNSUPPORTED_SIGNATURE_TYPE ); <nl> return - 1 ; <nl> } <nl> - if ( rsa_pss_to_ctx ( ctx , NULL , sigalg , pkey )) <nl> + if ( rsa_pss_to_ctx ( ctx , NULL , sigalg , pkey ) > 0 ) { <nl> /* Carry on */ <nl> return 2 ; <nl> + } <nl> return - 1 ; <nl> } <nl> 
static int tls_decrypt_ticket ( SSL * s , const unsigned char * etick , <nl> if ( sdec == NULL <nl> || EVP_DecryptUpdate ( ctx , sdec , & slen , p , eticklen ) <= 0 ) { <nl> EVP_CIPHER_CTX_free ( ctx ); <nl> + OPENSSL_free ( sdec ); <nl> return - 1 ; <nl> } <nl> if ( EVP_DecryptFinal ( ctx , sdec + slen , & mlen ) <= 0 ) {
dtls1_heartbeat ( SSL * s ) <nl> * - Padding <nl> */ <nl> buf = OPENSSL_malloc ( 1 + 2 + payload + padding ); <nl> + if ( buf == NULL ) <nl> + { <nl> + SSLerr ( SSL_F_DTLS1_HEARTBEAT , ERR_R_MALLOC_FAILURE ); <nl> + return - 1 ; <nl> + } <nl> p = buf ; <nl> /* Message Type */ <nl> * p ++ = TLS1_HB_REQUEST ;
int OBJ_create ( const char * oid , const char * sn , const char * ln ) <nl>  <nl> /* Convert numerical OID string to an ASN1_OBJECT structure */ <nl> tmpoid = OBJ_txt2obj ( oid , 1 ); <nl> + if ( tmpoid == NULL ) <nl> + return 0 ; <nl>  <nl> /* If NID is not NID_undef then object already exists */ <nl> if ( OBJ_obj2nid ( tmpoid ) != NID_undef ) {
int OCSP_parse_url ( char * url , char ** phost , char ** pport , char ** ppath , int * pss <nl>  <nl>  <nl> err : <nl> + if ( buf ) OPENSSL_free ( buf ); <nl> if (* ppath ) OPENSSL_free (* ppath ); <nl> if (* pport ) OPENSSL_free (* pport ); <nl> if (* phost ) OPENSSL_free (* phost );
long BIO_debug_callback ( BIO * bio , int cmd , const char * argp , <nl>  <nl> len = BIO_snprintf ( buf , sizeof buf ," BIO [% p ]: ",( void *) bio ); <nl>  <nl> + /* Ignore errors and continue printing the other information . */ <nl> + if ( len < 0 ) <nl> + len = 0 ; <nl> p = buf + len ; <nl> p_maxlen = sizeof ( buf ) - len ; <nl> 
static struct file_st * win32_splitter ( DSO * dso , const char * filename , <nl> DSOerr ( DSO_F_WIN32_SPLITTER , <nl> DSO_R_INCORRECT_FILE_SYNTAX ); <nl> /* goto err ;*/ <nl> + OPENSSL_free ( result ); <nl> return ( NULL ); <nl> } <nl> result -> device = start ; <nl> static char * win32_merger ( DSO * dso , const char * filespec1 , const char * filespec2 <nl>  <nl> merged = win32_joiner ( dso , filespec1_split ); <nl> } <nl> + OPENSSL_free ( filespec1_split ); <nl> + OPENSSL_free ( filespec2_split ); <nl> return ( merged ); <nl> } <nl> 
* [ including the GNU Public Licence .] <nl> */ <nl> /* ==================================================================== <nl> - * Copyright ( c ) 1998 - 2002 The OpenSSL Project . All rights reserved . <nl> + * Copyright ( c ) 1998 - 2003 The OpenSSL Project . All rights reserved . <nl> * <nl> * Redistribution and use in source and binary forms , with or without <nl> * modification , are permitted provided that the following conditions <nl> int ASN1_item_sign ( const ASN1_ITEM * it , X509_ALGOR * algor1 , X509_ALGOR * algor2 , <nl> else <nl> a = algor2 ; <nl> if ( a == NULL ) continue ; <nl> - if ( type -> pkey_type == NID_dsaWithSHA1 ) <nl> + if ( type -> pkey_type == NID_dsaWithSHA1 || <nl> + type -> pkey_type == NID_ecdsa_with_SHA1 ) <nl> { <nl> - /* special case : RFC 2459 tells us to omit ' parameters ' <nl> - * with id - dsa - with - sha1 */ <nl> + /* special case : RFC 3279 tells us to omit ' parameters ' <nl> + * with id - dsa - with - sha1 and ecdsa - with - SHA1 */ <nl> ASN1_TYPE_free ( a -> parameter ); <nl> a -> parameter = NULL ; <nl> }
/* gcc knows how to retrieve return address , but we don ' t know */ <nl> /* how to generate call stacks . */ <nl> # define GC_RETURN_ADDR ( GC_word ) __builtin_return_address ( 0 ) <nl> -# if defined ( __i386__ ) || defined ( __amd64__ ) \ <nl> - || defined ( __x86_64__ ) /* and probably others ... */ <nl> -# define GC_RETURN_ADDR_PARENT ( GC_word ) __builtin_return_address ( 1 ) <nl> +# if ( __GNUC__ >= 4 ) && ( defined ( __i386__ ) || defined ( __amd64__ ) \ <nl> + || defined ( __x86_64__ ) /* and probably others ... */) <nl> +# define GC_RETURN_ADDR_PARENT \ <nl> + ( GC_word ) __builtin_extract_return_addr ( __builtin_return_address ( 1 )) <nl> # endif <nl> # else <nl> /* Just pass 0 for gcc compatibility . */
void * malloc ( size_t lb ) <nl> } <nl> # endif /* GC_LINUX_THREADS */ <nl>  <nl> -# ifndef SIZE_MAX <nl> -# define SIZE_MAX (~( size_t ) 0 ) <nl> +# include < limits . h > <nl> +# ifdef SIZE_MAX <nl> +# define GC_SIZE_MAX SIZE_MAX <nl> +# else <nl> +# define GC_SIZE_MAX (~( size_t ) 0 ) <nl> # endif <nl> + <nl> void * calloc ( size_t n , size_t lb ) <nl> { <nl> - if ( lb && n > SIZE_MAX / lb ) <nl> + if ( lb && n > GC_SIZE_MAX / lb ) <nl> return NULL ; <nl> # if defined ( GC_LINUX_THREADS ) /* && ! defined ( USE_PROC_FOR_LIBRARIES ) */ <nl> /* libpthread allocated some memory that is only pointed to by */
static int process_results ( struct cgpu_info * bflsc , int dev , char * pbuf , int * no <nl>  <nl> if ( lines < QUE_RES_LINES_MIN ) { <nl> tmp = str_text ( pbuf ); <nl> - applog ( LOG_ERR , "% s % i :% s result too small (% s ) ignored ", <nl> - bflsc -> drv -> name , bflsc -> device_id , xlink , tmp ); <nl> + applog ( LOG_ERR , "% s % i :% s result of % d too small (% s ) ignored ", <nl> + bflsc -> drv -> name , bflsc -> device_id , xlink , lines , tmp ); <nl> free ( tmp ); <nl> goto arigatou ; <nl> }
static char * parse_config ( json_t * config , bool fileconf ) <nl> /* We don ' t handle subtables . */ <nl> assert (!( opt -> type & OPT_SUBTABLE )); <nl>  <nl> + if (! opt -> names ) <nl> + continue ; <nl> + <nl> /* Pull apart the option name ( s ). */ <nl> name = strdup ( opt -> names ); <nl> for ( p = strtok ( name , "|"); p ; p = strtok ( NULL , "|")) {
void switch_pools ( struct pool * selected ) <nl> case POOL_LOADBALANCE : <nl> for ( i = 0 ; i < total_pools ; i ++) { <nl> pool = priority_pool ( i ); <nl> - if ( pool_unusable ( pool )) <nl> + if ( pool_unusable ( pool ) && pool != selected ) <nl> continue ; <nl> pool_no = pool -> pool_no ; <nl> break ; <nl> void switch_pools ( struct pool * selected ) <nl> if ( next_pool >= total_pools ) <nl> next_pool = 0 ; <nl> pool = pools [ next_pool ]; <nl> - if ( pool_unusable ( pool )) <nl> + if ( pool_unusable ( pool ) && pool != selected ) <nl> continue ; <nl> pool_no = next_pool ; <nl> break ;
// client versioning <nl> // <nl>  <nl> - static const int CLIENT_VERSION_MAJOR = 0 ; <nl> - static const int CLIENT_VERSION_MINOR = 6 ; <nl> - static const int CLIENT_VERSION_REVISION = 99 ; <nl> - static const int CLIENT_VERSION_BUILD = 0 ; <nl> +// These need to be macro ' s , as version . cpp ' s voodoo requires it <nl> +# define CLIENT_VERSION_MAJOR 0 <nl> +# define CLIENT_VERSION_MINOR 6 <nl> +# define CLIENT_VERSION_REVISION 99 <nl> +# define CLIENT_VERSION_BUILD 0 <nl>  <nl> static const int CLIENT_VERSION = <nl> 1000000 * CLIENT_VERSION_MAJOR
read_gif ( Gif_Reader * grr , int read_flags , <nl> Gif_DeleteArray ( gfc . suffix ); <nl> Gif_DeleteArray ( gfc . length ); <nl> gfc . gfi = 0 ; <nl> + last_name = 0 ; <nl>  <nl> if ( gfs ) <nl> gfs -> errors = gfc . errors [ 1 ];
struct semanage_fcontext { <nl> struct semanage_fcontext_key { <nl>  <nl> /* Matching expression */ <nl> - const char * expr ; <nl> + char * expr ; <nl>  <nl> /* Type of object */ <nl> int type ; <nl> int semanage_fcontext_key_create ( semanage_handle_t * handle , <nl> " create file context key "); <nl> return STATUS_ERR ; <nl> } <nl> - tmp_key -> expr = expr ; <nl> + tmp_key -> expr = strdup ( expr ); <nl> + if (! tmp_key -> expr ) { <nl> + ERR ( handle , " out of memory , could not create file context key ."); <nl> + return STATUS_ERR ; <nl> + } <nl> tmp_key -> type = type ; <nl>  <nl> * key_ptr = tmp_key ; <nl> hidden_def ( semanage_fcontext_key_extract ) <nl>  <nl> void semanage_fcontext_key_free ( semanage_fcontext_key_t * key ) <nl> { <nl> + free ( key -> expr ); <nl> free ( key ); <nl> } <nl> 
static char * selabel_sub ( struct selabel_sub * ptr , const char * src ) <nl> if ( strncmp ( src , ptr -> src , ptr -> slen ) == 0 ) { <nl> if ( src [ ptr -> slen ] == '/' || <nl> src [ ptr -> slen ] == 0 ) { <nl> - asprintf (& dst , "% s % s ", ptr -> dst , & src [ ptr -> slen ]); <nl> + if ( asprintf (& dst , "% s % s ", ptr -> dst , & src [ ptr -> slen ]) < 0 ) <nl> + return NULL ; <nl> return dst ; <nl> } <nl> }
int cil_resolve_aliasactual ( struct cil_tree_node * current , void * extra_args , enu <nl> } <nl> if ( NODE ( alias_datum )-> flavor != alias_flavor ) { <nl> cil_log ( CIL_ERR , "% s is not an alias \ n ", alias_datum -> name ); <nl> + rc = SEPOL_ERR ; <nl> goto exit ; <nl> } <nl>  <nl> int cil_resolve_aliasactual ( struct cil_tree_node * current , void * extra_args , enu <nl> goto exit ; <nl> } <nl>  <nl> + if ( NODE ( actual_datum )-> flavor != flavor ) { <nl> + cil_log ( CIL_ERR , "% s is a % s , but aliases a % s \ n ", alias_datum -> name , cil_node_to_string ( NODE ( alias_datum )), cil_node_to_string ( NODE ( actual_datum ))); <nl> + rc = SEPOL_ERR ; <nl> + goto exit ; <nl> + } <nl> + <nl> alias = ( struct cil_alias *) alias_datum ; <nl>  <nl> if ( alias -> actual != NULL ) {
BEGINrunInput <nl> # endif <nl>  <nl> CODESTARTrunInput <nl> + CHKmalloc ( pReadfds ); <nl> if ( runModConf -> bOmitLocalLogging && nfd == 1 ) <nl> ABORT_FINALIZE ( RS_RET_OK ); <nl> /* this is an endless loop - it is terminated when the thread is
BEGINafterRun <nl> int i ; <nl> CODESTARTafterRun <nl> /* do cleanup here */ <nl> + if ( startIndexUxLocalSockets == 1 && nfd == 1 ) { <nl> + /* No sockets were configured , no cleanup needed . */ <nl> + return RS_RET_OK ; <nl> + } <nl> + <nl> /* Close the UNIX sockets . */ <nl> for ( i = 0 ; i < nfd ; i ++) <nl> if ( listeners [ i ]. fd != - 1 )
doGetGID ( struct nvlst * valnode , struct cnfparamdescr * param , <nl> char stringBuf [ 2048 ]; /* 2048 has been proven to be large enough */ <nl>  <nl> cstr = es_str2cstr ( valnode -> val . d . estr , NULL ); <nl> - getgrnam_r ( cstr , & wrkBuf , stringBuf , sizeof ( stringBuf ), & resultBuf ); <nl> + const int e = getgrnam_r ( cstr , & wrkBuf , stringBuf , <nl> + sizeof ( stringBuf ), & resultBuf ); <nl> if ( resultBuf == NULL ) { <nl> + if ( e != 0 ) { <nl> + LogError ( e , RS_RET_ERR , " parameter '% s ': error to " <nl> + " obtaining group id for '% s '", param -> name , cstr ); <nl> + } <nl> parser_errmsg (" parameter '% s ': ID for group % s could not " <nl> " be found ", param -> name , cstr ); <nl> r = 0 ;
dbgprintf (" DDDD : wti % p : worker starting \ n ", pThis ); <nl> if ( pThis -> actWrkrInfo [ i ]. actWrkrData != NULL ) { <nl> dbgprintf (" DDDD : calling freeWrkrData !\ n "); <nl> pThis -> actWrkrInfo [ i ]. pAction -> pMod -> mod . om . freeWrkrInstance ( pThis -> actWrkrInfo [ i ]. actWrkrData ); <nl> + pThis -> actWrkrInfo [ i ]. actWrkrData = NULL ; /* re - init for next activation */ <nl> } <nl> } <nl> 
split_binary_parameters ( uchar ** const szBinary , char *** const __restrict__ aPara <nl> (* aParams )[ iPrm ] = NULL ; /* NULL per argv [] convention */ <nl>  <nl> finalize_it : <nl> + if ( estrBinary != param_binary ) { <nl> + es_deleteStr ( estrBinary ); <nl> + } <nl> + if ( estrParams != NULL ) { <nl> + es_deleteStr ( estrParams ); <nl> + } <nl> RETiRet ; <nl> }
static rsRetVal <nl> getPeerNames ( prop_t ** peerName , prop_t ** peerIP , struct sockaddr * pAddr , sbool bUXServer ) <nl> { <nl> int error ; <nl> - uchar szIP [ NI_MAXHOST ] = ""; <nl> - uchar szHname [ NI_MAXHOST ] = ""; <nl> + uchar szIP [ NI_MAXHOST + 1 ] = ""; <nl> + uchar szHname [ NI_MAXHOST + 1 ] = ""; <nl> struct addrinfo hints , * res ; <nl> sbool bMaliciousHName = 0 ; <nl>  <nl> getPeerNames ( prop_t ** peerName , prop_t ** peerIP , struct sockaddr * pAddr , sbool b <nl> * peerIP = NULL ; <nl>  <nl> if ( bUXServer ) { <nl> - strcpy (( char *) szHname , ( char *) glbl . GetLocalHostName ()); <nl> - strcpy (( char *) szIP , ( char *) glbl . GetLocalHostIP ()); <nl> + strncpy (( char *) szHname , ( char *) glbl . GetLocalHostName (), NI_MAXHOST ); <nl> + strncpy (( char *) szIP , ( char *) glbl . GetLocalHostIP (), NI_MAXHOST ); <nl> + szHname [ NI_MAXHOST ] = '\ 0 '; <nl> + szIP [ NI_MAXHOST ] = '\ 0 '; <nl> } else { <nl> error = getnameinfo ( pAddr , SALEN ( pAddr ), ( char *) szIP , sizeof ( szIP ), NULL , 0 , NI_NUMERICHOST ); <nl> if ( error ) {
LstnInit ( netstrms_t * pNS , void * pUsr , rsRetVal (* fAddLstn )( void *, netstrm_t *), <nl> for ( r = res ; r != NULL ; r = r -> ai_next ) { <nl> sock = socket ( r -> ai_family , r -> ai_socktype , r -> ai_protocol ); <nl> if ( sock < 0 ) { <nl> - if (!( r -> ai_family == PF_INET6 && errno == EAFNOSUPPORT )) <nl> + if (!( r -> ai_family == PF_INET6 && errno == EAFNOSUPPORT )) { <nl> dbgprintf (" error % d creating tcp listen socket ", errno ); <nl> /* it is debatable if PF_INET with EAFNOSUPPORT should <nl> * also be ignored ... <nl> */ <nl> + } <nl> continue ; <nl> } <nl> 
PROTOTYPEObj ( statsobj ); <nl> */ <nl> # define STATSCOUNTER_DEF ( ctr , mut ) \ <nl> intctr_t ctr ; \ <nl> - DEF_ATOMIC_HELPER_MUT ( mut ) <nl> + DEF_ATOMIC_HELPER_MUT ( mut ); <nl>  <nl> # define STATSCOUNTER_INIT ( ctr , mut ) \ <nl> INIT_ATOMIC_HELPER_MUT ( mut ); \ <nl> PROTOTYPEObj ( statsobj ); <nl>  <nl> # define STATSCOUNTER_INC ( ctr , mut ) \ <nl> if ( GatherStats ) \ <nl> - ATOMIC_INC (& ctr , mut ); <nl> + ATOMIC_INC (& ctr , & mut ); <nl>  <nl> # define STATSCOUNTER_DEC ( ctr , mut ) \ <nl> if ( GatherStats ) \
submitSyslog ( int pri , uchar * buf ) <nl> /* we now try to parse the timestamp . iff it parses , we assume <nl> * it is a timestamp . Otherwise we know for sure it is no ts ;) <nl> */ <nl> - i = 4 ; /* first digit after '[' */ <nl> + i = 4 ; /* space or first digit after '[' */ <nl> + while ( buf [ i ] && isspace ( buf [ i ])) <nl> + ++ i ; /* skip space */ <nl> secs = 0 ; <nl> while ( buf [ i ] && isdigit ( buf [ i ])) { <nl> secs = secs * 10 + buf [ i ] - ' 0 ';
MODULE_TYPE_NOKEEP <nl> MODULE_CNFNAME (" mmanon ") <nl>  <nl>  <nl> - DEFobjCurrIf ( errmsg ); <nl> DEF_OMOD_STATIC_DATA <nl>  <nl> /* config variables */ <nl> BEGINparseSelectorAct <nl> CODESTARTparseSelectorAct <nl> CODE_STD_STRING_REQUESTparseSelectorAct ( 1 ) <nl> if ( strncmp (( char *) p , ": mmanon :", sizeof (": mmanon :") - 1 )) { <nl> - errmsg . LogError ( 0 , RS_RET_LEGA_ACT_NOT_SUPPORTED , <nl> + LogError ( 0 , RS_RET_LEGA_ACT_NOT_SUPPORTED , <nl> " mmanon supports only v6 + config format , use : " <nl> " action ( type =\" mmanon \" ...)"); <nl> } <nl> ENDparseSelectorAct <nl>  <nl> BEGINmodExit <nl> CODESTARTmodExit <nl> - objRelease ( errmsg , CORE_COMPONENT ); <nl> ENDmodExit <nl>  <nl>  <nl> CODESTARTmodInit <nl> * ipIFVersProvided = CURR_MOD_IF_VERSION ; /* we only support the current interface specification */ <nl> CODEmodInit_QueryRegCFSLineHdlr <nl> DBGPRINTF (" mmanon : module compiled with rsyslog version % s .\ n ", VERSION ); <nl> - CHKiRet ( objUse ( errmsg , CORE_COMPONENT )); <nl> ENDmodInit
gui_bar_window_draw ( struct t_gui_bar_window * bar_window , <nl>  <nl> /* move cursor if it was asked in an item content ( input_text does that <nl> to move cursor in user input text ) */ <nl> - if ( window && ( gui_current_window == window ) <nl> + if ((! window || ( gui_current_window == window )) <nl> && ( bar_window -> cursor_x >= 0 ) && ( bar_window -> cursor_y >= 0 )) <nl> { <nl> move ( bar_window -> cursor_y , bar_window -> cursor_x );
__FBSDID ("$ FreeBSD : head / lib / libarchive / archive_string . c 201095 2009 - 12 - 28 02 : 33 <nl> # define wmemmove ( a , b , i ) ( wchar_t *) memmove (( a ), ( b ), ( i ) * sizeof ( wchar_t )) <nl> # endif <nl>  <nl> +# undef max <nl> +# define max ( a , b ) (( a )>( b )?( a ):( b )) <nl> + <nl> struct archive_string_conv { <nl> struct archive_string_conv * next ; <nl> char * from_charset ; <nl> archive_string_append_from_wcs ( struct archive_string * as , <nl> as -> s [ as -> length ] = '\ 0 '; <nl> /* Re - allocate buffer for MBS . */ <nl> if ( archive_string_ensure ( as , <nl> - as -> length + len * 2 + 1 ) == NULL ) <nl> + as -> length + max ( len * 2 , <nl> + ( size_t ) MB_CUR_MAX ) + 1 ) == NULL ) <nl> return (- 1 ); <nl> p = as -> s + as -> length ; <nl> end = as -> s + as -> buffer_length - MB_CUR_MAX - 1 ; <nl> strncat_from_utf8_libarchive2 ( struct archive_string * as , <nl> as -> length = p - as -> s ; <nl> /* Re - allocate buffer for MBS . */ <nl> if ( archive_string_ensure ( as , <nl> - as -> length + len * 2 + 1 ) == NULL ) <nl> + as -> length + max ( len * 2 , <nl> + ( size_t ) MB_CUR_MAX ) + 1 ) == NULL ) <nl> return (- 1 ); <nl> p = as -> s + as -> length ; <nl> end = as -> s + as -> buffer_length - MB_CUR_MAX - 1 ;
acl_new_entry ( struct archive_acl * acl , <nl> acl -> acl_text = NULL ; <nl> } <nl>  <nl> - /* If there ' s a matching entry already in the list , overwrite it . */ <nl> + /* <nl> + * If there ' s a matching entry already in the list , overwrite it . <nl> + * NFSv4 entries may be repeated and are not overwritten . <nl> + * <nl> + * TODO : compare names of no id is provided ( needs more rework ) <nl> + */ <nl> ap = acl -> acl_head ; <nl> aq = NULL ; <nl> while ( ap != NULL ) { <nl> - if ( ap -> type == type && ap -> tag == tag && ap -> id == id ) { <nl> + if ((( type & ARCHIVE_ENTRY_ACL_TYPE_NFS4 ) == 0 ) && <nl> + ap -> type == type && ap -> tag == tag && ap -> id == id ) { <nl> if ( id != - 1 || ( tag != ARCHIVE_ENTRY_ACL_USER && <nl> tag != ARCHIVE_ENTRY_ACL_GROUP )) { <nl> ap -> permset = permset ;
copy_out ( struct archive_write * a , uint64_t offset , uint64_t length ) <nl> ( intmax_t ) rs ); <nl> return ( ARCHIVE_FATAL ); <nl> } <nl> + if ( rs == 0 ) { <nl> + archive_set_error (&( a -> archive ), 0 , <nl> + " Truncated xar archive "); <nl> + return ( ARCHIVE_FATAL ); <nl> + } <nl> xar -> wbuff_remaining -= rs ; <nl> length -= rs ; <nl> if ( xar -> wbuff_remaining == 0 ) {
lha_read_file_header_1 ( struct archive_read * a , struct lha * lha ) <nl> /* Get a real compressed file size . */ <nl> lha -> compsize -= extdsize - 2 ; <nl>  <nl> + if ( lha -> compsize < 0 ) <nl> + goto invalid ; /* Invalid compressed file size */ <nl> + <nl> if ( sum_calculated != headersum ) { <nl> archive_set_error (& a -> archive , ARCHIVE_ERRNO_MISC , <nl> " LHa header sum error ");
read_header ( struct archive_read * a , struct archive_entry * entry , <nl> return ( ARCHIVE_FATAL ); <nl> } <nl> filename [ filename_size ++] = '\ 0 '; <nl> - filename [ filename_size ++] = '\ 0 '; <nl> + /* <nl> + * Do not increment filename_size here as the computations below <nl> + * add the space for the terminating NUL explicitly . <nl> + */ <nl> + filename [ filename_size ] = '\ 0 '; <nl>  <nl> /* Decoded unicode form is UTF - 16BE , so we have to update a string <nl> * conversion object for it . */
parse_codes ( struct archive_read * a ) <nl> rar -> range_dec . Stream = & rar -> bytein ; <nl> __archive_ppmd7_functions . Ppmd7_Construct (& rar -> ppmd7_context ); <nl>  <nl> + if ( rar -> dictionary_size == 0 ) { <nl> + archive_set_error (& a -> archive , ARCHIVE_ERRNO_FILE_FORMAT , <nl> + " Invalid zero dictionary size "); <nl> + return ( ARCHIVE_FATAL ); <nl> + } <nl> + <nl> if (! __archive_ppmd7_functions . Ppmd7_Alloc (& rar -> ppmd7_context , <nl> rar -> dictionary_size , & g_szalloc )) <nl> {
__archive_read_program ( struct archive_read_filter * self , const char * cmd ) <nl> & state -> child_stdout ); <nl> if ( child == - 1 ) { <nl> free ( state -> out_buf ); <nl> + archive_string_free (& state -> description ); <nl> free ( state ); <nl> archive_set_error (& self -> archive -> archive , EINVAL , <nl> " Can ' t initialize filter ; unable to run program \"% s \"", <nl> __archive_read_program ( struct archive_read_filter * self , const char * cmd ) <nl> if ( state -> child == NULL ) { <nl> child_stop ( self , state ); <nl> free ( state -> out_buf ); <nl> + archive_string_free (& state -> description ); <nl> free ( state ); <nl> archive_set_error (& self -> archive -> archive , EINVAL , <nl> " Can ' t initialize filter ; unable to run program \"% s \"",
_warc_read ( struct archive_read * a , const void ** buf , size_t * bsz , int64_t * off ) <nl> return ( ARCHIVE_EOF ); <nl> } <nl>  <nl> + if ( w -> unconsumed ) { <nl> + __archive_read_consume ( a , w -> unconsumed ); <nl> + w -> unconsumed = 0U ; <nl> + } <nl> + <nl> rab = __archive_read_ahead ( a , 1U , & nrd ); <nl> if ( nrd < 0 ) { <nl> * bsz = 0U ;
static void xmlCleanURI ( xmlURIPtr uri ); <nl> (((*( p ) == '!')) || ((*( p ) == '$')) || ((*( p ) == '&')) || \ <nl> ((*( p ) == '(')) || ((*( p ) == ')')) || ((*( p ) == '*')) || \ <nl> ((*( p ) == '+')) || ((*( p ) == ',')) || ((*( p ) == ';')) || \ <nl> - ((*( p ) == '='))) <nl> + ((*( p ) == '=')) || ((*( p ) == '\''))) <nl>  <nl> /* <nl> * gen - delims = ":" / "/" / "?" / "#" / "[" / "]" / "@"
static int msg_parse_fetch ( struct ImapHeader * h , char * s ) <nl> } <nl> s ++; <nl> ptmp = tmp ; <nl> - while (* s && * s != '\"') <nl> + while (* s && (* s != '\"') && ( ptmp != ( tmp + sizeof ( tmp ) - 1 ))) <nl> * ptmp ++ = * s ++; <nl> if (* s != '\"') <nl> return - 1 ; <nl> static int msg_parse_fetch ( struct ImapHeader * h , char * s ) <nl> s += 11 ; <nl> SKIPWS ( s ); <nl> ptmp = tmp ; <nl> - while ( isdigit (( unsigned char ) * s )) <nl> + while ( isdigit (( unsigned char ) * s ) && ( ptmp != ( tmp + sizeof ( tmp ) - 1 ))) <nl> * ptmp ++ = * s ++; <nl> * ptmp = '\ 0 '; <nl> if ( mutt_str_atol ( tmp , & h -> content_length ) < 0 )
static void cmd_parse_status ( struct ImapData * idata , char * s ) <nl> idata -> status = IMAP_FATAL ; <nl> return ; <nl> } <nl> + <nl> + if ( strlen ( idata -> buf ) < litlen ) <nl> + { <nl> + mutt_debug ( 1 , " Error parsing STATUS mailbox \ n "); <nl> + return ; <nl> + } <nl> + <nl> mailbox = idata -> buf ; <nl> s = mailbox + litlen ; <nl> * s = '\ 0 ';
int mutt_builtin_editor ( const char * path , HEADER * msg , HEADER * cur ) <nl> if ( Context ) <nl> { <nl> if (!* p && cur ) <nl> - { <nl> + { <nl> /* include the current message */ <nl> p = tmp + strlen ( tmp ) + 1 ; <nl> snprintf ( tmp + strlen ( tmp ), sizeof ( tmp ) - strlen ( tmp ), " % d ", <nl> int mutt_builtin_editor ( const char * path , HEADER * msg , HEADER * cur ) <nl> done = 1 ; <nl> else <nl> { <nl> - strcat ( tmp , "\ n "); <nl> + strncat ( tmp , "\ n ", sizeof ( tmp )); tmp [ sizeof ( tmp ) - 1 ] = '\ 0 '; <nl> if ( buflen == bufmax ) <nl> safe_realloc (( void **)& buf , sizeof ( char *) * ( bufmax += 25 )); <nl> buf [ buflen ++] = safe_strdup ( tmp [ 1 ] == '~' ? tmp + 1 : tmp );
struct option_t MuttVars [] = { <nl> ** This variable controls the number of lines of context that are given <nl> ** when scrolling through menus . ( Similar to ``$$ pager_context ''.) <nl> */ <nl> - { " menu_move_off ", DT_BOOL , R_NONE , OPTMENUMOVEOFF , 0 }, <nl> + { " menu_move_off ", DT_BOOL , R_NONE , OPTMENUMOVEOFF , 1 }, <nl> /* <nl> ** . pp <nl> ** When \ fIunset \ fP , the bottom entry of menus will never scroll up past
static int mbox_open_mailbox_append ( CONTEXT * ctx , int flags ) <nl>  <nl> static int mbox_close_mailbox ( CONTEXT * ctx ) <nl> { <nl> + if (! ctx -> fp ) <nl> + { <nl> + return 0 ; <nl> + } <nl> + <nl> if ( ctx -> append ) <nl> { <nl> mx_unlock_file ( ctx -> path , fileno ( ctx -> fp ), 1 );
int mutt_compose_menu ( HEADER * msg , /* structure for new message */ <nl>  <nl> if (( s = mutt_get_parameter (" charset ", b -> parameter ))) <nl> mutt_set_parameter (" charset ", s , & par ); <nl> + <nl> + /* These are needed for " traditional " PGP . <nl> + * Should we switch to a " negative list " instead ? <nl> + */ <nl> + <nl> + if (( s = mutt_get_parameter (" x - action ", b -> parameter ))) <nl> + mutt_set_parameter (" x - action ", s , & par ); <nl> + if (( s = mutt_get_parameter (" format ", b -> parameter ))) <nl> + mutt_set_parameter (" format ", s , & par ); <nl>  <nl> /* ignore the other parameters for now */ <nl> mutt_free_parameter (& b -> parameter );
void imap_quote_string ( char * dest , size_t dlen , const char * src , bool quote_back <nl> const char * s = src ; <nl>  <nl> * pt ++ = '"'; <nl> - /* save room for trailing quote - char */ <nl> - dlen -= 2 ; <nl> + /* save room for quote - chars */ <nl> + dlen -= 3 ; <nl>  <nl> for (; * s && dlen ; s ++) <nl> {
int _usb_read ( struct cgpu_info * cgpu , int intinfo , int epinfo , char * buf , size_t <nl> /* If we found the end of message marker , just use that data and <nl> * return success . */ <nl> if ( eom ) { <nl> - tot = ( void *) eom - ( void *) usbbuf + endlen ; <nl> - err = LIBUSB_SUCCESS ; <nl> + size_t eomlen = ( void *) eom - ( void *) usbbuf + endlen ; <nl> + <nl> + if ( eomlen < bufsiz ) { <nl> + bufsiz = eomlen ; <nl> + err = LIBUSB_SUCCESS ; <nl> + } <nl> } <nl>  <nl> // N . B . usbdev -> buffer was emptied before the while () loop
static bool klondike_init ( struct cgpu_info * klncgpu ) <nl> sscanf ( opt_klondike_options , "% hu ,% lf ,% lf ,% hhu ", & cfgset . hashclock , & temp1 , & temp2 , & cfgset . fantarget ); <nl> cfgset . temptarget = cvtCToKln ( temp1 ); <nl> cfgset . tempcritical = cvtCToKln ( temp2 ); <nl> - cfgset . fantarget = ( int ) 256 * cfgset . fantarget / 100 ; <nl> + cfgset . fantarget = ( int ) 255 * cfgset . fantarget / 100 ; <nl> size = sizeof ( cfgset ); <nl> } <nl>  <nl> static void get_klondike_statline_before ( char * buf , struct cgpu_info * klncgpu ) <nl> { <nl> struct klondike_info * klninfo = ( struct klondike_info *)( klncgpu -> device_data ); <nl> uint8_t temp = 0xFF ; <nl> + uint16_t fan = 0 ; <nl> int dev ; <nl>  <nl> if ( klninfo -> status == NULL ) <nl> static void get_klondike_statline_before ( char * buf , struct cgpu_info * klncgpu ) <nl> for ( dev = 0 ; dev <= klninfo -> status -> slavecount ; dev ++) { <nl> if ( klninfo -> status [ dev ]. temp < temp ) <nl> temp = klninfo -> status [ dev ]. temp ; <nl> + fan += klninfo -> cfg [ dev ]. fantarget ; <nl> } <nl> + fan /= klninfo -> status -> slavecount + 1 ; <nl> rd_unlock (&( klninfo -> stat_lock )); <nl>  <nl> - tailsprintf ( buf , " % 3 . 0fC 1 . 2V | ", cvtKlnToC ( temp )); <nl> + tailsprintf ( buf , " % 3 . 0fC % 3d % | ", cvtKlnToC ( temp ), fan * 100 / 255 ); <nl> } <nl>  <nl> static struct api_data * klondike_api_stats ( struct cgpu_info * klncgpu ) <nl> static struct api_data * klondike_api_stats ( struct cgpu_info * klncgpu ) <nl> sprintf ( buf , " Clock % d ", dev ); <nl> root = api_add_freq ( root , buf , & dClk , true ); <nl>  <nl> - unsigned int iFan = ( unsigned int ) 100 * klninfo -> cfg [ dev ]. fantarget / 256 ; <nl> + unsigned int iFan = ( unsigned int ) 100 * klninfo -> cfg [ dev ]. fantarget / 255 ; <nl> sprintf ( buf , " Fan Percent % d ", dev ); <nl> root = api_add_int ( root , buf , & iFan , true ); <nl> 
static bool hfa_get_header ( struct cgpu_info * hashfast , struct hf_header * h , uint <nl> char buf [ 512 ]; <nl> char * header ; <nl>  <nl> + if ( unlikely ( hashfast -> usbinfo . nodev )) <nl> + return false ; <nl> + <nl> orig_len = len = sizeof (* h ); <nl>  <nl> /* Read for up to 200ms till we find the first occurrence of HF_PREAMBLE <nl> static bool hfa_get_header ( struct cgpu_info * hashfast , struct hf_header * h , uint <nl> if ( cgtimer_to_ms (& ts_diff ) > 200 ) <nl> return false ; <nl>  <nl> + if ( unlikely ( hashfast -> usbinfo . nodev )) <nl> + return false ; <nl> ret = usb_read ( hashfast , buf + ofs , len , & amount , C_HF_GETHEADER ); <nl> + <nl> if ( unlikely ( ret && ret != LIBUSB_ERROR_TIMEOUT )) <nl> return false ; <nl> ofs += amount ; <nl> static bool hfa_get_packet ( struct cgpu_info * hashfast , struct hf_header * h ) <nl> uint8_t hcrc ; <nl> bool ret ; <nl>  <nl> + if ( unlikely ( hashfast -> usbinfo . nodev )) <nl> + return false ; <nl> + <nl> ret = hfa_get_header ( hashfast , h , & hcrc ); <nl> if ( unlikely (! ret )) <nl> goto out ;
static void mcast () <nl>  <nl> count ++; <nl> came_from_siz = sizeof ( came_from ); <nl> - if ( SOCKETFAIL ( rep = recvfrom ( mcast_sock , buf , sizeof ( buf ), <nl> + if ( SOCKETFAIL ( rep = recvfrom ( mcast_sock , buf , sizeof ( buf ) - 1 , <nl> 0 , ( struct sockaddr *)(& came_from ), & came_from_siz ))) { <nl> applog ( LOG_DEBUG , " API mcast failed count =% d (% s ) (% d )", <nl> count , SOCKERRMSG , ( int ) mcast_sock );
static bool modminer_detect_one ( struct libusb_device * dev , struct usb_find_devic <nl>  <nl> tmp -> device_path = strdup ( devpath ); <nl> tmp -> usbdev = modminer -> usbdev ; <nl> + tmp -> usbinfo . bus_number = modminer -> usbinfo . bus_number ; <nl> + tmp -> usbinfo . device_address = modminer -> usbinfo . device_address ; <nl> // Only the first copy gets the already used stats <nl> if (! added ) <nl> tmp -> usbinfo . usbstat = modminer -> usbinfo . usbstat ;
privsep_preauth_child ( void ) <nl> arc4random_buf ( rnd , sizeof ( rnd )); <nl> # ifdef WITH_OPENSSL <nl> RAND_seed ( rnd , sizeof ( rnd )); <nl> + if (( RAND_bytes (( u_char *) rnd , 1 )) != 1 ) <nl> + fatal ("% s : RAND_bytes failed ", __func__ ); <nl> # endif <nl> explicit_bzero ( rnd , sizeof ( rnd )); <nl>  <nl> privsep_postauth ( Authctxt * authctxt ) <nl> arc4random_buf ( rnd , sizeof ( rnd )); <nl> # ifdef WITH_OPENSSL <nl> RAND_seed ( rnd , sizeof ( rnd )); <nl> + if (( RAND_bytes (( u_char *) rnd , 1 )) != 1 ) <nl> + fatal ("% s : RAND_bytes failed ", __func__ ); <nl> # endif <nl> explicit_bzero ( rnd , sizeof ( rnd )); <nl>  <nl> server_accept_loop ( int * sock_in , int * sock_out , int * newsock , int * config_s ) <nl> arc4random_buf ( rnd , sizeof ( rnd )); <nl> # ifdef WITH_OPENSSL <nl> RAND_seed ( rnd , sizeof ( rnd )); <nl> + if (( RAND_bytes (( u_char *) rnd , 1 )) != 1 ) <nl> + fatal ("% s : RAND_bytes failed ", __func__ ); <nl> # endif <nl> explicit_bzero ( rnd , sizeof ( rnd )); <nl> }
-/* $ OpenBSD : scp . c , v 1 . 209 2020 / 05 / 01 06 : 31 : 42 djm Exp $ */ <nl> +/* $ OpenBSD : scp . c , v 1 . 210 2020 / 05 / 06 20 : 57 : 38 djm Exp $ */ <nl> /* <nl> * scp - secure remote copy . This is basically patched BSD rcp which <nl> * uses ssh to do the data transfer ( instead of using rcmd ). <nl> sink ( int argc , char ** argv , const char * src ) <nl> sink ( 1 , vect , src ); <nl> if ( setimes ) { <nl> setimes = 0 ; <nl> - if ( utimes ( vect [ 0 ], tv ) == - 1 ) <nl> - run_err ("% s : set times : % s ", <nl> - vect [ 0 ], strerror ( errno )); <nl> + ( void ) utimes ( vect [ 0 ], tv ); <nl> } <nl> if ( mod_flag ) <nl> ( void ) chmod ( vect [ 0 ], mode );
static off_t copyfd_sparse ( int src_fd , int dst_fd1 , int dst_fd2 , off_t size2 ) <nl> size2 -= rd ; <nl> if ( size2 < 0 ) <nl> dst_fd2 = - 1 ; <nl> +// TODO : truncate to 0 or even delete the second file <nl> +//( currently we delete the file later ) <nl> } <nl> out : <nl> 
static int open_user_core ( uid_t uid , uid_t fsuid , pid_t pid , char ** percent_valu <nl>  <nl> static bool dump_fd_info ( const char * dest_filename , char * source_filename , int source_base_ofs , uid_t uid , gid_t gid ) <nl> { <nl> - FILE * fp = fopen ( dest_filename , " w "); <nl> + FILE * fp = fopen ( dest_filename , " wx "); <nl> if (! fp ) <nl> return false ; <nl> 
void MultiLineEdit :: keyPressEvent ( QKeyEvent * event ) { <nl> case Qt :: Key_Greater : <nl> moveCursor ( QTextCursor :: End ); <nl> return ; <nl> + <nl> + // modify <nl> + case Qt :: Key_D : <nl> + moveCursor ( QTextCursor :: WordRight , QTextCursor :: KeepAnchor ); <nl> + cut (); <nl> + return ; <nl> } <nl> } <nl> }
void ChatLineModelItem :: computeWrapList () const { <nl> line . setNumColumns ( length ); <nl> layout . endLayout (); <nl>  <nl> - while (( idx = finder . toNextBoundary ()) >= 0 && idx < length ) { <nl> - idx ++; // the boundary is * before * the actual character <nl> + while (( idx = finder . toNextBoundary ()) >= 0 && idx <= length ) { <nl> + if ( idx < length ) <nl> + idx ++; // the boundary is * before * the actual character <nl> + <nl> + if ( idx == oldidx ) <nl> + continue ; <nl>  <nl> word . start = oldidx ; <nl> int wordend = idx ;
-/* $ Id : replay_live . c , v 1 . 4 2003 / 12 / 16 03 : 58 : 37 aturner Exp $ */ <nl> +/* $ Id : replay_live . c , v 1 . 5 2004 / 01 / 15 07 : 29 : 45 aturner Exp $ */ <nl>  <nl> /* <nl> * Copyright ( c ) 2003 Aaron Turner . <nl> # include " config . h " <nl>  <nl> # include < libnet . h > <nl> +# ifdef HAVE_PCAPNAV <nl> # include < pcapnav . h > <nl> +# else <nl> +# include " fakepcapnav . h " <nl> +# endif <nl> # include < sys / time . h > <nl> # include < signal . h > <nl> # include < string . h >
aiff_read_chanmap ( SF_PRIVATE * psf , unsigned dword ) <nl> psf_binheader_readf ( psf , " j ", dword - bytesread ) ; <nl>  <nl> if ( map_info -> channel_map != NULL ) <nl> - { size_t chanmap_size = psf -> sf . channels * sizeof ( psf -> channel_map [ 0 ]) ; <nl> + { size_t chanmap_size = SF_MIN ( psf -> sf . channels , layout_tag & 0xffff ) * sizeof ( psf -> channel_map [ 0 ]) ; <nl>  <nl> free ( psf -> channel_map ) ; <nl> 
/* <nl> -** Copyright ( C ) 2002 - 2013 Erik de Castro Lopo < erikd @ mega - nerd . com > <nl> +** Copyright ( C ) 2002 - 2014 Erik de Castro Lopo < erikd @ mega - nerd . com > <nl> ** Copyright ( C ) 2003 Ross Bencina < rbencina @ iprimus . com . au > <nl> ** <nl> ** This program is free software ; you can redistribute it and / or modify <nl> psf_fwrite ( const void * ptr , sf_count_t bytes , sf_count_t items , SF_PRIVATE * psf <nl> { sf_count_t total = 0 ; <nl> ssize_t count ; <nl>  <nl> + if ( bytes == 0 || items == 0 ) <nl> + return 0 ; <nl> + <nl> if ( psf -> virtual_io ) <nl> return psf -> vio . write ( ptr , bytes * items , psf -> vio_user_data ) / bytes ; <nl> 
mpc2k_write_header ( SF_PRIVATE * psf , int calc_length ) <nl> if ( psf -> is_pipe == SF_FALSE ) <nl> psf_fseek ( psf , 0 , SEEK_SET ) ; <nl>  <nl> - snprintf ( sample_name , sizeof ( sample_name ), "% s ", psf -> filename ) ; <nl> + snprintf ( sample_name , sizeof ( sample_name ), "% s ", psf -> filename ) ; <nl>  <nl> psf_binheader_writef ( psf , " e11b ", 1 , 4 , sample_name , make_size_t ( HEADER_NAME_LEN )) ; <nl> psf_binheader_writef ( psf , " e111 ", 100 , 0 , ( psf -> sf . channels - 1 ) & 1 ) ;
php_http_info_t * php_http_info_parse ( php_http_info_t * info , const char * pre_head <nl> } else { <nl> PHP_HTTP_INFO ( info ). request . url = php_http_url_parse_authority ( url , http - url , ~ 0 TSRMLS_CC ); <nl> } <nl> + if (! PHP_HTTP_INFO ( info ). request . url ) { <nl> + PTR_SET ( PHP_HTTP_INFO ( info ). request . method , NULL ); <nl> + return NULL ; <nl> + } <nl> } else { <nl> PTR_SET ( PHP_HTTP_INFO ( info ). request . method , NULL ); <nl> return NULL ;
enum HTTPVerb { <nl> PUT , <nl> DELETE , <nl> PATCH , <nl> + OPTIONS , <nl> INVALID <nl> }; <nl>  <nl> struct HttpRequest { <nl> } <nl> break ; <nl> } <nl> + case 7 : <nl> + if (! strncmp ( headers -> key , " options ", 7 )) { <nl> + return OPTIONS ; <nl> + } <nl> + break ; <nl> + } <nl> return INVALID ; <nl> } <nl> 
int ImagingLibTiffDecode ( Imaging im , ImagingCodecState state , UINT8 * buffer , int <nl> char * filename = " tempfile . tif "; <nl> char * mode = " r "; <nl> TIFF * tiff ; <nl> - int size ; <nl> + tsize_t size ; <nl>  <nl>  <nl> /* buffer is the encoded file , bytes is the length of the encoded file */
ImagingPcxDecode ( Imaging im , ImagingCodecState state , UINT8 * buf , Py_ssize_t byt <nl> UINT8 n ; <nl> UINT8 * ptr ; <nl>  <nl> - if ( strcmp ( im -> mode , " 1 ") == 0 && state -> xsize > state -> bytes * 8 ) { <nl> - state -> errcode = IMAGING_CODEC_OVERRUN ; <nl> - return - 1 ; <nl> - } else if ( strcmp ( im -> mode , " P ") == 0 && state -> xsize > state -> bytes ) { <nl> + if (( state -> xsize * state -> bits + 7 ) / 8 > state -> bytes ) { <nl> state -> errcode = IMAGING_CODEC_OVERRUN ; <nl> return - 1 ; <nl> }
ImagingUnsharpMask ( Imaging im , Imaging imOut , float radius , int percent , <nl> int channel = 0 ; <nl> int channels = 0 ; <nl> int padding = 0 ; <nl> + int hasAlpha = 0 ; <nl>  <nl> int x = 0 ; <nl> int y = 0 ; <nl> ImagingUnsharpMask ( Imaging im , Imaging imOut , float radius , int percent , <nl>  <nl> ImagingSectionEnter (& cookie ); <nl>  <nl> + if ( strcmp ( im -> mode , " RGBX ") == 0 || strcmp ( im -> mode , " RGBA ") == 0 ) { <nl> + hasAlpha = 1 ; <nl> + } <nl> + <nl> for ( y = 0 ; y < im -> ysize ; y ++) { <nl> if ( channels == 1 ) { <nl> lineIn8 = im -> image8 [ y ]; <nl> ImagingUnsharpMask ( Imaging im , Imaging imOut , float radius , int percent , <nl> ( channel * 8 ); <nl> } <nl> } <nl> - if ( strcmp ( im -> mode , " RGBX ") == 0 <nl> - || strcmp ( im -> mode , " RGBA ") == 0 ) { <nl> + if ( hasAlpha ) { <nl> /* preserve the alpha channel <nl> this may not work for little - endian systems , fix it ! */ <nl> newPixel =
OPJ_BOOL opj_jp2_read_boxhdr_char ( opj_jp2_box_t * box , <nl> opj_event_msg ( p_manager , EVT_ERROR , " Cannot handle box of undefined sizes \ n "); <nl> return OPJ_FALSE ; <nl> } <nl> - <nl> + if ( box -> length < * p_number_bytes_read ) { <nl> + opj_event_msg ( p_manager , EVT_ERROR , " Box length is inconsistent .\ n "); <nl> + return OPJ_FALSE ; <nl> + } <nl> return OPJ_TRUE ; <nl> } <nl> 
OPJ_BOOL opj_j2k_update_image_data ( opj_tcd_t * p_tcd , OPJ_BYTE * p_data , opj_im <nl> if ( ( l_offset_x0_src < 0 ) || ( l_offset_y0_src < 0 ) || ( l_offset_x1_src < 0 ) || ( l_offset_y1_src < 0 ) ){ <nl> return OPJ_FALSE ; <nl> } <nl> + /* testcase 2977 . pdf . asan . 67 . 2198 */ <nl> + if (( OPJ_INT32 ) l_width_dest < 0 || ( OPJ_INT32 ) l_height_dest < 0 ) { <nl> + return OPJ_FALSE ; <nl> + } <nl> /*-----*/ <nl>  <nl> /* Compute the input buffer offset */
void opj_tcd_makelayer ( opj_tcd_t * tcd , <nl> n = passno + 1 ; <nl> continue ; <nl> } <nl> - if ( thresh - ( dd / dr ) <= DBL_EPSILON ) /* do not rely on float equality , check with DBL_EPSILON margin */ <nl> + if ( thresh - ( dd / dr ) < DBL_EPSILON ) /* do not rely on float equality , check with DBL_EPSILON margin */ <nl> n = passno + 1 ; <nl> } <nl> 
int ContentLine_Analyzer :: DoDeliverOnce ( int len , const u_char * data ) <nl> case '\ n ': <nl> if ( last_char == '\ r ' ) <nl> { <nl> + // Weird corner - case : <nl> + // this can happen if we see a \ r at the end of a packet where crlf is <nl> + // set to CR_as_EOL | LF_as_EOL , with the packet causing crlf to be set to <nl> + // 0 and the next packet beginning with a \ n . In this case we just swallow <nl> + // the character and re - set last_char . <nl> + if ( offset == 0 ) <nl> + { <nl> + last_char = c ; <nl> + break ; <nl> + } <nl> -- offset ; // remove '\ r ' <nl> EMIT_LINE <nl> }
get_device_ancestors ( HDEVINFO hDevInfo , DWORD index , PyObject * candidates , BOOL <nl> return NULL ; <nl> } <nl> interfaceDetailData -> cbSize = sizeof ( SP_INTERFACE_DEVICE_DETAIL_DATA ); <nl> + devInfoData . cbSize = sizeof ( SP_DEVINFO_DATA ); <nl>  <nl> status = SetupDiGetDeviceInterfaceDetail ( <nl> hDevInfo , // Interface Device info handle
int h2o_read_command ( const char * cmd , char ** argv , h2o_buffer_t ** resp , int * chi <nl> /* create pipe for reading the result */ <nl> if ( pipe ( respfds ) != 0 ) <nl> goto Exit ; <nl> - fcntl ( respfds [ 0 ], F_SETFD , O_CLOEXEC ); <nl> + if ( fcntl ( respfds [ 0 ], F_SETFD , O_CLOEXEC ) < 0 ) <nl> + goto Exit ; <nl>  <nl> /* spawn */ <nl> int mapped_fds [] = { respfds [ 1 ], 1 , /* stdout of the child process is read from the pipe */
static int fill_headers ( h2o_req_t * req , struct phr_header * headers , size_t num_h <nl> } <nl>  <nl> /* add date : if it ' s missing from the response */ <nl> - if ( h2o_find_header (& req -> res . headers , H2O_TOKEN_DATE , 0 ) < 0 ) <nl> + if ( h2o_find_header (& req -> res . headers , H2O_TOKEN_DATE , 0 ) == - 1 ) <nl> h2o_resp_add_date_header ( req ); <nl>  <nl> return 0 ;
static int on_config_paths ( h2o_configurator_command_t * cmd , h2o_configurator_con <nl> yoml_t * key = node -> data . mapping . elements [ i ]. key ; <nl> yoml_t * value = node -> data . mapping . elements [ i ]. value ; <nl> h2o_buf_t path ; <nl> + size_t num_handlers_before_config ; <nl> + /* assertions */ <nl> if ( key -> type != YOML_TYPE_SCALAR ) { <nl> h2o_config_print_error ( cmd , file , key , " key ( representing the virtual path ) must be a string "); <nl> return - 1 ; <nl> } <nl> + /* setup */ <nl> + num_handlers_before_config = ctx -> hostconf -> handlers . size ; <nl> + /* apply the configuration directives */ <nl> path = h2o_buf_init ( key -> data . scalar , strlen ( key -> data . scalar )); <nl> ctx -> path = & path ; <nl> if ( apply_commands ( ctx , file , value ) != 0 ) <nl> return - 1 ; <nl> ctx -> path = NULL ; <nl> + /* post - condition check */ <nl> + if ( num_handlers_before_config == ctx -> hostconf -> handlers . size ) { <nl> + h2o_config_print_error ( cmd , file , value , " no handler was defined for the path "); <nl> + return - 1 ; <nl> + } <nl> } <nl>  <nl> return 0 ;
unsigned char is_netmask_v4 ( char * ip_strv4 ) { <nl> char * mask_str = NULL ; <nl> int cidr ; <nl>  <nl> + if ( ip_strv4 == NULL ) <nl> + return netmask_v4 ; <nl> + <nl> if (( mask_str = strchr ( ip_strv4 , '/'))) { <nl> *( mask_str ++) = '\ 0 '; <nl>  <nl> unsigned char is_netmask_v6 ( char * ip_strv6 ) { <nl> char * mask_str = NULL ; <nl> int cidr ; <nl>  <nl> + if ( ip_strv6 == NULL ) <nl> + return netmask_v6 ; <nl> + <nl> if (( mask_str = strchr ( ip_strv6 , '/'))) { <nl> *( mask_str ++) = '\ 0 '; <nl> 
struct bug_info * rhbz_bug_info ( struct abrt_xmlrpc * ax , int bug_id ) <nl> if ( strcmp ( bz -> bi_status , " CLOSED ") == 0 && ! bz -> bi_resolution ) <nl> error_msg_and_die ( _ (" Bug % i is CLOSED , but it has no RESOLUTION "), bz -> bi_id ); <nl>  <nl> - ret = ( int *) rhbz_bug_read_item (" dup_id ", bug_item , <nl> + ret = ( int *) rhbz_bug_read_item (" dupe_of ", bug_item , <nl> RHBZ_READ_INT ); <nl> if ( strcmp ( bz -> bi_status , " CLOSED ") == 0 <nl> && strcmp ( bz -> bi_resolution , " DUPLICATE ") == 0
ureport_json_attachment_new ( const char * bthash , const char * type , const char * da <nl> * @ param type Type of attachment <nl> * @ param data Attached data <nl> * @ param config Configuration used in communication <nl> - * @ return False in case of any error ; otherwise True <nl> + * @ return True in case of any error ; otherwise False <nl> */ <nl> # define ureport_attach_string libreport_ureport_attach_string <nl> bool <nl> ureport_attach_string ( const char * bthash , const char * type , const char * data , <nl> * @ param type Type of attachment <nl> * @ param data Attached data <nl> * @ param config Configuration used in communication <nl> - * @ return False in case of any error ; otherwise True <nl> + * @ return True in case of any error ; otherwise False <nl> */ <nl> # define ureport_attach_int libreport_ureport_attach_int <nl> bool
static void find_char ( parse_ctx ctx , char c , int skip_quotes ) <nl> if ( skip_quotes && ( c != '"') && (*( ctx -> pos ) == '"')) { <nl> ctx -> pos ++; <nl> find_char ( ctx , '"', 0 ); <nl> + if ( ctx -> pos >= ctx -> end ) { <nl> + PLIST_XML_ERR (" EOF while looking for matching double quote \ n "); <nl> + return ; <nl> + } <nl> if (*( ctx -> pos ) != '"') { <nl> PLIST_XML_ERR (" Unmatched double quote \ n "); <nl> return ; <nl> static void find_str ( parse_ctx ctx , const char * str , size_t len , int skip_quotes <nl> if ( skip_quotes && (*( ctx -> pos ) == '"')) { <nl> ctx -> pos ++; <nl> find_char ( ctx , '"', 0 ); <nl> + if ( ctx -> pos >= ctx -> end ) { <nl> + PLIST_XML_ERR (" EOF while looking for matching double quote \ n "); <nl> + return ; <nl> + } <nl> if (*( ctx -> pos ) != '"') { <nl> PLIST_XML_ERR (" Unmatched double quote \ n "); <nl> return ;
static plist_t parse_bin_node ( struct bplist_data * bplist , const char ** object ) <nl> return parse_string_node ( object , size ); <nl>  <nl> case BPLIST_UNICODE : <nl> + if ( size * 2 < size ) { <nl> + PLIST_BIN_ERR ("% s : Integer overflow when calculating BPLIST_UNICODE data size .\ n ", __func__ ); <nl> + return NULL ; <nl> + } <nl> if (* object + size * 2 > bplist -> offset_table ) { <nl> PLIST_BIN_ERR ("% s : BPLIST_UNICODE data bytes point outside of valid range \ n ", __func__ ); <nl> return NULL ;
static char * smyrnaDir ; /* path to directory containin smyrna data files */ <nl> char * smyrnaGlade ; <nl> unsigned char SmyrnaVerbose ; <nl>  <nl> +# if 0 <nl> infixtoposfic ( char * infix , char * posfix , int bfsize ) <nl> { <nl> char a = NULL ; <nl> infixtoposfic ( char * infix , char * posfix , int bfsize ) <nl> } <nl> posfix [ ind2 ]='\ 0 '; <nl> } <nl> - <nl> - <nl> - <nl> +# endif <nl>  <nl> /* smyrnaPath : <nl> * Construct pathname for smyrna data file .
static void setup_page ( GVJ_t * job , graph_t * g ) <nl> /* CAUTION - This block was difficult to get right . */ <nl> /* Test with and without assymetric margins , e . g : - Gmargin =" 1 , 0 " */ <nl> if ( job -> rotation ) { <nl> - if ( job -> flags & GVRENDER_Y_GOES_DOWN ) { <nl> + if (( job -> flags & GVRENDER_Y_GOES_DOWN ) || ( Y_invert )) { <nl> /* test with : - Glandscape - Tgif - Tsvg - Tpng */ <nl> job -> translation . x = - job -> pageBox . UR . x - job -> pageBoundingBox . LL . x / job -> scale . x ; <nl> job -> translation . y = - job -> pageBox . UR . y - job -> pageBoundingBox . LL . y / job -> scale . y ; <nl> static void setup_page ( GVJ_t * job , graph_t * g ) <nl> } <nl> else { <nl> job -> translation . x = - job -> pageBox . LL . x + job -> pageBoundingBox . LL . x / job -> scale . x ; <nl> - if ( job -> flags & GVRENDER_Y_GOES_DOWN ) { <nl> + if (( job -> flags & GVRENDER_Y_GOES_DOWN ) || ( Y_invert )) { <nl> /* test with : - Tgif - Tsvg - Tpng */ <nl> job -> translation . y = - job -> pageBox . UR . y - job -> pageBoundingBox . LL . y / job -> scale . y ; <nl> } <nl> static void setup_view ( GVJ_t * job , graph_t * g ) <nl> job -> scale . y = job -> zoom * job -> dpi . y / POINTS_PER_INCH ; <nl>  <nl> job -> devscale . x = job -> dpi . x / POINTS_PER_INCH ; <nl> - job -> devscale . y = job -> dpi . y / POINTS_PER_INCH * (( job -> flags & GVRENDER_Y_GOES_DOWN ) ? - 1 . : 1 .); <nl> + job -> devscale . y = job -> dpi . y / POINTS_PER_INCH ; <nl> + if (( job -> flags & GVRENDER_Y_GOES_DOWN ) || ( Y_invert )) <nl> + job -> devscale . y *= - 1 ; <nl>  <nl> sx = job -> width / ( job -> scale . x * 2 .); <nl> sy = job -> height / ( job -> scale . y * 2 .);
static graph_t * create_test_graph ( void ) <nl> } <nl> } <nl>  <nl> +# ifndef WITH_CGRAPH <nl> sg = agsubg ( g , " cluster1 "); <nl> aginsert ( sg , node [ 0 ]); <nl> +# else /* WITH_CGRAPH */ <nl> + sg = agsubg ( g , " cluster1 ", 1 ); <nl> + agsubnode ( sg , node [ 0 ], 1 ); <nl> +# endif /* WITH_CGRAPH */ <nl>  <nl> return g ; <nl> }
static void round_corners ( GVC_t * gvc , node_t * n , point * A , int sides , <nl> int j = 0 ; <nl> char * fillc = findFill ( n ); <nl> point * pts = N_GNEW ( 2 * sides , point ); <nl> + gvrender_begin_context ( gvc ); <nl> gvrender_set_pencolor ( gvc , fillc ); <nl> gvrender_set_fillcolor ( gvc , fillc ); <nl> for ( seg = 0 ; seg < sides ; seg ++) { <nl> static void round_corners ( GVC_t * gvc , node_t * n , point * A , int sides , <nl> P2PF ( B [ 4 * seg + 2 + i ], BF [ i ]); <nl> gvrender_beziercurve ( gvc , BF , 4 , FALSE , FALSE , TRUE ); <nl> } <nl> + gvrender_end_context ( gvc ); <nl> } <nl> pencolor ( gvc , n ); <nl> for ( seg = 0 ; seg < sides ; seg ++) {
static void cmd_notice ( const char * data , IRC_SERVER_REC * server , <nl> return ; <nl> if ( strcmp ( target , "*") == 0 ) <nl> target = item == NULL ? NULL : window_item_get_target ( item ); <nl> - if (* target == '\ 0 ' || * msg == '\ 0 ') <nl> + if ( target == NULL || * target == '\ 0 ' || * msg == '\ 0 ') <nl> cmd_param_error ( CMDERR_NOT_ENOUGH_PARAMS ); <nl>  <nl> recoded = recode_out ( SERVER ( server ), msg , target ); <nl> static void cmd_ctcp ( const char * data , IRC_SERVER_REC * server , <nl> return ; <nl> if ( strcmp ( target , "*") == 0 ) <nl> target = item == NULL ? NULL : window_item_get_target ( item ); <nl> - if (* target == '\ 0 ' || * ctcpcmd == '\ 0 ') <nl> + if ( target == NULL || * target == '\ 0 ' || * ctcpcmd == '\ 0 ') <nl> cmd_param_error ( CMDERR_NOT_ENOUGH_PARAMS ); <nl>  <nl> ascii_strup ( ctcpcmd ); <nl> static void cmd_nctcp ( const char * data , IRC_SERVER_REC * server , <nl> return ; <nl> if ( strcmp ( target , "*") == 0 ) <nl> target = item == NULL ? NULL : window_item_get_target ( item ); <nl> - if (* target == '\ 0 ' || * ctcpcmd == '\ 0 ') <nl> + if ( target == NULL || * target == '\ 0 ' || * ctcpcmd == '\ 0 ') <nl> cmd_param_error ( CMDERR_NOT_ENOUGH_PARAMS ); <nl>  <nl> ascii_strup ( ctcpcmd );
int expand_escape ( const char ** data ) <nl> * data += 2 ; <nl> return strtol ( digit , NULL , 16 ); <nl> case ' c ': <nl> - /* control character (\ cA = ^ A ) */ <nl> - (* data )++; <nl> + /* check for end of string */ <nl> + if ((* data )[ 1 ] == '\ 0 ') <nl> + return 0 ; <nl> + /* control character (\ cA = ^ A ) */ <nl> + (* data )++; <nl> return i_toupper (** data ) - 64 ; <nl> case ' 0 ': case ' 1 ': case ' 2 ': case ' 3 ': <nl> case ' 4 ': case ' 5 ': case ' 6 ': case ' 7 ':
static void read_settings ( void ) <nl> strstr ( timestamp_format , "% r ") != NULL || <nl> strstr ( timestamp_format , "% s ") != NULL || <nl> strstr ( timestamp_format , "% S ") != NULL || <nl> + strstr ( timestamp_format , "% X ") != NULL || <nl> strstr ( timestamp_format , "% T ") != NULL ; <nl>  <nl> }
static void sig_hilight_text ( WINDOW_REC * window , SERVER_REC * server , const char <nl> if ( window == active_win || ( level & ( MSGLEVEL_NEVER | MSGLEVEL_NO_ACT ))) <nl> return ; <nl>  <nl> - new_data = ( level & MSGLEVEL_HILIGHT ) ? <nl> - NEWDATA_HILIGHT : NEWDATA_TEXT ; <nl> + new_data = ( level & ( MSGLEVEL_HILIGHT | MSGLEVEL_MSGS )) ? <nl> + NEWDATA_HILIGHT : <nl> + (( level & MSGLEVEL_PUBLIC ) ? NEWDATA_MSG : NEWDATA_TEXT ); <nl>  <nl> if ( new_data < NEWDATA_HILIGHT && <nl> channel != NULL && find_substr ( noact_channels , channel ))
asn1_buf_to_c_string ( const mbedtls_asn1_buf * orig , struct gc_arena * gc ) <nl> size_t i ; <nl> char * val ; <nl>  <nl> + if (!( orig -> tag == MBEDTLS_ASN1_UTF8_STRING <nl> + || orig -> tag == MBEDTLS_ASN1_PRINTABLE_STRING <nl> + || orig -> tag == MBEDTLS_ASN1_IA5_STRING )) <nl> + { <nl> + /* Only support C - string compatible types */ <nl> + return string_alloc (" ERROR : unsupported ASN . 1 string type ", gc ); <nl> + } <nl> + <nl> for ( i = 0 ; i < orig -> len ; ++ i ) <nl> { <nl> if ( orig -> p [ i ] == '\ 0 ')
verify_callback ( int preverify_ok , X509_STORE_CTX * ctx ) <nl> if ( opt -> verify_export_cert ) <nl> { <nl> gc = gc_new (); <nl> - if ( tmp_file = get_peer_cert ( ctx , opt -> verify_export_cert ,& gc )) <nl> + if (( tmp_file = get_peer_cert ( ctx , opt -> verify_export_cert ,& gc ))) <nl> { <nl> setenv_str ( opt -> es , " peer_cert ", tmp_file ); <nl> }
get_proxy_authenticate ( socket_descriptor_t sd , <nl> { <nl> if (! recv_line ( sd , buf , sizeof ( buf ), timeout , true , NULL , signal_received )) <nl> { <nl> + free (* data ); <nl> * data = NULL ; <nl> return HTTP_AUTH_NONE ; <nl> } <nl> establish_http_proxy_passthru ( struct http_proxy_info * p , <nl> if ( p -> options . auth_retry == PAR_NCT && method == HTTP_AUTH_BASIC ) <nl> { <nl> msg ( D_PROXY , " HTTP proxy : support for basic auth and other cleartext proxy auth methods is disabled "); <nl> + free ( pa ); <nl> goto error ; <nl> } <nl> p -> auth_method = method ;
# include " file . h " <nl>  <nl> # ifndef lint <nl> - FILE_RCSID ("@(#)$ File : cdf . c , v 1 . 63 2014 / 06 / 09 13 : 04 : 37 christos Exp $") <nl> + FILE_RCSID ("@(#)$ File : cdf . c , v 1 . 64 2014 / 07 / 24 19 : 35 : 39 christos Exp $") <nl> # endif <nl>  <nl> # include < assert . h > <nl> cdf_read_property_info ( const cdf_stream_t * sst , const cdf_header_t * h , <nl> q = ( const uint8_t *)( const void *) <nl> (( const char *)( const void *) p + ofs <nl> - 2 * sizeof ( uint32_t )); <nl> + if ( q < p ) { <nl> + DPRINTF ((" Wrapped around % p < % p \ n ", q , p )); <nl> + goto out ; <nl> + } <nl> if ( q > e ) { <nl> DPRINTF ((" Ran of the end % p > % p \ n ", q , e )); <nl> goto out ;
# include " file . h " <nl>  <nl> # ifndef lint <nl> - FILE_RCSID ("@(#)$ File : funcs . c , v 1 . 80 2015 / 01 / 02 21 : 29 : 39 christos Exp $") <nl> + FILE_RCSID ("@(#)$ File : funcs . c , v 1 . 81 2015 / 05 / 28 19 : 26 : 59 christos Exp $") <nl> # endif /* lint */ <nl>  <nl> # include " magic . h " <nl> file_check_mem ( struct magic_set * ms , unsigned int level ) <nl> size_t len ; <nl>  <nl> if ( level >= ms -> c . len ) { <nl> - len = ( ms -> c . len += 20 ) * sizeof (* ms -> c . li ); <nl> + len = ( ms -> c . len = 20 + level ) * sizeof (* ms -> c . li ); <nl> ms -> c . li = CAST ( struct level_info *, ( ms -> c . li == NULL ) ? <nl> malloc ( len ) : <nl> realloc ( ms -> c . li , len ));
ecma_create_arguments_object ( ecma_object_t * func_obj_p , /**< callee function */ <nl> ecma_string_t * formal_params [ formal_params_number ]; <nl>  <nl> JERRY_ASSERT ( formal_params_iter_p -> current_value_p == NULL ); <nl> - for ( uint32_t param_index = 0 ; <nl> + uint32_t param_index ; <nl> + for ( param_index = 0 ; <nl> ecma_collection_iterator_next ( formal_params_iter_p ); <nl> param_index ++) <nl> { <nl> ecma_create_arguments_object ( ecma_object_t * func_obj_p , /**< callee function */ <nl> JERRY_ASSERT ( ecma_is_value_string (* formal_params_iter_p -> current_value_p )); <nl> formal_params [ param_index ] = ECMA_GET_NON_NULL_POINTER ( formal_params_iter_p -> current_value_p -> value ); <nl> } <nl> + JERRY_ASSERT ( param_index == formal_params_number ); <nl>  <nl> for ( int32_t indx = formal_params_number - 1 ; <nl> indx >= 0 ;
run_int_from_pos ( struct __int_data * int_data ) <nl> { <nl> const OPCODE * curr = & __program [ int_data -> pos ]; <nl> completion = __opfuncs [ curr -> op_idx ](* curr , int_data ); <nl> + <nl> + JERRY_ASSERT ( ! ecma_is_completion_value_normal ( completion ) <nl> + || ecma_is_completion_value_normal_simple_value ( completion , <nl> + ECMA_SIMPLE_VALUE_EMPTY ) ); <nl> } while ( completion . type == ECMA_COMPLETION_TYPE_NORMAL ); <nl>  <nl> if ( completion . type == ECMA_COMPLETION_TYPE_BREAK )
signature_verify ( netdissect_options * ndo , const u_char * pptr , u_int plen , <nl> /* <nl> * Do we have all the packet data to be checked ? <nl> */ <nl> - if (! ND_TTEST2 ( pptr , plen )) { <nl> + if (! ND_TTEST2 (* pptr , plen )) { <nl> /* No . */ <nl> return ( CANT_CHECK_SIGNATURE ); <nl> } <nl> signature_verify ( netdissect_options * ndo , const u_char * pptr , u_int plen , <nl> /* <nl> * Do we have the entire signature to check ? <nl> */ <nl> - if (! ND_TTEST2 ( sig_ptr , sizeof ( sig ))) { <nl> + if (! ND_TTEST2 (* sig_ptr , sizeof ( sig ))) { <nl> /* No . */ <nl> return ( CANT_CHECK_SIGNATURE ); <nl> }
struct ip6_rthdr0 { <nl> uint8_t ip6r0_nxt ; /* next header */ <nl> uint8_t ip6r0_len ; /* length in units of 8 octets */ <nl> uint8_t ip6r0_type ; /* always zero */ <nl> - uint8_t ip6r0_segleft ; /* segments left */ <nl> - uint8_t ip6r0_reserved ; /* reserved field */ <nl> - uint8_t ip6r0_slmap [ 3 ]; /* strict / loose bit map */ <nl> + uint8_t ip6r0_segleft ; /* segments left */ <nl> + uint32_t ip6r0_reserved ; /* reserved field */ <nl> struct in6_addr ip6r0_addr [ 1 ]; /* up to 23 addresses */ <nl> } UNALIGNED ; <nl> 
bgp_attr_print ( netdissect_options * ndo , <nl> bgp_vpn_rd_print ( ndo , tptr ), <nl> isonsap_string ( ndo , tptr + BGP_VPN_RD_LEN , tlen - BGP_VPN_RD_LEN ))); <nl> /* rfc986 mapped IPv4 address ? */ <nl> - if ( EXTRACT_32BITS ( tptr + BGP_VPN_RD_LEN ) == 0x47000601 ) <nl> + if ( tlen == BGP_VPN_RD_LEN + 4 + sizeof ( struct in_addr ) <nl> + && EXTRACT_32BITS ( tptr + BGP_VPN_RD_LEN ) == 0x47000601 ) <nl> ND_PRINT (( ndo , " = % s ", ipaddr_string ( ndo , tptr + BGP_VPN_RD_LEN + 4 ))); <nl> /* rfc1888 mapped IPv6 address ? */ <nl> - else if ( EXTRACT_24BITS ( tptr + BGP_VPN_RD_LEN ) == 0x350000 ) <nl> + else if ( tlen == BGP_VPN_RD_LEN + 3 + sizeof ( struct in6_addr ) <nl> + && EXTRACT_24BITS ( tptr + BGP_VPN_RD_LEN ) == 0x350000 ) <nl> ND_PRINT (( ndo , " = % s ", ip6addr_string ( ndo , tptr + BGP_VPN_RD_LEN + 3 ))); <nl> tptr += tlen ; <nl> tlen = 0 ;
# include " addrtoname . h " <nl> # include " gmpls . h " <nl>  <nl> + static const char tstr [] = " [| LMP ]"; <nl> + <nl> /* <nl> * LMP common header <nl> * <nl> lmp_print_data_link_subobjs ( netdissect_options * ndo , const u_char * obj_tptr , <nl> } bw ; <nl>  <nl> while ( total_subobj_len > 0 && hexdump == FALSE ) { <nl> + ND_TCHECK_16BITS ( obj_tptr + offset ); <nl> subobj_type = EXTRACT_8BITS ( obj_tptr + offset ); <nl> subobj_len = EXTRACT_8BITS ( obj_tptr + offset + 1 ); <nl> ND_PRINT (( ndo , "\ n \ t Subobject , Type : % s (% u ), Length : % u ", <nl> lmp_print_data_link_subobjs ( netdissect_options * ndo , const u_char * obj_tptr , <nl> } <nl> switch ( subobj_type ) { <nl> case INT_SWITCHING_TYPE_SUBOBJ : <nl> + ND_TCHECK_8BITS ( obj_tptr + offset + 2 ); <nl> ND_PRINT (( ndo , "\ n \ t Switching Type : % s (% u )", <nl> tok2str ( gmpls_switch_cap_values , <nl> " Unknown ", <nl> EXTRACT_8BITS ( obj_tptr + offset + 2 )), <nl> EXTRACT_8BITS ( obj_tptr + offset + 2 ))); <nl> + ND_TCHECK_8BITS ( obj_tptr + offset + 3 ); <nl> ND_PRINT (( ndo , "\ n \ t Encoding Type : % s (% u )", <nl> tok2str ( gmpls_encoding_values , <nl> " Unknown ", <nl> lmp_print_data_link_subobjs ( netdissect_options * ndo , const u_char * obj_tptr , <nl> bw . i = EXTRACT_32BITS ( obj_tptr + offset + 4 ); <nl> ND_PRINT (( ndo , "\ n \ t Min Reservable Bandwidth : %. 3f Mbps ", <nl> bw . f * 8 / 1000000 )); <nl> + ND_TCHECK_32BITS ( obj_tptr + offset + 8 ); <nl> bw . i = EXTRACT_32BITS ( obj_tptr + offset + 8 ); <nl> ND_PRINT (( ndo , "\ n \ t Max Reservable Bandwidth : %. 3f Mbps ", <nl> bw . f * 8 / 1000000 )); <nl> break ; <nl> case WAVELENGTH_SUBOBJ : <nl> + ND_TCHECK_32BITS ( obj_tptr + offset + 4 ); <nl> ND_PRINT (( ndo , "\ n \ t Wavelength : % u ", <nl> EXTRACT_32BITS ( obj_tptr + offset + 4 ))); <nl> break ; <nl> lmp_print ( netdissect_options * ndo , <nl> } <nl> return ; <nl> trunc : <nl> - ND_PRINT (( ndo , "\ n \ t \ t packet exceeded snapshot ")); <nl> + ND_PRINT (( ndo , "% s ", tstr )); <nl> } <nl> /* <nl> * Local Variables :
name_len ( netdissect_options * ndo , <nl> return (- 1 ); /* name goes past the end of the buffer */ <nl> ND_TCHECK2 (* s , 1 ); <nl> s += (* s ) + 1 ; <nl> + ND_TCHECK2 (* s , 1 ); <nl> } <nl> return ( PTR_DIFF ( s , s0 ) + 1 ); <nl> 
nfs_printfh ( netdissect_options * ndo , <nl>  <nl> if ( sfsname ) { <nl> /* file system ID is ASCII , not numeric , for this server OS */ <nl> - static char temp [ NFSX_V3FHMAX + 1 ]; <nl> + char temp [ NFSX_V3FHMAX + 1 ]; <nl> + u_int stringlen ; <nl>  <nl> /* Make sure string is null - terminated */ <nl> - strncpy ( temp , sfsname , NFSX_V3FHMAX ); <nl> - temp [ sizeof ( temp ) - 1 ] = '\ 0 '; <nl> + stringlen = len ; <nl> + if ( stringlen > NFSX_V3FHMAX ) <nl> + stringlen = NFSX_V3FHMAX ; <nl> + strncpy ( temp , sfsname , stringlen ); <nl> + temp [ stringlen ] = '\ 0 '; <nl> /* Remove trailing spaces */ <nl> spacep = strchr ( temp , ' '); <nl> if ( spacep )
isis_print_id ( const uint8_t * cp , int id_len ) <nl> int i ; <nl> static char id [ sizeof (" xxxx . xxxx . xxxx . yy - zz ")]; <nl> char * pos = id ; <nl> + int sysid_len ; <nl>  <nl> - for ( i = 1 ; i <= SYSTEM_ID_LEN ; i ++) { <nl> + sysid_len = SYSTEM_ID_LEN ; <nl> + if ( sysid_len > id_len ) <nl> + sysid_len = id_len ; <nl> + for ( i = 1 ; i <= sysid_len ; i ++) { <nl> snprintf ( pos , sizeof ( id ) - ( pos - id ), "% 02x ", * cp ++); <nl> pos += strlen ( pos ); <nl> if ( i == 2 || i == 4 )
arcnet_if_print ( netdissect_options * ndo , const struct pcap_pkthdr * h , const u_ch <nl> u_int seqid = 0 ; <nl> u_char arc_type ; <nl>  <nl> - if ( caplen < ARC_HDRLEN ) { <nl> + if ( caplen < ARC_HDRLEN || length < ARC_HDRLEN ) { <nl> ND_PRINT (( ndo , "[| arcnet ]")); <nl> return ( caplen ); <nl> } <nl> arcnet_if_print ( netdissect_options * ndo , const struct pcap_pkthdr * h , const u_ch <nl> } <nl>  <nl> if ( phds ) { <nl> - if ( caplen < ARC_HDRNEWLEN ) { <nl> + if ( caplen < ARC_HDRNEWLEN || length < ARC_HDRNEWLEN ) { <nl> arcnet_print ( ndo , p , length , 0 , 0 , 0 ); <nl> ND_PRINT (( ndo , "[| phds ]")); <nl> return ( caplen ); <nl> } <nl>  <nl> if ( ap -> arc_flag == 0xff ) { <nl> - if ( caplen < ARC_HDRNEWLEN_EXC ) { <nl> + if ( caplen < ARC_HDRNEWLEN_EXC || length < ARC_HDRNEWLEN_EXC ) { <nl> arcnet_print ( ndo , p , length , 0 , 0 , 0 ); <nl> ND_PRINT (( ndo , "[| phds extended ]")); <nl> return ( caplen ); <nl> arcnet_linux_if_print ( netdissect_options * ndo , const struct pcap_pkthdr * h , cons <nl> int archdrlen = 0 ; <nl> u_char arc_type ; <nl>  <nl> - if ( caplen < ARC_LINUX_HDRLEN ) { <nl> + if ( caplen < ARC_LINUX_HDRLEN || length < ARC_LINUX_HDRLEN ) { <nl> ND_PRINT (( ndo , "[| arcnet ]")); <nl> return ( caplen ); <nl> } <nl> arcnet_linux_if_print ( netdissect_options * ndo , const struct pcap_pkthdr * h , cons <nl> switch ( arc_type ) { <nl> default : <nl> archdrlen = ARC_LINUX_HDRNEWLEN ; <nl> - if ( caplen < ARC_LINUX_HDRNEWLEN ) { <nl> + if ( caplen < ARC_LINUX_HDRNEWLEN || length < ARC_LINUX_HDRNEWLEN ) { <nl> ND_PRINT (( ndo , "[| arcnet ]")); <nl> return ( caplen ); <nl> }
wb_id ( netdissect_options * ndo , <nl> len -= sizeof (* io ) * nid ; <nl> io = ( struct id_off *)( id + 1 ); <nl> cp = ( char *)( io + nid ); <nl> - if (! ND_TTEST2 ( cp , len )) { <nl> + if ( ND_TTEST2 ( cp , len )) { <nl> ND_PRINT (( ndo , "\"")); <nl> fn_print ( ndo , ( u_char *) cp , ( u_char *) cp + len ); <nl> ND_PRINT (( ndo , "\"")); <nl> wb_prep ( netdissect_options * ndo , <nl> } <nl> n = EXTRACT_32BITS (& prep -> pp_n ); <nl> ps = ( const struct pgstate *)( prep + 1 ); <nl> - while (-- n >= 0 && ! ND_TTEST (* ps )) { <nl> + while (-- n >= 0 && ND_TTEST (* ps )) { <nl> const struct id_off * io , * ie ; <nl> char c = '<'; <nl>  <nl> wb_prep ( netdissect_options * ndo , <nl> ipaddr_string ( ndo , & ps -> page . p_sid ), <nl> EXTRACT_32BITS (& ps -> page . p_uid ))); <nl> io = ( struct id_off *)( ps + 1 ); <nl> - for ( ie = io + ps -> nid ; io < ie && ! ND_TTEST (* io ); ++ io ) { <nl> + for ( ie = io + ps -> nid ; io < ie && ND_TTEST (* io ); ++ io ) { <nl> ND_PRINT (( ndo , "% c % s :% u ", c , ipaddr_string ( ndo , & io -> id ), <nl> EXTRACT_32BITS (& io -> off ))); <nl> c = ',';
ieee802_15_4_if_print ( netdissect_options * ndo , <nl> return hdrlen ; <nl> } <nl> if ( ndo -> ndo_vflag ) <nl> - ND_PRINT (( ndo ,"% 04x :% s ", panid , le64addr_string ( ndo , p + 2 ))); <nl> + ND_PRINT (( ndo ,"% 04x :% s ", panid , le64addr_string ( ndo , p ))); <nl> p += 8 ; <nl> caplen -= 8 ; <nl> hdrlen += 8 ;
telnet_parse ( netdissect_options * ndo , const u_char * sp , u_int length , int print ) <nl> break ; <nl> p ++; <nl> } <nl> + ND_TCHECK (* p ); <nl> if (* p != IAC ) <nl> goto pktend ; <nl> 
* +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ <nl> */ <nl>  <nl> - struct tok message_type_values [] = { <nl> + static const struct tok message_type_values [] = { <nl> { 0x00 , " REQUEST " }, <nl> { 0x01 , " REQUEST_NO_RETURN " }, <nl> { 0x02 , " NOTIFICATION " }, <nl> struct tok message_type_values [] = { <nl> { 0 , NULL } <nl> }; <nl>  <nl> - struct tok return_code_values [] = { <nl> + static const struct tok return_code_values [] = { <nl> { 0x00 , " E_OK " }, <nl> { 0x01 , " E_NOT_OK " }, <nl> { 0x02 , " E_UNKNOWN_SERVICE " }, <nl> struct tok return_code_values [] = { <nl> { 0x0d , " E_E2E " }, <nl> { 0x0e , " E_E2E_NOT_AVAILABLE " }, <nl> { 0x0f , " E_E2E_NO_NEW_DATA " }, <nl> + { 0 , NULL } <nl> }; <nl>  <nl> void
bgp_capabilities_print ( netdissect_options * ndo , <nl> ND_TCHECK2 ( opt [ i + 2 ], cap_len ); <nl> switch ( cap_type ) { <nl> case BGP_CAPCODE_MP : <nl> + /* AFI ( 16 bits ), Reserved ( 8 bits ), SAFI ( 8 bits ) */ <nl> + ND_TCHECK_8BITS ( opt + i + 5 ); <nl> ND_PRINT (( ndo , "\ n \ t \ tAFI % s (% u ), SAFI % s (% u )", <nl> tok2str ( af_values , " Unknown ", <nl> EXTRACT_16BITS ( opt + i + 2 )),
ubik_print ( netdissect_options * ndo , <nl> INTOUT (); <nl> ND_PRINT (( ndo , " length ")); <nl> INTOUT (); <nl> + ND_TCHECK_32BITS ( bp ); <nl> temp = EXTRACT_32BITS ( bp ); <nl> bp += sizeof ( int32_t ); <nl> tok2str ( ubik_lock_types , " type % d ", temp );
isis_print_is_reach_subtlv ( netdissect_options * ndo , <nl> break ; <nl> case ISIS_SUBTLV_EXT_IS_REACH_BW_CONSTRAINTS : /* fall through */ <nl> case ISIS_SUBTLV_EXT_IS_REACH_BW_CONSTRAINTS_OLD : <nl> + if ( subl == 0 ) <nl> + break ; <nl> ND_PRINT (( ndo , "% sBandwidth Constraints Model ID : % s (% u )", <nl> ident , <nl> tok2str ( diffserv_te_bc_values , " unknown ", * tptr ), <nl> isis_print_is_reach_subtlv ( netdissect_options * ndo , <nl> tptr ++; <nl> /* decode BCs until the subTLV ends */ <nl> for ( te_class = 0 ; te_class < ( subl - 1 )/ 4 ; te_class ++) { <nl> - ND_TCHECK2 (* tptr , 4 ); <nl> bw . i = EXTRACT_32BITS ( tptr ); <nl> ND_PRINT (( ndo , "% s Bandwidth constraint CT % u : %. 3f Mbps ", <nl> ident ,
rsvp_obj_print ( netdissect_options * ndo , <nl> case RSVP_OBJ_FASTREROUTE : <nl> /* the differences between c - type 1 and 7 are minor */ <nl> obj_ptr . rsvp_obj_frr = ( const struct rsvp_obj_frr_t *) obj_tptr ; <nl> - bw . i = EXTRACT_32BITS ( obj_ptr . rsvp_obj_frr -> bandwidth ); <nl>  <nl> switch ( rsvp_obj_ctype ) { <nl> case RSVP_CTYPE_1 : /* new style */ <nl> if ( obj_tlen < sizeof ( struct rsvp_obj_frr_t )) <nl> return - 1 ; <nl> + bw . i = EXTRACT_32BITS ( obj_ptr . rsvp_obj_frr -> bandwidth ); <nl> ND_PRINT (( ndo , "% s Setup Priority : % u , Holding Priority : % u , Hop - limit : % u , Bandwidth : %. 10g Mbps ", <nl> ident , <nl> ( int ) obj_ptr . rsvp_obj_frr -> setup_prio , <nl> rsvp_obj_print ( netdissect_options * ndo , <nl> case RSVP_CTYPE_TUNNEL_IPV4 : /* old style */ <nl> if ( obj_tlen < 16 ) <nl> return - 1 ; <nl> + bw . i = EXTRACT_32BITS ( obj_ptr . rsvp_obj_frr -> bandwidth ); <nl> ND_PRINT (( ndo , "% s Setup Priority : % u , Holding Priority : % u , Hop - limit : % u , Bandwidth : %. 10g Mbps ", <nl> ident , <nl> ( int ) obj_ptr . rsvp_obj_frr -> setup_prio ,
loop : <nl> client = accept_client ( fd , & addr . in , false ); <nl> } <nl>  <nl> - slog_debug ( client , " P : got connection : % s ", conninfo ( client )); <nl> + if ( client ) <nl> + slog_debug ( client , " P : got connection : % s ", conninfo ( client )); <nl>  <nl> /* <nl> * there may be several clients waiting ,
static void start_auth_request ( PgSocket * client , const char * username ) <nl> int res ; <nl> PktBuf * buf ; <nl>  <nl> - client -> auth_user = client -> db -> auth_user ; <nl> /* have to fetch user info from db */ <nl> client -> pool = get_pool ( client -> db , client -> db -> auth_user ); <nl> if (! find_server ( client )) {
close_uzbl ( WebKitWebView * page , GArray * argv , GString * result ) { <nl> if ( uzbl . gui . main_window ) <nl> gtk_widget_destroy ( uzbl . gui . main_window ); <nl> else if ( uzbl . gui . plug ) <nl> - gtk_widget_destroy ( uzbl . gui . plug ); <nl> + gtk_widget_destroy ( GTK_WIDGET ( uzbl . gui . plug )); <nl>  <nl> gtk_main_quit (); <nl> }
key_press_cb ( GtkWidget * window , GdkEventKey * event ) <nl> if ( event -> type != GDK_KEY_PRESS || <nl> event -> keyval == GDK_Page_Up || <nl> event -> keyval == GDK_Page_Down || <nl> + event -> keyval == GDK_Home || <nl> + event -> keyval == GDK_End || <nl> event -> keyval == GDK_Up || <nl> event -> keyval == GDK_Down || <nl> event -> keyval == GDK_Left ||
static int buffer_grow ( buffer_t buffer , int min_length ) { <nl> return 0 ; <nl> } <nl> while ( size < min_length ) { <nl> + int old_size = size ; <nl> size *= 2 ; <nl> + if ( size <= old_size ) { <nl> + /* size did not increase . Could be an overflow or size < 1 . Just go with min_length */ <nl> + size = min_length ; <nl> + } <nl> } <nl> buffer -> buffer = ( char *) realloc ( buffer -> buffer , sizeof ( char ) * size ); <nl> if ( buffer -> buffer == NULL ) {
public : <nl> y += secVnc . height (); <nl> secPlain . move ( xPad , y ); <nl> y += secPlain . height (); <nl> + <nl> + xPad -= SECOND_COL_XPAD ; <nl> # endif <nl>  <nl> /* Render " OK " and " Cancel " buttons */
void mg_send_digest_auth_request ( struct mg_connection * c ) { <nl> " realm =\"% s \", nonce =\"% lu \"\ r \ n \ r \ n ", <nl> conn -> server -> config_options [ AUTH_DOMAIN ], <nl> ( unsigned long ) time ( NULL )); <nl> + close_local_endpoint ( conn ); <nl> } <nl>  <nl> // Use the global passwords file , if specified by auth_gpass option ,
void TEMPLATE ( cdef_frame )( cdef_strengths * cdef_strengths , const yuv_frame_t * fra <nl> int hpadding = 16 - padding ; <nl> int stride16 = ( bs + 2 * padding + 15 ) & ~ 15 ; <nl> int offset16 = padding * stride16 + padding + hpadding ; <nl> - uint16_t * src16 = thor_alloc (( bs + 2 * padding ) * stride16 * sizeof ( uint16_t ) + hpadding , 32 ); <nl> + uint16_t * src16 = thor_alloc ((( bs + 2 * padding ) * stride16 + hpadding ) * sizeof ( uint16_t ), 32 ); <nl> cdef_init ( stride16 , cdef_directions_copy ); <nl> cdef_init ( sstride , cdef_directions ); <nl> 
inf_gtk_io_io_remove_watch ( InfIo * io , <nl> InfIoWatch * watch ) <nl> { <nl> InfGtkIoPrivate * priv ; <nl> + guint watch_id ; <nl>  <nl> priv = INF_GTK_IO_PRIVATE ( io ); <nl> g_mutex_lock ( priv -> mutex ); <nl>  <nl> g_assert ( g_slist_find ( priv -> watches , watch ) != NULL ); <nl> + <nl> priv -> watches = g_slist_remove ( priv -> watches , watch ); <nl> + watch_id = watch -> id ; <nl>  <nl> if ( watch -> executing ) <nl> { <nl> inf_gtk_io_io_remove_watch ( InfIo * io , <nl> /* Note that we can do this safely without having locked the mutex because <nl> * if the callback function is currently being invoked then its user_data <nl> * will not be destroyed immediately . */ <nl> - g_source_remove ( watch -> id ); <nl> + g_source_remove ( watch_id ); <nl> } <nl>  <nl> static InfIoTimeout *
int socket_create ( uint16_t port ) <nl>  <nl> memset (( void *) & saddr , 0 , sizeof ( saddr )); <nl> saddr . sin_family = AF_INET ; <nl> - saddr . sin_addr . s_addr = htonl ( INADDR_ANY ); <nl> + saddr . sin_addr . s_addr = htonl ( INADDR_LOOPBACK ); <nl> saddr . sin_port = htons ( port ); <nl>  <nl> if ( 0 > bind ( sfd , ( struct sockaddr *) & saddr , sizeof ( saddr ))) { <nl> int socket_accept ( int fd , uint16_t port ) <nl>  <nl> memset (& addr , 0 , sizeof ( addr )); <nl> addr . sin_family = AF_INET ; <nl> - addr . sin_addr . s_addr = htonl ( INADDR_ANY ); <nl> + addr . sin_addr . s_addr = htonl ( INADDR_LOOPBACK ); <nl> addr . sin_port = htons ( port ); <nl>  <nl> addr_len = sizeof ( addr );
int jas_image_addcmpt ( jas_image_t * image , int cmptno , <nl> jas_image_cmptparm_t * cmptparm ) <nl> { <nl> jas_image_cmpt_t * newcmpt ; <nl> - if ( cmptno < 0 ) <nl> + if ( cmptno < 0 ) { <nl> cmptno = image -> numcmpts_ ; <nl> + } <nl> assert ( cmptno >= 0 && cmptno <= image -> numcmpts_ ); <nl> if ( image -> numcmpts_ >= image -> maxcmpts_ ) { <nl> if ( jas_image_growcmpts ( image , image -> maxcmpts_ + 128 )) { <nl> static int jas_image_growcmpts ( jas_image_t * image , int maxcmpts ) <nl> jas_image_cmpt_t ** newcmpts ; <nl> int cmptno ; <nl>  <nl> - newcmpts = (! image -> cmpts_ ) ? jas_alloc2 ( maxcmpts , sizeof ( jas_image_cmpt_t *)) : <nl> + newcmpts = (! image -> cmpts_ ) ? jas_alloc2 ( maxcmpts , <nl> + sizeof ( jas_image_cmpt_t *)) : <nl> jas_realloc2 ( image -> cmpts_ , maxcmpts , sizeof ( jas_image_cmpt_t *)); <nl> if (! newcmpts ) { <nl> return - 1 ; <nl> static int jas_image_growcmpts ( jas_image_t * image , int maxcmpts ) <nl> return 0 ; <nl> } <nl>  <nl> - int jas_image_copycmpt ( jas_image_t * dstimage , int dstcmptno , jas_image_t * srcimage , <nl> - int srccmptno ) <nl> + int jas_image_copycmpt ( jas_image_t * dstimage , int dstcmptno , <nl> + jas_image_t * srcimage , int srccmptno ) <nl> { <nl> jas_image_cmpt_t * newcmpt ; <nl> if ( dstimage -> numcmpts_ >= dstimage -> maxcmpts_ ) {
static int jpc_dec_tileinit ( jpc_dec_t * dec , jpc_dec_tile_t * tile ) <nl> uint_fast32_t tmpxend ; <nl> uint_fast32_t tmpyend ; <nl> jpc_dec_cp_t * cp ; <nl> - jpc_tsfb_band_t bnds [ 64 ]; <nl> + jpc_tsfb_band_t bnds [ JPC_MAXBANDS ]; <nl> jpc_pchg_t * pchg ; <nl> int pchgno ; <nl> jpc_dec_cmpt_t * cmpt ;
static int jpc_siz_getparms ( jpc_ms_t * ms , jpc_cstate_t * cstate , <nl> jas_free ( siz -> comps ); <nl> return - 1 ; <nl> } <nl> + if ( siz -> comps [ i ]. hsamp == 0 || siz -> comps [ i ]. hsamp > 255 ) { <nl> + jas_eprintf (" invalid XRsiz value % d \ n ", siz -> comps [ i ]. hsamp ); <nl> + jas_free ( siz -> comps ); <nl> + return - 1 ; <nl> + } <nl> + if ( siz -> comps [ i ]. vsamp == 0 || siz -> comps [ i ]. vsamp > 255 ) { <nl> + jas_eprintf (" invalid YRsiz value % d \ n ", siz -> comps [ i ]. vsamp ); <nl> + jas_free ( siz -> comps ); <nl> + return - 1 ; <nl> + } <nl> siz -> comps [ i ]. sgnd = ( tmp >> 7 ) & 1 ; <nl> siz -> comps [ i ]. prec = ( tmp & 0x7f ) + 1 ; <nl> }
arr_insert ( PyObject * NPY_UNUSED ( self ), PyObject * args , PyObject * kwdict ) <nl> } else { <nl> Py_XDECREF ( values ); <nl> Py_XDECREF ( mask ); <nl> + Py_XDECREF ( array ); <nl> Py_RETURN_NONE ; <nl> } <nl> }
bool X86_getInstruction ( csh ud , const uint8_t * code , size_t code_len , <nl> insn . prefixPresent [ 0x64 ] = 0 ; <nl> insn . prefixPresent [ 0x65 ] = 0 ; <nl> insn . prefixPresent [ 0x66 ] = 0 ; <nl> + insn . prefixPresent [ 0x67 ] = 0 ; <nl> insn . prefixPresent [ 0xf0 ] = 0 ; <nl> insn . prefixPresent [ 0xf2 ] = 0 ; <nl> insn . prefixPresent [ 0xf3 ] = 0 ;
bool M68K_getInstruction ( csh ud , const uint8_t * code , size_t code_len , MCInst * i <nl> cs_struct * handle = instr -> csh ; <nl> m68k_info * info ; <nl>  <nl> - if ( inst_info == NULL ) { <nl> + if ( handle -> printer_info == NULL ) { <nl> info = cs_mem_malloc ( sizeof ( m68k_info )); <nl> if (! info ) { <nl> handle -> errnum = CS_ERR_MEM ;
static inline uint64_t AArch64_AM_decodeLogicalImmediate ( uint64_t val , unsigned <nl> unsigned N = ( val >> 12 ) & 1 ; <nl> unsigned immr = ( val >> 6 ) & 0x3f ; <nl> unsigned imms = val & 0x3f ; <nl> + unsigned i ; <nl>  <nl> // assert (( regSize == 64 || N == 0 ) && " undefined logical immediate encoding "); <nl> int len = 31 - countLeadingZeros (( N << 6 ) | (~ imms & 0x3f )); <nl> static inline uint64_t AArch64_AM_decodeLogicalImmediate ( uint64_t val , unsigned <nl> unsigned S = imms & ( size - 1 ); <nl> // assert ( S != size - 1 && " undefined logical immediate encoding "); <nl> uint64_t pattern = ( 1ULL << ( S + 1 )) - 1 ; <nl> - for ( unsigned i = 0 ; i < R ; ++ i ) <nl> + for ( i = 0 ; i < R ; ++ i ) <nl> pattern = ror ( pattern , size ); <nl>  <nl> // Replicate the pattern to fill the regSize .
CAMLprim value caml_bytes_set ( value str , value index , value newval ) <nl> */ <nl> CAMLprim value caml_string_set ( value str , value index , value newval ) <nl> { <nl> - return caml_string_set ( str , index , newval ); <nl> + return caml_bytes_set ( str , index , newval ); <nl> } <nl>  <nl> 
static inline void drop_trailing_newlines ( char * s ) <nl> static void dorealloc ( char ** mem , size_t oldlen , size_t newlen ) <nl> { <nl> int batches ; <nl> - if ( newlen % BATCH_SIZE <= oldlen % BATCH_SIZE ) <nl> + if ( newlen <= oldlen ) <nl> return ; <nl> - batches = ( newlen % BATCH_SIZE ) + 1 ; <nl> + batches = ( newlen / BATCH_SIZE ) + 1 ; <nl> if (!* mem ) { <nl> do { <nl> * mem = malloc ( batches * BATCH_SIZE );
void gps_tracker ( void ) <nl> } <nl>  <nl> // New version , JSON <nl> - if ( recv ( gpsd_sock , line + pos , sizeof ( line ) - 1 , 0 ) <= 0 ) <nl> + if ( recv ( gpsd_sock , line + pos , sizeof ( line ) - pos - 1 , 0 ) <= 0 ) <nl> return ; <nl>  <nl> // search for TPV class : {" class ":" TPV "
EXPORT void ac_crypto_engine_calc_mic ( ac_crypto_engine_t * engine , <nl> else if ( keyver == 3 ) <nl> { <nl> size_t miclen = 16 ; <nl> - CMAC_CTX * ctx ; <nl> + CMAC_CTX * ctx = NULL ; <nl>  <nl> // Compute MIC <nl> ctx = CMAC_CTX_new ();
static int http_RecvPostMessage ( <nl> if ( Fp == NULL ) <nl> return HTTP_INTERNAL_SERVER_ERROR ; <nl> } else { <nl> +# ifdef UPNP_ENABLE_POST_WRITE <nl> Fp = fopen ( filename , " wb "); <nl> if ( Fp == NULL ) <nl> return HTTP_UNAUTHORIZED ; <nl> +# else <nl> + return HTTP_NOT_FOUND ; <nl> +# endif <nl> } <nl> parser -> position = POS_ENTITY ; <nl> do {
int CrushWrapper :: get_rule_weight_osd_map ( unsigned ruleno , map < int , float > * pmap ) <nl> crush_rule * rule = crush -> rules [ ruleno ]; <nl>  <nl> // build a weight map for each TAKE in the rule , and then merge them <nl> + <nl> + // FIXME : if there are multiple takes that place a different number of <nl> + // objects we do not take that into account . ( Also , note that doing this <nl> + // right is also a function of the pool , since the crush rule <nl> + // might choose 2 + choose 2 but pool size may only be 3 .) <nl> for ( unsigned i = 0 ; i < rule -> len ; ++ i ) { <nl> map < int , float > m ; <nl> float sum = 0 ;
public : <nl> */ <nl> void init_host_id () { <nl> /* uint64_t needs 16 , two '-' separators and a trailing null */ <nl> - char charbuf [ 16 + zone . name . size () + zonegroup . name . size () + 2 + 1 ]; <nl> - snprintf ( charbuf , sizeof ( charbuf ), "% llx -% s -% s ", ( unsigned long long ) instance_id (), zone . name . c_str (), zonegroup . name . c_str ()); <nl> + const string & zone_name = zone . get_name (); <nl> + const string & zonegroup_name = zonegroup . get_name (); <nl> + char charbuf [ 16 + zone_name . size () + zonegroup_name . size () + 2 + 1 ]; <nl> + snprintf ( charbuf , sizeof ( charbuf ), "% llx -% s -% s ", ( unsigned long long ) instance_id (), zone_name . c_str (), zonegroup_name . c_str ()); <nl> string s ( charbuf ); <nl> host_id = s ; <nl> } <nl> public : <nl> const char * if_match , <nl> const char * if_nomatch , <nl> AttrsMod attrs_mod , <nl> + bool copy_if_newer , <nl> map < string , bufferlist >& attrs , <nl> RGWObjCategory category , <nl> uint64_t olh_epoch , <nl> public : <nl> const char * if_match , <nl> const char * if_nomatch , <nl> AttrsMod attrs_mod , <nl> + bool copy_if_newer , <nl> map < std :: string , bufferlist >& attrs , <nl> RGWObjCategory category , <nl> uint64_t olh_epoch ,
int Client :: _read_sync ( Fh * f , uint64_t off , uint64_t len , bufferlist * bl ) <nl> } <nl> // short read ? <nl> if ( r >= 0 && r < wanted ) { <nl> - if ( pos + ( unsigned ) left <= in -> size ) { <nl> + if ( pos + left <= in -> size ) { <nl> // hole , zero and return . <nl> bufferptr z ( left ); <nl> z . zero ();
unsigned ceph_str_hash_rjenkins ( const char * str , unsigned length ) <nl> unsigned ceph_str_hash_linux ( const char * str , unsigned length ) <nl> { <nl> unsigned long hash = 0 ; <nl> - unsigned char c ; <nl>  <nl> while ( length --) { <nl> - c = * str ++; <nl> + unsigned char c = * str ++; <nl> hash = ( hash + ( c << 4 ) + ( c >> 4 )) * 11 ; <nl> } <nl> return hash ;
void Client :: unmount () <nl> p != inode_map . end (); <nl> p = next ) { <nl> next = p ; <nl> - next ++; <nl> + ++ next ; <nl> Inode * in = p -> second ; <nl> if (! in ) { <nl> ldout ( cct , 0 ) << " null inode_map entry ino " << p -> first << dendl ; <nl> void Client :: _ll_drop_pins () <nl> it = next ) { <nl> Inode * in = it -> second ; <nl> next = it ; <nl> - next ++; <nl> + ++ next ; <nl> if ( in -> ll_ref ) <nl> _ll_put ( in , in -> ll_ref ); <nl> }
void PG :: _compare_scrubmaps ( const map < int , ScrubMap *> & maps , <nl> set < int > cur_missing ; <nl> set < int > cur_inconsistent ; <nl> for ( j = maps . begin (); j != maps . end (); ++ j ) { <nl> + if ( j == auth ) <nl> + continue ; <nl> if ( j -> second -> objects . count (* k )) { <nl> // Compare <nl> stringstream ss ;
int Client :: check_permissions ( Inode * in , int flags , int uid , int gid ) <nl> pw = getpwuid ( uid ); <nl> if ( pw == NULL ) { <nl> ldout ( cct , 3 ) << " getting user entry failed " << dendl ; <nl> + free ( sgids ); <nl> return - EACCES ; <nl> } <nl> while ( 1 ) {
void MDS :: replay_done () <nl> } <nl>  <nl> if ( continue_replay ) { <nl> - mdlog -> get_journaler ()-> set_writeable (); <nl> continue_replay = false ; <nl> standby_replay_restart (); <nl> return ; <nl> } <nl>  <nl> + mdlog -> get_journaler ()-> set_writeable (); <nl> + <nl> if ( g_conf . mds_wipe_sessions ) { <nl> dout ( 1 ) << " wiping out client sessions " << dendl ; <nl> sessionmap . wipe ();
void handle_observe ( MMonObserve * observe ) <nl> lock . Lock (); <nl> registered . insert ( observe -> machine_id ); <nl> lock . Unlock (); <nl> + delete observe ; <nl> } <nl>  <nl> void handle_notify ( MMonObserveNotify * notify ) <nl> void handle_notify ( MMonObserveNotify * notify ) <nl> } <nl>  <nl> map_ver [ notify -> machine_id ] = notify -> ver ; <nl> + <nl> + delete notify ; <nl> } <nl>  <nl> static void send_observe_requests (); <nl> void handle_ack ( MMonCommandAck * ack ) <nl> which ++; <nl> which = which % LAST ; <nl>  <nl> - if ( ack -> version > last_seen_version ) <nl> + if ( ack -> version > last_seen_version ) <nl> last_seen_version = ack -> version ; <nl>  <nl> string w = ack -> cmd [ 0 ]; <nl> void handle_ack ( MMonCommandAck * ack ) <nl> } <nl> lock . Unlock (); <nl> } <nl> + delete ack ; <nl> } <nl>  <nl> void send_command ()
int RGWRados :: init_watch () <nl>  <nl> librados :: Rados * rad = & rados [ 0 ]; <nl> int r = rad -> ioctx_create ( control_pool , control_pool_ctx ); <nl> - <nl> if ( r == - ENOENT ) { <nl> r = rad -> pool_create ( control_pool ); <nl> if ( r == - EEXIST ) <nl> int RGWRados :: init_watch () <nl> r = rad -> ioctx_create ( control_pool , control_pool_ctx ); <nl> if ( r < 0 ) <nl> return r ; <nl> + } else if ( r < 0 ) { <nl> + return r ; <nl> } <nl>  <nl> num_watchers = cct -> _conf -> rgw_num_control_oids ;
int lockdep_will_lock ( const char * name , int id ) <nl> * _dout << "\ npreviously locked at \ n "; <nl> p -> second -> print (* _dout ); <nl> } <nl> + delete bt ; <nl> * _dout << dendl ; <nl> assert ( 0 ); <nl> }
int BlueStore :: _do_truncate ( <nl> << " 0x " << std :: hex << offset << std :: dec << dendl ; <nl> _dump_onode ( o , 30 ); <nl>  <nl> + if ( offset == o -> onode . size ) <nl> + return 0 ; <nl> + <nl> if ( offset < o -> onode . size ) { <nl> // ensure any wal IO has completed before we truncate off any extents <nl> // they may touch .
int ceph_do_lookup ( struct super_block * sb , struct dentry * dentry , int mask ) <nl> struct ceph_mds_request_head * rhead ; <nl> int err ; <nl>  <nl> + if ( dentry -> d_name . len > NAME_MAX ) <nl> + return - ENAMETOOLONG ; <nl> + <nl> dout ( 10 , " do_lookup % p mask % d \ n ", dentry , CEPH_STAT_MASK_INODE_ALL ); <nl> path = ceph_build_dentry_path ( dentry , & pathlen ); <nl> if ( IS_ERR ( path ))
void Locker :: xlock_finish ( SimpleLock * lock , Mutation * mut ) <nl> lock -> get_num_client_lease () == 0 ) { <nl> assert (! lock -> is_stable ()); <nl> lock -> get_parent ()-> auth_unpin ( lock ); <nl> - lock -> set_state ( LOCK_LOCK ); <nl> + if ( lock -> get_type () != CEPH_LOCK_DN && (( CInode *) lock -> get_parent ())-> get_loner () >= 0 ) <nl> + lock -> set_state ( LOCK_EXCL ); <nl> + else <nl> + lock -> set_state ( LOCK_LOCK ); <nl> } <nl>  <nl> // others waiting ?
int MemStore :: _remove ( coll_t cid , const ghobject_t & oid ) <nl> auto i = c -> object_hash . find ( oid ); <nl> if ( i == c -> object_hash . end ()) <nl> return - ENOENT ; <nl> + used_bytes -= i -> second -> get_size (); <nl> c -> object_hash . erase ( i ); <nl> c -> object_map . erase ( oid ); <nl> - used_bytes -= i -> second -> get_size (); <nl>  <nl> return 0 ; <nl> }
int rgw_bucket_init_index ( cls_method_context_t hctx , bufferlist * in , bufferlist <nl>  <nl> if ( header_bl . length () != 0 ) { <nl> CLS_LOG (" ERROR : index already initialized \ n "); <nl> + return - EINVAL ; <nl> } <nl>  <nl> rgw_bucket_dir dir ;
void * Thread :: entry_wrapper () <nl> int p = ceph_gettid (); // may return - ENOSYS on other platforms <nl> if ( p > 0 ) <nl> pid = p ; <nl> - if ( ioprio_class >= 0 && <nl> + if ( pid && <nl> + ioprio_class >= 0 && <nl> ioprio_priority >= 0 ) { <nl> ceph_ioprio_set ( IOPRIO_WHO_PROCESS , <nl> pid ,
public : <nl> } <nl>  <nl> void encode ( bufferlist & bl ) const { <nl> - __u8 struct_v = 4 ; <nl> - :: encode ( struct_v , bl ); <nl> + ENCODE_START ( 5 , 5 , bl ); <nl> :: encode ( stamp , bl ); <nl> :: encode ( metablob , bl ); <nl> :: encode ( subtrees , bl ); <nl> :: encode ( ambiguous_subtrees , bl ); <nl> :: encode ( expire_pos , bl ); <nl> + ENCODE_FINISH ( bl ); <nl> } <nl> void decode ( bufferlist :: iterator & bl ) { <nl> - __u8 struct_v ; <nl> - :: decode ( struct_v , bl ); <nl> + DECODE_START_LEGACY_COMPAT_LEN ( 5 , 5 , 5 , bl ); <nl> if ( struct_v >= 2 ) <nl> :: decode ( stamp , bl ); <nl> :: decode ( metablob , bl ); <nl> public : <nl> :: decode ( ambiguous_subtrees , bl ); <nl> if ( struct_v >= 3 ) <nl> :: decode ( expire_pos , bl ); <nl> + DECODE_FINISH ( bl ); <nl> } <nl>  <nl> void replay ( MDS * mds );
struct object_info_t { <nl> typedef enum { <nl> FLAG_LOST = 1 << 0 , <nl> FLAG_WHITEOUT = 1 << 1 , // object logically does not exist <nl> + FLAG_DIRTY = 1 << 2 , // object has been modified since last flushed or undirtied <nl> // ... <nl> FLAG_USES_TMAP = 1 << 8 , <nl> } flag_t ; <nl> struct object_info_t { <nl> bool is_whiteout () const { <nl> return test_flag ( FLAG_WHITEOUT ); <nl> } <nl> + bool is_dirty () const { <nl> + return test_flag ( FLAG_DIRTY ); <nl> + } <nl>  <nl> void encode ( bufferlist & bl ) const ; <nl> void decode ( bufferlist :: iterator & bl );
extern " C " int rados_conf_parse_argv_remainder ( rados_t cluster , int argc , <nl> conf -> apply_changes ( NULL ); <nl> assert ( args . size () <= ( unsigned int ) argc ); <nl> unsigned int i ; <nl> - for ( i = 0 ; i < argc ; ++ i ) { <nl> + for ( i = 0 ; i < ( unsigned int ) argc ; ++ i ) { <nl> if ( i < args . size ()) <nl> remargv [ i ] = args [ i ]; <nl> else
int BlueStore :: _do_read ( <nl> dout ( 20 ) << __func__ << " " << offset << "~" << length << " size " <nl> << o -> onode . size << dendl ; <nl> bl . clear (); <nl> + _dump_onode ( o ); <nl>  <nl> if ( offset > o -> onode . size ) { <nl> r = 0 ; <nl> int BlueStore :: _do_read ( <nl> offset += x_len ; <nl> continue ; <nl> } <nl> - <nl> unsigned x_len = length ; <nl> if ( op != oend && <nl> op -> first > offset && <nl> int BlueStore :: _do_read ( <nl> } <nl> continue ; <nl> } <nl> + if ( bp != bend && <nl> + bp -> first > offset && <nl> + bp -> first - offset < x_len ) { <nl> + x_len = bp -> first - offset ; <nl> + } <nl>  <nl> // zero . <nl> dout ( 30 ) << __func__ << " zero " << offset << "~" << x_len << dendl ;
const std :: vector < Option > ceph_options = { <nl> . set_default ( true ) <nl> . set_description (""), <nl>  <nl> + Option (" osd_class_update_on_start ", Option :: TYPE_BOOL , Option :: LEVEL_ADVANCED ) <nl> + . set_default ( true ) <nl> + . set_description (""), <nl> + <nl> Option (" osd_crush_initial_weight ", Option :: TYPE_FLOAT , Option :: LEVEL_ADVANCED ) <nl> . set_default (- 1 ) <nl> . set_description (""),
void Client :: dump_status ( Formatter * f ) <nl>  <nl> int Client :: init () <nl> { <nl> - client_lock . Lock (); <nl> - assert (! initialized ); <nl> - <nl> timer . init (); <nl> - <nl> objectcacher -> start (); <nl> - <nl> objecter -> init (); <nl>  <nl> + client_lock . Lock (); <nl> + assert (! initialized ); <nl> + <nl> // ok ! <nl> messenger -> add_dispatcher_tail ( objecter ); <nl> messenger -> add_dispatcher_tail ( this ); <nl> void Client :: shutdown () <nl> assert ( initialized ); <nl> initialized = false ; <nl> timer . shutdown (); <nl> - objecter -> shutdown (); <nl> client_lock . Unlock (); <nl>  <nl> + objecter -> shutdown (); <nl> objecter_finisher . wait_for_empty (); <nl> objecter_finisher . stop (); <nl> 
void RGWAbortMultipart :: execute () <nl> // and also remove the metadata obj <nl> op_ret = del_op . delete_obj (); <nl> if ( op_ret == - ENOENT ) { <nl> - op_ret = - ERR_NO_SUCH_BUCKET ; <nl> + op_ret = - ERR_NO_SUCH_UPLOAD ; <nl> } <nl> } <nl> 
int OSDMonitor :: prepare_new_pool ( string & name , uint64_t auid , <nl> { <nl> if ( name . length () == 0 ) <nl> return - EINVAL ; <nl> + if ( pg_num == 0 ) <nl> + pg_num = g_conf -> osd_pool_default_pg_num ; <nl> + if ( pgp_num == 0 ) <nl> + pgp_num = g_conf -> osd_pool_default_pgp_num ; <nl> + if ( pgp_num > pg_num ) <nl> + return - ERANGE ; <nl> int r ; <nl> r = prepare_pool_crush_ruleset ( pool_type , erasure_code_profile , <nl> crush_ruleset_name , & crush_ruleset , ss ); <nl> int OSDMonitor :: prepare_new_pool ( string & name , uint64_t auid , <nl> pi -> crush_ruleset = crush_ruleset ; <nl> pi -> expected_num_objects = expected_num_objects ; <nl> pi -> object_hash = CEPH_STR_HASH_RJENKINS ; <nl> - pi -> set_pg_num ( pg_num ? pg_num : g_conf -> osd_pool_default_pg_num ); <nl> - pi -> set_pgp_num ( pgp_num ? pgp_num : g_conf -> osd_pool_default_pgp_num ); <nl> + pi -> set_pg_num ( pg_num ); <nl> + pi -> set_pgp_num ( pgp_num ); <nl> pi -> last_change = pending_inc . epoch ; <nl> pi -> auid = auid ; <nl> pi -> erasure_code_profile = erasure_code_profile ;
void MDSMonitor :: tick () <nl> i != pending_mdsmap . mds_info . end (); <nl> ++ i ) { <nl> if ( i -> second . rank >= 0 && pending_mdsmap . is_followable ( i -> second . rank )) { <nl> - if ( info . standby_for_name . length () && <nl> - info . standby_for_name != i -> second . name ) <nl> + if (( info . standby_for_name . length () && info . standby_for_name != i -> second . name ) || <nl> + info . standby_for_rank >= 0 ) <nl> continue ; // we ' re supposed to follow someone else <nl>  <nl> - if ( try_standby_replay ( info , i -> second )) { <nl> + if ( info . standby_for_rank == MDSMap :: MDS_STANDBY_ANY && <nl> + try_standby_replay ( info , i -> second )) { <nl> do_propose = true ; <nl> break ; <nl> }
int ceph_fuse_ll_main ( Client * c , int argc , const char * argv []) <nl> newargv [ newargc ++] = "- o "; <nl> newargv [ newargc ++] = " allow_other "; <nl>  <nl> + newargv [ newargc ++] = "- o "; <nl> + newargv [ newargc ++] = " default_permissions "; <nl> + <nl> // newargv [ newargc ++] = "- d "; <nl>  <nl> for ( int argctr = 1 ; argctr < argc ; argctr ++) newargv [ newargc ++] = argv [ argctr ];
namespace librbd { <nl> ictx -> journal -> commit_io_event ( journal_tid , rval ); <nl> } <nl>  <nl> - // note : possible for image to be closed after op marked finished <nl> done = true ; <nl> - if ( async_op . started ()) { <nl> - async_op . finish_op (); <nl> - } <nl> - <nl> if ( complete_cb ) { <nl> lock . Unlock (); <nl> complete_cb ( rbd_comp , complete_arg ); <nl> namespace librbd { <nl> ictx -> event_socket . notify (); <nl> } <nl> cond . Signal (); <nl> + <nl> + // note : possible for image to be closed after op marked finished <nl> + if ( async_op . started ()) { <nl> + async_op . finish_op (); <nl> + } <nl> tracepoint ( librbd , aio_complete_exit ); <nl> } <nl> 
void ceph_handle_caps ( struct ceph_mds_client * mdsc , <nl> up_write (& mdsc -> snap_rwsem ); <nl> check_caps = 1 ; /* we may have sent a RELEASE to the old auth */ <nl> goto done ; <nl> - <nl> } <nl>  <nl> /* preallocate space for xattrs ? */ <nl> bad : <nl> return ; <nl>  <nl> release : <nl> + up_write (& mdsc -> snap_rwsem ); <nl> send_cap_msg ( mdsc , vino . ino , CEPH_CAP_OP_RELEASE , <nl> 0 , 0 , 0 , <nl> seq , 0 ,
void PGMap :: dump_stuck_plain ( ostream & ss , PGMap :: StuckPG type , utime_t cutoff ) c <nl> { <nl> hash_map < pg_t , pg_stat_t > stuck_pg_stats ; <nl> get_stuck_stats ( type , cutoff , stuck_pg_stats ); <nl> - dump_pg_stats_plain ( ss , stuck_pg_stats ); <nl> + if (! stuck_pg_stats . empty ()) <nl> + dump_pg_stats_plain ( ss , stuck_pg_stats ); <nl> } <nl>  <nl> void PGMap :: dump_osd_perf_stats ( Formatter * f ) const
void BackTrace :: print ( std :: ostream & out ) <nl> function [ sz - 1 ] = 0 ; <nl> } <nl> out << " " << ( i - skip + 1 ) << ": (" << function << end << std :: endl ; <nl> - free ( foo ); <nl> // fprintf ( out , " % s :% s \ n ", stack . strings [ i ], function ); <nl> } else { <nl> // didn ' t find the mangled name , just print the whole line
int ObjectStoreTool :: export_files ( ObjectStore * store , coll_t coll ) <nl> for ( vector < ghobject_t >:: iterator i = objects . begin (); <nl> i != objects . end (); <nl> ++ i ) { <nl> - if ( i -> is_pgmeta ()) { <nl> + assert (! i -> hobj . is_meta ()); <nl> + if ( i -> is_pgmeta () || i -> hobj . is_temp ()) { <nl> continue ; <nl> } <nl> r = export_file ( store , coll , * i ); <nl> int ObjectStoreTool :: get_object ( ObjectStore * store , coll_t coll , <nl> coll . is_pg_prefix (& pg ); <nl> SnapMapper mapper (& driver , 0 , 0 , 0 , pg . shard ); <nl>  <nl> + if ( ob . hoid . hobj . is_temp ()) { <nl> + cerr << " ERROR : Export contains temporary object '" << ob . hoid << "'" << std :: endl ; <nl> + return - EFAULT ; <nl> + } <nl> assert ( g_ceph_context ); <nl> if ( ob . hoid . hobj . nspace != g_ceph_context -> _conf -> osd_hit_set_namespace ) { <nl> object_t oid = ob . hoid . hobj . oid ;
CInode * MDCache :: create_system_inode ( inodeno_t ino , int mode ) <nl> in -> inode . mtime = g_clock . now (); <nl> in -> inode . nlink = 1 ; <nl> in -> inode . truncate_size = - 1ull ; <nl> - if ( in -> inode . is_dir ()) <nl> + <nl> + memset (& in -> inode . dir_layout , 0 , sizeof ( in -> inode . dir_layout )); <nl> + if ( in -> inode . is_dir ()) { <nl> memset (& in -> inode . layout , 0 , sizeof ( in -> inode . layout )); <nl> - else <nl> + in -> inode . dir_layout . dl_dir_hash = g_conf . mds_default_dir_hash ; <nl> + } else { <nl> in -> inode . layout = default_file_layout ; <nl> + } <nl>  <nl> if ( in -> is_base ()) { <nl> if ( in -> is_root ())
int FileStore :: wipe_subvol ( const char * s ) <nl> while (:: readdir_r ( dir , ( struct dirent *) buf , & de ) == 0 ) { <nl> if (! de ) <nl> break ; <nl> - if ( strcmp ( de -> d_name , ".")) <nl> - continue ; <nl> - if ( strcmp ( de -> d_name , "..")) <nl> + if ( strcmp ( de -> d_name , ".") == 0 || <nl> + strcmp ( de -> d_name , "..") == 0 ) <nl> continue ; <nl> ostringstream oss ; <nl> oss << basedir << "/" << de -> d_name ;
class FileLock : public SimpleLock { <nl> } <nl> bool can_rdlock_soon () { <nl> if ( parent -> is_auth ()) <nl> - return ( state == LOCK_GLOCKL ); <nl> + return <nl> + ( state == LOCK_GLOCKL ) || <nl> + ( state == LOCK_LOCK && xlock_by ); <nl> else <nl> return false ; <nl> }
int CrushWrapper :: device_class_clone ( <nl> // pick a new shadow bucket id that is not used by the current map <nl> // * or * any previous shadow buckets . <nl> bno = - 1 ; <nl> - while ( crush -> buckets [- 1 - bno ] || <nl> + while (((- 1 - bno ) < crush -> max_buckets && crush -> buckets [- 1 - bno ]) || <nl> used_ids . count ( bno )) { <nl> -- bno ; <nl> }
void ReplicatedPG :: execute_ctx ( OpContext * ctx ) <nl> log_op_stats ( <nl> ctx ); <nl>  <nl> - publish_stats_to_osd (); <nl> - <nl> if ( m && m -> wants_ondisk () && ! ctx -> sent_disk ) { <nl> // send commit . <nl> MOSDOpReply * reply = ctx -> reply ; <nl> void ReplicatedPG :: eval_repop ( RepGather * repop ) <nl> if ( repop -> all_applied && repop -> all_committed ) { <nl> repop -> rep_done = true ; <nl>  <nl> + publish_stats_to_osd (); <nl> calc_min_last_complete_ondisk (); <nl>  <nl> for ( auto p = repop -> on_success . begin ();
int ceph_setxattr ( struct dentry * dentry , const char * name , <nl> if ( strncmp ( name , " user .", 5 ) != 0 ) <nl> return - EOPNOTSUPP ; <nl>  <nl> + if ( _ceph_match_vir_xattr ( name ) != NULL ) <nl> + return - EOPNOTSUPP ; <nl> + <nl> /* copy value into some pages */ <nl> nr_pages = calc_pages_for ( 0 , size ); <nl> if ( nr_pages ) {
int BlueStore :: _split_collection ( TransContext * txc , <nl> << " bits " << bits << dendl ; <nl> RWLock :: WLocker l ( c -> lock ); <nl> RWLock :: WLocker l2 ( d -> lock ); <nl> + int r ; <nl>  <nl> // blow away src cache <nl> c -> onode_map . clear (); <nl> int BlueStore :: _split_collection ( TransContext * txc , <nl>  <nl> dout ( 10 ) << __func__ << " " << c -> cid << " to " << d -> cid << " " <nl> << " bits " << bits << " = " << r << dendl ; <nl> - return 0 ; <nl> + return r ; <nl> } <nl>  <nl> 
void OSD :: handle_pg_create ( MOSDPGCreate * m ) <nl> query_map [* p ][ pgid ] = PG :: Query ( PG :: Query :: INFO , history ); <nl>  <nl> PG * pg = try_create_pg ( pgid , t ); <nl> - if ( pg ) <nl> + if ( pg ) { <nl> to_peer . push_back ( pg ); <nl> + pg -> unlock (); <nl> + } <nl> } <nl>  <nl> store -> apply_transaction ( t ); <nl>  <nl> for ( vector < PG *>:: iterator p = to_peer . begin (); p != to_peer . end (); p ++) { <nl> PG * pg = * p ; <nl> + pg -> lock (); <nl> wake_pg_waiters ( pg -> info . pgid ); <nl> pg -> peer ( t , query_map , & info_map ); <nl> pg -> update_stats ();
struct ObjectOperation { <nl> string mname = " filter "; <nl> :: encode ( cname , osd_op . indata ); <nl> :: encode ( mname , osd_op . indata ); <nl> - :: encode ( cookie , osd_op . indata ); <nl> osd_op . indata . append ( filter ); <nl> + :: encode ( cookie , osd_op . indata ); <nl> } <nl> void add_alloc_hint ( int op , uint64_t expected_object_size , <nl> uint64_t expected_write_size ) {
int crush_bucket_add_item ( struct crush_bucket * b , int item , int weight ) <nl>  <nl> int crush_remove_uniform_bucket_item ( struct crush_bucket_uniform * bucket , int item ) <nl> { <nl> - int i , j ; <nl> + unsigned i , j ; <nl> int newsize ; <nl>  <nl> for ( i = 0 ; i < bucket -> h . size ; i ++) <nl> int crush_remove_uniform_bucket_item ( struct crush_bucket_uniform * bucket , int it <nl>  <nl> int crush_remove_list_bucket_item ( struct crush_bucket_list * bucket , int item ) <nl> { <nl> - int i , j ; <nl> + unsigned i , j ; <nl> int newsize ; <nl> int weight ; <nl>  <nl> int crush_remove_list_bucket_item ( struct crush_bucket_list * bucket , int item ) <nl>  <nl> int crush_remove_tree_bucket_item ( struct crush_bucket_tree * bucket , int item ) <nl> { <nl> - int i ; <nl> - int newsize ; <nl> + unsigned i ; <nl> + unsigned newsize ; <nl>  <nl> for ( i = 0 ; i < bucket -> h . size ; i ++) { <nl> int node ; <nl> int crush_remove_tree_bucket_item ( struct crush_bucket_tree * bucket , int item ) <nl> int crush_remove_straw_bucket_item ( struct crush_bucket_straw * bucket , int item ) <nl> { <nl> int newsize = bucket -> h . size - 1 ; <nl> - int i , j ; <nl> + unsigned i , j ; <nl>  <nl> for ( i = 0 ; i < bucket -> h . size ; i ++) { <nl> if ( bucket -> h . items [ i ] == item ) {
flushjournal_out : <nl> boost :: scoped_ptr < Throttle > client_byte_throttler ( <nl> new Throttle ( g_ceph_context , " osd_client_bytes ", <nl> g_conf -> osd_client_message_size_cap )); <nl> - boost :: scoped_ptr < Throttle > client_msg_throttler ( <nl> - new Throttle ( g_ceph_context , " osd_client_messages ", <nl> - g_conf -> osd_client_message_cap )); <nl>  <nl> // All feature bits 0 - 34 should be present from dumpling v0 . 67 forward <nl> uint64_t osd_required = <nl> flushjournal_out : <nl> ms_public -> set_default_policy ( Messenger :: Policy :: stateless_server ( 0 )); <nl> ms_public -> set_policy_throttlers ( entity_name_t :: TYPE_CLIENT , <nl> client_byte_throttler . get (), <nl> - client_msg_throttler . get ()); <nl> + nullptr ); <nl> ms_public -> set_policy ( entity_name_t :: TYPE_MON , <nl> Messenger :: Policy :: lossy_client ( CEPH_FEATURE_UID | <nl> CEPH_FEATURE_PGID64 | <nl> flushjournal_out : <nl> delete ms_objecter ; <nl>  <nl> client_byte_throttler . reset (); <nl> - client_msg_throttler . reset (); <nl>  <nl> // cd on exit , so that gmon . out ( if any ) goes into a separate directory for each node . <nl> char s [ 20 ];
void ManagedLock < I >:: handle_shutdown_pre_release ( int r ) { <nl> using managed_lock :: ReleaseRequest ; <nl> ReleaseRequest < I >* req = ReleaseRequest < I >:: create ( m_ioctx , m_watcher , <nl> m_work_queue , m_oid , cookie , <nl> - new FunctionContext ([ this ]( int r ) { <nl> - post_release_lock_handler ( true , r , create_context_callback < <nl> + new FunctionContext ([ this , r ]( int l ) { <nl> + int rst = r < 0 ? r : l ; <nl> + post_release_lock_handler ( true , rst , create_context_callback < <nl> ManagedLock < I >, & ManagedLock < I >:: handle_shutdown_post_release >( this )); <nl> })); <nl> req -> send ();
void OSD :: build_initial_pg_history ( <nl> h -> last_epoch_split = e ; <nl> } <nl> lastmap = osdmap ; <nl> + up_primary = new_up_primary ; <nl> + acting_primary = new_acting_primary ; <nl> + up = new_up ; <nl> + acting = new_acting ; <nl> } <nl> dout ( 20 ) << __func__ << " " << debug . str () << dendl ; <nl> dout ( 10 ) << __func__ << " " << * h << " " << * pi
static int process_request ( RGWRados * store , RGWREST * rest , RGWRequest * req , RGWC <nl> goto done ; <nl> } <nl>  <nl> - if ( op -> supports_website ()) { <nl> + /** <nl> + * Only some accesses support website mode , and website mode does NOT apply <nl> + * if you are using the REST endpoint either ( ergo , no authenticated access ) <nl> + */ <nl> + dout ( 20 ) << " retarget uid =" << s -> user . user_id << dendl ; <nl> + if ( op -> supports_website () && ! rgw_user_is_authenticated ( s -> user )) { <nl> + // if ( op -> supports_website ()) { <nl> req -> log ( s , " recalculating target "); <nl> ret = handler -> retarget ( op , & op ); <nl> if ( ret < 0 ) {
int ReplicatedPG :: do_osd_ops ( OpContext * ctx , vector < OSDOp >& ops ) <nl> case CEPH_OSD_OP_WATCH : <nl> ++ ctx -> num_write ; <nl> { <nl> + if (! obs . exists ) { <nl> + result = - ENOENT ; <nl> + break ; <nl> + } <nl> uint64_t cookie = op . watch . cookie ; <nl> bool do_watch = op . watch . flag & 1 ; <nl> entity_name_t entity = ctx -> reqid . name ;
int SyntheticClient :: run () <nl> int iarg1 = iargs . front (); iargs . pop_front (); <nl> string prefix = get_sarg ( 0 ); <nl>  <nl> + char realtfile [ 100 ]; <nl> + sprintf ( realtfile , tfile . c_str (), client -> get_nodeid ()); <nl> + <nl> if ( run_me ()) { <nl> dout ( 2 ) << " trace " << tfile << " prefix " << prefix << " ... " << iarg1 << " times " << dendl ; <nl>  <nl> - Trace t ( tfile . c_str ()); <nl> + Trace t ( realtfile ); <nl>  <nl> client -> mkdir ( prefix . c_str (), 0755 ); <nl> 
void ceph_handle_snap ( struct ceph_mds_client * mdsc , <nl> continue ; <nl> ci = ceph_inode ( inode ); <nl> spin_lock (& inode -> i_lock ); <nl> + if (! ci -> i_snap_realm ) <nl> + goto split_skip_inode ; <nl> ceph_put_snap_realm ( mdsc , ci -> i_snap_realm ); <nl> list_add (& ci -> i_snap_realm_item , <nl> & realm -> inodes_with_caps ); <nl> ci -> i_snap_realm = realm ; <nl> realm -> nref ++; <nl> + split_skip_inode : <nl> spin_unlock (& inode -> i_lock ); <nl> iput ( inode ); <nl> }
void SaveVCalendar ( TNEFStruct TNEF , int isMtgReq ) { <nl> if ( isMtgReq ) { <nl> CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " MtgReq ", " ics ", filepath ); <nl> } else { <nl> - CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " calendar ", " vcf ", filepath ); <nl> + CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , " calendar ", " ics ", filepath ); <nl> } <nl>  <nl> printf ("% s \ n ", ifilename );
void feh_wm_set_bg ( char * fil , Imlib_Image im , int centered , int scaled , <nl> char bgfil [ 4096 ]; <nl> char sendbuf [ 4096 ]; <nl>  <nl> + /* <nl> + * TODO this re - implements mkstemp ( badly ). However , it is only needed <nl> + * for non - file images and enlightenment . Might be easier to just remove <nl> + * it . <nl> + */ <nl> + <nl> snprintf ( bgname , sizeof ( bgname ), " FEHBG_ % d ", num ); <nl>  <nl> if (! fil && im ) { <nl> + if ( getenv (" HOME ") == NULL ) { <nl> + weprintf (" Cannot save wallpaper to temporary file : You have no HOME "); <nl> + return ; <nl> + } <nl> snprintf ( bgfil , sizeof ( bgfil ), "% s /.% s . png ", getenv (" HOME "), bgname ); <nl> imlib_context_set_image ( im ); <nl> imlib_image_set_format (" png ");
void virtio_delete_queues ( VirtIODevice * vdev ) <nl> struct virtqueue * vq ; <nl> unsigned i ; <nl>  <nl> + if ( vdev -> info == NULL ) <nl> + return ; <nl> + <nl> for ( i = 0 ; i < vdev -> maxQueues ; i ++) { <nl> vq = vdev -> info [ i ]. vq ; <nl> if ( vq != NULL ) {
static int put_hash_callback ( VALUE key , VALUE val , VALUE context ){ <nl> case T_STRING : <nl> bson_byte_buffer_put_bson_key ( b , key , validating_keys ); <nl> break ; <nl> + case T_SYMBOL : <nl> + bson_byte_buffer_put_bson_key ( b , rb_sym_to_s ( key ), validating_keys ); <nl> + break ; <nl> default : <nl> rb_bson_byte_buffer_put_cstring ( buffer , rb_funcall ( key , rb_intern (" to_bson_key "), 1 , validating_keys )); <nl> }
JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setTcpNotSentLowAt ( JNI <nl>  <nl> JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setTrafficClass ( JNIEnv * env , jclass clazz , jint fd , jint optval ) { <nl> netty_unix_socket_setOption ( env , fd , IPPROTO_IP , IP_TOS , & optval , sizeof ( optval )); <nl> + <nl> + /* Try to set the ipv6 equivalent , but don ' t throw if this is an ipv4 only socket . */ <nl> + int rc = setsockopt ( fd , IPPROTO_IPV6 , IPV6_TCLASS , & optval , sizeof ( optval )); <nl> + if ( rc < 0 && errno != ENOPROTOOPT ) { <nl> + netty_unix_errors_throwChannelExceptionErrorNo ( env , " setting ipv6 dscp failed : ", errno ); <nl> + } <nl> } <nl>  <nl> JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setBroadcast ( JNIEnv * env , jclass clazz , jint fd , jint optval ) {
static int jpeg_size ( unsigned char * data , unsigned int data_size , <nl> return 0 ; <nl> } <nl> i += 2 ; <nl> - block_length = data [ i ] * 256 + data [ i + 1 ]; <nl> + if ( i + 1 < data_size ) <nl> + block_length = data [ i ] * 256 + data [ i + 1 ]; <nl> } <nl> } <nl> }
int pdf_add_bookmark ( struct pdf_doc * pdf , struct pdf_object * page , <nl> " Unable to add bookmark , no pages available \ n "); <nl>  <nl> strncpy ( obj -> bookmark . name , name , sizeof ( obj -> bookmark . name )); <nl> - obj -> bookmark . name [ sizeof ( obj -> bookmark . name )] = '\ 0 '; <nl> + obj -> bookmark . name [ sizeof ( obj -> bookmark . name ) - 1 ] = '\ 0 '; <nl> obj -> bookmark . page = page ; <nl>  <nl> return 0 ;
EbmlElement * EbmlElement :: FindNextElement ( IOCallback & DataStream , const EbmlSe <nl> memmove (& PossibleIdNSize [ 0 ],& PossibleIdNSize [ 1 ], -- ReadIndex ); <nl> } <nl>  <nl> + if ( MaxDataSize <= ReadSize ) <nl> + break ; <nl> if ( DataStream . read (& PossibleIdNSize [ ReadIndex ++], 1 ) == 0 ) { <nl> return NULL ; // no more data ? <nl> } <nl> ReadSize ++; <nl>  <nl> - } while (! bFound && MaxDataSize > ReadSize ); <nl> + } while (! bFound ); <nl>  <nl> if (! bFound ) <nl> // we reached the maximum we could read without a proper ID <nl> EbmlElement * EbmlElement :: FindNextElement ( IOCallback & DataStream , const EbmlSe <nl> bFound = false ; <nl> break ; <nl> } <nl> + if ( MaxDataSize <= ReadSize ) { <nl> + bFound = false ; <nl> + break ; <nl> + } <nl> if ( DataStream . read ( & PossibleIdNSize [ SizeIdx ++], 1 ) == 0 ) { <nl> return NULL ; // no more data ? <nl> }
void CMsgURLRequest :: setContent ( char * p_pchContent ) <nl> if ( strcasecmp ( coAttr . c_str (), " string ") != 0 ) <nl> nSize = strtol ( coReader . getAttributeValue (" Size "), NULL , 10 ); <nl>  <nl> - coReader . nextElement ("# text "); <nl> + try { <nl> + pchElement = coReader . nextElement ("# text "); <nl> + } <nl> + catch ( invalid_message_content & rcoEx ) <nl> + { <nl> + setParameter ( coName , string ("")); <nl> + pchElement = coReader . nextElement (); <nl> + continue ; <nl> + } <nl> const char * pchContent = coReader . elementContent (); <nl> if ( strcasecmp ( coAttr . c_str (), " string ") == 0 ) <nl> setParameter ( coName , string ( pchContent ));
static void init_cfg ( int argc , char ** argv ) { <nl> cfg . bridge3 . devsandbox = " eth3 "; <nl>  <nl> // extract user data <nl> + EUID_ROOT (); <nl> struct passwd * pw = getpwuid ( getuid ()); <nl> if (! pw ) <nl> errExit (" getpwuid "); <nl> + EUID_USER (); <nl> cfg . username = strdup ( pw -> pw_name ); <nl> if (! cfg . username ) <nl> errExit (" strdup ");
int main ( int argc , char ** argv ) { <nl> return 1 ; <nl> } <nl>  <nl> - if ( sscanf ( argv [ i ] + 6 , "% d ", & br -> mtu ) != 1 || br -> mtu < 68 || br -> mtu > 9198 ) { <nl> + if ( sscanf ( argv [ i ] + 6 , "% d ", & br -> mtu ) != 1 || br -> mtu < 576 || br -> mtu > 9198 ) { <nl> fprintf ( stderr , " Error : invalid mtu value \ n "); <nl> return 1 ; <nl> }
static char * check_dir_or_file ( const char * name ) { <nl> if ( ptr && strlen ( ptr ) == strlen ("/ firejail ")) { <nl> if ( arg_debug ) <nl> printf (" firejail exec symlink detected \ n "); <nl> + free ( actual_path ); <nl> free ( fname ); <nl> fname = NULL ; <nl> i ++; <nl> continue ; <nl> } <nl> + free ( actual_path ); <nl> } <nl>  <nl> }
static void WritePixels ( struct ngiflib_img * i , struct ngiflib_decode_context * <nl> if ( p -> mode & NGIFLIB_MODE_INDEXED ) { <nl> # endif /* NGIFLIB_INDEXED_ONLY */ <nl> for ( j = ( int ) tocopy ; j > 0 ; j --) { <nl> - if (* pixels != p -> transparent_color ) *( context -> frbuff_p . p8 ++) = * pixels ; <nl> + if (* pixels != p -> transparent_color ) * context -> frbuff_p . p8 = * pixels ; <nl> pixels ++; <nl> + context -> frbuff_p . p8 ++; <nl> } <nl> # ifndef NGIFLIB_INDEXED_ONLY <nl> } else { <nl> for ( j = ( int ) tocopy ; j > 0 ; j --) { <nl> if (* pixels != p -> transparent_color ) { <nl> - *( context -> frbuff_p . p32 ++) = GifIndexToTrueColor ( i -> palette , * pixels ); <nl> + * context -> frbuff_p . p32 = GifIndexToTrueColor ( i -> palette , * pixels ); <nl> } <nl> pixels ++; <nl> + context -> frbuff_p . p32 ++; <nl> } <nl> } <nl> # endif /* NGIFLIB_INDEXED_ONLY */
static int DecodeGifImg ( struct ngiflib_img * i ) { <nl> act_code = GetGifWord ( i , & context ); <nl> casspecial = ( u8 ) act_code ; <nl> old_code = act_code ; <nl> - WritePixel ( i , & context , casspecial ); npix --; <nl> + if ( npix > 0 ) WritePixel ( i , & context , casspecial ); <nl> + npix --; <nl> } else { <nl> read_byt = act_code ; <nl> if ( act_code >= free ) { /* code pas encore dans alphabet */ <nl> static int DecodeGifImg ( struct ngiflib_img * i ) { <nl> /* act_code est concret */ <nl> casspecial = ( u8 ) act_code ; /* dernier debut de chaine ! */ <nl> *(-- stackp ) = casspecial ; /* push on stack */ <nl> - WritePixels ( i , & context , stackp , stack_top - stackp ); /* unstack all pixels at once */ <nl> + if ( npix >= ( stack_top - stackp )) { <nl> + WritePixels ( i , & context , stackp , stack_top - stackp ); /* unstack all pixels at once */ <nl> + } else if ( npix > 0 ) { /* " pixel overflow " */ <nl> + WritePixels ( i , & context , stackp , npix ); <nl> + } <nl> npix -= ( stack_top - stackp ); <nl> stackp = stack_top ; <nl> /* putchar ('\ n '); */
void * poller (){ <nl> cmd_stdout = popen ( entry -> command , " r "); <nl> if ( cmd_stdout != NULL ) fgets ( cmd_result , 64 , cmd_stdout ); <nl> if ( is_number ( cmd_result )) result = atoll ( cmd_result ); <nl> - break ; <nl> + pclose ( cmd_stdout ); <nl> + break ; <nl> default : <nl> printf (" Unknown Action !\ n "); <nl> result = 0 ;
int ares_init_options_with_socket_function ( ares_channel * channelptr , struct ares <nl> channel -> ndomains = - 1 ; <nl> channel -> nsort = - 1 ; <nl> channel -> lookups = NULL ; <nl> + channel -> servers = NULL ; <nl>  <nl> /* Initialize configuration by each of the four sources , from highest <nl> * precedence to lowest .
static int create_zone_index ( const char * directory , timelib_tzdb * db ) <nl> db_index [ index_next ]. pos = data_size ; <nl> data_size += length ; <nl> free ( tzfile_data ); <nl> + <nl> + index_next ++; <nl> + } else { <nl> + free ( db_index [ index_next ]. id ); <nl> } <nl> } <nl> - <nl> - index_next ++; <nl> } <nl> } <nl> 
Perl_re_op_compile ( pTHX_ SV ** const patternp , int pat_count , <nl>  <nl> /* We have that number in RExC_npar */ <nl> RExC_total_parens = RExC_npar ; <nl> + <nl> + /* XXX For backporting , use long jumps if there is any possibility of <nl> + * overflow */ <nl> + if ( RExC_size > U16_MAX && ! RExC_use_BRANCHJ ) { <nl> + RExC_use_BRANCHJ = TRUE ; <nl> + flags |= RESTART_PARSE ; <nl> + } <nl> } <nl> else if (! MUST_RESTART ( flags )) { <nl> ReREFCNT_dec ( Rx );
static Image * ReadTIFFImage ( const ImageInfo * image_info , <nl> /* <nl> Convert stripped TIFF image . <nl> */ <nl> - extent = 4 * MagickMax ( image -> columns *( samples_per_pixel + extra_samples )* <nl> - ( image -> depth + 7 )/ 8 , TIFFStripSize ( tiff )); <nl> + extent = MagickMax ( sizeof ( uint32 ),( samples_per_pixel + extra_samples )* <nl> + ( image -> depth + 7 )/ 8 )* image -> columns * rows_per_strip ; <nl> strip_pixels =( unsigned char *) AcquireQuantumMemory ( extent , <nl> sizeof (* strip_pixels )); <nl> if ( strip_pixels == ( unsigned char *) NULL )
hybiReadAndDecode ( ws_ctx_t * wsctx , char * dst , int len , int * sockRet , int nInBuf ) <nl> int bufsize ; <nl> int nextRead ; <nl> unsigned char * data ; <nl> - uint32_t * data32 ; <nl>  <nl> /* if data was carried over , copy to start of buffer */ <nl> memcpy ( wsctx -> writePos , wsctx -> carryBuf , wsctx -> carrylen ); <nl> hybiReadAndDecode ( ws_ctx_t * wsctx , char * dst , int len , int * sockRet , int nInBuf ) <nl> /* for a possible base64 decoding , we decode multiples of 4 bytes until <nl> * the whole frame is received and carry over any remaining bytes in the carry buf */ <nl> data = ( unsigned char *)( wsctx -> writePos - toDecode ); <nl> - data32 = ( uint32_t *) data ; <nl>  <nl> for ( i = 0 ; i < ( toDecode >> 2 ); i ++) { <nl> - data32 [ i ] ^= wsctx -> header . mask . u ; <nl> + uint32_t tmp ; <nl> + memcpy (& tmp , data + i * sizeof ( tmp ), sizeof ( tmp )); <nl> + tmp ^= wsctx -> header . mask . u ; <nl> + memcpy ( data + i * sizeof ( tmp ), & tmp , sizeof ( tmp )); <nl> } <nl> ws_dbg (" mask decoding ; i =% d toDecode =% d \ n ", i , toDecode ); <nl> 
# include < errno . h > <nl> /* strftime () */ <nl> # include < time . h > <nl> +/* INT_MAX */ <nl> +# include < limits . h > <nl>  <nl> # ifdef LIBVNCSERVER_WITH_WEBSOCKETS <nl> # include " rfbssl . h " <nl> char * rfbProcessFileTransferReadBuffer ( rfbClientPtr cl , uint32_t length ) <nl> 0XFFFFFFFF , i . e . SIZE_MAX for 32 - bit systems . On 64 - bit systems , a length of 0XFFFFFFFF <nl> will safely be allocated since this check will never trigger and malloc () can digest length + 1 <nl> without problems as length is a uint32_t . <nl> + We also later pass length to rfbReadExact () that expects a signed int type and <nl> + that might wrap on platforms with a 32 - bit int type if length is bigger <nl> + than 0X7FFFFFFF . <nl> */ <nl> - if ( length == SIZE_MAX ) { <nl> + if ( length == SIZE_MAX || length > INT_MAX ) { <nl> rfbErr (" rfbProcessFileTransferReadBuffer : too big file transfer length requested : % u ", ( unsigned int ) length ); <nl> rfbCloseClient ( cl ); <nl> return NULL ;
ConnectClientToUnixSock ( const char * sockFile ) <nl> int sock ; <nl> struct sockaddr_un addr ; <nl> addr . sun_family = AF_UNIX ; <nl> + if ( strlen ( sockFile ) + 1 > sizeof ( addr . sun_path )) { <nl> + rfbClientErr (" ConnectToUnixSock : socket file name too long \ n "); <nl> + return - 1 ; <nl> + } <nl> strcpy ( addr . sun_path , sockFile ); <nl>  <nl> sock = socket ( AF_UNIX , SOCK_STREAM , 0 );
InitialiseRFBConnection ( rfbClient * client ) <nl> client -> si . format . blueMax = rfbClientSwap16IfLE ( client -> si . format . blueMax ); <nl> client -> si . nameLength = rfbClientSwap32IfLE ( client -> si . nameLength ); <nl>  <nl> - /* To guard against integer wrap - around , si . nameLength is cast to 64 bit */ <nl> - client -> desktopName = malloc (( uint64_t ) client -> si . nameLength + 1 ); <nl> + if ( client -> si . nameLength > 1 << 20 ) { <nl> + rfbClientErr (" Too big desktop name length sent by server : % u B > 1 MB \ n ", ( unsigned int ) client -> si . nameLength ); <nl> + return FALSE ; <nl> + } <nl> + <nl> + client -> desktopName = malloc ( client -> si . nameLength + 1 ); <nl> if (! client -> desktopName ) { <nl> rfbClientLog (" Error allocating memory for desktop name , % lu bytes \ n ", <nl> ( unsigned long ) client -> si . nameLength );
commonio_sort ( struct commonio_db * db , int (* cmp ) ( const void *, const void *)) <nl> for ( ptr = db -> head ; <nl> ( NULL != ptr ) <nl> # if KEEP_NIS_AT_END <nl> - && ( NULL != ptr -> line ) <nl> - && ( ('+' != ptr -> line [ 0 ]) <nl> - && ('-' != ptr -> line [ 0 ])) <nl> + && (( NULL == ptr -> line ) <nl> + || (('+' != ptr -> line [ 0 ]) <nl> + && ('-' != ptr -> line [ 0 ]))) <nl> # endif <nl> ; <nl> ptr = ptr -> next ) { <nl> n ++; <nl> } <nl> # if KEEP_NIS_AT_END <nl> - if (( NULL != ptr ) && ( NULL != ptr -> line )) { <nl> + if ( NULL != ptr ) { <nl> nis = ptr ; <nl> } <nl> # endif
Strgrow ( Str x ) <nl> { <nl> char * old = x -> ptr ; <nl> int newlen ; <nl> - newlen = x -> length * 6 / 5 ; <nl> - if ( newlen == x -> length ) <nl> + newlen = x -> area_size * 6 / 5 ; <nl> + if ( newlen == x -> area_size ) <nl> newlen += 2 ; <nl> x -> ptr = GC_MALLOC_ATOMIC ( newlen ); <nl> x -> area_size = newlen ;
vips_foreign_load_gif_scan_image ( VipsForeignLoadGif * gif ) <nl> { <nl> VipsObjectClass * class = VIPS_OBJECT_GET_CLASS ( gif ); <nl> GifFileType * file = gif -> file ; <nl> - ColorMapObject * map = file -> Image . ColorMap ? <nl> - file -> Image . ColorMap : file -> SColorMap ; <nl>  <nl> + ColorMapObject * map ; <nl> GifByteType * extension ; <nl>  <nl> if ( DGifGetImageDesc ( gif -> file ) == GIF_ERROR ) { <nl> vips_foreign_load_gif_scan_image ( VipsForeignLoadGif * gif ) <nl>  <nl> /* Test for a non - greyscale colourmap for this frame . <nl> */ <nl> + map = file -> Image . ColorMap ? file -> Image . ColorMap : file -> SColorMap ; <nl> if ( ! gif -> has_colour && <nl> map ) { <nl> int i ;
static void ctrycatchfinally ( JF , js_Ast * trystm , js_Ast * catchvar , js_Ast * catch <nl> emitstring ( J , F , OP_CATCH , catchvar -> string ); <nl> cstm ( J , F , catchstm ); <nl> emit ( J , F , OP_ENDCATCH ); <nl> + emit ( J , F , OP_ENDTRY ); <nl> L3 = emitjump ( J , F , OP_JUMP ); /* skip past the try block to the finally block */ <nl> } <nl> label ( J , F , L1 );
decode_NXAST_RAW_ENCAP ( const struct nx_action_encap * nae , <nl> { <nl> struct ofpact_encap * encap ; <nl> const struct ofp_ed_prop_header * ofp_prop ; <nl> + const size_t encap_ofs = out -> size ; <nl> size_t props_len ; <nl> uint16_t n_props = 0 ; <nl> int err ; <nl> decode_NXAST_RAW_ENCAP ( const struct nx_action_encap * nae , <nl> } <nl> n_props ++; <nl> } <nl> + encap = ofpbuf_at_assert ( out , encap_ofs , sizeof * encap ); <nl> encap -> n_props = n_props ; <nl> out -> header = & encap -> ofpact ; <nl> ofpact_finish_ENCAP ( out , & encap );
int IMA :: decodeBlockWAVE ( const uint8_t * encoded , int16_t * decoded ) <nl> if ( encoded [ 1 ] & 0x80 ) <nl> m_adpcmState [ c ]. previousValue -= 0x10000 ; <nl>  <nl> - m_adpcmState [ c ]. index = encoded [ 2 ]; <nl> + m_adpcmState [ c ]. index = clamp ( encoded [ 2 ], 0 , 88 ); <nl>  <nl> * decoded ++ = m_adpcmState [ c ]. previousValue ; <nl>  <nl> int IMA :: decodeBlockQT ( const uint8_t * encoded , int16_t * decoded ) <nl> predictor -= 0x10000 ; <nl>  <nl> state . previousValue = clamp ( predictor , MIN_INT16 , MAX_INT16 ); <nl> - state . index = encoded [ 1 ] & 0x7f ; <nl> + state . index = clamp ( encoded [ 1 ] & 0x7f , 0 , 88 ); <nl> encoded += 2 ; <nl>  <nl> for ( int n = 0 ; n < m_framesPerPacket ; n += 2 )
main ( int argc , <nl> /* We want sigchild in the child */ <nl> unblock_sigchild (); <nl>  <nl> + if ( setsid () == ( pid_t ) - 1 ) <nl> + die_with_error (" setsid "); <nl> + <nl> if ( label_exec ( opt_exec_label ) == - 1 ) <nl> die_with_error (" label_exec % s ", argv [ 0 ]); <nl> 
const char * szInsecureArgumentOptions [] = { <nl> "$", <nl> "<", <nl> ">", <nl> + "\ n ", <nl> + "\ r ", <nl> NULL <nl> }; <nl> 
namespace http { <nl> return ; <nl> } <nl> std :: vector < std :: vector < std :: string > > result ; <nl> - result = m_sql . safe_queryBlob (" SELECT Image FROM Floorplans WHERE ID =% s ", idx . c_str ()); <nl> + result = m_sql . safe_queryBlob (" SELECT Image FROM Floorplans WHERE ID =% d ", atol ( idx . c_str ())); <nl> if ( result . empty ()) <nl> return ; <nl> reply :: set_content (& rep , result [ 0 ][ 0 ]. begin (), result [ 0 ][ 0 ]. end ());
NS_ASSUME_NONNULL_BEGIN <nl> @ interface OTRXMPPMessageYapStroage : XMPPModule <nl>  <nl> @ property ( nonatomic , strong , readonly ) YapDatabaseConnection * databaseConnection ; <nl> +@ property ( nonatomic , readonly ) dispatch_queue_t moduleDelegateQueue ; <nl>  <nl> /** This connection is only used for readWrites */ <nl> - ( instancetype ) initWithDatabaseConnection :( YapDatabaseConnection *) databaseConnection ;
void sj_expand_mac_address_placeholders ( char * str ) { <nl> for ( sp = str ; sp != NULL && * sp != '\ 0 '; sp ++) { <nl> if (* sp == PLACEHOLDER_CHAR ) num_placeholders ++; <nl> } <nl> - if ( num_placeholders > 0 && num_placeholders <= 12 && <nl> + if ( num_placeholders > 0 && num_placeholders < 12 && <nl> num_placeholders % 2 == 0 /* Allows use of single '?' w / o subst . */) { <nl> const char * msp = mac + 11 ; /* Start from the end */ <nl> for (; sp >= str ; sp --) {
static void schedule_reconnect ( struct clubby * clubby ) { <nl> clubby -> reconnect_timeout = clubby -> cfg . reconnect_timeout_max ; <nl> } <nl> LOG ( LL_DEBUG , (" Reconnect timeout : % d ", clubby -> reconnect_timeout )); <nl> - sj_set_c_timer ( clubby -> reconnect_timeout * 1000 , 0 , reconnect_cb , clubby ); <nl> + if ( clubby -> reconnect_timeout > 0 ) { <nl> + sj_set_c_timer ( clubby -> reconnect_timeout * 1000 , 0 , reconnect_cb , clubby ); <nl> + } <nl> } <nl>  <nl> int sj_clubby_register_callback ( struct clubby * clubby , const char * id ,
static int ndbcluster_reset_logs ( THD * thd ) <nl> if (! ndb_binlog_running ) <nl> return 0 ; <nl>  <nl> + /* only reset master should reset logs */ <nl> + if (!( thd -> lex -> type & REFRESH_MASTER )) <nl> + return 0 ; <nl> + <nl> DBUG_ENTER (" ndbcluster_reset_logs "); <nl>  <nl> /*
void Dbtc :: execSCAN_TABREQ ( Signal * signal ) <nl> if (( transid1 == buddyApiPtr . p -> transid [ 0 ]) && <nl> ( transid2 == buddyApiPtr . p -> transid [ 1 ])) { <nl> jam (); <nl> + <nl> + if ( buddyApiPtr . p -> apiConnectstate == CS_ABORTING ) { <nl> + // transaction has timed out <nl> + jam (); <nl> + errCode = ZTIME_OUT_ERROR ; <nl> + goto SCAN_TAB_error ; <nl> + }// if <nl> currSavePointId = buddyApiPtr . p -> currSavePointId ; <nl> buddyApiPtr . p -> currSavePointId ++; <nl> }
innodb_initialize ( <nl>  <nl> my_eng_config = ( eng_config_info_t *) config_str ; <nl>  <nl> + /* If no call back function registered ( InnoDB engine failed to load ), <nl> + load InnoDB Memcached engine should fail too */ <nl> + if (! my_eng_config -> cb_ptr ) { <nl> + return ( ENGINE_TMPFAIL ); <nl> + } <nl> + <nl> /* Register the call back function */ <nl> register_innodb_cb (( void *) my_eng_config -> cb_ptr ); <nl> 
ha_innobase :: check ( <nl> ( ulong ) n_rows , <nl> ( ulong ) n_rows_in_table ); <nl> is_ok = FALSE ; <nl> + row_mysql_lock_data_dictionary ( prebuilt -> trx ); <nl> + dict_set_corrupted ( index ); <nl> + row_mysql_unlock_data_dictionary ( prebuilt -> trx ); <nl> } <nl> } <nl> 
Relay_log_info ::~ Relay_log_info () <nl> mysql_mutex_destroy (& pending_jobs_lock ); <nl> mysql_cond_destroy (& pending_jobs_cond ); <nl>  <nl> + if ( workers_copy_pfs . size ()) <nl> + { <nl> + for ( int i = workers_copy_pfs . size () - 1 ; i >= 0 ; i --) <nl> + delete workers_copy_pfs [ i ]; <nl> + workers_copy_pfs . clear (); <nl> + } <nl> + <nl> if (! rli_fake ) <nl> { <nl> my_atomic_rwlock_destroy (& slave_open_temp_tables_lock );
MgmApiSession :: setLogLevel ( Parser < MgmApiSession >:: Context &, <nl>  <nl> if ( level > NDB_MGM_MAX_LOGLEVEL ) { <nl> m_output -> println (" set loglevel reply "); <nl> - m_output -> println (" result : Invalid loglevel ", errorString . c_str ()); <nl> + m_output -> println (" result : Invalid loglevel : % s ", errorString . c_str ()); <nl> m_output -> println (""); <nl> return ; <nl> }
void st_select_lex_unit :: exclude_level () <nl> if ( s -> context . outer_context == & sl -> context ) <nl> s -> context . outer_context = sl -> context . outer_context ; <nl> } <nl> + if ( u -> fake_select_lex && <nl> + u -> fake_select_lex -> context . outer_context == & sl -> context ) <nl> + u -> fake_select_lex -> context . outer_context = sl -> context . outer_context ; <nl> u -> master = master ; <nl> last = &( u -> next ); <nl> }
rollback_inplace_alter_table ( <nl> if ( prebuilt -> table != ctx -> indexed_table ) { <nl> dberr_t err ; <nl> ulint flags = ctx -> indexed_table -> flags ; <nl> + <nl> + /* DML threads can access ctx -> indexed_table via the <nl> + online rebuild log . Free it first . */ <nl> + innobase_online_rebuild_log_free ( prebuilt -> table ); <nl> /* Drop the table . */ <nl> dict_table_close ( ctx -> indexed_table , TRUE , FALSE ); <nl> err = row_merge_drop_table ( ctx -> trx , ctx -> indexed_table ); <nl> rollback_inplace_alter_table ( <nl> flags ); <nl> fail = true ; <nl> } <nl> - <nl> - innobase_online_rebuild_log_free ( prebuilt -> table ); <nl> } else { <nl> DBUG_ASSERT (!( ha_alter_info -> handler_flags <nl> & Alter_inplace_info :: ADD_PK_INDEX ));
void Qmgr :: handleApiCloseComConf ( Signal * signal ) <nl> CloseComReqConf * const closeCom = ( CloseComReqConf *)& signal -> theData [ 0 ]; <nl>  <nl> /* Api failure special case */ <nl> - for ( Uint32 nodeId = 0 ; nodeId < MAX_NDB_NODES ; nodeId ++) <nl> + for ( Uint32 nodeId = 0 ; nodeId < MAX_NODES ; nodeId ++) <nl> { <nl> - if ( NdbNodeBitmask :: get ( closeCom -> theNodes , nodeId )) <nl> + if ( NodeBitmask :: get ( closeCom -> theNodes , nodeId )) <nl> { <nl> jam (); <nl> /* Check that * only * 1 * API * node is included in <nl> void Qmgr :: handleApiCloseComConf ( Signal * signal ) <nl> */ <nl> ndbrequire ( getNodeInfo ( nodeId ). getType () != NodeInfo :: DB ); <nl> ndbrequire ( closeCom -> noOfNodes == 1 ); <nl> - NdbNodeBitmask :: clear ( closeCom -> theNodes , nodeId ); <nl> - ndbrequire ( NdbNodeBitmask :: isclear ( closeCom -> theNodes )); <nl> + NodeBitmask :: clear ( closeCom -> theNodes , nodeId ); <nl> + ndbrequire ( NodeBitmask :: isclear ( closeCom -> theNodes )); <nl>  <nl> /* Now that we know communication from the failed Api has <nl> * ceased , we can send the required API_FAILREQ signals
row_merge_insert_index_tuples ( <nl> mtr_t mtr ; <nl>  <nl> # ifdef HAVE_PSI_STAGE_INTERFACE <nl> - if ( i % inc_every_nth_rec == 0 ) { <nl> + if ( progress != NULL && i % inc_every_nth_rec == 0 ) { <nl> ut_stage_inc ( progress ); <nl> } <nl> # endif /* HAVE_PSI_STAGE_INTERFACE */
bool make_date_time ( DATE_TIME_FORMAT * format , TIME * l_time , <nl> const char * ptr , * end ; <nl> MY_LOCALE * locale ; <nl> THD * thd = current_thd ; <nl> - char buf [ 128 ]; <nl> - String tmp ( buf , thd -> variables . character_set_results ); <nl> + char buf [ STRING_BUFFER_USUAL_SIZE ]; <nl> + String tmp ( buf , sizeof ( buf ), thd -> variables . character_set_results ); <nl> uint errors = 0 ; <nl>  <nl> + tmp . length ( 0 ); <nl> str -> length ( 0 ); <nl> str -> set_charset (& my_charset_bin ); <nl> locale = thd -> variables . lc_time_names ;
CLI_MYSQL_REAL_CONNECT ( MYSQL * mysql , const char * host , const char * user , <nl> goto error ; <nl>  <nl> if ( scramble_buffer_allocated == TRUE ) <nl> + { <nl> + scramble_buffer_allocated = FALSE ; <nl> my_free ( scramble_buffer ); <nl> + } <nl>  <nl> MYSQL_TRACE_STAGE ( mysql , READY_FOR_COMMAND ); <nl>  <nl> error : <nl> mysql_close_free ( mysql ); <nl> if (!( client_flag & CLIENT_REMEMBER_OPTIONS )) <nl> mysql_close_free_options ( mysql ); <nl> + if ( scramble_buffer_allocated ) <nl> + my_free ( scramble_buffer ); <nl> } <nl> DBUG_RETURN ( 0 ); <nl> }
ha_innobase :: general_fetch ( <nl>  <nl> DBUG_ENTER (" general_fetch "); <nl>  <nl> - ut_a ( prebuilt -> trx == thd_to_trx ( user_thd )); <nl> + ut_ad ( prebuilt -> trx == thd_to_trx ( user_thd )); <nl>  <nl> innobase_srv_conc_enter_innodb ( prebuilt -> trx ); <nl> 
fts_query_parse ( <nl> } else { <nl> query -> root = state . root ; <nl>  <nl> - if ( fts_enable_diag_print ) { <nl> + if ( fts_enable_diag_print && query -> root != NULL ) { <nl> fts_ast_node_print ( query -> root ); <nl> } <nl> }
Connection :: Connection ( ProtocolVersion v , RandomPool & ran ) <nl> : pre_master_secret_ ( 0 ), sequence_number_ ( 0 ), peer_sequence_number_ ( 0 ), <nl> pre_secret_len_ ( 0 ), send_server_key_ ( false ), master_clean_ ( false ), <nl> TLS_ ( v . major_ >= 3 && v . minor_ >= 1 ), version_ ( v ), random_ ( ran ) <nl> -{} <nl> +{ <nl> + memset ( sessionID_ , 0 , sizeof ( sessionID_ )); <nl> +} <nl>  <nl>  <nl> Connection ::~ Connection ()
Lgman :: execCONTINUEB ( Signal * signal ){ <nl> jam (); <nl> Ptr < Logfile_group > ptr ; <nl> m_logfile_group_pool . getPtr ( ptr , ptrI ); <nl> - if ( ptr . p -> m_state & Logfile_group :: LG_THREAD_MASK ) <nl> + if (( ptr . p -> m_state & Logfile_group :: LG_THREAD_MASK ) || <nl> + ptr . p -> m_outstanding_fs > 0 ) <nl> { <nl> jam (); <nl> sendSignalWithDelay ( reference (), GSN_CONTINUEB , signal , 100 ,
ndb_get_table_statistics ( ha_ndbcluster * file , bool report_error , Ndb * ndb , <nl> retry : <nl> if ( report_error ) <nl> { <nl> - if ( file ) <nl> + if ( file && pTrans ) <nl> { <nl> reterr = file -> ndb_err ( pTrans ); <nl> }
srv_purge_coordinator_thread ( <nl> ulint batch_size = srv_purge_batch_size ; <nl> ulint sleep_ms = ut_rnd_gen_ulint () % 10000 ; <nl>  <nl> - if ( srv_shutdown_state != 0 && srv_fast_shutdown ) { <nl> + if ( srv_shutdown_state != 0 && srv_fast_shutdown != 0 ) { <nl> break ; <nl> } <nl>  <nl> srv_purge_coordinator_thread ( <nl> os_thread_sleep ( sleep_ms ); <nl> } <nl>  <nl> - } while ( n_pages_purged > 0 && ! srv_fast_shutdown ); <nl> + } while ( n_pages_purged > 0 && srv_fast_shutdown == 0 ); <nl>  <nl> ++ iterations ; <nl>  <nl> srv_purge_coordinator_thread ( <nl> Force the coordinator thread to do the purge <nl> tasks from the work queue . */ <nl> while ( srv_get_task_queue_length () > 0 <nl> - && ! srv_fast_shutdown ) { <nl> + && srv_fast_shutdown == 0 ) { <nl> ut_a ( srv_shutdown_state ); <nl> srv_task_execute (); <nl> } <nl> srv_purge_coordinator_thread ( <nl>  <nl> } while ( trx_sys -> rseg_history_len > 100 <nl> && ( srv_shutdown_state == 0 <nl> - || ! srv_fast_shutdown )); <nl> + || ( srv_shutdown_state > 0 <nl> + && srv_fast_shutdown == 0 ))); <nl> } <nl> } <nl> 
static int ProcessServerHello ( const byte * input , int * sslBytes , <nl> XMEMCPY ( session -> sslServer -> arrays . sessionID , input , ID_LEN ); <nl> input += b ; <nl> * sslBytes -= b ; <nl> + if ( b ) <nl> + session -> sslServer -> options . haveSessionId = 1 ; <nl>  <nl> ( void )* input ++; /* eat first byte , always 0 */ <nl> b = * input ++; <nl> static int ProcessServerHello ( const byte * input , int * sslBytes , <nl> session -> sslClient -> options . cipherSuite = b ; <nl> * sslBytes -= SUITE_LEN ; <nl>  <nl> - if ( XMEMCMP ( session -> sslServer -> arrays . sessionID , <nl> - session -> sslClient -> arrays . sessionID , ID_LEN ) == 0 ) { <nl> + if ( session -> sslServer -> options . haveSessionId && <nl> + XMEMCMP ( session -> sslServer -> arrays . sessionID , <nl> + session -> sslClient -> arrays . sessionID , ID_LEN ) == 0 ) { <nl> /* resuming */ <nl> SSL_SESSION * resume = GetSession ( session -> sslServer , <nl> session -> sslServer -> arrays . masterSecret ); <nl> static int DoHandShake ( const byte * input , int * sslBytes , <nl> ret = DoFinished ( ssl , input , & inOutIdx , SNIFF ); <nl>  <nl> if ( ret == 0 && session -> flags . cached == 0 ) { <nl> + session -> sslServer -> options . haveSessionId = 1 ; <nl> AddSession ( session -> sslServer ); <nl> session -> flags . cached = 1 ; <nl> }
int TLSX_ValidateEllipticCurves ( CYASSL * ssl , byte first , byte second ) { <nl> int sig = 0 ; /* valitade signature */ <nl> int key = 0 ; /* validate key */ <nl>  <nl> + ( void ) oid ; <nl> + ( void ) octets ; <nl> + <nl> if (! extension ) <nl> return 1 ; /* no suite restriction */ <nl> 
int SendCertificateRequest ( WOLFSSL * ssl ) <nl> /* write to output */ <nl> output [ i ++] = ( byte ) typeTotal ; /* # of types */ <nl> # ifdef HAVE_ECC <nl> - if ( ssl -> options . cipherSuite0 == ECC_BYTE && <nl> + if (( ssl -> options . cipherSuite0 == ECC_BYTE || <nl> + ssl -> options . cipherSuite0 == CHACHA_BYTE ) && <nl> ssl -> specs . sig_algo == ecc_dsa_sa_algo ) { <nl> output [ i ++] = ecdsa_sign ; <nl> } else
void InitX509Name ( WOLFSSL_X509_NAME * name , int dynamicFlag ) <nl> # ifdef OPENSSL_EXTRA <nl> XMEMSET (& name -> fullName , 0 , sizeof ( DecodedName )); <nl> XMEMSET (& name -> cnEntry , 0 , sizeof ( WOLFSSL_X509_NAME_ENTRY )); <nl> + XMEMSET (& name -> extra , 0 , sizeof ( name -> extra )); <nl> name -> cnEntry . value = &( name -> cnEntry . data ); /* point to internal data */ <nl> name -> cnEntry . nid = ASN_COMMON_NAME ; <nl> name -> x509 = NULL ;
static int DecodePolicyOID ( char * out , word32 outSz , byte * in , word32 inSz ) <nl> # endif <nl> } <nl> idx += policy_length ; <nl> - } while (( int ) idx < total_length && cert -> extCertPoliciesNb < MAX_CERTPOL_NB ); <nl> + } while (( int ) idx < total_length <nl> + # if defined ( WOLFSSL_CERT_EXT ) <nl> + && cert -> extCertPoliciesNb < MAX_CERTPOL_NB <nl> + # endif <nl> + ); <nl>  <nl> WOLFSSL_LEAVE (" DecodeCertPolicy ", 0 ); <nl> return 0 ;
int mgmt_write_scan_failed ( struct hci_dev * hdev , u8 scan , u8 status ) <nl> return 0 ; <nl> } <nl>  <nl> - int mgmt_new_link_key ( struct hci_dev * hdev , struct link_key * key , bool persistent ) <nl> + int mgmt_new_link_key ( struct hci_dev * hdev , struct link_key * key , <nl> + bool persistent ) <nl> { <nl> struct mgmt_ev_new_link_key ev ; <nl> 
static int rdac_check_sense ( struct scsi_device * sdev , <nl> struct rdac_dh_data * h = get_rdac_data ( sdev ); <nl> switch ( sense_hdr -> sense_key ) { <nl> case NOT_READY : <nl> + if ( sense_hdr -> asc == 0x04 && sense_hdr -> ascq == 0x01 ) <nl> + /* LUN Not Ready - Logical Unit Not Ready and is in <nl> + * the process of becoming ready <nl> + * Just retry . <nl> + */ <nl> + return ADD_TO_MLQUEUE ; <nl> if ( sense_hdr -> asc == 0x04 && sense_hdr -> ascq == 0x81 ) <nl> /* LUN Not Ready - Storage firmware incompatible <nl> * Manual code synchonisation required .
static int ipu_get_resources ( struct ipu_crtc * ipu_crtc , <nl> int ret ; <nl>  <nl> ipu_crtc -> ipu_ch = ipu_idmac_get ( ipu , pdata -> dma [ 0 ]); <nl> - if ( IS_ERR_OR_NULL ( ipu_crtc -> ipu_ch )) { <nl> + if ( IS_ERR ( ipu_crtc -> ipu_ch )) { <nl> ret = PTR_ERR ( ipu_crtc -> ipu_ch ); <nl> goto err_out ; <nl> } <nl> static int ipu_get_resources ( struct ipu_crtc * ipu_crtc , <nl> if ( pdata -> dp >= 0 ) { <nl> ipu_crtc -> dp = ipu_dp_get ( ipu , pdata -> dp ); <nl> if ( IS_ERR ( ipu_crtc -> dp )) { <nl> - ret = PTR_ERR ( ipu_crtc -> ipu_ch ); <nl> + ret = PTR_ERR ( ipu_crtc -> dp ); <nl> goto err_out ; <nl> } <nl> } <nl> static int ipu_drm_probe ( struct platform_device * pdev ) <nl> ipu_crtc -> dev = & pdev -> dev ; <nl>  <nl> ret = ipu_crtc_init ( ipu_crtc , pdata ); <nl> + if ( ret ) <nl> + return ret ; <nl>  <nl> platform_set_drvdata ( pdev , ipu_crtc ); <nl> 
affs_remount ( struct super_block * sb , int * flags , char * data ) <nl> int root_block ; <nl> unsigned long mount_flags ; <nl> int res = 0 ; <nl> - char * new_opts = kstrdup ( data , GFP_KERNEL ); <nl> + char * new_opts ; <nl> char volume [ 32 ]; <nl> char * prefix = NULL ; <nl>  <nl> + new_opts = kstrdup ( data , GFP_KERNEL ); <nl> + if (! new_opts ) <nl> + return - ENOMEM ; <nl> + <nl> pr_debug ("% s ( flags = 0x % x , opts =\"% s \")\ n ", __func__ , * flags , data ); <nl>  <nl> sync_filesystem ( sb );
int kvm_emulate_pio ( struct kvm_vcpu * vcpu , int in , int size , unsigned port ) <nl> trace_kvm_pio ( vcpu -> run -> io . direction == KVM_EXIT_IO_OUT , port , <nl> size , 1 ); <nl>  <nl> - val = kvm_register_read ( vcpu , VCPU_REGS_RAX ); <nl> - memcpy ( vcpu -> arch . pio_data , & val , 4 ); <nl> + if (! vcpu -> arch . pio . in ) { <nl> + val = kvm_register_read ( vcpu , VCPU_REGS_RAX ); <nl> + memcpy ( vcpu -> arch . pio_data , & val , 4 ); <nl> + } <nl>  <nl> if (! kernel_pio ( vcpu , vcpu -> arch . pio_data )) { <nl> complete_pio ( vcpu );
static ssize_t xenbus_file_write ( struct file * filp , <nl> goto out ; <nl>  <nl> /* Can ' t write a xenbus message larger we can buffer */ <nl> - if (( len + u -> len ) > sizeof ( u -> u . buffer )) { <nl> + if ( len > sizeof ( u -> u . buffer ) - u -> len ) { <nl> /* On error , dump existing buffer */ <nl> u -> len = 0 ; <nl> rc = - EINVAL ;
static int skfp_ioctl ( struct net_device * dev , struct ifreq * rq , int cmd ) <nl> break ; <nl> case SKFP_CLR_STATS : /* Zero out the driver statistics */ <nl> if (! capable ( CAP_NET_ADMIN )) { <nl> - memset (& lp -> MacStat , 0 , sizeof ( lp -> MacStat )); <nl> - } else { <nl> status = - EPERM ; <nl> + } else { <nl> + memset (& lp -> MacStat , 0 , sizeof ( lp -> MacStat )); <nl> } <nl> break ; <nl> default :
static void intel_sdvo_mode_set ( struct drm_encoder * encoder , <nl>  <nl> /* Set the SDVO control regs . */ <nl> if ( INTEL_INFO ( dev )-> gen >= 4 ) { <nl> - sdvox = SDVO_BORDER_ENABLE ; <nl> + sdvox = 0 ; <nl> + if ( INTEL_INFO ( dev )-> gen < 5 ) <nl> + sdvox |= SDVO_BORDER_ENABLE ; <nl> if ( adjusted_mode -> flags & DRM_MODE_FLAG_PVSYNC ) <nl> sdvox |= SDVO_VSYNC_ACTIVE_HIGH ; <nl> if ( adjusted_mode -> flags & DRM_MODE_FLAG_PHSYNC ) <nl> static void intel_sdvo_mode_set ( struct drm_encoder * encoder , <nl> sdvox |= ( pixel_multiplier - 1 ) << SDVO_PORT_MULTIPLY_SHIFT ; <nl> } <nl>  <nl> - if ( input_dtd . part2 . sdvo_flags & SDVO_NEED_TO_STALL ) <nl> + if ( input_dtd . part2 . sdvo_flags & SDVO_NEED_TO_STALL && <nl> + INTEL_INFO ( dev )-> gen < 5 ) <nl> sdvox |= SDVO_STALL_SELECT ; <nl> intel_sdvo_write_sdvox ( intel_sdvo , sdvox ); <nl> }
void free_user_ns ( struct kref * kref ) <nl> struct user_namespace * ns ; <nl>  <nl> ns = container_of ( kref , struct user_namespace , kref ); <nl> + free_uid ( ns -> root_user ); <nl> kfree ( ns ); <nl> } <nl> 
static int clk_wzrd_probe ( struct platform_device * pdev ) <nl> reg = ( readl ( clk_wzrd -> base + WZRD_CLK_CFG_REG ( 0 )) & <nl> WZRD_DIVCLK_DIVIDE_MASK ) >> WZRD_DIVCLK_DIVIDE_SHIFT ; <nl> clk_name = kasprintf ( GFP_KERNEL , "% s_mul_div ", dev_name (& pdev -> dev )); <nl> + if (! clk_name ) { <nl> + ret = - ENOMEM ; <nl> + goto err_rm_int_clk ; <nl> + } <nl> + <nl> clk_wzrd -> clks_internal [ wzrd_clk_mul_div ] = clk_register_fixed_factor ( <nl> & pdev -> dev , clk_name , <nl> __clk_get_name ( clk_wzrd -> clks_internal [ wzrd_clk_mul ]),
int __init mvebu_mbus_init ( const char * soc , phys_addr_t mbuswins_phys_base , <nl> { <nl> const struct of_device_id * of_id ; <nl>  <nl> - for ( of_id = of_mvebu_mbus_ids ; of_id -> compatible ; of_id ++) <nl> + for ( of_id = of_mvebu_mbus_ids ; of_id -> compatible [ 0 ]; of_id ++) <nl> if (! strcmp ( of_id -> compatible , soc )) <nl> break ; <nl>  <nl> - if (! of_id -> compatible ) { <nl> + if (! of_id -> compatible [ 0 ]) { <nl> pr_err (" could not find a matching SoC family \ n "); <nl> return - ENODEV ; <nl> }
static int palmas_gpio_probe ( struct platform_device * pdev ) <nl> const struct palmas_device_data * dev_data ; <nl>  <nl> match = of_match_device ( of_palmas_gpio_match , & pdev -> dev ); <nl> + if (! match ) <nl> + return - ENODEV ; <nl> dev_data = match -> data ; <nl> if (! dev_data ) <nl> dev_data = & palmas_dev_data ;
static int __init sm_it87_init ( void ) <nl>  <nl> static void __exit sm_it87_exit ( void ) <nl> { <nl> - i2c_isa_del_driver (& it87_isa_driver ); <nl> + if ( isa_address ) <nl> + i2c_isa_del_driver (& it87_isa_driver ); <nl> i2c_del_driver (& it87_driver ); <nl> } <nl> 
static int pcmuio_attach ( struct comedi_device * dev , struct comedi_devconfig * it ) <nl>  <nl> /* save the ioport address for each ' port ' of 8 channels in the <nl> subdevice */ <nl> - for ( byte_no = 0 ; byte_no < PORTS_PER_SUBDEV ; ++ byte_no , ++ port ) { <nl> + for ( byte_no = 0 ; byte_no < PORTS_PER_SUBDEV ; <nl> + ++ byte_no , ++ port ) { <nl> if ( port >= PORTS_PER_ASIC ) { <nl> port = 0 ; <nl> ++ asic ;
int ext4_ext_map_blocks ( handle_t * handle , struct inode * inode , <nl> trace_ext4_ext_map_blocks_enter ( inode , map -> m_lblk , map -> m_len , flags ); <nl>  <nl> /* check in cache */ <nl> - if ( ext4_ext_in_cache ( inode , map -> m_lblk , & newex ) && <nl> - (( flags & EXT4_GET_BLOCKS_PUNCH_OUT_EXT ) == 0 )) { <nl> + if (!( flags & EXT4_GET_BLOCKS_PUNCH_OUT_EXT ) && <nl> + ext4_ext_in_cache ( inode , map -> m_lblk , & newex )) { <nl> if (! newex . ee_start_lo && ! newex . ee_start_hi ) { <nl> if (( flags & EXT4_GET_BLOCKS_CREATE ) == 0 ) { <nl> /*
int mv88e6xxx_leave_bridge ( struct dsa_switch * ds , int port , u32 br_port_mask ) <nl>  <nl> newfid = __ffs ( ps -> fid_mask ); <nl> ps -> fid [ port ] = newfid ; <nl> - ps -> fid_mask &= ( 1 << newfid ); <nl> + ps -> fid_mask &= ~( 1 << newfid ); <nl> ps -> bridge_mask [ fid ] &= ~( 1 << port ); <nl> ps -> bridge_mask [ newfid ] = 1 << port ; <nl> 
static int l2cap_parse_conf_req ( struct sock * sk , void * data ) <nl> break ; <nl> } <nl>  <nl> - if (! l2cap_mode_supported ( pi -> mode , pi -> conn -> feat_mask )) <nl> + if ( pi -> mode != rfc . mode ) <nl> return - ECONNREFUSED ; <nl> + <nl> break ; <nl> default : <nl> pi -> mode = l2cap_select_mode ( rfc . mode , pi -> conn -> feat_mask );
acpi_ex_load_table_op ( struct acpi_walk_state * walk_state , <nl>  <nl> ACPI_FUNCTION_TRACE ( ex_load_table_op ); <nl>  <nl> + /* Validate lengths for the signature_string , OEMIDString , OEMtable_iD */ <nl> + <nl> + if (( operand [ 0 ]-> string . length > ACPI_NAME_SIZE ) || <nl> + ( operand [ 1 ]-> string . length > ACPI_OEM_ID_SIZE ) || <nl> + ( operand [ 2 ]-> string . length > ACPI_OEM_TABLE_ID_SIZE )) { <nl> + return_ACPI_STATUS ( AE_BAD_PARAMETER ); <nl> + } <nl> + <nl> /* Find the ACPI table in the RSDT / XSDT */ <nl>  <nl> status = acpi_tb_find_table ( operand [ 0 ]-> string . pointer ,
static void incoming_packet ( struct sasem_context * context , <nl> } <nl>  <nl> if ( debug ) { <nl> - printk ( KERN_INFO " Incoming data : "); <nl> + pr_info (" Incoming data : "); <nl> for ( i = 0 ; i < 8 ; ++ i ) <nl> - printk ( KERN_CONT "% 02x ", buf [ i ]); <nl> - printk ( KERN_CONT "\ n "); <nl> + pr_cont ("% 02x ", buf [ i ]); <nl> + pr_cont ("\ n "); <nl> } <nl>  <nl> /*
i915_gem_object_finish_gpu ( struct drm_i915_gem_object * obj ) <nl> return ret ; <nl> } <nl>  <nl> + ret = i915_gem_object_wait_rendering ( obj ); <nl> + if ( ret ) <nl> + return ret ; <nl> + <nl> /* Ensure that we invalidate the GPU ' s caches and TLBs . */ <nl> obj -> base . read_domains &= ~ I915_GEM_GPU_DOMAINS ; <nl> - <nl> - return i915_gem_object_wait_rendering ( obj ); <nl> + return 0 ; <nl> } <nl>  <nl> /**
int dwc2_hcd_init ( struct dwc2_hsotg * hsotg , int irq , <nl> if (! hcd ) <nl> goto error1 ; <nl>  <nl> + if ( hsotg -> core_params -> dma_enable <= 0 ) <nl> + hcd -> self . uses_dma = 0 ; <nl> + <nl> hcd -> has_tt = 1 ; <nl>  <nl> spin_lock_init (& hsotg -> lock );
static ssize_t ican3_sysfs_set_term ( struct device * dev , <nl> return count ; <nl> } <nl>  <nl> - static DEVICE_ATTR ( termination , S_IWUGO | S_IRUGO , ican3_sysfs_show_term , <nl> + static DEVICE_ATTR ( termination , S_IWUSR | S_IRUGO , ican3_sysfs_show_term , <nl> ican3_sysfs_set_term ); <nl>  <nl> static struct attribute * ican3_sysfs_attrs [] = {
static int dw_mci_data_complete ( struct dw_mci * host , struct mmc_data * data ) <nl> data -> error = - EIO ; <nl> } <nl>  <nl> - dev_err ( host -> dev , " data error , status 0x % 08x \ n ", status ); <nl> + dev_dbg ( host -> dev , " data error , status 0x % 08x \ n ", status ); <nl>  <nl> /* <nl> * After an error , there may be data lingering
enum node_states { <nl> # else <nl> N_HIGH_MEMORY = N_NORMAL_MEMORY , <nl> # endif <nl> + N_MEMORY = N_HIGH_MEMORY , <nl> N_CPU , /* The node has one or more cpus */ <nl> NR_NODE_STATES <nl> };
ext4_move_extents ( struct file * o_filp , struct file * d_filp , <nl> orig_inode -> i_ino , donor_inode -> i_ino ); <nl> return - EINVAL ; <nl> } <nl> - <nl> + /* TODO : This is non obvious task to swap blocks for inodes with full <nl> + jornaling enabled */ <nl> + if ( ext4_should_journal_data ( orig_inode ) || <nl> + ext4_should_journal_data ( donor_inode )) { <nl> + return - EINVAL ; <nl> + } <nl> /* Protect orig and donor inodes against a truncate */ <nl> mext_inode_double_lock ( orig_inode , donor_inode ); <nl> 
void arch_release_hugepage ( struct page * page ) <nl> ptep = ( pte_t *) page [ 1 ]. index ; <nl> if (! ptep ) <nl> return ; <nl> + clear_table (( unsigned long *) ptep , _PAGE_TYPE_EMPTY , <nl> + PTRS_PER_PTE * sizeof ( pte_t )); <nl> page_table_free (& init_mm , ( unsigned long *) ptep ); <nl> page [ 1 ]. index = 0 ; <nl> }
static ssize_t cxlflash_show_port_status ( struct device * dev , <nl> u64 * fc_regs ; <nl>  <nl> rc = kstrtouint (( attr -> attr . name + 4 ), 10 , & port ); <nl> - if ( rc || ( port > NUM_FC_PORTS )) <nl> + if ( rc || ( port >= NUM_FC_PORTS )) <nl> return 0 ; <nl>  <nl> fc_regs = & afu -> afu_map -> global . fc_regs [ port ][ 0 ];
static int ks8695_poll ( struct napi_struct * napi , int budget ) <nl> if ( work_done < budget ) { <nl> unsigned long flags ; <nl> spin_lock_irqsave (& ksp -> rx_lock , flags ); <nl> + __napi_complete ( napi ); <nl> /* enable rx interrupt */ <nl> writel ( isr | mask_bit , KS8695_IRQ_VA + KS8695_INTEN ); <nl> - __napi_complete ( napi ); <nl> spin_unlock_irqrestore (& ksp -> rx_lock , flags ); <nl> } <nl> return work_done ;
special_insn : <nl> case 0x88 ... 0x8b : /* mov */ <nl> goto mov ; <nl> case 0x8d : /* lea r16 / r32 , m */ <nl> - c -> dst . val = c -> modrm_val ; <nl> + c -> dst . val = c -> modrm_ea ; <nl> break ; <nl> case 0x8f : /* pop ( sole member of Grp1a ) */ <nl> rc = emulate_grp1a ( ctxt , ops );
static enum blk_eh_timer_return mtip_cmd_timeout ( struct request * req , <nl> bool reserved ) <nl> { <nl> struct driver_data * dd = req -> q -> queuedata ; <nl> - int ret = BLK_EH_RESET_TIMER ; <nl>  <nl> if ( reserved ) <nl> goto exit_handler ; <nl> static enum blk_eh_timer_return mtip_cmd_timeout ( struct request * req , <nl>  <nl> wake_up_interruptible (& dd -> port -> svc_wait ); <nl> exit_handler : <nl> - return ret ; <nl> + return BLK_EH_RESET_TIMER ; <nl> } <nl>  <nl> static struct blk_mq_ops mtip_mq_ops = {
static void hpet_msi_capability_lookup ( unsigned int start_timer ) <nl> continue ; <nl>  <nl> irq = hpet_assign_irq ( hpet_domain , hdev , hdev -> num ); <nl> - if ( irq < 0 ) <nl> + if ( irq <= 0 ) <nl> continue ; <nl>  <nl> sprintf ( hdev -> name , " hpet % d ", i );
static int hci_dev_do_open ( struct hci_dev * hdev ) <nl> * be able to determine if there is a public address <nl> * or not . <nl> * <nl> + * In case of user channel usage , it is not important <nl> + * if a public address or static random address is <nl> + * available . <nl> + * <nl> * This check is only valid for BR / EDR controllers <nl> * since AMP controllers do not have an address . <nl> */ <nl> - if ( hdev -> dev_type == HCI_BREDR && <nl> + if (! test_bit ( HCI_USER_CHANNEL , & hdev -> dev_flags ) && <nl> + hdev -> dev_type == HCI_BREDR && <nl> ! bacmp (& hdev -> bdaddr , BDADDR_ANY ) && <nl> ! bacmp (& hdev -> static_addr , BDADDR_ANY )) { <nl> ret = - EADDRNOTAVAIL ;
static unsigned int br_nf_post_routing ( unsigned int hook , struct sk_buff * skb , <nl> if (! nf_bridge ) <nl> return NF_ACCEPT ; <nl>  <nl> + if (!( nf_bridge -> mask & ( BRNF_BRIDGED | BRNF_BRIDGED_DNAT ))) <nl> + return NF_ACCEPT ; <nl> + <nl> if (! realoutdev ) <nl> return NF_DROP ; <nl> 
static void brcmf_fws_dequeue_worker ( struct work_struct * worker ) <nl> fws = container_of ( worker , struct brcmf_fws_info , fws_dequeue_work ); <nl>  <nl> brcmf_fws_lock ( fws -> drvr , flags ); <nl> - for ( fifo = NL80211_NUM_ACS ; fifo >= 0 && ! fws -> bus_flow_blocked ; <nl> + for ( fifo = BRCMF_FWS_FIFO_BCMC ; fifo >= 0 && ! fws -> bus_flow_blocked ; <nl> fifo --) { <nl> while (( fws -> fifo_credit [ fifo ]) || ((! fws -> bcmc_credit_check ) && <nl> ( fifo == BRCMF_FWS_FIFO_BCMC ))) {
int drm_crtc_helper_set_config ( struct drm_mode_set * set ) <nl> int count = 0 , ro , fail = 0 ; <nl> struct drm_crtc_helper_funcs * crtc_funcs ; <nl> int ret = 0 ; <nl> + int i ; <nl>  <nl> DRM_DEBUG_KMS ("\ n "); <nl>  <nl> int drm_crtc_helper_set_config ( struct drm_mode_set * set ) <nl> if ( ret != 0 ) <nl> goto fail ; <nl> } <nl> + DRM_DEBUG_KMS (" Setting connector DPMS state to on \ n "); <nl> + for ( i = 0 ; i < set -> num_connectors ; i ++) { <nl> + DRM_DEBUG_KMS ("\ t [ CONNECTOR :% d :% s ] set DPMS on \ n ", set -> connectors [ i ]-> base . id , <nl> + drm_get_connector_name ( set -> connectors [ i ])); <nl> + set -> connectors [ i ]-> dpms = DRM_MODE_DPMS_ON ; <nl> + } <nl>  <nl> kfree ( save_connectors ); <nl> kfree ( save_encoders );
uint brcms_reset ( struct brcms_info * wl ) <nl> /* dpc will not be rescheduled */ <nl> wl -> resched = false ; <nl>  <nl> + /* inform publicly that interface is down */ <nl> + wl -> pub -> up = false ; <nl> + <nl> return 0 ; <nl> } <nl> 
static int ion_chunk_heap_allocate ( struct ion_heap * heap , <nl> unsigned long num_chunks ; <nl> unsigned long allocated_size ; <nl>  <nl> + if ( align > chunk_heap -> chunk_size ) <nl> + return - EINVAL ; <nl> + <nl> allocated_size = ALIGN ( size , chunk_heap -> chunk_size ); <nl> num_chunks = allocated_size / chunk_heap -> chunk_size ; <nl> 
int sk_convert_filter ( struct sock_filter * prog , int len , <nl> BUILD_BUG_ON ( BPF_MEMWORDS * sizeof ( u32 ) > MAX_BPF_STACK ); <nl> BUILD_BUG_ON ( BPF_REG_FP + 1 != MAX_BPF_REG ); <nl>  <nl> - if ( len <= 0 || len >= BPF_MAXINSNS ) <nl> + if ( len <= 0 || len > BPF_MAXINSNS ) <nl> return - EINVAL ; <nl>  <nl> if ( new_prog ) {
rcu_torture_init ( void ) <nl> writer_task = NULL ; <nl> goto unwind ; <nl> } <nl> - reader_tasks = kmalloc ( nrealreaders * sizeof ( reader_tasks [ 0 ]), <nl> + reader_tasks = kzalloc ( nrealreaders * sizeof ( reader_tasks [ 0 ]), <nl> GFP_KERNEL ); <nl> if ( reader_tasks == NULL ) { <nl> VERBOSE_PRINTK_ERRSTRING (" out of memory ");
static int evtchn_bind_to_user ( struct per_user_data * u , int port ) <nl> u -> name , ( void *)( unsigned long ) port ); <nl> if ( rc >= 0 ) <nl> rc = evtchn_make_refcounted ( port ); <nl> + else { <nl> + /* bind failed , should close the port now */ <nl> + struct evtchn_close close ; <nl> + close . port = port ; <nl> + if ( HYPERVISOR_event_channel_op ( EVTCHNOP_close , & close ) != 0 ) <nl> + BUG (); <nl> + set_port_user ( port , NULL ); <nl> + } <nl>  <nl> return rc ; <nl> } <nl> static void evtchn_unbind_from_user ( struct per_user_data * u , int port ) <nl> { <nl> int irq = irq_from_evtchn ( port ); <nl>  <nl> + BUG_ON ( irq < 0 ); <nl> + <nl> unbind_from_irqhandler ( irq , ( void *)( unsigned long ) port ); <nl>  <nl> set_port_user ( port , NULL );
static struct clocksource clocksource_mips = { <nl> . flags = CLOCK_SOURCE_IS_CONTINUOUS , <nl> }; <nl>  <nl> + unsigned long long notrace sched_clock ( void ) <nl> +{ <nl> + return clocksource_cyc2ns ( read_c0_cvmcount (), <nl> + clocksource_mips . mult , <nl> + clocksource_mips . shift ); <nl> +} <nl> + <nl> void __init plat_time_init ( void ) <nl> { <nl> clocksource_mips . rating = 300 ;
static inline int fls64 ( unsigned long x ) <nl> { <nl> unsigned long t , a , r ; <nl>  <nl> - t = __kernel_cmpbge ( x , 0x0101010101010101 ); <nl> + t = __kernel_cmpbge ( x , 0x0101010101010101UL ); <nl> a = __flsm1_tab [ t ]; <nl> t = __kernel_extbl ( x , a ); <nl> r = a * 8 + __flsm1_tab [ t ] + ( x != 0 );
static void rbd_client_release ( struct kref * kref ) <nl> struct rbd_client * rbdc = container_of ( kref , struct rbd_client , kref ); <nl>  <nl> dout (" rbd_release_client % p \ n ", rbdc ); <nl> + spin_lock (& rbd_client_list_lock ); <nl> list_del (& rbdc -> node ); <nl> + spin_unlock (& rbd_client_list_lock ); <nl>  <nl> ceph_destroy_client ( rbdc -> client ); <nl> kfree ( rbdc -> rbd_opts ); <nl> static void rbd_client_release ( struct kref * kref ) <nl> */ <nl> static void rbd_put_client ( struct rbd_device * rbd_dev ) <nl> { <nl> - spin_lock (& rbd_client_list_lock ); <nl> kref_put (& rbd_dev -> rbd_client -> kref , rbd_client_release ); <nl> - spin_unlock (& rbd_client_list_lock ); <nl> rbd_dev -> rbd_client = NULL ; <nl> } <nl> 
int sst_block_alloc_scratch ( struct sst_dsp * dsp ) <nl> ret = block_list_prepare ( dsp , & dsp -> scratch_block_list ); <nl> if ( ret < 0 ) { <nl> dev_err ( dsp -> dev , " error : scratch block prepare failed \ n "); <nl> + mutex_unlock (& dsp -> mutex ); <nl> return ret ; <nl> } <nl> 
bfa_ioc_mbox_isr ( struct bfa_ioc_s * ioc ) <nl> return ; <nl> } <nl>  <nl> - if (( mc > BFI_MC_MAX ) || ( mod -> mbhdlr [ mc ]. cbfn == NULL )) <nl> + if (( mc >= BFI_MC_MAX ) || ( mod -> mbhdlr [ mc ]. cbfn == NULL )) <nl> return ; <nl>  <nl> mod -> mbhdlr [ mc ]. cbfn ( mod -> mbhdlr [ mc ]. cbarg , & m );
bool ROUTEbRelay ( PSDevice pDevice , unsigned char * pbySkbData , unsigned int uData <nl> pHeadTD = pHeadTD -> next ; <nl> } <nl>  <nl> - pLastTD -> pTDInfo -> skb = 0 ; <nl> + pLastTD -> pTDInfo -> skb = NULL ; <nl> pLastTD -> pTDInfo -> byFlags = 0 ; <nl>  <nl> pDevice -> apCurrTD [ TYPE_AC0DMA ] = pHeadTD ;
static int pm2fb_check_var ( struct fb_var_screeninfo * var , struct fb_info * info ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + var -> transp . offset = 0 ; <nl> + var -> transp . length = 0 ; <nl> switch ( var -> bits_per_pixel ) { <nl> case 8 : <nl> var -> red . length = var -> green . length = var -> blue . length = 8 ;
int iwl_power_update_mode ( struct iwl_priv * priv , bool force ) <nl> if ( priv -> cfg -> ops -> lib -> update_chain_flags && <nl> update_chains ) <nl> priv -> cfg -> ops -> lib -> update_chain_flags ( priv ); <nl> - else <nl> + else if ( priv -> cfg -> ops -> lib -> update_chain_flags ) <nl> IWL_DEBUG_POWER ( priv , <nl> " Cannot update the power , chain noise " <nl> " calibration running : % d \ n ",
static int emac_dev_open ( struct net_device * ndev ) <nl> struct emac_priv * priv = netdev_priv ( ndev ); <nl>  <nl> netif_carrier_off ( ndev ); <nl> - for ( cnt = 0 ; cnt <= ETH_ALEN ; cnt ++) <nl> + for ( cnt = 0 ; cnt < ETH_ALEN ; cnt ++) <nl> ndev -> dev_addr [ cnt ] = priv -> mac_addr [ cnt ]; <nl>  <nl> /* Configuration items */
static int cp_tm1217_probe ( struct i2c_client * client , <nl> if ( input_dev == NULL ) { <nl> dev_err ( ts -> dev , <nl> " cp_tm1217 : Input Device Struct alloc failed \ n "); <nl> - kfree ( ts ); <nl> - return - ENOMEM ; <nl> + retval = - ENOMEM ; <nl> + goto fail ; <nl> } <nl> input_info = & ts -> cp_input_info [ i ]; <nl> snprintf ( input_info -> name , sizeof ( input_info -> name ), <nl> static int cp_tm1217_probe ( struct i2c_client * client , <nl> dev_err ( ts -> dev , <nl> " Input dev registration failed for % s \ n ", <nl> input_dev -> name ); <nl> + input_free_device ( input_dev ); <nl> goto fail ; <nl> } <nl> input_info -> input = input_dev ;
static struct w83627ehf_data * w83627ehf_update_device ( struct device * dev ) <nl> data -> temp_max_hyst [ i ] <nl> = w83627ehf_read_temp ( data , <nl> data -> reg_temp_hyst [ i ]); <nl> + if ( i > 2 ) <nl> + continue ; <nl> if ( data -> have_temp_offset & ( 1 << i )) <nl> data -> temp_offset [ i ] <nl> = w83627ehf_read_value ( data , <nl> static int w83627ehf_resume ( struct device * dev ) <nl> if ( data -> reg_temp_hyst [ i ]) <nl> w83627ehf_write_temp ( data , data -> reg_temp_hyst [ i ], <nl> data -> temp_max_hyst [ i ]); <nl> + if ( i > 2 ) <nl> + continue ; <nl> if ( data -> have_temp_offset & ( 1 << i )) <nl> w83627ehf_write_value ( data , <nl> W83627EHF_REG_TEMP_OFFSET [ i ],
static inline long snd_ctl_ioctl_compat ( struct file * file , unsigned int cmd , uns <nl> case SNDRV_CTL_IOCTL_POWER_STATE : <nl> case SNDRV_CTL_IOCTL_ELEM_LOCK : <nl> case SNDRV_CTL_IOCTL_ELEM_UNLOCK : <nl> + case SNDRV_CTL_IOCTL_ELEM_REMOVE : <nl> + case SNDRV_CTL_IOCTL_TLV_READ : <nl> + case SNDRV_CTL_IOCTL_TLV_WRITE : <nl> + case SNDRV_CTL_IOCTL_TLV_COMMAND : <nl> return snd_ctl_ioctl ( file , cmd , ( unsigned long ) argp ); <nl> case SNDRV_CTL_IOCTL_ELEM_LIST32 : <nl> return snd_ctl_elem_list_compat ( ctl -> card , argp );
* PCI bar 1 register I / O map <nl> */ <nl> # define APCI3501_AO_CTRL_STATUS_REG 0x00 <nl> -# define APCI3501_AO_CTRL_BIPOLAR ( 1 << 0 ) <nl> -# define APCI3501_AO_STATUS_READY ( 1 << 8 ) <nl> +# define APCI3501_AO_CTRL_BIPOLAR BIT ( 0 ) <nl> +# define APCI3501_AO_STATUS_READY BIT ( 8 ) <nl> # define APCI3501_AO_DATA_REG 0x04 <nl> # define APCI3501_AO_DATA_CHAN ( x ) (( x ) << 0 ) <nl> # define APCI3501_AO_DATA_VAL ( x ) (( x ) << 8 ) <nl> -# define APCI3501_AO_DATA_BIPOLAR ( 1 << 31 ) <nl> +# define APCI3501_AO_DATA_BIPOLAR BIT ( 31 ) <nl> # define APCI3501_AO_TRIG_SCS_REG 0x08 <nl> # define APCI3501_TIMER_SYNC_REG 0x20 <nl> # define APCI3501_TIMER_RELOAD_REG 0x24
vhost_scsi_handle_vq ( struct vhost_scsi * vs , struct vhost_virtqueue * vq ) <nl> break ; <nl> } <nl>  <nl> + /* virtio - scsi spec requires byte 0 of the lun to be 1 */ <nl> + if ( unlikely ( v_req . lun [ 0 ] != 1 )) { <nl> + vhost_scsi_send_bad_target ( vs , vq , head , out ); <nl> + continue ; <nl> + } <nl> + <nl> /* Extract the tpgt */ <nl> target = v_req . lun [ 1 ]; <nl> tpg = ACCESS_ONCE ( vs_tpg [ target ]);
static void dgap_sniff_nowait_nolock ( struct channel_t * ch , uchar * text , uchar * b <nl> /* <nl> * Loop while data remains . <nl> */ <nl> - while ( nbuf > 0 && ch -> ch_sniff_buf != 0 ) { <nl> + while ( nbuf > 0 && ch -> ch_sniff_buf ) { <nl> /* <nl> * Determine the amount of available space left in the <nl> * buffer . If there ' s none , wait until some appears . <nl> static int dgap_tty_open ( struct tty_struct * tty , struct file * file ) <nl> MAJOR ( tty_devnum ( tty )), MINOR ( tty_devnum ( tty )), un , brd -> name )); <nl>  <nl> /* <nl> - * Error if channel info pointer is 0 . <nl> + * Error if channel info pointer is NULL . <nl> */ <nl> - if (( bs = ch -> ch_bs ) == 0 ) { <nl> + bs = ch -> ch_bs ; <nl> + if (! bs ) { <nl> DGAP_UNLOCK ( ch -> ch_lock , lock_flags2 ); <nl> DGAP_UNLOCK ( brd -> bd_lock , lock_flags ); <nl> DPR_OPEN (("% d BS is 0 !\ n ", __LINE__ ));
enum oom_scan_t oom_scan_process_thread ( struct task_struct * task , <nl>  <nl> /* <nl> * Simple selection loop . We chose the process with the highest <nl> - * number of ' points '. <nl> + * number of ' points '. Returns - 1 on scan abort . <nl> * <nl> * ( not docbooked , we don ' t want this one cluttering up the manual ) <nl> */ <nl> static struct task_struct * select_bad_process ( unsigned int * ppoints , <nl> continue ; <nl> case OOM_SCAN_ABORT : <nl> rcu_read_unlock (); <nl> - return ERR_PTR (- 1UL ); <nl> + return ( struct task_struct *)(- 1UL ); <nl> case OOM_SCAN_OK : <nl> break ; <nl> }; <nl> void out_of_memory ( struct zonelist * zonelist , gfp_t gfp_mask , <nl> dump_header ( NULL , gfp_mask , order , NULL , mpol_mask ); <nl> panic (" Out of memory and no killable processes ...\ n "); <nl> } <nl> - if ( PTR_ERR ( p ) != - 1UL ) { <nl> + if ( p != ( void *)- 1UL ) { <nl> oom_kill_process ( p , gfp_mask , order , points , totalpages , NULL , <nl> nodemask , " Out of memory "); <nl> killed = 1 ;
void qla4xxx_process_aen ( struct scsi_qla_host * ha , uint8_t process_aen ) <nl> int qla4xxx_request_irqs ( struct scsi_qla_host * ha ) <nl> { <nl> int ret ; <nl> + int rval = QLA_ERROR ; <nl>  <nl> if ( is_qla40XX ( ha )) <nl> goto try_intx ; <nl> irq_attached : <nl> set_bit ( AF_IRQ_ATTACHED , & ha -> flags ); <nl> ha -> host -> irq = ha -> pdev -> irq ; <nl> ql4_printk ( KERN_INFO , ha , "% s : irq % d attached \ n ", <nl> - __func__ , ha -> pdev -> irq ); <nl> + __func__ , ha -> pdev -> irq ); <nl> + rval = QLA_SUCCESS ; <nl> irq_not_attached : <nl> - return ret ; <nl> + return rval ; <nl> } <nl>  <nl> void qla4xxx_free_irqs ( struct scsi_qla_host * ha )
pid_t pid_vnr ( struct pid * pid ); <nl> hlist_for_each_entry_rcu (( task ), pos___ , \ <nl> & pid -> tasks [ type ], pids [ type ]. node ) { <nl>  <nl> + /* <nl> + * Both old and new leaders may be attached to <nl> + * the same pid in the middle of de_thread (). <nl> + */ <nl> # define while_each_pid_task ( pid , type , task ) \ <nl> + if ( type == PIDTYPE_PID ) \ <nl> + break ; \ <nl> } \ <nl> } while ( 0 ) <nl> 
bool __init early_can_reuse_p2m_middle ( unsigned long set_pfn , unsigned long set_ <nl> if ( p2m_index ( set_pfn )) <nl> return false ; <nl>  <nl> - for ( pfn = 0 ; pfn <= MAX_DOMAIN_PAGES ; pfn += P2M_PER_PAGE ) { <nl> + for ( pfn = 0 ; pfn < MAX_DOMAIN_PAGES ; pfn += P2M_PER_PAGE ) { <nl> topidx = p2m_top_index ( pfn ); <nl>  <nl> if (! p2m_top [ topidx ])
retry : <nl> printk (" locked it .\ n "); <nl>  <nl> do_each_thread ( g , p ) { <nl> + /* <nl> + * It ' s not reliable to print a task ' s held locks <nl> + * if it ' s not sleeping ( or if it ' s not the current <nl> + * task ): <nl> + */ <nl> + if ( p -> state == TASK_RUNNING && p != current ) <nl> + continue ; <nl> if ( p -> lockdep_depth ) <nl> lockdep_print_held_locks ( p ); <nl> if (! unlock )
static int hih6130_probe ( struct i2c_client * client , <nl> hih6130 -> client = client ; <nl> mutex_init (& hih6130 -> lock ); <nl>  <nl> + if (! i2c_check_functionality ( client -> adapter , I2C_FUNC_SMBUS_QUICK )) <nl> + hih6130 -> write_length = 1 ; <nl> + <nl> hwmon_dev = devm_hwmon_device_register_with_groups ( dev , client -> name , <nl> hih6130 , <nl> hih6130_groups );
tvp514x_probe ( struct i2c_client * client , const struct i2c_device_id * id ) <nl> if ( ret < 0 ) { <nl> v4l2_err ( sd , "% s decoder driver failed to register !!\ n ", <nl> sd -> name ); <nl> - kfree ( decoder ); <nl> return ret ; <nl> } <nl> # endif
* <nl> * ( C ) 2000 Red Hat . GPL ' d <nl> * <nl> - * $ Id : cfi_cmdset_0020 . c , v 1 . 17 2004 / 11 / 20 12 : 49 : 04 dwmw2 Exp $ <nl> + * $ Id : cfi_cmdset_0020 . c , v 1 . 19 2005 / 07 / 13 15 : 52 : 45 dwmw2 Exp $ <nl> * <nl> * 10 / 10 / 2000 Nicolas Pitre < nico @ cam . org > <nl> * - completely revamped method functions so they are aware and <nl> * - modified Intel Command Set 0x0001 to support ST Advanced Architecture <nl> * ( command set 0x0020 ) <nl> * - added a writev function <nl> + * 07 / 13 / 2005 Joern Engel < joern @ wh . fh - wedel . de > <nl> + * - Plugged memory leak in cfi_staa_writev (). <nl> */ <nl>  <nl> # include < linux / version . h > <nl> cfi_staa_writev ( struct mtd_info * mtd , const struct kvec * vecs , <nl> write_error : <nl> if ( retlen ) <nl> * retlen = totlen ; <nl> + kfree ( buffer ); <nl> return ret ; <nl> } <nl> 
unsigned long compaction_suitable ( struct zone * zone , int order ) <nl> * fragmentation index determines if allocation failures are due to <nl> * low memory or external fragmentation <nl> * <nl> - * index of - 1 implies allocations might succeed dependingon watermarks <nl> + * index of - 1000 implies allocations might succeed depending on <nl> + * watermarks <nl> * index towards 0 implies failure is due to lack of memory <nl> * index towards 1000 implies failure is due to fragmentation <nl> * <nl> unsigned long compaction_suitable ( struct zone * zone , int order ) <nl> if ( fragindex >= 0 && fragindex <= sysctl_extfrag_threshold ) <nl> return COMPACT_SKIPPED ; <nl>  <nl> - if ( fragindex == - 1 && zone_watermark_ok ( zone , order , watermark , 0 , 0 )) <nl> + if ( fragindex == - 1000 && zone_watermark_ok ( zone , order , watermark , <nl> + 0 , 0 )) <nl> return COMPACT_PARTIAL ; <nl>  <nl> return COMPACT_CONTINUE ;
static int bcm2835_dma_terminate_all ( struct dma_chan * chan ) <nl> * c -> desc is NULL and exit .) <nl> */ <nl> if ( c -> desc ) { <nl> + bcm2835_dma_desc_free (& c -> desc -> vd ); <nl> c -> desc = NULL ; <nl> bcm2835_dma_abort ( c -> chan_base ); <nl> 
static void ql_update_sbq ( struct ql_adapter * qdev , struct rx_ring * rx_ring ) <nl> sbq_desc -> p . skb -> data , <nl> rx_ring -> sbq_buf_size / <nl> 2 , PCI_DMA_FROMDEVICE ); <nl> + if ( pci_dma_mapping_error ( qdev -> pdev , map )) { <nl> + QPRINTK ( qdev , IFUP , ERR , " PCI mapping failed .\ n "); <nl> + rx_ring -> sbq_clean_idx = clean_idx ; <nl> + return ; <nl> + } <nl> pci_unmap_addr_set ( sbq_desc , mapaddr , map ); <nl> pci_unmap_len_set ( sbq_desc , maplen , <nl> rx_ring -> sbq_buf_size / 2 );
static int setup ( struct spi_device * spi ) <nl> if (( chip -> chip_select_num > 0 ) <nl> && ( chip -> chip_select_num <= spi -> master -> num_chipselect )) <nl> peripheral_request ( ssel [ spi -> master -> bus_num ] <nl> - [ chip -> chip_select_num - 1 ], DRV_NAME ); <nl> + [ chip -> chip_select_num - 1 ], spi -> modalias ); <nl>  <nl> cs_deactive ( drv_data , chip ); <nl> 
static const struct usb_device_id products [] = { <nl> { QMI_FIXED_INTF ( 0x413c , 0x81a9 , 8 )}, /* Dell Wireless 5808e Gobi ( TM ) 4G LTE Mobile Broadband Card */ <nl> { QMI_FIXED_INTF ( 0x413c , 0x81b1 , 8 )}, /* Dell Wireless 5809e Gobi ( TM ) 4G LTE Mobile Broadband Card */ <nl> { QMI_FIXED_INTF ( 0x03f0 , 0x4e1d , 8 )}, /* HP lt4111 LTE / EV - DO / HSPA + Gobi 4G Module */ <nl> + { QMI_FIXED_INTF ( 0x22de , 0x9061 , 3 )}, /* WeTelecom WPD - 600N */ <nl>  <nl> /* 4 . Gobi 1000 devices */ <nl> { QMI_GOBI1K_DEVICE ( 0x05c6 , 0x9212 )}, /* Acer Gobi Modem Device */
static void free_unnecessary_pages ( void ) <nl> to_free_highmem = alloc_highmem - save ; <nl> } else { <nl> to_free_highmem = 0 ; <nl> - to_free_normal -= save - alloc_highmem ; <nl> + save -= alloc_highmem ; <nl> + if ( to_free_normal > save ) <nl> + to_free_normal -= save ; <nl> + else <nl> + to_free_normal = 0 ; <nl> } <nl>  <nl> memory_bm_position_reset (& copy_bm );
static int __btrfs_open_devices ( struct btrfs_fs_devices * fs_devices , <nl> if (! device -> name ) <nl> continue ; <nl>  <nl> - ret = btrfs_get_bdev_and_sb ( device -> name -> str , flags , holder , 1 , <nl> - & bdev , & bh ); <nl> - if ( ret ) <nl> + /* Just open everything we can ; ignore failures here */ <nl> + if ( btrfs_get_bdev_and_sb ( device -> name -> str , flags , holder , 1 , <nl> + & bdev , & bh )) <nl> continue ; <nl>  <nl> disk_super = ( struct btrfs_super_block *) bh -> b_data ;
bfa_ioc_get_type ( struct bfa_ioc * ioc ) <nl> static void <nl> bfa_ioc_get_adapter_serial_num ( struct bfa_ioc * ioc , char * serial_num ) <nl> { <nl> - memset ( serial_num , 0 , BFA_ADAPTER_SERIAL_NUM_LEN ); <nl> memcpy ( serial_num , <nl> ( void *) ioc -> attr -> brcd_serialnum , <nl> BFA_ADAPTER_SERIAL_NUM_LEN ); <nl> bfa_ioc_get_adapter_serial_num ( struct bfa_ioc * ioc , char * serial_num ) <nl> static void <nl> bfa_ioc_get_adapter_fw_ver ( struct bfa_ioc * ioc , char * fw_ver ) <nl> { <nl> - memset ( fw_ver , 0 , BFA_VERSION_LEN ); <nl> memcpy ( fw_ver , ioc -> attr -> fw_version , BFA_VERSION_LEN ); <nl> } <nl>  <nl> bfa_ioc_get_pci_chip_rev ( struct bfa_ioc * ioc , char * chip_rev ) <nl> static void <nl> bfa_ioc_get_adapter_optrom_ver ( struct bfa_ioc * ioc , char * optrom_ver ) <nl> { <nl> - memset ( optrom_ver , 0 , BFA_VERSION_LEN ); <nl> memcpy ( optrom_ver , ioc -> attr -> optrom_version , <nl> BFA_VERSION_LEN ); <nl> } <nl> bfa_ioc_get_adapter_optrom_ver ( struct bfa_ioc * ioc , char * optrom_ver ) <nl> static void <nl> bfa_ioc_get_adapter_manufacturer ( struct bfa_ioc * ioc , char * manufacturer ) <nl> { <nl> - memset ( manufacturer , 0 , BFA_ADAPTER_MFG_NAME_LEN ); <nl> memcpy ( manufacturer , BFA_MFG_NAME , BFA_ADAPTER_MFG_NAME_LEN ); <nl> } <nl> 
static void nilfs_segctor_drop_written_files ( struct nilfs_sc_info * sci , <nl> struct the_nilfs * nilfs ) <nl> { <nl> struct nilfs_inode_info * ii , * n ; <nl> + int during_mount = !( sci -> sc_super -> s_flags & MS_ACTIVE ); <nl> int defer_iput = false ; <nl>  <nl> spin_lock (& nilfs -> ns_inode_lock ); <nl> static void nilfs_segctor_drop_written_files ( struct nilfs_sc_info * sci , <nl> brelse ( ii -> i_bh ); <nl> ii -> i_bh = NULL ; <nl> list_del_init (& ii -> i_dirty ); <nl> - if (! ii -> vfs_inode . i_nlink ) { <nl> + if (! ii -> vfs_inode . i_nlink || during_mount ) { <nl> /* <nl> - * Defer calling iput () to avoid a deadlock <nl> - * over I_SYNC flag for inodes with i_nlink == 0 <nl> + * Defer calling iput () to avoid deadlocks if <nl> + * i_nlink == 0 or mount is not yet finished . <nl> */ <nl> list_add_tail (& ii -> i_dirty , & sci -> sc_iput_queue ); <nl> defer_iput = true ;
static void __init reserve_setup_data ( void ) <nl> struct setup_data * data ; <nl> u64 pa_data ; <nl> char buf [ 32 ]; <nl> + int found = 0 ; <nl>  <nl> if ( boot_params . hdr . version < 0x0209 ) <nl> return ; <nl> static void __init reserve_setup_data ( void ) <nl> reserve_early ( pa_data , pa_data + sizeof (* data )+ data -> len , buf ); <nl> e820_update_range ( pa_data , sizeof (* data )+ data -> len , <nl> E820_RAM , E820_RESERVED_KERN ); <nl> + found = 1 ; <nl> pa_data = data -> next ; <nl> early_iounmap ( data , sizeof (* data )); <nl> } <nl> + if (! found ) <nl> + return ; <nl> + <nl> sanitize_e820_map ( e820 . map , ARRAY_SIZE ( e820 . map ), & e820 . nr_map ); <nl> printk ( KERN_INFO " extended physical RAM map :\ n "); <nl> e820_print_map (" reserve setup_data ");
static struct snd_soc_codec_driver soc_codec_dev_wm8962 = { <nl> . remove = wm8962_remove , <nl> . resume = wm8962_resume , <nl> . set_bias_level = wm8962_set_bias_level , <nl> - . reg_cache_size = WM8962_MAX_REGISTER , <nl> + . reg_cache_size = WM8962_MAX_REGISTER + 1 , <nl> . reg_word_size = sizeof ( u16 ), <nl> . reg_cache_default = wm8962_reg , <nl> . volatile_register = wm8962_volatile_register ,
extern void integrator_secondary_startup ( void ); <nl> * control for which core is the next to come out of the secondary <nl> * boot " holding pen " <nl> */ <nl> - volatile int __initdata pen_release = - 1 ; <nl> - unsigned long __initdata phys_pen_release = 0 ; <nl> + volatile int __cpuinitdata pen_release = - 1 ; <nl> + unsigned long __cpuinitdata phys_pen_release = 0 ; <nl>  <nl> static DEFINE_SPINLOCK ( boot_lock ); <nl> 
static void hot_add_req ( struct work_struct * dummy ) <nl> memset (& resp , 0 , sizeof ( struct dm_hot_add_response )); <nl> resp . hdr . type = DM_MEM_HOT_ADD_RESPONSE ; <nl> resp . hdr . size = sizeof ( struct dm_hot_add_response ); <nl> - resp . hdr . trans_id = atomic_inc_return (& trans_id ); <nl>  <nl> # ifdef CONFIG_MEMORY_HOTPLUG <nl> pg_start = dm -> ha_wrk . ha_page_range . finfo . start_page ; <nl> static void hot_add_req ( struct work_struct * dummy ) <nl> pr_info (" Memory hot add failed \ n "); <nl>  <nl> dm -> state = DM_INITIALIZED ; <nl> + resp . hdr . trans_id = atomic_inc_return (& trans_id ); <nl> vmbus_sendpacket ( dm -> dev -> channel , & resp , <nl> sizeof ( struct dm_hot_add_response ), <nl> ( unsigned long ) NULL , <nl> static void balloon_up ( struct work_struct * dummy ) <nl> bl_resp = ( struct dm_balloon_response *) send_buffer ; <nl> memset ( send_buffer , 0 , PAGE_SIZE ); <nl> bl_resp -> hdr . type = DM_BALLOON_RESPONSE ; <nl> - bl_resp -> hdr . trans_id = atomic_inc_return (& trans_id ); <nl> bl_resp -> hdr . size = sizeof ( struct dm_balloon_response ); <nl> bl_resp -> more_pages = 1 ; <nl>  <nl> static void balloon_up ( struct work_struct * dummy ) <nl> */ <nl>  <nl> do { <nl> + bl_resp -> hdr . trans_id = atomic_inc_return (& trans_id ); <nl> ret = vmbus_sendpacket ( dm_device . dev -> channel , <nl> bl_resp , <nl> bl_resp -> hdr . size ,
static void sync_request_write ( struct mddev * mddev , struct r1bio * r1_bio ) <nl>  <nl> if ( atomic_dec_and_test (& r1_bio -> remaining )) { <nl> /* if we ' re here , all write ( s ) have completed , so clean up */ <nl> - md_done_sync ( mddev , r1_bio -> sectors , 1 ); <nl> - put_buf ( r1_bio ); <nl> + int s = r1_bio -> sectors ; <nl> + if ( test_bit ( R1BIO_MadeGood , & r1_bio -> state ) || <nl> + test_bit ( R1BIO_WriteError , & r1_bio -> state )) <nl> + reschedule_retry ( r1_bio ); <nl> + else { <nl> + put_buf ( r1_bio ); <nl> + md_done_sync ( mddev , s , 1 ); <nl> + } <nl> } <nl> } <nl> 
static int ip_vs_del_service ( struct ip_vs_service * svc ) <nl> /* <nl> * Flush all the virtual services <nl> */ <nl> - static int ip_vs_flush ( struct net * net , bool cleanup ) <nl> + static int ip_vs_flush ( struct netns_ipvs * ipvs , bool cleanup ) <nl> { <nl> - struct netns_ipvs * ipvs = net_ipvs ( net ); <nl> int idx ; <nl> struct ip_vs_service * svc ; <nl> struct hlist_node * n ; <nl> static int ip_vs_flush ( struct net * net , bool cleanup ) <nl> */ <nl> void ip_vs_service_net_cleanup ( struct net * net ) <nl> { <nl> + struct netns_ipvs * ipvs = net_ipvs ( net ); <nl> EnterFunction ( 2 ); <nl> /* Check for " full " addressed entries */ <nl> mutex_lock (& __ip_vs_mutex ); <nl> - ip_vs_flush ( net , true ); <nl> + ip_vs_flush ( ipvs , true ); <nl> mutex_unlock (& __ip_vs_mutex ); <nl> LeaveFunction ( 2 ); <nl> } <nl> do_ip_vs_set_ctl ( struct sock * sk , int cmd , void __user * user , unsigned int len ) <nl> mutex_lock (& __ip_vs_mutex ); <nl> if ( cmd == IP_VS_SO_SET_FLUSH ) { <nl> /* Flush the virtual service */ <nl> - ret = ip_vs_flush ( net , false ); <nl> + ret = ip_vs_flush ( ipvs , false ); <nl> goto out_unlock ; <nl> } else if ( cmd == IP_VS_SO_SET_TIMEOUT ) { <nl> /* Set timeout values for ( tcp tcpfin udp ) */ <nl> static int ip_vs_genl_set_cmd ( struct sk_buff * skb , struct genl_info * info ) <nl> mutex_lock (& __ip_vs_mutex ); <nl>  <nl> if ( cmd == IPVS_CMD_FLUSH ) { <nl> - ret = ip_vs_flush ( net , false ); <nl> + ret = ip_vs_flush ( ipvs , false ); <nl> goto out ; <nl> } else if ( cmd == IPVS_CMD_SET_CONFIG ) { <nl> ret = ip_vs_genl_set_config ( net , info -> attrs );
static ssize_t i40e_dbg_command_write ( struct file * filp , <nl> /* check the range on address */ <nl> if ( address > ( pf -> ioremap_len - sizeof ( u32 ))) { <nl> dev_info (& pf -> pdev -> dev , " read reg address 0x % 08x too large , max = 0x % 08lx \ n ", <nl> - address , ( pf -> ioremap_len - sizeof ( u32 ))); <nl> + address , ( unsigned long int )( pf -> ioremap_len - sizeof ( u32 ))); <nl> goto command_write_done ; <nl> } <nl>  <nl> static ssize_t i40e_dbg_command_write ( struct file * filp , <nl> /* check the range on address */ <nl> if ( address > ( pf -> ioremap_len - sizeof ( u32 ))) { <nl> dev_info (& pf -> pdev -> dev , " write reg address 0x % 08x too large , max = 0x % 08lx \ n ", <nl> - address , ( pf -> ioremap_len - sizeof ( u32 ))); <nl> + address , ( unsigned long int )( pf -> ioremap_len - sizeof ( u32 ))); <nl> goto command_write_done ; <nl> } <nl> wr32 (& pf -> hw , address , value );
static int add_std_chmaps ( struct hda_codec * codec ) <nl> struct snd_pcm_chmap * chmap ; <nl> const struct snd_pcm_chmap_elem * elem ; <nl>  <nl> - if (! pcm || ! pcm -> pcm || pcm -> own_chmap || <nl> - ! hinfo -> substreams ) <nl> + if (! pcm -> pcm || pcm -> own_chmap || ! hinfo -> substreams ) <nl> continue ; <nl> elem = hinfo -> chmap ? hinfo -> chmap : snd_pcm_std_chmaps ; <nl> err = snd_pcm_add_chmap_ctls ( pcm -> pcm , str , elem ,
static int hpsa_ioctl32_passthru ( struct scsi_device * dev , int cmd , void * arg ) <nl> int err ; <nl> u32 cp ; <nl>  <nl> + memset (& arg64 , 0 , sizeof ( arg64 )); <nl> err = 0 ; <nl> err |= copy_from_user (& arg64 . LUN_info , & arg32 -> LUN_info , <nl> sizeof ( arg64 . LUN_info )); <nl> static int hpsa_ioctl32_big_passthru ( struct scsi_device * dev , <nl> int err ; <nl> u32 cp ; <nl>  <nl> + memset (& arg64 , 0 , sizeof ( arg64 )); <nl> err = 0 ; <nl> err |= copy_from_user (& arg64 . LUN_info , & arg32 -> LUN_info , <nl> sizeof ( arg64 . LUN_info ));
static int rndis_change_virtual_intf ( struct wiphy * wiphy , int ifindex , <nl> static int rndis_scan ( struct wiphy * wiphy , struct net_device * dev , <nl> struct cfg80211_scan_request * request ); <nl>  <nl> - struct cfg80211_ops rndis_config_ops = { <nl> + static struct cfg80211_ops rndis_config_ops = { <nl> . change_virtual_intf = rndis_change_virtual_intf , <nl> . scan = rndis_scan , <nl> }; <nl>  <nl> - void * rndis_wiphy_privid = & rndis_wiphy_privid ; <nl> + static void * rndis_wiphy_privid = & rndis_wiphy_privid ; <nl>  <nl> static const int bcm4320_power_output [ 4 ] = { 25 , 50 , 75 , 100 }; <nl> 
static void mv643xx_eth_free_tx_rings ( struct net_device * dev ) <nl> struct mv643xx_private * mp = netdev_priv ( dev ); <nl> unsigned int port_num = mp -> port_num ; <nl> unsigned int curr ; <nl> + struct sk_buff * skb ; <nl>  <nl> /* Stop Tx Queues */ <nl> mv_write ( MV643XX_ETH_TRANSMIT_QUEUE_COMMAND_REG ( port_num ), 0x0000ff00 ); <nl>  <nl> /* Free outstanding skb ' s on TX rings */ <nl> for ( curr = 0 ; mp -> tx_ring_skbs && curr < mp -> tx_ring_size ; curr ++) { <nl> - if ( mp -> tx_skb [ curr ]) { <nl> - dev_kfree_skb ( mp -> tx_skb [ curr ]); <nl> + skb = mp -> tx_skb [ curr ]; <nl> + if ( skb ) { <nl> + mp -> tx_ring_skbs -= skb_shinfo ( skb )-> nr_frags ; <nl> + dev_kfree_skb ( skb ); <nl> mp -> tx_ring_skbs --; <nl> } <nl> }
int i915_vma_unbind ( struct i915_vma * vma ) <nl> * cause memory corruption through use - after - free . <nl> */ <nl>  <nl> + /* Throw away the active reference before moving to the unbound list */ <nl> + i915_gem_object_retire ( obj ); <nl> + <nl> if ( i915_is_ggtt ( vma -> vm )) { <nl> i915_gem_object_finish_gtt ( obj ); <nl> 
static void collapse_huge_page ( struct mm_struct * mm , <nl> set_pmd_at ( mm , address , pmd , _pmd ); <nl> spin_unlock (& mm -> page_table_lock ); <nl> anon_vma_unlock ( vma -> anon_vma ); <nl> - mem_cgroup_uncharge_page ( new_page ); <nl> goto out ; <nl> } <nl>  <nl> out_up_write : <nl> return ; <nl>  <nl> out : <nl> + mem_cgroup_uncharge_page ( new_page ); <nl> # ifdef CONFIG_NUMA <nl> put_page ( new_page ); <nl> # endif
static int el3_start_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl> { <nl> kio_addr_t ioaddr = dev -> base_addr ; <nl> struct el3_private * priv = netdev_priv ( dev ); <nl> + unsigned long flags ; <nl>  <nl> DEBUG ( 3 , "% s : el3_start_xmit ( length = % ld ) called , " <nl> " status % 4 . 4x .\ n ", dev -> name , ( long ) skb -> len , <nl> inw ( ioaddr + EL3_STATUS )); <nl>  <nl> + spin_lock_irqsave (& priv -> lock , flags ); <nl> + <nl> priv -> stats . tx_bytes += skb -> len ; <nl>  <nl> /* Put out the doubleword header ... */ <nl> static int el3_start_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl>  <nl> dev_kfree_skb ( skb ); <nl> pop_tx_status ( dev ); <nl> + spin_unlock_irqrestore (& priv -> lock , flags ); <nl>  <nl> return 0 ; <nl> } <nl> static void media_check ( unsigned long arg ) <nl>  <nl> if (! netif_device_present ( dev )) goto reschedule ; <nl>  <nl> - EL3WINDOW ( 1 ); <nl> /* Check for pending interrupt with expired latency timer : with <nl> this , we can limp along even if the interrupt is blocked */ <nl> if (( inw ( ioaddr + EL3_STATUS ) & IntLatch ) && <nl> ( inb ( ioaddr + EL3_TIMER ) == 0xff )) { <nl> if (! lp -> fast_poll ) <nl> printk ( KERN_WARNING "% s : interrupt ( s ) dropped !\ n ", dev -> name ); <nl> - el3_interrupt ( dev -> irq , lp ); <nl> + el3_interrupt ( dev -> irq , dev ); <nl> lp -> fast_poll = HZ ; <nl> } <nl> if ( lp -> fast_poll ) {
# define VI6_DISP_IRQ_ENB 0x0078 <nl> # define VI6_DISP_IRQ_ENB_DSTE ( 1 << 8 ) <nl> # define VI6_DISP_IRQ_ENB_MAEE ( 1 << 5 ) <nl> -# define VI6_DISP_IRQ_ENB_LNEE ( n ) ( 1 << (( n ) + 4 )) <nl> +# define VI6_DISP_IRQ_ENB_LNEE ( n ) ( 1 << ( n )) <nl>  <nl> # define VI6_DISP_IRQ_STA 0x007c <nl> # define VI6_DISP_IRQ_STA_DSE ( 1 << 8 )
void pps_event ( struct pps_device * pps , struct pps_event_time * ts , int event , <nl> int captured = 0 ; <nl> struct pps_ktime ts_real ; <nl>  <nl> - if (( event & ( PPS_CAPTUREASSERT | PPS_CAPTURECLEAR )) == 0 ) { <nl> - dev_err ( pps -> dev , " unknown event (% x )\ n ", event ); <nl> - return ; <nl> - } <nl> + /* check event type */ <nl> + BUG_ON (( event & ( PPS_CAPTUREASSERT | PPS_CAPTURECLEAR )) == 0 ); <nl>  <nl> dev_dbg ( pps -> dev , " PPS event at % ld .% 09ld \ n ", <nl> ts -> ts_real . tv_sec , ts -> ts_real . tv_nsec );
static unsigned long super_cache_scan ( struct shrinker * shrink , <nl> inodes = list_lru_count_node (& sb -> s_inode_lru , sc -> nid ); <nl> dentries = list_lru_count_node (& sb -> s_dentry_lru , sc -> nid ); <nl> total_objects = dentries + inodes + fs_objects + 1 ; <nl> + if (! total_objects ) <nl> + total_objects = 1 ; <nl>  <nl> /* proportion the scan between the caches */ <nl> dentries = mult_frac ( sc -> nr_to_scan , dentries , total_objects );
dsa_slave_create ( struct dsa_switch * ds , struct device * parent , <nl> netif_carrier_off ( slave_dev ); <nl>  <nl> if ( p -> phy != NULL ) { <nl> - if ( ds -> drv -> get_phy_flags ( ds , port )) <nl> + if ( ds -> drv -> get_phy_flags ) <nl> p -> phy -> dev_flags |= ds -> drv -> get_phy_flags ( ds , port ); <nl>  <nl> phy_attach ( slave_dev , dev_name (& p -> phy -> dev ),
static const struct net_device_ops ixp4xx_netdev_ops = { <nl> . ndo_validate_addr = eth_validate_addr , <nl> }; <nl>  <nl> - static int __devinit eth_init_one ( struct platform_device * pdev ) <nl> + static int eth_init_one ( struct platform_device * pdev ) <nl> { <nl> struct port * port ; <nl> struct net_device * dev ; <nl> err_free : <nl> return err ; <nl> } <nl>  <nl> - static int __devexit eth_remove_one ( struct platform_device * pdev ) <nl> + static int eth_remove_one ( struct platform_device * pdev ) <nl> { <nl> struct net_device * dev = platform_get_drvdata ( pdev ); <nl> struct port * port = netdev_priv ( dev );
static void __init tegra210_pll_init ( void __iomem * clk_base , <nl>  <nl> /* PLLU_VCO */ <nl> val = readl ( clk_base + pll_u_vco_params . base_reg ); <nl> - val &= ~ BIT ( 24 ); /* disable PLLU_OVERRIDE */ <nl> + val &= ~ PLLU_BASE_OVERRIDE ; /* disable PLLU_OVERRIDE */ <nl> writel ( val , clk_base + pll_u_vco_params . base_reg ); <nl>  <nl> clk = tegra_clk_register_pllre (" pll_u_vco ", " pll_ref ", clk_base , pmc ,
static void __init stp_reset ( void ) <nl>  <nl> stp_page = alloc_bootmem_pages ( PAGE_SIZE ); <nl> rc = chsc_sstpc ( stp_page , STP_OP_CTRL , 0x0000 ); <nl> - if ( rc == 1 ) <nl> + if ( rc == 0 ) <nl> set_bit ( CLOCK_SYNC_HAS_STP , & clock_sync_flags ); <nl> else if ( stp_online ) { <nl> printk ( KERN_WARNING " Running on non STP capable machine .\ n ");
static struct nlm_host * nlm_lookup_host ( struct nlm_lookup_host_info * ni ) <nl> continue ; <nl> if ( host -> h_server != ni -> server ) <nl> continue ; <nl> - if (! nlm_cmp_addr ( nlm_srcaddr ( host ), ni -> src_sap )) <nl> + if ( ni -> server && <nl> + ! nlm_cmp_addr ( nlm_srcaddr ( host ), ni -> src_sap )) <nl> continue ; <nl>  <nl> /* Move to head of hash chain . */
static int perf_event__repipe_attr ( struct perf_tool * tool , <nl> union perf_event * event , <nl> struct perf_evlist ** pevlist ) <nl> { <nl> + struct perf_inject * inject = container_of ( tool , struct perf_inject , <nl> + tool ); <nl> int ret ; <nl>  <nl> ret = perf_event__process_attr ( tool , event , pevlist ); <nl> if ( ret ) <nl> return ret ; <nl>  <nl> + if (! inject -> pipe_output ) <nl> + return 0 ; <nl> + <nl> return perf_event__repipe_synth ( tool , event ); <nl> } <nl> 
static ssize_t kpagecount_read ( struct file * file , char __user * buf , <nl> pfn ++; <nl> out ++; <nl> count -= KPMSIZE ; <nl> + <nl> + cond_resched (); <nl> } <nl>  <nl> * ppos += ( char __user *) out - buf ; <nl> static ssize_t kpageflags_read ( struct file * file , char __user * buf , <nl> pfn ++; <nl> out ++; <nl> count -= KPMSIZE ; <nl> + <nl> + cond_resched (); <nl> } <nl>  <nl> * ppos += ( char __user *) out - buf ; <nl> static ssize_t kpagecgroup_read ( struct file * file , char __user * buf , <nl> pfn ++; <nl> out ++; <nl> count -= KPMSIZE ; <nl> + <nl> + cond_resched (); <nl> } <nl>  <nl> * ppos += ( char __user *) out - buf ;
static int __init ide_generic_init ( void ) <nl> for ( i = 0 ; i < MAX_HWIFS ; i ++) { <nl> ide_hwif_t * hwif = & ide_hwifs [ i ]; <nl>  <nl> - if ( hwif -> io_ports [ IDE_DATA_OFFSET ] && ! hwif -> present ) <nl> + if ( hwif -> io_ports [ IDE_DATA_OFFSET ] && <nl> + ( hwif -> chipset == ide_unknown || <nl> + hwif -> chipset == ide_forced )) <nl> idx [ i ] = i ; <nl> else <nl> idx [ i ] = 0xff ;
ipv6 : <nl> case IPPROTO_IPIP : <nl> proto = htons ( ETH_P_IP ); <nl> goto ip ; <nl> + case IPPROTO_IPV6 : <nl> + proto = htons ( ETH_P_IPV6 ); <nl> + goto ipv6 ; <nl> default : <nl> break ; <nl> }
static int fcoe_if_destroy ( struct net_device * netdev ) <nl> /* tear - down the FCoE controller */ <nl> fcoe_ctlr_destroy (& fc -> ctlr ); <nl>  <nl> + /* Free queued packets for the per - CPU receive threads */ <nl> + fcoe_percpu_clean ( lp ); <nl> + <nl> /* Cleanup the fc_lport */ <nl> fc_lport_destroy ( lp ); <nl> fc_fcp_destroy ( lp ); <nl> static int fcoe_if_destroy ( struct net_device * netdev ) <nl> if ( lp -> emp ) <nl> fc_exch_mgr_free ( lp -> emp ); <nl>  <nl> - /* Free the per - CPU receive threads */ <nl> - fcoe_percpu_clean ( lp ); <nl> - <nl> /* Free existing skbs */ <nl> fcoe_clean_pending_queue ( lp ); <nl> 
static int i915_drm_resume ( struct drm_device * dev ) <nl>  <nl> intel_modeset_init_hw ( dev ); <nl>  <nl> - { <nl> - spin_lock_irq (& dev_priv -> irq_lock ); <nl> - if ( dev_priv -> display . hpd_irq_setup ) <nl> - dev_priv -> display . hpd_irq_setup ( dev ); <nl> - spin_unlock_irq (& dev_priv -> irq_lock ); <nl> - } <nl> + spin_lock_irq (& dev_priv -> irq_lock ); <nl> + if ( dev_priv -> display . hpd_irq_setup ) <nl> + dev_priv -> display . hpd_irq_setup ( dev ); <nl> + spin_unlock_irq (& dev_priv -> irq_lock ); <nl>  <nl> intel_dp_mst_resume ( dev ); <nl> drm_modeset_lock_all ( dev );
static int create_i2c_bus ( struct i2c_adapter * adapter , <nl> algo -> setscl = via_i2c_setscl ; <nl> algo -> getsda = via_i2c_getsda ; <nl> algo -> getscl = via_i2c_getscl ; <nl> - algo -> udelay = 40 ; <nl> - algo -> timeout = 20 ; <nl> + algo -> udelay = 10 ; <nl> + algo -> timeout = 2 ; <nl> algo -> data = adap_cfg ; <nl>  <nl> sprintf ( adapter -> name , " viafb i2c io_port idx 0x % 02x ",
static int binder_mmap ( struct file * filp , struct vm_area_struct * vma ) <nl> const char * failure_string ; <nl> struct binder_buffer * buffer ; <nl>  <nl> + if ( proc -> tsk != current ) <nl> + return - EINVAL ; <nl> + <nl> if (( vma -> vm_end - vma -> vm_start ) > SZ_4M ) <nl> vma -> vm_end = vma -> vm_start + SZ_4M ; <nl>  <nl> static int binder_mmap ( struct file * filp , struct vm_area_struct * vma ) <nl> binder_insert_free_buffer ( proc , buffer ); <nl> proc -> free_async_space = proc -> buffer_size / 2 ; <nl> barrier (); <nl> - proc -> files = get_files_struct ( proc -> tsk ); <nl> + proc -> files = get_files_struct ( current ); <nl> proc -> vma = vma ; <nl> proc -> vma_vm_mm = vma -> vm_mm ; <nl> 
static int i2o_cfg_parms ( unsigned long arg , unsigned int type ) <nl> if (! dev ) <nl> return - ENXIO ; <nl>  <nl> + /* <nl> + * Stop users being able to try and allocate arbitary amounts <nl> + * of DMA space . 64K is way more than sufficient for this . <nl> + */ <nl> + if ( kcmd . oplen > 65536 ) <nl> + return - EMSGSIZE ; <nl> + <nl> ops = memdup_user ( kcmd . opbuf , kcmd . oplen ); <nl> if ( IS_ERR ( ops )) <nl> return PTR_ERR ( ops );
static int cfg80211_netdev_notifier_call ( struct notifier_block * nb , <nl> * Configure power management to the driver here so that its <nl> * correctly set also after interface type changes etc . <nl> */ <nl> - if ( wdev -> iftype == NL80211_IFTYPE_STATION && <nl> + if (( wdev -> iftype == NL80211_IFTYPE_STATION || <nl> + wdev -> iftype == NL80211_IFTYPE_P2P_CLIENT ) && <nl> rdev -> ops -> set_power_mgmt ) <nl> if ( rdev -> ops -> set_power_mgmt ( wdev -> wiphy , dev , <nl> wdev -> ps ,
static void ixgbe_reset_subtask ( struct ixgbe_adapter * adapter ) <nl> netdev_err ( adapter -> netdev , " Reset adapter \ n "); <nl> adapter -> tx_timeout_count ++; <nl>  <nl> + rtnl_lock (); <nl> ixgbe_reinit_locked ( adapter ); <nl> + rtnl_unlock (); <nl> } <nl>  <nl> /**
static int __devinit sdhci_probe_slot ( struct pci_dev * pdev , int slot ) <nl>  <nl> version = readw ( host -> ioaddr + SDHCI_HOST_VERSION ); <nl> version = ( version & SDHCI_SPEC_VER_MASK ) >> SDHCI_SPEC_VER_SHIFT ; <nl> - if ( version != 0 ) { <nl> + if ( version > 1 ) { <nl> printk ( KERN_ERR "% s : Unknown controller version (% d ). " <nl> " You may experience problems .\ n ", host -> slot_descr , <nl> version );
dispatch_ioctl ( struct client * client , unsigned int cmd , void __user * arg ) <nl> return - EFAULT ; <nl> } <nl>  <nl> - return 0 ; <nl> + return retval ; <nl> } <nl>  <nl> static long
static int get_victim_by_default ( struct f2fs_sb_info * sbi , <nl> unsigned int secno , max_cost ; <nl> int nsearched = 0 ; <nl>  <nl> + mutex_lock (& dirty_i -> seglist_lock ); <nl> + <nl> p . alloc_mode = alloc_mode ; <nl> select_policy ( sbi , gc_type , type , & p ); <nl>  <nl> p . min_segno = NULL_SEGNO ; <nl> p . min_cost = max_cost = get_max_cost ( sbi , & p ); <nl>  <nl> - mutex_lock (& dirty_i -> seglist_lock ); <nl> - <nl> if ( p . alloc_mode == LFS && gc_type == FG_GC ) { <nl> p . min_segno = check_bg_victims ( sbi ); <nl> if ( p . min_segno != NULL_SEGNO )
static inline int r600_cs_track_validate_cb ( struct radeon_cs_parser * p , int i ) <nl> if ( array_mode == V_0280A0_ARRAY_LINEAR_GENERAL ) { <nl> /* the initial DDX does bad things with the CB size occasionally */ <nl> /* it rounds up height too far for slice tile max but the BO is smaller */ <nl> - tmp = ( height - 7 ) * pitch * bpe ; <nl> + tmp = ( height - 7 ) * 8 * bpe ; <nl> if (( tmp + track -> cb_color_bo_offset [ i ]) > radeon_bo_size ( track -> cb_color_bo [ i ])) { <nl> dev_warn ( p -> dev , "% s offset [% d ] % d % d % lu too big \ n ", __func__ , i , track -> cb_color_bo_offset [ i ], tmp , radeon_bo_size ( track -> cb_color_bo [ i ])); <nl> return - EINVAL ;
static int dispatch_procfs_write ( struct file * file , <nl>  <nl> if (! ibm || ! ibm -> write ) <nl> return - EINVAL ; <nl> + if ( count > PAGE_SIZE - 2 ) <nl> + return - EINVAL ; <nl>  <nl> kernbuf = kmalloc ( count + 2 , GFP_KERNEL ); <nl> if (! kernbuf )
static struct scsi_host_template aha1740_template = { <nl>  <nl> static int aha1740_probe ( struct device * dev ) <nl> { <nl> - int slotbase ; <nl> + int slotbase , rc ; <nl> unsigned int irq_level , irq_type , translation ; <nl> struct Scsi_Host * shpnt ; <nl> struct aha1740_hostdata * host ; <nl> static int aha1740_probe ( struct device * dev ) <nl> } <nl>  <nl> eisa_set_drvdata ( edev , shpnt ); <nl> - scsi_add_host ( shpnt , dev ); /* XXX handle failure */ <nl> + <nl> + rc = scsi_add_host ( shpnt , dev ); <nl> + if ( rc ) <nl> + goto err_irq ; <nl> + <nl> scsi_scan_host ( shpnt ); <nl> return 0 ; <nl>  <nl> + err_irq : <nl> + free_irq ( irq_level , shpnt ); <nl> err_unmap : <nl> dma_unmap_single (& edev -> dev , host -> ecb_dma_addr , <nl> sizeof ( host -> ecb ), DMA_BIDIRECTIONAL );
int setup_one_line ( struct line * lines , int n , char * init , <nl> * error_out = " Failed to allocate memory "; <nl> return - ENOMEM ; <nl> } <nl> - if ( line -> valid ) <nl> + if ( line -> valid ) { <nl> tty_unregister_device ( driver , n ); <nl> + kfree ( line -> init_str ); <nl> + } <nl> line -> init_str = new ; <nl> line -> valid = 1 ; <nl> err = parse_chan_pair ( new , line , n , opts , error_out );
static ssize_t ext4_ind_direct_IO ( int rw , struct kiocb * iocb , <nl> } <nl>  <nl> retry : <nl> - ret = blockdev_direct_IO ( rw , iocb , inode , inode -> i_sb -> s_bdev , iov , <nl> + if ( rw == READ && ext4_should_dioread_nolock ( inode )) <nl> + ret = blockdev_direct_IO_no_locking ( rw , iocb , inode , <nl> + inode -> i_sb -> s_bdev , iov , <nl> + offset , nr_segs , <nl> + ext4_get_block , NULL ); <nl> + else <nl> + ret = blockdev_direct_IO ( rw , iocb , inode , <nl> + inode -> i_sb -> s_bdev , iov , <nl> offset , nr_segs , <nl> ext4_get_block , NULL ); <nl> if ( ret == - ENOSPC && ext4_should_retry_alloc ( inode -> i_sb , & retries ))
static int wm8731_check_osc ( struct snd_soc_dapm_widget * source , <nl> { <nl> struct wm8731_priv * wm8731 = snd_soc_codec_get_drvdata ( source -> codec ); <nl>  <nl> - return wm8731 -> sysclk_type == WM8731_SYSCLK_MCLK ; <nl> + return wm8731 -> sysclk_type == WM8731_SYSCLK_XTAL ; <nl> } <nl>  <nl> static const struct snd_soc_dapm_route wm8731_intercon [] = {
static int omap_pcm_open ( struct snd_pcm_substream * substream ) <nl> if ( ret < 0 ) <nl> goto out ; <nl>  <nl> - prtd = kzalloc ( sizeof ( prtd ), GFP_KERNEL ); <nl> + prtd = kzalloc ( sizeof (* prtd ), GFP_KERNEL ); <nl> if ( prtd == NULL ) { <nl> ret = - ENOMEM ; <nl> goto out ;
int datagram_send_ctl ( struct net * net , struct sock * sk , <nl>  <nl> if ( addr_type != IPV6_ADDR_ANY ) { <nl> int strict = __ipv6_addr_src_scope ( addr_type ) <= IPV6_ADDR_SCOPE_LINKLOCAL ; <nl> - if (! inet_sk ( sk )-> transparent && <nl> + if (!( inet_sk ( sk )-> freebind || inet_sk ( sk )-> transparent ) && <nl> ! ipv6_chk_addr ( net , & src_info -> ipi6_addr , <nl> strict ? dev : NULL , 0 )) <nl> err = - EINVAL ;
static const char * vgacon_startup ( void ) <nl> # endif <nl> } <nl>  <nl> + /* SCREEN_INFO initialized ? */ <nl> + if (( ORIG_VIDEO_MODE == 0 ) && <nl> + ( ORIG_VIDEO_LINES == 0 ) && <nl> + ( ORIG_VIDEO_COLS == 0 )) <nl> + goto no_vga ; <nl> + <nl> /* VGA16 modes are not handled by VGACON */ <nl> - if (( ORIG_VIDEO_MODE == 0x00 ) || /* SCREEN_INFO not initialized */ <nl> - ( ORIG_VIDEO_MODE == 0x0D ) || /* 320x200 / 4 */ <nl> + if (( ORIG_VIDEO_MODE == 0x0D ) || /* 320x200 / 4 */ <nl> ( ORIG_VIDEO_MODE == 0x0E ) || /* 640x200 / 4 */ <nl> ( ORIG_VIDEO_MODE == 0x10 ) || /* 640x350 / 4 */ <nl> ( ORIG_VIDEO_MODE == 0x12 ) || /* 640x480 / 4 */
static int omap_sham_finup ( struct ahash_request * req ) <nl> ctx -> flags |= FLAGS_FINUP ; <nl>  <nl> err1 = omap_sham_update ( req ); <nl> - if ( err1 == - EINPROGRESS ) <nl> + if ( err1 == - EINPROGRESS || err1 == - EBUSY ) <nl> return err1 ; <nl> /* <nl> * final () has to be always called to cleanup resources
static ssize_t dev_attr_show ( struct kobject * kobj , struct attribute * attr , <nl> if ( dev_attr -> show ) <nl> ret = dev_attr -> show ( dev , dev_attr , buf ); <nl> if ( ret >= ( ssize_t ) PAGE_SIZE ) { <nl> - printk (" dev_attr_show : % pSR returned bad count \ n ", <nl> - dev_attr -> show ); <nl> + print_symbol (" dev_attr_show : % s returned bad count \ n ", <nl> + ( unsigned long ) dev_attr -> show ); <nl> } <nl> return ret ; <nl> }
failed : <nl> static void unlink_all_urbs ( struct esd_usb2 * dev ) <nl> { <nl> struct esd_usb2_net_priv * priv ; <nl> - int i ; <nl> + int i , j ; <nl>  <nl> usb_kill_anchored_urbs (& dev -> rx_submitted ); <nl> for ( i = 0 ; i < dev -> net_count ; i ++) { <nl> static void unlink_all_urbs ( struct esd_usb2 * dev ) <nl> usb_kill_anchored_urbs (& priv -> tx_submitted ); <nl> atomic_set (& priv -> active_tx_jobs , 0 ); <nl>  <nl> - for ( i = 0 ; i < MAX_TX_URBS ; i ++) <nl> - priv -> tx_contexts [ i ]. echo_index = MAX_TX_URBS ; <nl> + for ( j = 0 ; j < MAX_TX_URBS ; j ++) <nl> + priv -> tx_contexts [ j ]. echo_index = MAX_TX_URBS ; <nl> } <nl> } <nl> }
static __kprobes void kprobe_optimizer ( struct work_struct * work ) <nl> { <nl> LIST_HEAD ( free_list ); <nl>  <nl> + mutex_lock (& kprobe_mutex ); <nl> /* Lock modules while optimizing kprobes */ <nl> mutex_lock (& module_mutex ); <nl> - mutex_lock (& kprobe_mutex ); <nl>  <nl> /* <nl> * Step 1 : Unoptimize kprobes and collect cleaned ( unused and disarmed ) <nl> static __kprobes void kprobe_optimizer ( struct work_struct * work ) <nl> /* Step 4 : Free cleaned kprobes after quiesence period */ <nl> do_free_cleaned_kprobes (& free_list ); <nl>  <nl> - mutex_unlock (& kprobe_mutex ); <nl> mutex_unlock (& module_mutex ); <nl> + mutex_unlock (& kprobe_mutex ); <nl>  <nl> /* Step 5 : Kick optimizer again if needed */ <nl> if (! list_empty (& optimizing_list ) || ! list_empty (& unoptimizing_list ))
static void * cramfs_read ( struct super_block * sb , unsigned int offset , unsigned i <nl> { <nl> struct address_space * mapping = sb -> s_bdev -> bd_inode -> i_mapping ; <nl> struct page * pages [ BLKS_PER_BUF ]; <nl> - unsigned i , blocknr , buffer , unread ; <nl> + unsigned i , blocknr , buffer ; <nl> unsigned long devsize ; <nl> char * data ; <nl>  <nl> static void * cramfs_read ( struct super_block * sb , unsigned int offset , unsigned i <nl> devsize = mapping -> host -> i_size >> PAGE_CACHE_SHIFT ; <nl>  <nl> /* Ok , read in BLKS_PER_BUF pages completely first . */ <nl> - unread = 0 ; <nl> for ( i = 0 ; i < BLKS_PER_BUF ; i ++) { <nl> struct page * page = NULL ; <nl> 
static int create_input_ctls ( struct hda_codec * codec ) <nl> static struct nid_path * get_input_path ( struct hda_codec * codec , int adc_idx , int imux_idx ) <nl> { <nl> struct hda_gen_spec * spec = codec -> spec ; <nl> + if ( imux_idx < 0 || imux_idx >= HDA_MAX_NUM_INPUTS ) { <nl> + snd_BUG (); <nl> + return NULL ; <nl> + } <nl> if ( spec -> dyn_adc_switch ) <nl> adc_idx = spec -> dyn_adc_idx [ imux_idx ]; <nl> + if ( adc_idx < 0 || adc_idx >= AUTO_CFG_MAX_OUTS ) { <nl> + snd_BUG (); <nl> + return NULL ; <nl> + } <nl> return snd_hda_get_path_from_idx ( codec , spec -> input_paths [ imux_idx ][ adc_idx ]); <nl> } <nl> 
smb_send_kvec ( struct TCP_Server_Info * server , struct kvec * iov , size_t n_vec , <nl> rc = kernel_sendmsg ( ssocket , & smb_msg , & iov [ first_vec ], <nl> n_vec - first_vec , remaining ); <nl> if ( rc == - ENOSPC || rc == - EAGAIN ) { <nl> + /* <nl> + * Catch if a low level driver returns - ENOSPC . This <nl> + * WARN_ON will be removed by 3 . 10 if no one reports <nl> + * seeing this . <nl> + */ <nl> + WARN_ON_ONCE ( rc == - ENOSPC ); <nl> i ++; <nl> if ( i >= 14 || (! server -> noblocksnd && ( i > 2 ))) { <nl> cERROR ( 1 , " sends on sock % p stuck for 15 "
static void do_reads ( struct mirror_set * ms , struct bio_list * reads ) <nl> /* <nl> * We can only read balance if the region is in sync . <nl> */ <nl> - if ( rh_in_sync (& ms -> rh , region , 0 )) <nl> + if ( rh_in_sync (& ms -> rh , region , 1 )) <nl> m = choose_mirror ( ms , bio -> bi_sector ); <nl> else <nl> m = ms -> default_mirror ;
static void prepare_dma ( struct s3c64xx_spi_dma_data * dma , <nl> struct scatterlist sg ; <nl> struct dma_async_tx_descriptor * desc ; <nl>  <nl> + memset (& config , 0 , sizeof ( config )); <nl> + <nl> if ( dma -> direction == DMA_DEV_TO_MEM ) { <nl> sdd = container_of (( void *) dma , <nl> struct s3c64xx_spi_driver_data , rx_dma );
static int da732x_hpf_set ( struct snd_kcontrol * kcontrol , <nl> struct snd_soc_codec * codec = snd_soc_kcontrol_codec ( kcontrol ); <nl> struct soc_enum * enum_ctrl = ( struct soc_enum *) kcontrol -> private_value ; <nl> unsigned int reg = enum_ctrl -> reg ; <nl> - unsigned int sel = ucontrol -> value . integer . value [ 0 ]; <nl> + unsigned int sel = ucontrol -> value . enumerated . item [ 0 ]; <nl> unsigned int bits ; <nl>  <nl> switch ( sel ) { <nl> static int da732x_hpf_get ( struct snd_kcontrol * kcontrol , <nl>  <nl> switch ( val ) { <nl> case DA732X_HPF_VOICE_EN : <nl> - ucontrol -> value . integer . value [ 0 ] = DA732X_HPF_VOICE ; <nl> + ucontrol -> value . enumerated . item [ 0 ] = DA732X_HPF_VOICE ; <nl> break ; <nl> case DA732X_HPF_MUSIC_EN : <nl> - ucontrol -> value . integer . value [ 0 ] = DA732X_HPF_MUSIC ; <nl> + ucontrol -> value . enumerated . item [ 0 ] = DA732X_HPF_MUSIC ; <nl> break ; <nl> default : <nl> - ucontrol -> value . integer . value [ 0 ] = DA732X_HPF_DISABLED ; <nl> + ucontrol -> value . enumerated . item [ 0 ] = DA732X_HPF_DISABLED ; <nl> break ; <nl> } <nl> 
static void dmaengine_pcm_request_chan_of ( struct dmaengine_pcm * pcm , <nl> return ; <nl>  <nl> if ( pcm -> flags & SND_DMAENGINE_PCM_FLAG_HALF_DUPLEX ) { <nl> - pcm -> chan [ 0 ] = of_dma_request_slave_channel ( of_node , " tx_rx "); <nl> + pcm -> chan [ 0 ] = of_dma_request_slave_channel ( of_node , " rx - tx "); <nl> pcm -> chan [ 1 ] = pcm -> chan [ 0 ]; <nl> } else { <nl> for ( i = SNDRV_PCM_STREAM_PLAYBACK ; i <= SNDRV_PCM_STREAM_CAPTURE ; i ++) {
static __cpuinit int thermal_throttle_cpu_callback ( struct notifier_block * nfb , <nl> int err ; <nl>  <nl> sys_dev = get_cpu_sysdev ( cpu ); <nl> - mutex_lock (& therm_cpu_lock ); <nl> switch ( action ) { <nl> case CPU_ONLINE : <nl> case CPU_ONLINE_FROZEN : <nl> + mutex_lock (& therm_cpu_lock ); <nl> err = thermal_throttle_add_dev ( sys_dev ); <nl> + mutex_unlock (& therm_cpu_lock ); <nl> WARN_ON ( err ); <nl> break ; <nl> case CPU_DEAD : <nl> case CPU_DEAD_FROZEN : <nl> + mutex_lock (& therm_cpu_lock ); <nl> thermal_throttle_remove_dev ( sys_dev ); <nl> + mutex_unlock (& therm_cpu_lock ); <nl> break ; <nl> } <nl> - mutex_unlock (& therm_cpu_lock ); <nl> return NOTIFY_OK ; <nl> } <nl> 
done : <nl> if ( status ) { <nl> if ( dma_channel_status ( dma ) == MUSB_DMA_STATUS_BUSY ) { <nl> dma -> status = MUSB_DMA_STATUS_CORE_ABORT ; <nl> - ( void ) musb -> dma_controller -> channel_abort ( dma ); <nl> + musb -> dma_controller -> channel_abort ( dma ); <nl> } <nl>  <nl> /* do the proper sequence to abort the transfer in the <nl> void musb_host_rx ( struct musb * musb , u8 epnum ) <nl> /* clean up dma and collect transfer count */ <nl> if ( dma_channel_status ( dma ) == MUSB_DMA_STATUS_BUSY ) { <nl> dma -> status = MUSB_DMA_STATUS_CORE_ABORT ; <nl> - ( void ) musb -> dma_controller -> channel_abort ( dma ); <nl> + musb -> dma_controller -> channel_abort ( dma ); <nl> xfer_len = dma -> actual_len ; <nl> } <nl> musb_h_flush_rxfifo ( hw_ep , MUSB_RXCSR_CLRDATATOG ); <nl> void musb_host_rx ( struct musb * musb , u8 epnum ) <nl> */ <nl> if ( dma_channel_status ( dma ) == MUSB_DMA_STATUS_BUSY ) { <nl> dma -> status = MUSB_DMA_STATUS_CORE_ABORT ; <nl> - ( void ) musb -> dma_controller -> channel_abort ( dma ); <nl> + musb -> dma_controller -> channel_abort ( dma ); <nl> xfer_len = dma -> actual_len ; <nl> done = true ; <nl> }
static unsigned int inline norm_fsc8 ( struct cx88_tvnorm * norm ) <nl> { <nl> static const unsigned int ntsc = 28636360 ; <nl> static const unsigned int pal = 35468950 ; <nl> + static const unsigned int palm = 28604892 ; <nl> + <nl> + if ( norm -> id & V4L2_STD_PAL_M ) <nl> + return palm ; <nl>  <nl> return ( norm -> id & V4L2_STD_625_50 ) ? pal : ntsc ; <nl> } <nl> static unsigned int inline norm_notchfilter ( struct cx88_tvnorm * norm ) <nl>  <nl> static unsigned int inline norm_htotal ( struct cx88_tvnorm * norm ) <nl> { <nl> + /* Should always be Line Draw Time / ( 4 * FSC ) */ <nl> + <nl> + if ( norm -> id & V4L2_STD_PAL_M ) <nl> + return 909 ; <nl> + <nl> return ( norm -> id & V4L2_STD_625_50 ) ? 1135 : 910 ; <nl> } <nl> 
static netdev_tx_t tg3_start_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl> struct iphdr * iph ; <nl> u32 tcp_opt_len , hdr_len ; <nl>  <nl> - if ( skb_header_cloned ( skb ) && <nl> - pskb_expand_head ( skb , 0 , 0 , GFP_ATOMIC )) <nl> + if ( skb_cow_head ( skb , 0 )) <nl> goto drop ; <nl>  <nl> iph = ip_hdr ( skb );
static int ath10k_pci_post_rx_pipe ( struct ath10k_pci_pipe * pipe_info , <nl> static void ath10k_pci_rx_pipe_cleanup ( struct ath10k_pci_pipe * pipe_info ); <nl> static void ath10k_pci_stop_ce ( struct ath10k * ar ); <nl> static void ath10k_pci_device_reset ( struct ath10k * ar ); <nl> - static int ath10k_pci_reset_target ( struct ath10k * ar ); <nl> + static int ath10k_pci_wait_for_target_init ( struct ath10k * ar ); <nl> static int ath10k_pci_start_intr ( struct ath10k * ar ); <nl> static void ath10k_pci_stop_intr ( struct ath10k * ar ); <nl>  <nl> static int ath10k_pci_hif_power_up ( struct ath10k * ar ) <nl> */ <nl> ath10k_pci_device_reset ( ar ); <nl>  <nl> - ret = ath10k_pci_reset_target ( ar ); <nl> + ret = ath10k_pci_wait_for_target_init ( ar ); <nl> if ( ret ) <nl> goto err_irq ; <nl>  <nl> static void ath10k_pci_stop_intr ( struct ath10k * ar ) <nl> pci_disable_msi ( ar_pci -> pdev ); <nl> } <nl>  <nl> - static int ath10k_pci_reset_target ( struct ath10k * ar ) <nl> + static int ath10k_pci_wait_for_target_init ( struct ath10k * ar ) <nl> { <nl> struct ath10k_pci * ar_pci = ath10k_pci_priv ( ar ); <nl> int wait_limit = 300 ; /* 3 sec */
static struct ath_buf * ath_tx_setup_buffer ( struct ath_softc * sc , <nl> struct ath_frame_info * fi = get_frame_info ( skb ); <nl> struct ieee80211_hdr * hdr = ( struct ieee80211_hdr *) skb -> data ; <nl> struct ath_buf * bf ; <nl> + int fragno ; <nl> u16 seqno ; <nl>  <nl> bf = ath_tx_get_buffer ( sc ); <nl> static struct ath_buf * ath_tx_setup_buffer ( struct ath_softc * sc , <nl> ATH_TXBUF_RESET ( bf ); <nl>  <nl> if ( tid ) { <nl> + fragno = le16_to_cpu ( hdr -> seq_ctrl ) & IEEE80211_SCTL_FRAG ; <nl> seqno = tid -> seq_next ; <nl> hdr -> seq_ctrl = cpu_to_le16 ( tid -> seq_next << IEEE80211_SEQ_SEQ_SHIFT ); <nl> - INCR ( tid -> seq_next , IEEE80211_SEQ_MAX ); <nl> + <nl> + if ( fragno ) <nl> + hdr -> seq_ctrl |= cpu_to_le16 ( fragno ); <nl> + <nl> + if (! ieee80211_has_morefrags ( hdr -> frame_control )) <nl> + INCR ( tid -> seq_next , IEEE80211_SEQ_MAX ); <nl> + <nl> bf -> bf_state . seqno = seqno ; <nl> } <nl> 
static int btaudio_mixer_ioctl ( struct inode * inode , struct file * file , <nl> if ( cmd == SOUND_OLD_MIXER_INFO ) { <nl> _old_mixer_info info ; <nl> memset (& info , 0 , sizeof ( info )); <nl> - strlcpy ( info . id ," bt878 ", sizeof ( info . id )- 1 ); <nl> + strlcpy ( info . id , " bt878 ", sizeof ( info . id )); <nl> strlcpy ( info . name ," Brooktree Bt878 audio ", sizeof ( info . name )); <nl> if ( copy_to_user ( argp , & info , sizeof ( info ))) <nl> return - EFAULT ;
static const struct ac97_codec_id snd_ac97_codec_ids [] = { <nl> { 0x50534304 , 0xffffffff , " UCB1400 ", patch_ucb1400 , NULL }, <nl> { 0x53494c20 , 0xffffffe0 , " Si3036 , 8 ", mpatch_si3036 , mpatch_si3036 , AC97_MODEM_PATCH }, <nl> { 0x54524102 , 0xffffffff , " TR28022 ", NULL , NULL }, <nl> +{ 0x54524103 , 0xffffffff , " TR28023 ", NULL , NULL }, <nl> { 0x54524106 , 0xffffffff , " TR28026 ", NULL , NULL }, <nl> { 0x54524108 , 0xffffffff , " TR28028 ", patch_tritech_tr28028 , NULL }, // added by xin jin [ 07 / 09 / 99 ] <nl> { 0x54524123 , 0xffffffff , " TR28602 ", NULL , NULL }, // only guess -- jk [ TR28023 = eMicro EM28023 ( new CT1297 )] <nl> static const struct ac97_codec_id snd_ac97_codec_ids [] = { <nl> { 0x56494170 , 0xffffffff , " VIA1617A ", patch_vt1617a , NULL }, // modified VT1616 with S / PDIF <nl> { 0x56494182 , 0xffffffff , " VIA1618 ", NULL , NULL }, <nl> { 0x57454301 , 0xffffffff , " W83971D ", NULL , NULL }, <nl> -{ 0x574d4c00 , 0xffffffff , " WM9701A ", NULL , NULL }, <nl> +{ 0x574d4c00 , 0xffffffff , " WM9701 , WM9701A ", NULL , NULL }, <nl> { 0x574d4C03 , 0xffffffff , " WM9703 , WM9707 , WM9708 , WM9717 ", patch_wolfson03 , NULL }, <nl> { 0x574d4C04 , 0xffffffff , " WM9704M , WM9704Q ", patch_wolfson04 , NULL }, <nl> { 0x574d4C05 , 0xffffffff , " WM9705 , WM9710 ", patch_wolfson05 , NULL },
static int gfs2_write_end ( struct file * file , struct address_space * mapping , <nl> } <nl>  <nl> brelse ( dibh ); <nl> - gfs2_trans_end ( sdp ); <nl> failed : <nl> + gfs2_trans_end ( sdp ); <nl> if ( al ) { <nl> gfs2_inplace_release ( ip ); <nl> gfs2_quota_unlock ( ip );
static __always_inline void timekeeping_apply_adjustment ( struct timekeeper * tk , <nl> * <nl> * XXX - TODO : Doc ntp_error calculation . <nl> */ <nl> - if ( tk -> tkr . mult + mult_adj < mult_adj ) { <nl> + if (( mult_adj > 0 ) && ( tk -> tkr . mult + mult_adj < mult_adj )) { <nl> /* NTP adjustment caused clocksource mult overflow */ <nl> WARN_ON_ONCE ( 1 ); <nl> return ;
xfs_itruncate_start ( <nl> mp = ip -> i_mount ; <nl>  <nl> /* wait for the completion of any pending DIOs */ <nl> - if ( new_size < ip -> i_size ) <nl> + if ( new_size == 0 || new_size < ip -> i_size ) <nl> vn_iowait ( ip ); <nl>  <nl> /*
void xenbus_dev_changed ( const char * node , struct xen_bus_type * bus ) <nl>  <nl> kfree ( root ); <nl> } <nl> + EXPORT_SYMBOL_GPL ( xenbus_dev_changed ); <nl>  <nl> static void frontend_changed ( struct xenbus_watch * watch , <nl> const char ** vec , unsigned int len )
int bond_enslave ( struct net_device * bond_dev , struct net_device * slave_dev ) <nl> bond_set_carrier ( bond ); <nl>  <nl> if ( USES_PRIMARY ( bond -> params . mode )) { <nl> + block_netpoll_tx (); <nl> write_lock_bh (& bond -> curr_slave_lock ); <nl> bond_select_active_slave ( bond ); <nl> write_unlock_bh (& bond -> curr_slave_lock ); <nl> + unblock_netpoll_tx (); <nl> } <nl>  <nl> pr_info ("% s : enslaving % s as a % s interface with a % s link .\ n ", <nl> err_detach : <nl> if ( bond -> primary_slave == new_slave ) <nl> bond -> primary_slave = NULL ; <nl> if ( bond -> curr_active_slave == new_slave ) { <nl> + block_netpoll_tx (); <nl> write_lock_bh (& bond -> curr_slave_lock ); <nl> bond_change_active_slave ( bond , NULL ); <nl> bond_select_active_slave ( bond ); <nl> write_unlock_bh (& bond -> curr_slave_lock ); <nl> + unblock_netpoll_tx (); <nl> } <nl> slave_disable_netpoll ( new_slave ); <nl>  <nl> static int bond_slave_netdev_event ( unsigned long event , <nl> pr_info ("% s : Primary slave changed to % s , reselecting active slave .\ n ", <nl> bond -> dev -> name , bond -> primary_slave ? slave_dev -> name : <nl> " none "); <nl> + <nl> + block_netpoll_tx (); <nl> write_lock_bh (& bond -> curr_slave_lock ); <nl> bond_select_active_slave ( bond ); <nl> write_unlock_bh (& bond -> curr_slave_lock ); <nl> + unblock_netpoll_tx (); <nl> break ; <nl> case NETDEV_FEAT_CHANGE : <nl> bond_compute_features ( bond );
void * high_memory ; <nl> EXPORT_SYMBOL ( high_memory ); <nl> struct page * mem_map ; <nl> unsigned long max_mapnr ; <nl> + EXPORT_SYMBOL ( max_mapnr ); <nl> unsigned long highest_memmap_pfn ; <nl> struct percpu_counter vm_committed_as ; <nl> int sysctl_overcommit_memory = OVERCOMMIT_GUESS ; /* heuristic overcommit */
static int kdb_ll ( int argc , const char ** argv ) <nl> while ( va ) { <nl> char buf [ 80 ]; <nl>  <nl> + if ( KDB_FLAG ( CMD_INTERRUPT )) <nl> + return 0 ; <nl> + <nl> sprintf ( buf , "% s " kdb_machreg_fmt "\ n ", command , va ); <nl> diag = kdb_parse ( buf ); <nl> if ( diag )
static int rocker_probe ( struct pci_dev * pdev , const struct pci_device_id * id ) <nl> goto err_probe_ports ; <nl> } <nl>  <nl> - dev_info (& pdev -> dev , " Rocker switch with id % 016llx \ n ", rocker -> hw . id ); <nl> + dev_info (& pdev -> dev , " Rocker switch with id %* phN \ n ", <nl> + ( int ) sizeof ( rocker -> hw . id ), & rocker -> hw . id ); <nl>  <nl> return 0 ; <nl> 
struct btrfs_block_group_cache * btrfs_find_block_group ( struct btrfs_root * root , <nl> if ( search_start ) { <nl> struct btrfs_block_group_cache * shint ; <nl> shint = btrfs_lookup_block_group ( info , search_start ); <nl> - if ( shint -> data == data ) { <nl> + if ( shint && shint -> data == data ) { <nl> used = btrfs_block_group_used (& shint -> item ); <nl> if ( used + shint -> pinned < <nl> div_factor ( shint -> key . offset , factor )) { <nl> struct buffer_head * btrfs_alloc_free_block ( struct btrfs_trans_handle * trans , <nl> struct buffer_head * buf ; <nl>  <nl> ret = btrfs_alloc_extent ( trans , root , root -> root_key . objectid , <nl> - 1 , empty_size , hint , <nl> - ( unsigned long )- 1 , & ins , 0 ); <nl> + 1 , empty_size , hint , ( u64 )- 1 , & ins , 0 ); <nl> if ( ret ) { <nl> BUG_ON ( ret > 0 ); <nl> return ERR_PTR ( ret );
static const struct nft_set_ops * nft_select_set_ops ( const struct nlattr * const <nl>  <nl> static const struct nla_policy nft_set_policy [ NFTA_SET_MAX + 1 ] = { <nl> [ NFTA_SET_TABLE ] = { . type = NLA_STRING }, <nl> - [ NFTA_SET_NAME ] = { . type = NLA_STRING }, <nl> + [ NFTA_SET_NAME ] = { . type = NLA_STRING , <nl> + . len = IFNAMSIZ - 1 }, <nl> [ NFTA_SET_FLAGS ] = { . type = NLA_U32 }, <nl> [ NFTA_SET_KEY_TYPE ] = { . type = NLA_U32 }, <nl> [ NFTA_SET_KEY_LEN ] = { . type = NLA_U32 },
static int pie_init ( struct Qdisc * sch , struct nlattr * opt ) <nl> sch -> limit = q -> params . limit ; <nl>  <nl> setup_timer (& q -> adapt_timer , pie_timer , ( unsigned long ) sch ); <nl> - mod_timer (& q -> adapt_timer , jiffies + HZ / 2 ); <nl>  <nl> if ( opt ) { <nl> int err = pie_change ( sch , opt ); <nl> static int pie_init ( struct Qdisc * sch , struct nlattr * opt ) <nl> return err ; <nl> } <nl>  <nl> + mod_timer (& q -> adapt_timer , jiffies + HZ / 2 ); <nl> return 0 ; <nl> } <nl> 
static int io_subchannel_sch_event ( struct subchannel * sch , int process ) <nl> goto out ; <nl> break ; <nl> case IO_SCH_UNREG_ATTACH : <nl> + if ( cdev -> private -> flags . resuming ) { <nl> + /* Device will be handled later . */ <nl> + rc = 0 ; <nl> + goto out ; <nl> + } <nl> /* Unregister ccw device . */ <nl> - if (! cdev -> private -> flags . resuming ) <nl> - ccw_device_unregister ( cdev ); <nl> + ccw_device_unregister ( cdev ); <nl> break ; <nl> default : <nl> break ;
irqreturn_t dwc2_handle_common_intr ( int irq , void * dev ) <nl> u32 gintsts ; <nl> irqreturn_t retval = IRQ_NONE ; <nl>  <nl> + spin_lock (& hsotg -> lock ); <nl> + <nl> if (! dwc2_is_controller_alive ( hsotg )) { <nl> dev_warn ( hsotg -> dev , " Controller is dead \ n "); <nl> goto out ; <nl> } <nl>  <nl> - spin_lock (& hsotg -> lock ); <nl> - <nl> gintsts = dwc2_read_common_intr ( hsotg ); <nl> if ( gintsts & ~ GINTSTS_PRTINT ) <nl> retval = IRQ_HANDLED ; <nl> irqreturn_t dwc2_handle_common_intr ( int irq , void * dev ) <nl> } <nl> } <nl>  <nl> - spin_unlock (& hsotg -> lock ); <nl> out : <nl> + spin_unlock (& hsotg -> lock ); <nl> return retval ; <nl> } <nl> EXPORT_SYMBOL_GPL ( dwc2_handle_common_intr );
isdn_net_setcfg ( isdn_net_ioctl_cfg * cfg ) <nl> char * c , <nl> * e ; <nl>  <nl> + if ( strnlen ( cfg -> drvid , sizeof ( cfg -> drvid )) == <nl> + sizeof ( cfg -> drvid )) <nl> + return - EINVAL ; <nl> drvidx = - 1 ; <nl> chidx = - 1 ; <nl> strcpy ( drvid , cfg -> drvid );
static int get_v4lctrl ( struct i2c_client * client , struct v4l2_control * ctrl ) <nl> ctrl -> value = cx25840_read ( client , 0x420 ) >> 1 ; <nl> break ; <nl> case V4L2_CID_HUE : <nl> - ctrl -> value = cx25840_read ( client , 0x422 ); <nl> + ctrl -> value = ( s8 ) cx25840_read ( client , 0x422 ); <nl> break ; <nl> case V4L2_CID_AUDIO_VOLUME : <nl> case V4L2_CID_AUDIO_BASS :
void b43legacy_pio_handle_txstatus ( struct b43legacy_wldev * dev , <nl> queue = parse_cookie ( dev , status -> cookie , & packet ); <nl> B43legacy_WARN_ON (! queue ); <nl>  <nl> + if (! packet -> skb ) <nl> + return ; <nl> + <nl> queue -> tx_devq_packets --; <nl> queue -> tx_devq_used -= ( packet -> skb -> len + <nl> sizeof ( struct b43legacy_txhdr_fw3 ));
static int da9052_rtc_probe ( struct platform_device * pdev ) <nl> return ret ; <nl> } <nl>  <nl> + device_init_wakeup (& pdev -> dev , true ); <nl> + <nl> rtc -> rtc = devm_rtc_device_register (& pdev -> dev , pdev -> name , <nl> & da9052_rtc_ops , THIS_MODULE ); <nl> return PTR_ERR_OR_ZERO ( rtc -> rtc );
static int nfs_release_page ( struct page * page , gfp_t gfp ) <nl> { <nl> dfprintk ( PAGECACHE , " NFS : release_page (% p )\ n ", page ); <nl>  <nl> + if ( gfp & __GFP_WAIT ) <nl> + nfs_wb_page ( page -> mapping -> host , page ); <nl> /* If PagePrivate () is set , then the page is not freeable */ <nl> if ( PagePrivate ( page )) <nl> return 0 ;
static void set_connectable_complete ( struct hci_dev * hdev , u8 status ) <nl> if (! cmd ) <nl> goto unlock ; <nl>  <nl> + if ( status ) { <nl> + u8 mgmt_err = mgmt_status ( status ); <nl> + cmd_status ( cmd -> sk , cmd -> index , cmd -> opcode , mgmt_err ); <nl> + goto remove_cmd ; <nl> + } <nl> + <nl> cp = cmd -> param ; <nl> if ( cp -> val ) <nl> changed = ! test_and_set_bit ( HCI_CONNECTABLE , & hdev -> dev_flags ); <nl> static void set_connectable_complete ( struct hci_dev * hdev , u8 status ) <nl> if ( changed ) <nl> new_settings ( hdev , cmd -> sk ); <nl>  <nl> + remove_cmd : <nl> mgmt_pending_remove ( cmd ); <nl>  <nl> unlock :
static int dma_set_runtime_config ( struct dma_chan * chan , <nl> u32 cctl = 0 ; <nl> int i ; <nl>  <nl> + if (! plchan -> slave ) <nl> + return - EINVAL ; <nl> + <nl> /* Transfer direction */ <nl> plchan -> runtime_direction = config -> direction ; <nl> if ( config -> direction == DMA_TO_DEVICE ) {
void handle_ra_miss ( struct address_space * mapping , <nl> { <nl> ra -> flags |= RA_FLAG_MISS ; <nl> ra -> flags &= ~ RA_FLAG_INCACHE ; <nl> + ra -> cache_hit = 0 ; <nl> } <nl>  <nl> /*
static int mmc_blk_ioctl_cmd ( struct block_device * bdev , <nl> md = mmc_blk_get ( bdev -> bd_disk ); <nl> if (! md ) { <nl> err = - EINVAL ; <nl> - goto cmd_done ; <nl> + goto cmd_err ; <nl> } <nl>  <nl> card = md -> queue . card ; <nl> cmd_rel_host : <nl>  <nl> cmd_done : <nl> mmc_blk_put ( md ); <nl> + cmd_err : <nl> kfree ( idata -> buf ); <nl> kfree ( idata ); <nl> return err ;
__do_user_fault ( struct task_struct * tsk , unsigned long addr , <nl> struct siginfo si ; <nl>  <nl> # ifdef CONFIG_DEBUG_USER <nl> - if ( user_debug & UDBG_SEGV ) { <nl> + if ((( user_debug & UDBG_SEGV ) && ( sig == SIGSEGV )) || <nl> + (( user_debug & UDBG_BUS ) && ( sig == SIGBUS ))) { <nl> printk ( KERN_DEBUG "% s : unhandled page fault (% d ) at 0x % 08lx , code 0x % 03x \ n ", <nl> tsk -> comm , sig , addr , fsr ); <nl> show_pte ( tsk -> mm , addr );
static int __init d40_lcla_allocate ( struct d40_base * base ) <nl>  <nl> d40_err ( base -> dev , " Failed to allocate % d pages .\ n ", <nl> base -> lcla_pool . pages ); <nl> + ret = - ENOMEM ; <nl>  <nl> for ( j = 0 ; j < i ; j ++) <nl> free_pages ( page_list [ j ], base -> lcla_pool . pages );
static int event_buffer_open ( struct inode * inode , struct file * file ) <nl> if (! capable ( CAP_SYS_ADMIN )) <nl> return - EPERM ; <nl>  <nl> - if ( test_and_set_bit ( 0 , & buffer_opened )) <nl> + if ( test_and_set_bit_lock ( 0 , & buffer_opened )) <nl> return - EBUSY ; <nl>  <nl> /* Register as a user of dcookies <nl> static int event_buffer_open ( struct inode * inode , struct file * file ) <nl> fail : <nl> dcookie_unregister ( file -> private_data ); <nl> out : <nl> - clear_bit ( 0 , & buffer_opened ); <nl> + __clear_bit_unlock ( 0 , & buffer_opened ); <nl> return err ; <nl> } <nl>  <nl> static int event_buffer_release ( struct inode * inode , struct file * file ) <nl> dcookie_unregister ( file -> private_data ); <nl> buffer_pos = 0 ; <nl> atomic_set (& buffer_ready , 0 ); <nl> - clear_bit ( 0 , & buffer_opened ); <nl> + __clear_bit_unlock ( 0 , & buffer_opened ); <nl> return 0 ; <nl> } <nl> 
void ib_copy_ah_attr_to_user ( struct ib_uverbs_ah_attr * dst , <nl> dst -> grh . sgid_index = src -> grh . sgid_index ; <nl> dst -> grh . hop_limit = src -> grh . hop_limit ; <nl> dst -> grh . traffic_class = src -> grh . traffic_class ; <nl> + memset (& dst -> grh . reserved , 0 , sizeof ( dst -> grh . reserved )); <nl> dst -> dlid = src -> dlid ; <nl> dst -> sl = src -> sl ; <nl> dst -> src_path_bits = src -> src_path_bits ; <nl> dst -> static_rate = src -> static_rate ; <nl> dst -> is_global = src -> ah_flags & IB_AH_GRH ? 1 : 0 ; <nl> dst -> port_num = src -> port_num ; <nl> + dst -> reserved = 0 ; <nl> } <nl> EXPORT_SYMBOL ( ib_copy_ah_attr_to_user ); <nl>  <nl> void ib_copy_qp_attr_to_user ( struct ib_uverbs_qp_attr * dst , <nl> struct ib_qp_attr * src ) <nl> { <nl> + dst -> qp_state = src -> qp_state ; <nl> dst -> cur_qp_state = src -> cur_qp_state ; <nl> dst -> path_mtu = src -> path_mtu ; <nl> dst -> path_mig_state = src -> path_mig_state ; <nl> void ib_copy_qp_attr_to_user ( struct ib_uverbs_qp_attr * dst , <nl> dst -> rnr_retry = src -> rnr_retry ; <nl> dst -> alt_port_num = src -> alt_port_num ; <nl> dst -> alt_timeout = src -> alt_timeout ; <nl> + memset ( dst -> reserved , 0 , sizeof ( dst -> reserved )); <nl> } <nl> EXPORT_SYMBOL ( ib_copy_qp_attr_to_user ); <nl> 
static int i40evf_request_misc_irq ( struct i40evf_adapter * adapter ) <nl> int err ; <nl>  <nl> snprintf ( adapter -> misc_vector_name , <nl> - sizeof ( adapter -> misc_vector_name ) - 1 , " i40evf : mbx "); <nl> + sizeof ( adapter -> misc_vector_name ) - 1 , " i40evf -% s : mbx ", <nl> + dev_name (& adapter -> pdev -> dev )); <nl> err = request_irq ( adapter -> msix_entries [ 0 ]. vector , <nl> & i40evf_msix_aq , 0 , <nl> adapter -> misc_vector_name , netdev );
static int __devinit rtsx_probe ( struct pci_dev * pci , <nl> th = kthread_create ( rtsx_scan_thread , dev , " rtsx - scan "); <nl> if ( IS_ERR ( th )) { <nl> printk ( KERN_ERR " Unable to start the device - scanning thread \ n "); <nl> + complete (& dev -> scanning_done ); <nl> quiesce_and_remove_host ( dev ); <nl> err = PTR_ERR ( th ); <nl> goto errout ;
mac802154_tx ( struct ieee802154_local * local , struct sk_buff * skb ) <nl> mac802154_monitors_rx ( local , skb ); <nl>  <nl> if (!( local -> hw . flags & IEEE802154_HW_OMIT_CKSUM )) { <nl> - u16 crc = crc_ccitt ( 0 , skb -> data , skb -> len ); <nl> - u8 * data = skb_put ( skb , 2 ); <nl> + __le16 crc = cpu_to_le16 ( crc_ccitt ( 0 , skb -> data , skb -> len )); <nl>  <nl> - data [ 0 ] = crc & 0xff ; <nl> - data [ 1 ] = crc >> 8 ; <nl> + memcpy ( skb_put ( skb , 2 ), & crc , 2 ); <nl> } <nl>  <nl> if ( skb_cow_head ( skb , local -> hw . extra_tx_headroom ))
static void __init bmips_smp_setup ( void ) <nl> int i , cpu = 1 , boot_cpu = 0 ; <nl>  <nl> # if defined ( CONFIG_CPU_BMIPS4350 ) || defined ( CONFIG_CPU_BMIPS4380 ) <nl> + int cpu_hw_intr ; <nl> + <nl> /* arbitration priority */ <nl> clear_c0_brcm_cmt_ctrl ( 0x30 ); <nl>  <nl> static void __init bmips_smp_setup ( void ) <nl> * MIPS interrupt 2 ( HW INT 0 ) is the CPU0 L1 controller output <nl> * MIPS interrupt 3 ( HW INT 1 ) is the CPU1 L1 controller output <nl> */ <nl> - change_c0_brcm_cmt_intr ( 0xf8018000 , <nl> - ( 0x02 << 27 ) | ( 0x03 << 15 )); <nl> + if ( boot_cpu == 0 ) <nl> + cpu_hw_intr = 0x02 ; <nl> + else <nl> + cpu_hw_intr = 0x1d ; <nl> + <nl> + change_c0_brcm_cmt_intr ( 0xf8018000 , ( cpu_hw_intr << 27 ) | ( 0x03 << 15 )); <nl>  <nl> /* single core , 2 threads ( 2 pipelines ) */ <nl> max_cpus = 2 ;
done : <nl>  <nl> out : <nl> if ( unlikely ( frozen_buffer )) /* It ' s usually NULL */ <nl> - kfree ( frozen_buffer ); <nl> + jbd_slab_free ( frozen_buffer , bh -> b_size ); <nl>  <nl> JBUFFER_TRACE ( jh , " exit "); <nl> return error ;
static void tcp_event_data_sent ( struct tcp_sock * tp , <nl> struct inet_connection_sock * icsk = inet_csk ( sk ); <nl> const u32 now = tcp_time_stamp ; <nl>  <nl> + if ( tcp_packets_in_flight ( tp ) == 0 ) <nl> + tcp_ca_event ( sk , CA_EVENT_TX_START ); <nl> + <nl> tp -> lsndtime = now ; <nl>  <nl> /* If it is a reply for ato after last received <nl> static int tcp_transmit_skb ( struct sock * sk , struct sk_buff * skb , int clone_it , <nl> & md5 ); <nl> tcp_header_size = tcp_options_size + sizeof ( struct tcphdr ); <nl>  <nl> - if ( tcp_packets_in_flight ( tp ) == 0 ) <nl> - tcp_ca_event ( sk , CA_EVENT_TX_START ); <nl> - <nl> /* if no packet is in qdisc / device queue , then allow XPS to select <nl> * another queue . We can be called from tcp_tsq_handler () <nl> * which holds one reference to sk_wmem_alloc .
nfsd3_proc_create ( struct svc_rqst * rqstp , struct nfsd3_createargs * argp , <nl> /* Now create the file and set attributes */ <nl> nfserr = do_nfsd_create ( rqstp , dirfhp , argp -> name , argp -> len , <nl> attr , newfhp , <nl> - argp -> createmode , argp -> verf , NULL , NULL ); <nl> + argp -> createmode , ( u32 *) argp -> verf , NULL , NULL ); <nl>  <nl> RETURN_STATUS ( nfserr ); <nl> }
pca963x_dt_init ( struct i2c_client * client , struct pca963x_chipdef * chip ) <nl> return ERR_PTR (- ENOMEM ); <nl>  <nl> for_each_child_of_node ( np , child ) { <nl> - struct led_info led ; <nl> + struct led_info led = {}; <nl> u32 reg ; <nl> int res ; <nl> 
static int do_setxattr ( struct btrfs_trans_handle * trans , <nl> if ( ret ) <nl> goto out ; <nl> btrfs_release_path ( path ); <nl> + <nl> + /* <nl> + * remove the attribute <nl> + */ <nl> + if (! value ) <nl> + goto out ; <nl> } <nl>  <nl> again : <nl> out : <nl> return ret ; <nl> } <nl>  <nl> +/* <nl> + * @ value : "" makes the attribute to empty , NULL removes it <nl> + */ <nl> int __btrfs_setxattr ( struct btrfs_trans_handle * trans , <nl> struct inode * inode , const char * name , <nl> const void * value , size_t size , int flags )
int skb_gro_receive ( struct sk_buff ** head , struct sk_buff * skb ) <nl> * NAPI_GRO_CB ( nskb ) = * NAPI_GRO_CB ( p ); <nl> skb_shinfo ( nskb )-> frag_list = p ; <nl> skb_shinfo ( nskb )-> gso_size = pinfo -> gso_size ; <nl> + pinfo -> gso_size = 0 ; <nl> skb_header_release ( p ); <nl> nskb -> prev = p ; <nl> 
static int nortel_pci_cor_reset ( struct orinoco_private * priv ) <nl> return 0 ; <nl> } <nl>  <nl> - int nortel_pci_hw_init ( struct nortel_pci_card * card ) <nl> + static int nortel_pci_hw_init ( struct nortel_pci_card * card ) <nl> { <nl> int i ; <nl> u32 reg ;
static int gdlm_thread ( void * data , int blist ) <nl> struct gdlm_ls * ls = ( struct gdlm_ls *) data ; <nl> struct gdlm_lock * lp = NULL ; <nl> uint8_t complete , blocking , submit , drop ; <nl> - DECLARE_WAITQUEUE ( wait , current ); <nl>  <nl> /* Only thread1 is allowed to do blocking callbacks since gfs <nl> may wait for a completion callback within a blocking cb . */ <nl>  <nl> while (! kthread_should_stop ()) { <nl> - set_current_state ( TASK_INTERRUPTIBLE ); <nl> - add_wait_queue (& ls -> thread_wait , & wait ); <nl> - if ( no_work ( ls , blist )) <nl> - schedule (); <nl> - remove_wait_queue (& ls -> thread_wait , & wait ); <nl> - set_current_state ( TASK_RUNNING ); <nl> + wait_event_interruptible ( ls -> thread_wait , <nl> + ! no_work ( ls , blist ) || kthread_should_stop ()); <nl>  <nl> complete = blocking = submit = drop = 0 ; <nl> 
static char * usb_dump_endpoint_descriptor ( int speed , char * start , char * end , <nl> break ; <nl> case USB_ENDPOINT_XFER_INT : <nl> type = " Int ."; <nl> - if ( speed == USB_SPEED_HIGH ) <nl> + if ( speed == USB_SPEED_HIGH || speed == USB_SPEED_SUPER ) <nl> interval = 1 << ( desc -> bInterval - 1 ); <nl> else <nl> interval = desc -> bInterval ; <nl> static char * usb_dump_endpoint_descriptor ( int speed , char * start , char * end , <nl> default : /* " can ' t happen " */ <nl> return start ; <nl> } <nl> - interval *= ( speed == USB_SPEED_HIGH ) ? 125 : 1000 ; <nl> + interval *= ( speed == USB_SPEED_HIGH || <nl> + speed == USB_SPEED_SUPER ) ? 125 : 1000 ; <nl> if ( interval % 1000 ) <nl> unit = ' u '; <nl> else { <nl> static ssize_t usb_device_dump ( char __user ** buffer , size_t * nbytes , <nl> if ( level == 0 ) { <nl> int max ; <nl>  <nl> - /* high speed reserves 80 %, full / low reserves 90 % */ <nl> - if ( usbdev -> speed == USB_SPEED_HIGH ) <nl> + /* super / high speed reserves 80 %, full / low reserves 90 % */ <nl> + if ( usbdev -> speed == USB_SPEED_HIGH || <nl> + usbdev -> speed == USB_SPEED_SUPER ) <nl> max = 800 ; <nl> else <nl> max = FRAME_TIME_MAX_USECS_ALLOC ;
nvc0_fifo_init ( struct nouveau_object * object ) <nl> nv_wr32 ( priv , 0x002a00 , 0xffffffff ); /* clears PFIFO . INTR bit 30 */ <nl> nv_wr32 ( priv , 0x002100 , 0xffffffff ); <nl> nv_wr32 ( priv , 0x002140 , 0x3fffffff ); <nl> + nv_wr32 ( priv , 0x002628 , 0x00000001 ); /* makes mthd 0x20 work */ <nl> return 0 ; <nl> } <nl> 
static int add_regulator_attributes ( struct regulator_dev * rdev ) <nl> if ( status < 0 ) <nl> return status ; <nl> } <nl> - if ( ops -> is_enabled ) { <nl> + if ( rdev -> ena_gpio || ops -> is_enabled ) { <nl> status = device_create_file ( dev , & dev_attr_state ); <nl> if ( status < 0 ) <nl> return status ;
static inline int eirr_to_irq ( unsigned long eirr ) <nl> /* ONLY called from entry . S : intr_extint () */ <nl> void do_cpu_irq_mask ( struct pt_regs * regs ) <nl> { <nl> + struct pt_regs * old_regs ; <nl> unsigned long eirr_val ; <nl> int irq , cpu = smp_processor_id (); <nl> # ifdef CONFIG_SMP <nl> cpumask_t dest ; <nl> # endif <nl>  <nl> + old_regs = set_irq_regs ( regs ); <nl> local_irq_disable (); <nl> irq_enter (); <nl>  <nl> void do_cpu_irq_mask ( struct pt_regs * regs ) <nl>  <nl> out : <nl> irq_exit (); <nl> + set_irq_regs ( old_regs ); <nl> return ; <nl>  <nl> set_out :
struct clk * rockchip_clk_register_cpuclk ( const char * name , <nl> pr_err ("% s : could not lookup parent clock % s \ n ", <nl> __func__ , parent_names [ 0 ]); <nl> ret = - EINVAL ; <nl> - goto free_cpuclk ; <nl> + goto free_alt_parent ; <nl> } <nl>  <nl> ret = clk_notifier_register ( clk , & cpuclk -> clk_nb ); <nl> if ( ret ) { <nl> pr_err ("% s : failed to register clock notifier for % s \ n ", <nl> __func__ , name ); <nl> - goto free_cpuclk ; <nl> + goto free_alt_parent ; <nl> } <nl>  <nl> if ( nrates > 0 ) { <nl> free_rate_table : <nl> kfree ( cpuclk -> rate_table ); <nl> unregister_notifier : <nl> clk_notifier_unregister ( clk , & cpuclk -> clk_nb ); <nl> + free_alt_parent : <nl> + clk_disable_unprepare ( cpuclk -> alt_parent ); <nl> free_cpuclk : <nl> kfree ( cpuclk ); <nl> return ERR_PTR ( ret );
int wl1271_init_ieee80211 ( struct wl1271 * wl ) <nl> wl -> hw -> wiphy -> max_scan_ie_len = WL1271_CMD_TEMPL_DFLT_SIZE - <nl> sizeof ( struct ieee80211_header ); <nl>  <nl> + wl -> hw -> wiphy -> max_sched_scan_ie_len = WL1271_CMD_TEMPL_DFLT_SIZE - <nl> + sizeof ( struct ieee80211_header ); <nl> + <nl> wl -> hw -> wiphy -> flags |= WIPHY_FLAG_AP_UAPSD ; <nl>  <nl> /* make sure all our channels fit in the scanned_ch bitmask */
static void cnic_shutdown_rings ( struct cnic_dev * dev ) <nl> } else if ( test_bit ( CNIC_F_BNX2X_CLASS , & dev -> flags )) { <nl> struct cnic_local * cp = dev -> cnic_priv ; <nl> u32 cli = BNX2X_ISCSI_CL_ID ( CNIC_E1HVN ( cp )); <nl> + union l5cm_specific_data l5_data ; <nl>  <nl> cnic_ring_ctl ( dev , BNX2X_ISCSI_L2_CID , cli , 0 ); <nl> + <nl> + l5_data . phy_address . lo = cli ; <nl> + l5_data . phy_address . hi = 0 ; <nl> + cnic_submit_kwqe_16 ( dev , RAMROD_CMD_ID_ETH_HALT , <nl> + BNX2X_ISCSI_L2_CID , ETH_CONNECTION_TYPE , & l5_data ); <nl> + msleep ( 10 ); <nl> } <nl> } <nl> 
struct simple_xattr * simple_xattr_alloc ( const void * value , size_t size ) <nl>  <nl> /* wrap around ? */ <nl> len = sizeof (* new_xattr ) + size ; <nl> - if ( len <= sizeof (* new_xattr )) <nl> + if ( len < sizeof (* new_xattr )) <nl> return NULL ; <nl>  <nl> new_xattr = kmalloc ( len , GFP_KERNEL );
static int xlp9xx_irq_to_irt ( int irq ) <nl> switch ( irq ) { <nl> case PIC_GPIO_IRQ : <nl> return 12 ; <nl> + case PIC_I2C_0_IRQ : <nl> + return 125 ; <nl> + case PIC_I2C_1_IRQ : <nl> + return 126 ; <nl> + case PIC_I2C_2_IRQ : <nl> + return 127 ; <nl> + case PIC_I2C_3_IRQ : <nl> + return 128 ; <nl> case PIC_9XX_XHCI_0_IRQ : <nl> return 114 ; <nl> case PIC_9XX_XHCI_1_IRQ :
static long pmcraid_ioctl_passthrough ( <nl> rc = - EFAULT ; <nl> goto out_free_buffer ; <nl> } <nl> + } else if ( request_size < 0 ) { <nl> + rc = - EINVAL ; <nl> + goto out_free_buffer ; <nl> } <nl>  <nl> /* check if we have any additional command parameters */
static int sdhci_bcm_kona_probe ( struct platform_device * pdev ) <nl> kona_dev = sdhci_pltfm_priv ( pltfm_priv ); <nl> mutex_init (& kona_dev -> write_lock ); <nl>  <nl> - mmc_of_parse ( host -> mmc ); <nl> + ret = mmc_of_parse ( host -> mmc ); <nl> + if ( ret ) <nl> + goto err_pltfm_free ; <nl>  <nl> if (! host -> mmc -> f_max ) { <nl> dev_err (& pdev -> dev , " Missing max - freq for SDHCI cfg \ n ");
static int rt2x00mac_tx_rts_cts ( struct rt2x00_dev * rt2x00dev , <nl> ( struct ieee80211_rts *)( skb -> data )); <nl>  <nl> if ( rt2x00queue_write_tx_frame ( queue , skb )) { <nl> + dev_kfree_skb_any ( skb ); <nl> WARNING ( rt2x00dev , " Failed to send RTS / CTS frame .\ n "); <nl> return NETDEV_TX_BUSY ; <nl> }
static int ip_vs_wrr_init_svc ( struct ip_vs_service * svc ) <nl> /* <nl> * Allocate the mark variable for WRR scheduling <nl> */ <nl> - mark = kmalloc ( sizeof ( struct ip_vs_wrr_mark ), GFP_ATOMIC ); <nl> + mark = kmalloc ( sizeof ( struct ip_vs_wrr_mark ), GFP_KERNEL ); <nl> if ( mark == NULL ) <nl> return - ENOMEM ; <nl> 
fec_restart ( struct net_device * ndev ) <nl> } <nl>  <nl> /* Clear any outstanding interrupt . */ <nl> - writel ( 0xffc00000 , fep -> hwp + FEC_IEVENT ); <nl> + writel ( 0xffffffff , fep -> hwp + FEC_IEVENT ); <nl>  <nl> fec_enet_bd_init ( ndev ); <nl> 
static int fec_enet_get_free_txdesc_num ( struct fec_enet_private * fep , <nl> entries = (( const char *) txq -> dirty_tx - <nl> ( const char *) txq -> cur_tx ) / fep -> bufdesc_size - 1 ; <nl>  <nl> - return entries > 0 ? entries : entries + txq -> tx_ring_size ; <nl> + return entries >= 0 ? entries : entries + txq -> tx_ring_size ; <nl> } <nl>  <nl> static void swap_buffer ( void * bufaddr , int len )
static int do_swap_page ( struct mm_struct * mm , struct vm_area_struct * vma , <nl> } else if ( PageHWPoison ( page )) { <nl> ret = VM_FAULT_HWPOISON ; <nl> delayacct_clear_flag ( DELAYACCT_PF_SWAPIN ); <nl> - goto out ; <nl> + goto out_release ; <nl> } <nl>  <nl> lock_page ( page ); <nl> out_nomap : <nl> pte_unmap_unlock ( page_table , ptl ); <nl> out_page : <nl> unlock_page ( page ); <nl> + out_release : <nl> page_cache_release ( page ); <nl> return ret ; <nl> }
static int ioapic_service ( struct kvm_ioapic * ioapic , int irq , bool line_status ) <nl> BUG_ON ( ioapic -> rtc_status . pending_eoi != 0 ); <nl> ret = kvm_irq_delivery_to_apic ( ioapic -> kvm , NULL , & irqe , <nl> ioapic -> rtc_status . dest_map ); <nl> - ioapic -> rtc_status . pending_eoi = ret ; <nl> + ioapic -> rtc_status . pending_eoi = ( ret < 0 ? 0 : ret ); <nl> } else <nl> ret = kvm_irq_delivery_to_apic ( ioapic -> kvm , NULL , & irqe , NULL ); <nl> 
static struct resource dove_sdio0_resources [] = { <nl> }; <nl>  <nl> static struct platform_device dove_sdio0 = { <nl> - . name = " sdhci - mv ", <nl> + . name = " sdhci - dove ", <nl> . id = 0 , <nl> . dev = { <nl> . dma_mask = & sdio_dmamask , <nl> static struct resource dove_sdio1_resources [] = { <nl> }; <nl>  <nl> static struct platform_device dove_sdio1 = { <nl> - . name = " sdhci - mv ", <nl> + . name = " sdhci - dove ", <nl> . id = 1 , <nl> . dev = { <nl> . dma_mask = & sdio_dmamask ,
static unsigned int qnap_ts41x_mpp_config [] __initdata = { <nl> MPP37_GPIO , /* Reset button */ <nl> MPP43_GPIO , /* USB Copy button */ <nl> MPP44_GPIO , /* Board ID : 0 : TS - 419U , 1 : TS - 419 */ <nl> - MPP45_GPIO , /* JP1 : 0 : console , 1 : LCD */ <nl> + MPP45_GPIO , /* JP1 : 0 : LCD , 1 : serial console */ <nl> MPP46_GPIO , /* External SATA HDD1 error indicator */ <nl> MPP47_GPIO , /* External SATA HDD2 error indicator */ <nl> MPP48_GPIO , /* External SATA HDD3 error indicator */
static int dapm_mux_update_power ( struct snd_soc_dapm_widget * widget , <nl> return 0 ; <nl> } <nl>  <nl> -/* test and update the power status of a mixer widget */ <nl> +/* test and update the power status of a mixer or switch widget */ <nl> static int dapm_mixer_update_power ( struct snd_soc_dapm_widget * widget , <nl> struct snd_kcontrol * kcontrol , int reg , <nl> int val_mask , int val , int invert ) <nl> static int dapm_mixer_update_power ( struct snd_soc_dapm_widget * widget , <nl> struct snd_soc_dapm_path * path ; <nl> int found = 0 ; <nl>  <nl> - if ( widget -> id != snd_soc_dapm_mixer ) <nl> + if ( widget -> id != snd_soc_dapm_mixer && <nl> + widget -> id != snd_soc_dapm_switch ) <nl> return - ENODEV ; <nl>  <nl> if (! snd_soc_test_bits ( widget -> codec , reg , val_mask , val ))
ARIZONA_MIXER_CONTROLS (" DSP2R ", ARIZONA_DSP2RMIX_INPUT_1_SOURCE ), <nl> ARIZONA_MIXER_CONTROLS (" DSP3L ", ARIZONA_DSP3LMIX_INPUT_1_SOURCE ), <nl> ARIZONA_MIXER_CONTROLS (" DSP3R ", ARIZONA_DSP3RMIX_INPUT_1_SOURCE ), <nl> ARIZONA_MIXER_CONTROLS (" DSP4L ", ARIZONA_DSP4LMIX_INPUT_1_SOURCE ), <nl> - ARIZONA_MIXER_CONTROLS (" DSP5R ", ARIZONA_DSP4RMIX_INPUT_1_SOURCE ), <nl> + ARIZONA_MIXER_CONTROLS (" DSP4R ", ARIZONA_DSP4RMIX_INPUT_1_SOURCE ), <nl>  <nl> ARIZONA_MIXER_CONTROLS (" Mic ", ARIZONA_MICMIX_INPUT_1_SOURCE ), <nl> ARIZONA_MIXER_CONTROLS (" Noise ", ARIZONA_NOISEMIX_INPUT_1_SOURCE ),
static int aic3x_read ( struct snd_soc_codec * codec , unsigned int reg , <nl> if ( reg >= AIC3X_CACHEREGNUM ) <nl> return - 1 ; <nl>  <nl> - * value = codec -> hw_read ( codec , reg ); <nl> + codec -> cache_bypass = 1 ; <nl> + * value = snd_soc_read ( codec , reg ); <nl> + codec -> cache_bypass = 0 ; <nl> + <nl> cache [ reg ] = * value ; <nl>  <nl> return 0 ;
static int virtscsi_queuecommand ( struct Scsi_Host * sh , struct scsi_cmnd * sc ) <nl> sizeof cmd -> req . cmd , sizeof cmd -> resp . cmd , <nl> GFP_ATOMIC ) >= 0 ) <nl> ret = 0 ; <nl> + else <nl> + mempool_free ( cmd , virtscsi_cmd_pool ); <nl>  <nl> out : <nl> return ret ;
static int fc2580_set_params ( struct dvb_frontend * fe ) <nl> { <nl> struct fc2580_priv * priv = fe -> tuner_priv ; <nl> struct dtv_frontend_properties * c = & fe -> dtv_property_cache ; <nl> - int ret , i ; <nl> + int ret = 0 , i ; <nl> unsigned int r_val , n_val , k_val , k_val_reg , f_ref ; <nl> u8 tmp_val , r18_val ; <nl> u64 f_vco ;
static int btrfs_xattr_acl_set ( struct dentry * dentry , const char * name , <nl> int ret ; <nl> struct posix_acl * acl = NULL ; <nl>  <nl> + if (! is_owner_or_cap ( dentry -> d_inode )) <nl> + return - EPERM ; <nl> + <nl> if ( value ) { <nl> acl = posix_acl_from_xattr ( value , size ); <nl> if ( acl == NULL ) {
/* <nl> - * linux / drivers / ide / pci / opti621 . c Version 0 . 7 Sept 10 , 2002 <nl> + * linux / drivers / ide / pci / opti621 . c Version 0 . 8 Aug 27 , 2007 <nl> * <nl> * Copyright ( C ) 1996 - 1998 Linus Torvalds & authors ( see below ) <nl> */ <nl> * There is a 25 / 33MHz switch in configuration <nl> * register , but driver is written for use at any frequency which get <nl> * ( use idebus = xx to select PCI bus speed ). <nl> - * Use hda = autotune and hdb = autotune for automatical tune of the PIO modes . <nl> - * If you get strange results , do not use this and set PIO manually <nl> - * by hdparm . <nl> * <nl> * Version 0 . 1 , Nov 8 , 1996 <nl> * by Jaromir Koutek , for 2 . 1 . 8 . <nl> static void __devinit init_hwif_opti621 ( ide_hwif_t * hwif ) <nl> hwif -> drives [ 1 ]. drive_data = PIO_DONT_KNOW ; <nl>  <nl> hwif -> set_pio_mode = & opti621_set_pio_mode ; <nl> + <nl> + hwif -> drives [ 0 ]. autotune = 1 ; <nl> + hwif -> drives [ 1 ]. autotune = 1 ; <nl> } <nl>  <nl> static ide_pci_device_t opti621_chipsets [] __devinitdata = {
static void mvneta_rxq_drop_pkts ( struct mvneta_port * pp , <nl> struct mvneta_rx_desc * rx_desc = rxq -> descs + i ; <nl> void * data = ( void *) rx_desc -> buf_cookie ; <nl>  <nl> - mvneta_frag_free ( pp , data ); <nl> dma_unmap_single ( pp -> dev -> dev . parent , rx_desc -> buf_phys_addr , <nl> MVNETA_RX_BUF_SIZE ( pp -> pkt_size ), DMA_FROM_DEVICE ); <nl> + mvneta_frag_free ( pp , data ); <nl> } <nl>  <nl> if ( rx_done )
static loff_t nfs_file_llseek ( struct file * filp , loff_t offset , int origin ) <nl> * origin == SEEK_END || SEEK_DATA || SEEK_HOLE => we must revalidate <nl> * the cached file length <nl> */ <nl> - if ( origin != SEEK_SET || origin != SEEK_CUR ) { <nl> + if ( origin != SEEK_SET && origin != SEEK_CUR ) { <nl> struct inode * inode = filp -> f_mapping -> host ; <nl>  <nl> int retval = nfs_revalidate_file_size ( inode , filp );
void sctp_assoc_update ( struct sctp_association * asoc , <nl> asoc -> peer . peer_hmacs = new -> peer . peer_hmacs ; <nl> new -> peer . peer_hmacs = NULL ; <nl>  <nl> - sctp_auth_key_put ( asoc -> asoc_shared_key ); <nl> sctp_auth_asoc_init_active_key ( asoc , GFP_ATOMIC ); <nl> } <nl> 
static void do_ubd_request ( struct request_queue * q ) <nl> " errno = % d \ n ", - n ); <nl> else if ( list_empty (& dev -> restart )) <nl> list_add (& dev -> restart , & restart ); <nl> + kfree ( io_req ); <nl> return ; <nl> } <nl> 
static void handle_critical_trips ( struct thermal_zone_device * tz , <nl> tz -> ops -> get_trip_temp ( tz , trip , & trip_temp ); <nl>  <nl> /* If we have not crossed the trip_temp , we do not care . */ <nl> - if ( tz -> temperature < trip_temp ) <nl> + if ( trip_temp <= 0 || tz -> temperature < trip_temp ) <nl> return ; <nl>  <nl> trace_thermal_zone_trip ( tz , trip , trip_type );
void WMMOnAssocRsp ( struct adapter * padapter ) <nl> inx [ 0 ] = 0 ; inx [ 1 ] = 1 ; inx [ 2 ] = 2 ; inx [ 3 ] = 3 ; <nl>  <nl> if ( pregpriv -> wifi_spec == 1 ) { <nl> - u32 j , tmp , change_inx ; <nl> + u32 j , tmp , change_inx = false ; <nl>  <nl> /* entry indx : 0 -> vo , 1 -> vi , 2 -> be , 3 -> bk . */ <nl> for ( i = 0 ; i < 4 ; i ++) {
static struct mount * clone_mnt ( struct mount * old , struct dentry * root , <nl> } <nl>  <nl> /* Don ' t allow unprivileged users to reveal what is under a mount */ <nl> - if (( flag & CL_UNPRIVILEGED ) && list_empty (& old -> mnt_expire )) <nl> + if (( flag & CL_UNPRIVILEGED ) && <nl> + (!( flag & CL_EXPIRE ) || list_empty (& old -> mnt_expire ))) <nl> mnt -> mnt . mnt_flags |= MNT_LOCKED ; <nl>  <nl> atomic_inc (& sb -> s_active );
static void gc_attach ( struct parport * pp ) <nl> pads = gc_cfg [ port_idx ]. args + 1 ; <nl> n_pads = gc_cfg [ port_idx ]. nargs - 1 ; <nl>  <nl> + memset (& gc_parport_cb , 0 , sizeof ( gc_parport_cb )); <nl> gc_parport_cb . flags = PARPORT_FLAG_EXCL ; <nl>  <nl> pd = parport_register_dev_model ( pp , " gamecon ", & gc_parport_cb ,
size_t nfs_generic_pg_test ( struct nfs_pageio_descriptor * desc , <nl> return 0 ; <nl> } <nl>  <nl> + /* <nl> + * Limit the request size so that we can still allocate a page array <nl> + * for it without upsetting the slab allocator . <nl> + */ <nl> + if ((( desc -> pg_count + req -> wb_bytes ) >> PAGE_SHIFT ) * <nl> + sizeof ( struct page ) > PAGE_SIZE ) <nl> + return 0 ; <nl> + <nl> return min ( desc -> pg_bsize - desc -> pg_count , ( size_t ) req -> wb_bytes ); <nl> } <nl> EXPORT_SYMBOL_GPL ( nfs_generic_pg_test );
int of_gpio_simple_xlate ( struct gpio_chip * gc , <nl> if ( WARN_ON ( gpiospec -> args_count < gc -> of_gpio_n_cells )) <nl> return - EINVAL ; <nl>  <nl> - if ( gpiospec -> args [ 0 ] > gc -> ngpio ) <nl> + if ( gpiospec -> args [ 0 ] >= gc -> ngpio ) <nl> return - EINVAL ; <nl>  <nl> if ( flags )
static int add_munmap ( unsigned long addr , unsigned long len , <nl> struct host_vm_op * last ; <nl> int ret = 0 ; <nl>  <nl> + if (( addr >= STUB_START ) && ( addr < STUB_END )) <nl> + return - EINVAL ; <nl> + <nl> if ( hvc -> index != 0 ) { <nl> last = & hvc -> ops [ hvc -> index - 1 ]; <nl> if (( last -> type == MUNMAP ) &&
at86rf230_tx_complete ( void * context ) <nl> { <nl> struct at86rf230_state_change * ctx = context ; <nl> struct at86rf230_local * lp = ctx -> lp ; <nl> - struct sk_buff * skb = lp -> tx_skb ; <nl>  <nl> enable_irq ( lp -> spi -> irq ); <nl>  <nl> - ieee802154_xmit_complete ( lp -> hw , skb , ! lp -> tx_aret ); <nl> + ieee802154_xmit_complete ( lp -> hw , lp -> tx_skb , ! lp -> tx_aret ); <nl> } <nl>  <nl> static void
static void sas_revalidate_domain ( struct work_struct * work ) <nl> struct sas_discovery_event * ev = to_sas_discovery_event ( work ); <nl> struct asd_sas_port * port = ev -> port ; <nl> struct sas_ha_struct * ha = port -> ha ; <nl> + struct domain_device * ddev = port -> port_dev ; <nl>  <nl> /* prevent revalidation from finding sata links in recovery */ <nl> mutex_lock (& ha -> disco_mutex ); <nl> static void sas_revalidate_domain ( struct work_struct * work ) <nl> SAS_DPRINTK (" REVALIDATING DOMAIN on port % d , pid :% d \ n ", port -> id , <nl> task_pid_nr ( current )); <nl>  <nl> - if ( port -> port_dev ) <nl> - res = sas_ex_revalidate_domain ( port -> port_dev ); <nl> + if ( ddev && ( ddev -> dev_type == SAS_FANOUT_EXPANDER_DEVICE || <nl> + ddev -> dev_type == SAS_EDGE_EXPANDER_DEVICE )) <nl> + res = sas_ex_revalidate_domain ( ddev ); <nl>  <nl> SAS_DPRINTK (" done REVALIDATING DOMAIN on port % d , pid :% d , res 0x % x \ n ", <nl> port -> id , task_pid_nr ( current ), res );
static int netlink_release ( struct socket * sock ) <nl>  <nl> netlink_table_grab (); <nl> if ( netlink_is_kernel ( sk )) { <nl> - kfree ( nl_table [ sk -> sk_protocol ]. listeners ); <nl> - nl_table [ sk -> sk_protocol ]. module = NULL ; <nl> - nl_table [ sk -> sk_protocol ]. registered = 0 ; <nl> + BUG_ON ( nl_table [ sk -> sk_protocol ]. registered == 0 ); <nl> + if (-- nl_table [ sk -> sk_protocol ]. registered == 0 ) { <nl> + kfree ( nl_table [ sk -> sk_protocol ]. listeners ); <nl> + nl_table [ sk -> sk_protocol ]. module = NULL ; <nl> + nl_table [ sk -> sk_protocol ]. registered = 0 ; <nl> + } <nl> } else if ( nlk -> subscriptions ) <nl> netlink_update_listeners ( sk ); <nl> netlink_table_ungrab (); <nl> netlink_kernel_create ( struct net * net , int unit , unsigned int groups , <nl> nl_table [ unit ]. registered = 1 ; <nl> } else { <nl> kfree ( listeners ); <nl> + nl_table [ unit ]. registered ++; <nl> } <nl> netlink_table_ungrab (); <nl> 
static int __devinit adp8870_probe ( struct i2c_client * client , <nl> mutex_init (& data -> lock ); <nl>  <nl> memset (& props , 0 , sizeof ( props )); <nl> + props . type = BACKLIGHT_RAW ; <nl> props . max_brightness = props . brightness = ADP8870_MAX_BRIGHTNESS ; <nl> bl = backlight_device_register ( dev_driver_string (& client -> dev ), <nl> & client -> dev , data , & adp8870_bl_ops , & props );
void __init tsc_calibrate ( void ) <nl> if ( hpet ) { <nl> printk ( KERN_INFO " TSC calibrated against HPET \ n "); <nl> if ( hpet2 < hpet1 ) <nl> - hpet2 += 0x100000000 ; <nl> + hpet2 += 0x100000000UL ; <nl> hpet2 -= hpet1 ; <nl> tsc1 = ( hpet2 * hpet_readl ( HPET_PERIOD )) / 1000000 ; <nl> } else {
static void alloc_init_pmd ( struct mm_struct * mm , pud_t * pud , <nl> if (! pmd_none ( old_pmd )) { <nl> flush_tlb_all (); <nl> if ( pmd_table ( old_pmd )) { <nl> - phys_addr_t table = __pa ( pte_offset_map (& old_pmd , 0 )); <nl> + phys_addr_t table = pmd_page_paddr ( old_pmd ); <nl> if (! WARN_ON_ONCE ( slab_is_available ())) <nl> memblock_free ( table , PAGE_SIZE ); <nl> } <nl> static void alloc_init_pud ( struct mm_struct * mm , pgd_t * pgd , <nl> if (! pud_none ( old_pud )) { <nl> flush_tlb_all (); <nl> if ( pud_table ( old_pud )) { <nl> - phys_addr_t table = __pa ( pmd_offset (& old_pud , 0 )); <nl> + phys_addr_t table = pud_page_paddr ( old_pud ); <nl> if (! WARN_ON_ONCE ( slab_is_available ())) <nl> memblock_free ( table , PAGE_SIZE ); <nl> }
 <nl> # ifdef CONFIG_PM <nl>  <nl> -/* changes to device_may_wakeup take effect on the next pm state change . <nl> - * by default , devices should wakeup if they can . <nl> +/* Changes to device_may_wakeup take effect on the next pm state change . <nl> + * <nl> + * By default , most devices should leave wakeup disabled . The exceptions <nl> + * are devices that everyone expects to be wakeup sources : keyboards , <nl> + * power buttons , possibly network interfaces , etc . <nl> */ <nl> static inline void device_init_wakeup ( struct device * dev , bool val ) <nl> { <nl> static inline bool device_may_wakeup ( struct device * dev ) <nl>  <nl> # else /* ! CONFIG_PM */ <nl>  <nl> -/* For some reason the next two routines work even without CONFIG_PM */ <nl> +/* For some reason the following routines work even without CONFIG_PM */ <nl> static inline void device_init_wakeup ( struct device * dev , bool val ) <nl> { <nl> dev -> power . can_wakeup = val ; <nl> static inline void device_init_wakeup ( struct device * dev , bool val ) <nl>  <nl> static inline void device_set_wakeup_capable ( struct device * dev , bool capable ) <nl> { <nl> + dev -> power . can_wakeup = capable ; <nl> } <nl>  <nl> static inline bool device_can_wakeup ( struct device * dev )
int irq_domain_simple_dt_translate ( struct irq_domain * d , <nl> return - EINVAL ; <nl> if ( intsize < 1 ) <nl> return - EINVAL ; <nl> + if ( d -> nr_irq && (( intspec [ 0 ] < d -> hwirq_base ) || <nl> + ( intspec [ 0 ] >= d -> hwirq_base + d -> nr_irq ))) <nl> + return - EINVAL ; <nl>  <nl> * out_hwirq = intspec [ 0 ]; <nl> * out_type = IRQ_TYPE_NONE ;
static int snd_compr_allocate_buffer ( struct snd_compr_stream * stream , <nl> unsigned int buffer_size ; <nl> void * buffer ; <nl>  <nl> + if ( params -> buffer . fragment_size == 0 || <nl> + params -> buffer . fragments > SIZE_MAX / params -> buffer . fragment_size ) <nl> + return - EINVAL ; <nl> + <nl> buffer_size = params -> buffer . fragment_size * params -> buffer . fragments ; <nl> if ( stream -> ops -> copy ) { <nl> buffer = NULL ;
static int mxs_i2c_xfer_msg ( struct i2c_adapter * adap , struct i2c_msg * msg , <nl>  <nl> if ( i2c -> cmd_err == - ENXIO ) <nl> mxs_i2c_reset ( i2c ); <nl> + else <nl> + writel ( MXS_I2C_QUEUECTRL_QUEUE_RUN , <nl> + i2c -> regs + MXS_I2C_QUEUECTRL_CLR ); <nl>  <nl> dev_dbg ( i2c -> dev , " Done with err =% d \ n ", i2c -> cmd_err ); <nl>  <nl> static int __devexit mxs_i2c_remove ( struct platform_device * pdev ) <nl> if ( ret ) <nl> return - EBUSY ; <nl>  <nl> - writel ( MXS_I2C_QUEUECTRL_QUEUE_RUN , <nl> - i2c -> regs + MXS_I2C_QUEUECTRL_CLR ); <nl> writel ( MXS_I2C_CTRL0_SFTRST , i2c -> regs + MXS_I2C_CTRL0_SET ); <nl>  <nl> platform_set_drvdata ( pdev , NULL );
# define CAL_NF ( nf ) (( s32 )(-( s32 )( nf ))) <nl> # define CAL_RSSI ( snr , nf ) (( s32 )(( s32 )( snr ) + CAL_NF ( nf ))) <nl>  <nl> - static struct cmd_ctrl_node * lbs_get_cmd_ctrl_node ( struct lbs_private * priv ); <nl> - <nl> /** <nl> * @ brief Simple callback that copies response back into command <nl> * <nl> done : <nl> * @ param priv A pointer to struct lbs_private structure <nl> * @ return cmd_ctrl_node A pointer to cmd_ctrl_node structure or NULL <nl> */ <nl> - static struct cmd_ctrl_node * lbs_get_cmd_ctrl_node ( struct lbs_private * priv ) <nl> + static struct cmd_ctrl_node * lbs_get_free_cmd_node ( struct lbs_private * priv ) <nl> { <nl> struct cmd_ctrl_node * tempnode ; <nl> unsigned long flags ; <nl> struct cmd_ctrl_node * __lbs_cmd_async ( struct lbs_private * priv , <nl> } <nl> } <nl>  <nl> - cmdnode = lbs_get_cmd_ctrl_node ( priv ); <nl> + cmdnode = lbs_get_free_cmd_node ( priv ); <nl> if ( cmdnode == NULL ) { <nl> lbs_deb_host (" PREP_CMD : cmdnode is NULL \ n "); <nl> 
void led_trigger_register_simple ( const char * name , struct led_trigger ** tp ) <nl> if ( trigger ) { <nl> trigger -> name = name ; <nl> err = led_trigger_register ( trigger ); <nl> - if ( err < 0 ) <nl> + if ( err < 0 ) { <nl> + kfree ( trigger ); <nl> + trigger = NULL ; <nl> printk ( KERN_WARNING " LED trigger % s failed to register " <nl> " (% d )\ n ", name , err ); <nl> + } <nl> } else <nl> printk ( KERN_WARNING " LED trigger % s failed to register " <nl> " ( no memory )\ n ", name );
static int dmx_section_feed_release_filter ( struct dmx_section_feed * feed , <nl> return - EINVAL ; <nl> } <nl>  <nl> - if ( feed -> is_filtering ) <nl> + if ( feed -> is_filtering ) { <nl> + /* release dvbdmx -> mutex as far as <nl> + it is acquired by stop_filtering () itself */ <nl> + mutex_unlock (& dvbdmx -> mutex ); <nl> feed -> stop_filtering ( feed ); <nl> + mutex_lock (& dvbdmx -> mutex ); <nl> + } <nl>  <nl> spin_lock_irq (& dvbdmx -> lock ); <nl> f = dvbdmxfeed -> filter ;
void usb_serial_generic_process_read_urb ( struct urb * urb ) <nl> char * ch = ( char *) urb -> transfer_buffer ; <nl> int i ; <nl>  <nl> + if (! urb -> actual_length ) <nl> + return ; <nl> + <nl> tty = tty_port_tty_get (& port -> port ); <nl> if (! tty ) <nl> return ;
int btrfs_sync_file ( struct file * file , struct dentry * dentry , int datasync ) <nl> } <nl> mutex_lock (& dentry -> d_inode -> i_mutex ); <nl> out : <nl> - return ret > 0 ? EIO : ret ; <nl> + return ret > 0 ? - EIO : ret ; <nl> } <nl>  <nl> static const struct vm_operations_struct btrfs_file_vm_ops = {
static struct ib_mr * mthca_reg_phys_mr ( struct ib_pd * pd , <nl> convert_access ( acc ), mr ); <nl>  <nl> if ( err ) { <nl> + kfree ( page_list ); <nl> kfree ( mr ); <nl> return ERR_PTR ( err ); <nl> }
void blkcg_drain_queue ( struct request_queue * q ) <nl> { <nl> lockdep_assert_held ( q -> queue_lock ); <nl>  <nl> + /* <nl> + * @ q could be exiting and already have destroyed all blkgs as <nl> + * indicated by NULL root_blkg . If so , don ' t confuse policies . <nl> + */ <nl> + if (! q -> root_blkg ) <nl> + return ; <nl> + <nl> blk_throtl_drain ( q ); <nl> } <nl> 
static struct platform_driver gef_wdt_driver = { <nl> . of_match_table = gef_wdt_ids , <nl> }, <nl> . probe = gef_wdt_probe , <nl> + . remove = gef_wdt_remove , <nl> }; <nl>  <nl> static int __init gef_wdt_init ( void )
static int handle_cap_grant ( struct inode * inode , struct ceph_mds_caps * grant , <nl> revoked_rdcache ) <nl> reply = 2 ; /* send revoke ack in check_caps */ <nl> cap -> issued = newcaps ; <nl> + cap -> implemented |= newcaps ; <nl> } else if ( cap -> issued == newcaps ) { <nl> dout (" caps unchanged : % s -> % s \ n ", <nl> ceph_cap_string ( cap -> issued ), ceph_cap_string ( newcaps )); <nl> static int handle_cap_grant ( struct inode * inode , struct ceph_mds_caps * grant , <nl> * pending revocation */ <nl> wake = 1 ; <nl> } <nl> + BUG_ON ( cap -> issued & ~ cap -> implemented ); <nl>  <nl> spin_unlock (& inode -> i_lock ); <nl> if ( writeback )
int ixgbe_ndo_set_vf_spoofchk ( struct net_device * netdev , int vf , bool setting ) <nl> struct ixgbe_hw * hw = & adapter -> hw ; <nl> u32 regval ; <nl>  <nl> + if ( vf >= adapter -> num_vfs ) <nl> + return - EINVAL ; <nl> + <nl> adapter -> vfinfo [ vf ]. spoofchk_enabled = setting ; <nl>  <nl> regval = IXGBE_READ_REG ( hw , IXGBE_PFVFSPOOF ( vf_target_reg ));
static void ftdi_process_read ( struct work_struct * work ) <nl> spin_unlock_irqrestore (& priv -> rx_lock , flags ); <nl> dbg ("% s - deferring remainder until unthrottled ", <nl> __func__ ); <nl> - return ; <nl> + goto out ; <nl> } <nl> spin_unlock_irqrestore (& priv -> rx_lock , flags ); <nl> /* if the port is closed stop trying to read */
static struct dmi_system_id __initdata acpisleep_dmi_table [] = { <nl> DMI_MATCH ( DMI_PRODUCT_NAME , " Macmini1 , 1 "), <nl> }, <nl> }, <nl> + { <nl> + . callback = init_old_suspend_ordering , <nl> + . ident = " Asus Pundit P1 - AH2 ( M2N8L motherboard )", <nl> + . matches = { <nl> + DMI_MATCH ( DMI_BOARD_VENDOR , " ASUSTek Computer INC ."), <nl> + DMI_MATCH ( DMI_BOARD_NAME , " M2N8L "), <nl> + }, <nl> + }, <nl> {}, <nl> }; <nl> # endif /* CONFIG_SUSPEND */
static s8 link_speed ; <nl> static u8 ch_no ; <nl> static u8 set_ip [ 2 ][ 4 ]; <nl> static u8 get_ip [ 2 ][ 4 ]; <nl> - static u32 gu32InactiveTime ; <nl> + static u32 inactive_time ; <nl> static u8 gu8DelBcn ; <nl> static u32 gu32WidConnRstHack ; <nl>  <nl> static s32 Handle_Get_InActiveTime ( struct host_if_drv * hif_drv , <nl>  <nl> strWID . id = ( u16 ) WID_GET_INACTIVE_TIME ; <nl> strWID . type = WID_INT ; <nl> - strWID . val = ( s8 *)& gu32InactiveTime ; <nl> + strWID . val = ( s8 *)& inactive_time ; <nl> strWID . size = sizeof ( u32 ); <nl>  <nl>  <nl> static s32 Handle_Get_InActiveTime ( struct host_if_drv * hif_drv , <nl> return - EFAULT ; <nl> } <nl>  <nl> - <nl> - PRINT_D ( CFG80211_DBG , " Getting inactive time : % d \ n ", gu32InactiveTime ); <nl> + PRINT_D ( CFG80211_DBG , " Getting inactive time : % d \ n ", inactive_time ); <nl>  <nl> up (& hif_drv -> hSemInactiveTime ); <nl>  <nl> s32 host_int_get_inactive_time ( struct host_if_drv * hif_drv , <nl>  <nl> down (& hif_drv -> hSemInactiveTime ); <nl>  <nl> - * pu32InactiveTime = gu32InactiveTime ; <nl> + * pu32InactiveTime = inactive_time ; <nl>  <nl> return s32Error ; <nl> }
static int pmic_irq_type ( unsigned irq , unsigned type ) <nl> u32 gpio = irq - pg -> irq_base ; <nl> unsigned long flags ; <nl>  <nl> - if ( gpio > pg -> chip . ngpio ) <nl> + if ( gpio >= pg -> chip . ngpio ) <nl> return - EINVAL ; <nl>  <nl> spin_lock_irqsave (& pg -> irqtypes . lock , flags );
static int sd_init ( struct gspca_dev * gspca_dev ) <nl> struct sd * sd = ( struct sd *) gspca_dev ; <nl> int i ; <nl> u16 sensor_id ; <nl> - u8 test_byte ; <nl> + u8 test_byte = 0 ; <nl> u16 reg80 , reg8e ; <nl>  <nl> static const u8 read_indexs [] =
void rtw_alloc_hwxmits ( struct adapter * padapter ) <nl>  <nl> pxmitpriv -> hwxmit_entry = HWXMIT_ENTRY ; <nl>  <nl> - pxmitpriv -> hwxmits = kzalloc ( sizeof ( struct hw_xmit ) * pxmitpriv -> hwxmit_entry , GFP_KERNEL ); <nl> + pxmitpriv -> hwxmits = kcalloc ( pxmitpriv -> hwxmit_entry , <nl> + sizeof ( struct hw_xmit ), GFP_KERNEL ); <nl>  <nl> hwxmits = pxmitpriv -> hwxmits ; <nl> 
struct xc5000_config { <nl> /* xc5000 callback command */ <nl> # define XC5000_TUNER_RESET 0 <nl>  <nl> -# if defined ( CONFIG_DVB_TUNER_XC5000 ) || defined ( CONFIG_DVB_TUNER_XC5000_MODULE ) <nl> +# if defined ( CONFIG_DVB_TUNER_XC5000 ) || \ <nl> + ( defined ( CONFIG_DVB_TUNER_XC5000_MODULE ) && defined ( MODULE )) <nl> extern struct dvb_frontend * xc5000_attach ( struct dvb_frontend * fe , <nl> struct i2c_adapter * i2c , <nl> struct xc5000_config * cfg );
static long media_device_enum_entities ( struct media_device * mdev , <nl> struct media_entity * ent ; <nl> struct media_entity_desc u_ent ; <nl>  <nl> + memset (& u_ent , 0 , sizeof ( u_ent )); <nl> if ( copy_from_user (& u_ent . id , & uent -> id , sizeof ( u_ent . id ))) <nl> return - EFAULT ; <nl> 
static int long_term_keys_show ( struct seq_file * f , void * ptr ) <nl> struct list_head * p , * n ; <nl>  <nl> hci_dev_lock ( hdev ); <nl> - list_for_each_safe ( p , n , & hdev -> link_keys ) { <nl> + list_for_each_safe ( p , n , & hdev -> long_term_keys ) { <nl> struct smp_ltk * ltk = list_entry ( p , struct smp_ltk , list ); <nl> - seq_printf ( f , "% pMR ( type % u ) % u % u % u %. 4x %* phN %* phN \\ n ", <nl> + seq_printf ( f , "% pMR ( type % u ) % u 0x % 02x % u %. 4x %* phN %* phN \ n ", <nl> & ltk -> bdaddr , ltk -> bdaddr_type , ltk -> authenticated , <nl> ltk -> type , ltk -> enc_size , __le16_to_cpu ( ltk -> ediv ), <nl> 8 , ltk -> rand , 16 , ltk -> val );
static int rtllib_qos_convert_ac_to_parameters ( struct rtllib_qos_parameter_info <nl> qos_param -> aifs [ aci ] = ( ac_params -> aci_aifsn ) & 0x0f ; <nl>  <nl> /* WMM spec P . 11 : The minimum value for AIFSN shall be 2 */ <nl> - qos_param -> aifs [ aci ] = ( qos_param -> aifs [ aci ] < 2 ) ? 2 : qos_param -> aifs [ aci ]; <nl> + qos_param -> aifs [ aci ] = max_t ( u8 , qos_param -> aifs [ aci ], 2 ); <nl>  <nl> qos_param -> cw_min [ aci ] = cpu_to_le16 ( ac_params -> ecw_min_max & <nl> 0x0F );
 <nl> # define DRV_MODULE_NAME " tg3 " <nl> # define PFX DRV_MODULE_NAME ": " <nl> -# define DRV_MODULE_VERSION " 3 . 84 " <nl> -# define DRV_MODULE_RELDATE " October 12 , 2007 " <nl> +# define DRV_MODULE_VERSION " 3 . 85 " <nl> +# define DRV_MODULE_RELDATE " October 18 , 2007 " <nl>  <nl> # define TG3_DEF_MAC_MODE 0 <nl> # define TG3_DEF_RX_MODE 0
DECLARE_EVENT_CLASS ( xhci_log_event , <nl> __field ( u64 , dma ) <nl> __field ( u32 , status ) <nl> __field ( u32 , flags ) <nl> - __dynamic_array ( __le32 , trb , 4 ) <nl> + __dynamic_array ( u8 , trb , sizeof ( struct xhci_generic_trb )) <nl> ), <nl> TP_fast_assign ( <nl> __entry -> va = trb_va ;
void md_check_recovery ( mddev_t * mddev ) <nl> /* resync has finished , collect result */ <nl> md_unregister_thread ( mddev -> sync_thread ); <nl> mddev -> sync_thread = NULL ; <nl> - if (! test_bit ( MD_RECOVERY_INTR , & mddev -> recovery )) { <nl> + if (! test_bit ( MD_RECOVERY_INTR , & mddev -> recovery ) && <nl> + ! test_bit ( MD_RECOVERY_REQUESTED , & mddev -> recovery )) { <nl> /* success ...*/ <nl> /* activate any spares */ <nl> if ( mddev -> pers -> spare_active ( mddev )) <nl> void md_check_recovery ( mddev_t * mddev ) <nl> } else if (( spares = remove_and_add_spares ( mddev ))) { <nl> clear_bit ( MD_RECOVERY_SYNC , & mddev -> recovery ); <nl> clear_bit ( MD_RECOVERY_CHECK , & mddev -> recovery ); <nl> + clear_bit ( MD_RECOVERY_REQUESTED , & mddev -> recovery ); <nl> set_bit ( MD_RECOVERY_RECOVER , & mddev -> recovery ); <nl> } else if ( mddev -> recovery_cp < MaxSector ) { <nl> set_bit ( MD_RECOVERY_SYNC , & mddev -> recovery );
static struct intel_iommu * device_to_iommu ( u8 bus , u8 devfn ) <nl> if ( drhd -> ignored ) <nl> continue ; <nl>  <nl> - for ( i = 0 ; i < drhd -> devices_cnt ; i ++) <nl> + for ( i = 0 ; i < drhd -> devices_cnt ; i ++) { <nl> if ( drhd -> devices [ i ] && <nl> drhd -> devices [ i ]-> bus -> number == bus && <nl> drhd -> devices [ i ]-> devfn == devfn ) <nl> return drhd -> iommu ; <nl> + if ( drhd -> devices [ i ]-> subordinate && <nl> + drhd -> devices [ i ]-> subordinate -> number <= bus && <nl> + drhd -> devices [ i ]-> subordinate -> subordinate >= bus ) <nl> + return drhd -> iommu ; <nl> + } <nl>  <nl> if ( drhd -> include_all ) <nl> return drhd -> iommu ;
static int exynos_drm_fbdev_update ( struct drm_fb_helper * helper , <nl>  <nl> fbi -> screen_base = buffer -> kvaddr + offset ; <nl> fbi -> screen_size = size ; <nl> + fbi -> fix . smem_len = size ; <nl>  <nl> return 0 ; <nl> }
static void mv_otg_work ( struct work_struct * work ) <nl> struct usb_otg * otg ; <nl> int old_state ; <nl>  <nl> - mvotg = container_of (( struct delayed_work *) work , struct mv_otg , work ); <nl> + mvotg = container_of ( to_delayed_work ( work ), struct mv_otg , work ); <nl>  <nl> run : <nl> /* work queue is single thread , or we need spin_lock to protect */
static void sonic_rx ( struct net_device * dev ) <nl> status = sonic_rda_get ( dev , entry , SONIC_RD_STATUS ); <nl> if ( status & SONIC_RCR_PRX ) { <nl> /* Malloc up new buffer . */ <nl> - new_skb = netdev_alloc_skb ( SONIC_RBSIZE + 2 ); <nl> + new_skb = netdev_alloc_skb ( dev , SONIC_RBSIZE + 2 ); <nl> if ( new_skb == NULL ) { <nl> printk ( KERN_ERR "% s : Memory squeeze , dropping packet .\ n ", dev -> name ); <nl> lp -> stats . rx_dropped ++;
static struct scsi_host_template aac_driver_template = { <nl>  <nl> static void __aac_shutdown ( struct aac_dev * aac ) <nl> { <nl> - kthread_stop ( aac -> thread ); <nl> + if ( aac -> aif_thread ) <nl> + kthread_stop ( aac -> thread ); <nl> aac_send_shutdown ( aac ); <nl> aac_adapter_disable_int ( aac ); <nl> free_irq ( aac -> pdev -> irq , aac );
int iwl_mvm_sched_scan_start ( struct iwl_mvm * mvm , <nl> return - EBUSY ; <nl> } <nl>  <nl> + /* we don ' t support " match all " in the firmware */ <nl> + if (! req -> n_match_sets ) <nl> + return - EOPNOTSUPP ; <nl> + <nl> ret = iwl_mvm_check_running_scans ( mvm , type ); <nl> if ( ret ) <nl> return ret ;
struct ib_umem * ib_umem_get ( struct ib_ucontext * context , unsigned long addr , <nl> if ( dmasync ) <nl> dma_set_attr ( DMA_ATTR_WRITE_BARRIER , & attrs ); <nl>  <nl> + if (! size ) <nl> + return ERR_PTR (- EINVAL ); <nl> + <nl> /* <nl> * If the combination of the addr and size requested for this memory <nl> * region causes an integer overflow , return error .
int bt_procfs_init ( struct net * net , const char * name , <nl> struct bt_sock_list * sk_list , <nl> int (* seq_show )( struct seq_file *, void *)) <nl> { <nl> - struct proc_dir_entry * pde ; <nl> - <nl> sk_list -> custom_seq_show = seq_show ; <nl>  <nl> - pde = proc_create ( name , 0 , net -> proc_net , & bt_fops ); <nl> - if (! pde ) <nl> + if (! proc_create_data ( name , 0 , net -> proc_net , & bt_fops , sk_list )) <nl> return - ENOMEM ; <nl> - <nl> - pde -> data = sk_list ; <nl> - <nl> return 0 ; <nl> } <nl> 
static int mxs_spi_transfer_one ( struct spi_master * master , <nl> * DMA only : 2 . 164808 seconds , 473 . 0KB / s <nl> * Combined : 1 . 676276 seconds , 610 . 9KB / s <nl> */ <nl> - if ( t -> len <= 256 ) { <nl> + if ( t -> len < 32 ) { <nl> writel ( BM_SSP_CTRL1_DMA_ENABLE , <nl> ssp -> base + HW_SSP_CTRL1 ( ssp ) + <nl> STMP_OFFSET_REG_CLR );
static struct platform_driver omap_hsmmc_driver = { <nl> static int __init omap_hsmmc_init ( void ) <nl> { <nl> /* Register the MMC driver */ <nl> - return platform_driver_register (& omap_hsmmc_driver ); <nl> + return platform_driver_probe (& omap_hsmmc_driver , omap_hsmmc_probe ); <nl> } <nl>  <nl> static void __exit omap_hsmmc_cleanup ( void )
int sctp_sysctl_net_register ( struct net * net ) <nl> table [ i ]. data += ( char *)(& net -> sctp ) - ( char *)& init_net . sctp ; <nl>  <nl> net -> sctp . sysctl_header = register_net_sysctl ( net , " net / sctp ", table ); <nl> + if ( net -> sctp . sysctl_header == NULL ) { <nl> + kfree ( table ); <nl> + return - ENOMEM ; <nl> + } <nl> return 0 ; <nl> } <nl> 
static int ov7670_read ( struct i2c_client * c , unsigned char reg , <nl> int ret ; <nl>  <nl> ret = i2c_smbus_read_byte_data ( c , reg ); <nl> - if ( ret >= 0 ) <nl> + if ( ret >= 0 ) { <nl> * value = ( unsigned char ) ret ; <nl> + ret = 0 ; <nl> + } <nl> return ret ; <nl> } <nl> 
static enum odd_mech_type zpodd_get_mech_type ( struct ata_device * dev ) <nl> static bool odd_can_poweroff ( struct ata_device * ata_dev ) <nl> { <nl> acpi_handle handle ; <nl> - acpi_status status ; <nl> struct acpi_device * acpi_dev ; <nl>  <nl> handle = ata_dev_acpi_handle ( ata_dev ); <nl> if (! handle ) <nl> return false ; <nl>  <nl> - status = acpi_bus_get_device ( handle , & acpi_dev ); <nl> - if ( ACPI_FAILURE ( status )) <nl> + if ( acpi_bus_get_device ( handle , & acpi_dev )) <nl> return false ; <nl>  <nl> return acpi_device_can_poweroff ( acpi_dev );
remove_write ( struct device_driver * drv , const char * buf , size_t count ) <nl> count = IFNAMSIZ - 1 ; <nl>  <nl> for ( i = 0 , p =( char *) buf ; i < count && * p ; i ++, p ++) { <nl> - if ((* p == '\ n ') | (* p == ' ')) { <nl> + if ((* p == '\ n ') || (* p == ' ')) { <nl> /* trailing lf , grr */ <nl> break ; <nl> } else {
static int bnx2x_init_dev ( struct bnx2x * bp , struct pci_dev * pdev , <nl> pci_write_config_dword ( bp -> pdev , PCICFG_GRC_ADDRESS , <nl> PCICFG_VENDOR_ID_OFFSET ); <nl>  <nl> + /* Set PCIe reset type to fundamental for EEH recovery */ <nl> + pdev -> needs_freset = 1 ; <nl> + <nl> /* AER ( Advanced Error reporting ) configuration */ <nl> rc = pci_enable_pcie_error_reporting ( pdev ); <nl> if (! rc )
kvm_irqfd_assign ( struct kvm * kvm , struct kvm_irqfd * args ) <nl> lockdep_is_held (& kvm -> irqfds . lock )); <nl> irqfd_update ( kvm , irqfd , irq_rt ); <nl>  <nl> - events = f . file -> f_op -> poll ( f . file , & irqfd -> pt ); <nl> - <nl> list_add_tail (& irqfd -> list , & kvm -> irqfds . items ); <nl>  <nl> + spin_unlock_irq (& kvm -> irqfds . lock ); <nl> + <nl> /* <nl> * Check if there was an event already pending on the eventfd <nl> * before we registered , and trigger it as if we didn ' t miss it . <nl> */ <nl> + events = f . file -> f_op -> poll ( f . file , & irqfd -> pt ); <nl> + <nl> if ( events & POLLIN ) <nl> schedule_work (& irqfd -> inject ); <nl>  <nl> - spin_unlock_irq (& kvm -> irqfds . lock ); <nl> - <nl> /* <nl> * do not drop the file until the irqfd is fully initialized , otherwise <nl> * we might race against the POLLHUP
find_mad_agent ( struct ib_mad_port_private * port_priv , <nl> mad -> mad_hdr . class_version ]. class ; <nl> if (! class ) <nl> goto out ; <nl> + if ( convert_mgmt_class ( mad -> mad_hdr . mgmt_class ) >= <nl> + IB_MGMT_MAX_METHODS ) <nl> + goto out ; <nl> method = class -> method_table [ convert_mgmt_class ( <nl> mad -> mad_hdr . mgmt_class )]; <nl> if ( method )
static int qset_add_urb_sg ( struct whc * whc , struct whc_qset * qset , struct urb * u <nl> || ( prev_end & ( WHCI_PAGE_SIZE - 1 )) <nl> || ( dma_addr & ( WHCI_PAGE_SIZE - 1 )) <nl> || std -> len + WHCI_PAGE_SIZE > QTD_MAX_XFER_SIZE ) { <nl> - if ( std -> len % qset -> max_packet != 0 ) <nl> + if ( std && std -> len % qset -> max_packet != 0 ) <nl> return - EINVAL ; <nl> std = qset_new_std ( whc , qset , urb , mem_flags ); <nl> if ( std == NULL ) {
 <nl> # define __pfn_to_page ( pfn ) \ <nl> ({ unsigned long __pfn = ( pfn ); \ <nl> - unsigned long __nid = arch_pfn_to_nid ( pfn ); \ <nl> + unsigned long __nid = arch_pfn_to_nid ( __pfn ); \ <nl> NODE_DATA ( __nid )-> node_mem_map + arch_local_page_offset ( __pfn , __nid );\ <nl> }) <nl> 
static int run_perf_stat ( int argc __used , const char ** argv ) <nl> "\ t Consider tweaking " <nl> " / proc / sys / kernel / perf_event_paranoid or running as root .", <nl> system_wide ? " system - wide " : ""); <nl> + } else if ( errno == ENOENT ) { <nl> + error ("% s event is not supported . ", event_name ( counter )); <nl> } else { <nl> error (" open_counter returned with % d (% s ). " <nl> "/ bin / dmesg may provide additional information .\ n ",
void iio_disable_all_buffers ( struct iio_dev * indio_dev ) <nl> indio_dev -> currentmode = INDIO_DIRECT_MODE ; <nl> if ( indio_dev -> setup_ops -> postdisable ) <nl> indio_dev -> setup_ops -> postdisable ( indio_dev ); <nl> + <nl> + if ( indio_dev -> available_scan_masks == NULL ) <nl> + kfree ( indio_dev -> active_scan_mask ); <nl> } <nl>  <nl> int iio_update_buffers ( struct iio_dev * indio_dev ,
static long rtc_dev_ioctl ( struct file * file , <nl> err = ops -> ioctl ( rtc -> dev . parent , cmd , arg ); <nl> if ( err == - ENOIOCTLCMD ) <nl> err = - ENOTTY ; <nl> - } <nl> + } else <nl> + err = - ENOTTY ; <nl> break ; <nl> } <nl> 
struct netdev_queue { <nl> struct Qdisc * qdisc ; <nl> unsigned long state ; <nl> struct Qdisc * qdisc_sleeping ; <nl> -# ifdef CONFIG_RPS <nl> +# if defined ( CONFIG_RPS ) || defined ( CONFIG_XPS ) <nl> struct kobject kobj ; <nl> # endif <nl> # if defined ( CONFIG_XPS ) && defined ( CONFIG_NUMA ) <nl> struct net_device { <nl>  <nl> unsigned char broadcast [ MAX_ADDR_LEN ]; /* hw bcast add */ <nl>  <nl> -# ifdef CONFIG_RPS <nl> +# if defined ( CONFIG_RPS ) || defined ( CONFIG_XPS ) <nl> struct kset * queues_kset ; <nl>  <nl> struct netdev_rx_queue * _rx ;
tracing_mark_write ( struct file * filp , const char __user * ubuf , <nl> size_t cnt , loff_t * fpos ) <nl> { <nl> unsigned long addr = ( unsigned long ) ubuf ; <nl> + struct trace_array * tr = filp -> private_data ; <nl> struct ring_buffer_event * event ; <nl> struct ring_buffer * buffer ; <nl> struct print_entry * entry ; <nl> tracing_mark_write ( struct file * filp , const char __user * ubuf , <nl>  <nl> local_save_flags ( irq_flags ); <nl> size = sizeof (* entry ) + cnt + 2 ; /* possible \ n added */ <nl> - buffer = global_trace . trace_buffer . buffer ; <nl> + buffer = tr -> trace_buffer . buffer ; <nl> event = trace_buffer_lock_reserve ( buffer , TRACE_PRINT , size , <nl> irq_flags , preempt_count ()); <nl> if (! event ) {
static ssize_t wm8962_beep_set ( struct device * dev , <nl> { <nl> struct wm8962_priv * wm8962 = dev_get_drvdata ( dev ); <nl> long int time ; <nl> + int ret ; <nl>  <nl> - strict_strtol ( buf , 10 , & time ); <nl> + ret = strict_strtol ( buf , 10 , & time ); <nl> + if ( ret != 0 ) <nl> + return ret ; <nl>  <nl> input_event ( wm8962 -> beep , EV_SND , SND_TONE , time ); <nl> 
static int uevent_net_init ( struct net * net ) <nl> if (! ue_sk -> sk ) { <nl> printk ( KERN_ERR <nl> " kobject_uevent : unable to create netlink socket !\ n "); <nl> + kfree ( ue_sk ); <nl> return - ENODEV ; <nl> } <nl> mutex_lock (& uevent_sock_mutex );
static bool hist_browser__toggle_fold ( struct hist_browser * browser ) <nl> struct callchain_list * cl = container_of ( ms , struct callchain_list , ms ); <nl> bool has_children ; <nl>  <nl> + if (! he || ! ms ) <nl> + return false ; <nl> + <nl> if ( ms == & he -> ms ) <nl> has_children = hist_entry__toggle_fold ( he ); <nl> else
static int em28xx_v4l2_suspend ( struct em28xx * dev ) <nl> if (! dev -> has_video ) <nl> return 0 ; <nl>  <nl> - em28xx_info (" Suspending video extension "); <nl> + em28xx_info (" Suspending video extension \ n "); <nl> em28xx_stop_urbs ( dev ); <nl> return 0 ; <nl> } <nl> static int em28xx_v4l2_resume ( struct em28xx * dev ) <nl> if (! dev -> has_video ) <nl> return 0 ; <nl>  <nl> - em28xx_info (" Resuming video extension "); <nl> + em28xx_info (" Resuming video extension \ n "); <nl> /* what do we do here */ <nl> return 0 ; <nl> }
static void usb_stor_scan_dwork ( struct work_struct * work ) <nl> !( us -> fflags & US_FL_SCM_MULT_TARG )) { <nl> mutex_lock (& us -> dev_mutex ); <nl> us -> max_lun = usb_stor_Bulk_max_lun ( us ); <nl> + /* <nl> + * Allow proper scanning of devices that present more than 8 LUNs <nl> + * While not affecting other devices that may need the previous behavior <nl> + */ <nl> + if ( us -> max_lun >= 8 ) <nl> + us_to_host ( us )-> max_lun = us -> max_lun + 1 ; <nl> mutex_unlock (& us -> dev_mutex ); <nl> } <nl> scsi_scan_host ( us_to_host ( us ));
int f2fs_getxattr ( struct inode * inode , int name_index , const char * name , <nl> if ( name == NULL ) <nl> return - EINVAL ; <nl> name_len = strlen ( name ); <nl> + if ( name_len > F2FS_NAME_LEN ) <nl> + return - ERANGE ; <nl>  <nl> base_addr = read_all_xattrs ( inode , NULL ); <nl> if (! base_addr )
static int ocfs2_initialize_super ( struct super_block * sb , <nl> cbits = le32_to_cpu ( di -> id2 . i_super . s_clustersize_bits ); <nl> bbits = le32_to_cpu ( di -> id2 . i_super . s_blocksize_bits ); <nl> sb -> s_maxbytes = ocfs2_max_file_offset ( bbits , cbits ); <nl> + memcpy ( sb -> s_uuid , di -> id2 . i_super . s_uuid , <nl> + sizeof ( di -> id2 . i_super . s_uuid )); <nl>  <nl> osb -> osb_dx_mask = ( 1 << ( cbits - bbits )) - 1 ; <nl> 
static void hsmmc_command_incomplete ( struct omap_hsmmc_host * host , <nl> if ( host -> data ) { <nl> omap_hsmmc_reset_controller_fsm ( host , SRD ); <nl> omap_hsmmc_dma_cleanup ( host , err ); <nl> - } <nl> - <nl> + } else if ( host -> mrq && host -> mrq -> cmd ) <nl> + host -> mrq -> cmd -> error = err ; <nl> } <nl>  <nl> static void omap_hsmmc_do_irq ( struct omap_hsmmc_host * host , int status )
static int dwc3_ep0_set_config ( struct dwc3 * dwc , struct usb_ctrlrequest * ctrl ) <nl> case DWC3_ADDRESS_STATE : <nl> ret = dwc3_ep0_delegate_req ( dwc , ctrl ); <nl> /* if the cfg matches and the cfg is non zero */ <nl> - if (! ret && cfg ) <nl> + if ( cfg && (! ret || ( ret == USB_GADGET_DELAYED_STATUS ))) <nl> dwc -> dev_state = DWC3_CONFIGURED_STATE ; <nl> break ; <nl> 
static void conn_action_txdone ( fsm_instance * fi , int event , void * arg ) <nl>  <nl> IUCV_DBF_TEXT ( trace , 4 , __func__ ); <nl>  <nl> - if ( conn && conn -> netdev ) <nl> - privptr = netdev_priv ( conn -> netdev ); <nl> + if (! conn || ! conn -> netdev ) { <nl> + IUCV_DBF_TEXT ( data , 2 , <nl> + " Send confirmation for unlinked connection \ n "); <nl> + return ; <nl> + } <nl> + privptr = netdev_priv ( conn -> netdev ); <nl> conn -> prof . tx_pending --; <nl> if ( single_flag ) { <nl> if (( skb = skb_dequeue (& conn -> commit_queue ))) {
static int __access_remote_vm ( struct task_struct * tsk , struct mm_struct * mm , <nl> */ <nl> # ifdef CONFIG_HAVE_IOREMAP_PROT <nl> vma = find_vma ( mm , addr ); <nl> - if (! vma ) <nl> + if (! vma || vma -> vm_start > addr ) <nl> break ; <nl> if ( vma -> vm_ops && vma -> vm_ops -> access ) <nl> ret = vma -> vm_ops -> access ( vma , addr , buf ,
conf_software : <nl> if ( dsp -> pcm_slot_rx >= 0 && <nl> dsp -> pcm_slot_rx < <nl> sizeof ( freeslots )) <nl> - freeslots [ dsp -> pcm_slot_tx ] = 0 ; <nl> + freeslots [ dsp -> pcm_slot_rx ] = 0 ; <nl> if ( dsp -> pcm_slot_tx >= 0 && <nl> dsp -> pcm_slot_tx < <nl> sizeof ( freeslots )) <nl> - freeslots [ dsp -> pcm_slot_rx ] = 0 ; <nl> + freeslots [ dsp -> pcm_slot_tx ] = 0 ; <nl> } <nl> } <nl> i = 0 ; <nl> conf_software : <nl> if ( dsp -> pcm_slot_rx >= 0 && <nl> dsp -> pcm_slot_rx < <nl> sizeof ( freeslots )) <nl> - freeslots [ dsp -> pcm_slot_tx ] = 0 ; <nl> + freeslots [ dsp -> pcm_slot_rx ] = 0 ; <nl> if ( dsp -> pcm_slot_tx >= 0 && <nl> dsp -> pcm_slot_tx < <nl> sizeof ( freeslots )) <nl> - freeslots [ dsp -> pcm_slot_rx ] = 0 ; <nl> + freeslots [ dsp -> pcm_slot_tx ] = 0 ; <nl> } <nl> } <nl> i1 = 0 ;
static int hfsplus_fill_super ( struct super_block * sb , void * data , int silent ) <nl> u64 last_fs_block , last_fs_page ; <nl> int err ; <nl>  <nl> - err = - EINVAL ; <nl> + err = - ENOMEM ; <nl> sbi = kzalloc ( sizeof (* sbi ), GFP_KERNEL ); <nl> if (! sbi ) <nl> goto out ;
static int ocfs2_initialize_super ( struct super_block * sb , <nl> sb -> s_fs_info = osb ; <nl> sb -> s_op = & ocfs2_sops ; <nl> sb -> s_export_op = & ocfs2_export_ops ; <nl> + sb -> s_time_gran = 1 ; <nl> sb -> s_flags |= MS_NOATIME ; <nl> /* this is needed to support O_LARGEFILE */ <nl> cbits = le32_to_cpu ( di -> id2 . i_super . s_clustersize_bits );
 <nl> # define BUILD_IRQ ( nr ) \ <nl> asmlinkage void IRQ_NAME ( nr ); \ <nl> - asm ("\ n . p2align \ n " \ <nl> + asm ("\ n . text \ n . p2align \ n " \ <nl> " IRQ " # nr " _interrupt :\ n \ t " \ <nl> " push $~(" # nr ") ; " \ <nl> " jmp common_interrupt ");
static struct dmar_domain * iommu_alloc_domain ( struct intel_iommu * iommu ) <nl> set_bit ( num , iommu -> domain_ids ); <nl> domain -> id = num ; <nl> domain -> iommu = iommu ; <nl> + domain -> flags = 0 ; <nl> iommu -> domains [ num ] = domain ; <nl> spin_unlock_irqrestore (& iommu -> lock , flags ); <nl> 
static int __smiapp_sel_supported ( struct v4l2_subdev * subdev , <nl> == SMIAPP_DIGITAL_CROP_CAPABILITY_INPUT_CROP ) <nl> return 0 ; <nl> return - EINVAL ; <nl> + case V4L2_SEL_TGT_NATIVE_SIZE : <nl> + if ( ssd == sensor -> pixel_array <nl> + && sel -> pad == SMIAPP_PA_PAD_SRC ) <nl> + return 0 ; <nl> + return - EINVAL ; <nl> case V4L2_SEL_TGT_COMPOSE : <nl> case V4L2_SEL_TGT_COMPOSE_BOUNDS : <nl> if ( sel -> pad == ssd -> source_pad ) <nl> static int __smiapp_get_selection ( struct v4l2_subdev * subdev , <nl>  <nl> switch ( sel -> target ) { <nl> case V4L2_SEL_TGT_CROP_BOUNDS : <nl> + case V4L2_SEL_TGT_NATIVE_SIZE : <nl> if ( ssd == sensor -> pixel_array ) { <nl> sel -> r . left = sel -> r . top = 0 ; <nl> sel -> r . width =
mptscsih_qcmd ( struct scsi_cmnd * SCpnt , void (* done )( struct scsi_cmnd *)) <nl> && ( vdevice -> vtarget -> tflags & MPT_TARGET_FLAGS_Q_YES ) <nl> && ( SCpnt -> device -> tagged_supported )) { <nl> scsictl = scsidir | MPI_SCSIIO_CONTROL_SIMPLEQ ; <nl> - } else { <nl> + if ( SCpnt -> request && SCpnt -> request -> ioprio ) { <nl> + if ((( SCpnt -> request -> ioprio & 0x7 ) == 1 ) || <nl> + !( SCpnt -> request -> ioprio & 0x7 )) <nl> + scsictl |= MPI_SCSIIO_CONTROL_HEADOFQ ; <nl> + } <nl> + } else <nl> scsictl = scsidir | MPI_SCSIIO_CONTROL_UNTAGGED ; <nl> - } <nl> + <nl>  <nl> /* Use the above information to set up the message frame <nl> */
static int call__parse ( struct ins_operands * ops ) <nl> return ops -> target . name == NULL ? - 1 : 0 ; <nl>  <nl> indirect_call : <nl> + tok = strchr ( endptr , '('); <nl> + if ( tok != NULL ) { <nl> + ops -> target . addr = 0 ; <nl> + return 0 ; <nl> + } <nl> + <nl> tok = strchr ( endptr , '*'); <nl> if ( tok == NULL ) <nl> return - 1 ; <nl> static int call__scnprintf ( struct ins * ins , char * bf , size_t size , <nl> if ( ops -> target . name ) <nl> return scnprintf ( bf , size , "%- 6 . 6s % s ", ins -> name , ops -> target . name ); <nl>  <nl> + if ( ops -> target . addr == 0 ) <nl> + return ins__raw_scnprintf ( ins , bf , size , ops ); <nl> + <nl> return scnprintf ( bf , size , "%- 6 . 6s *%" PRIx64 , ins -> name , ops -> target . addr ); <nl> } <nl> 
static void dev_remove ( struct net * net , dev_t dev ) <nl>  <nl> bl_pipe_msg . bl_wq = & nn -> bl_wq ; <nl> memset ( msg , 0 , sizeof (* msg )); <nl> - msg -> data = kzalloc ( 1 + sizeof ( bl_umount_request ), GFP_NOFS ); <nl> + msg -> len = sizeof ( bl_msg ) + bl_msg . totallen ; <nl> + msg -> data = kzalloc ( msg -> len , GFP_NOFS ); <nl> if (! msg -> data ) <nl> goto out ; <nl>  <nl> static void dev_remove ( struct net * net , dev_t dev ) <nl> memcpy ( msg -> data , & bl_msg , sizeof ( bl_msg )); <nl> dataptr = ( uint8_t *) msg -> data ; <nl> memcpy (& dataptr [ sizeof ( bl_msg )], & bl_umount_request , sizeof ( bl_umount_request )); <nl> - msg -> len = sizeof ( bl_msg ) + bl_msg . totallen ; <nl>  <nl> add_wait_queue (& nn -> bl_wq , & wq ); <nl> if ( rpc_queue_upcall ( nn -> bl_device_pipe , msg ) < 0 ) {
static int mwl8k_tx_wait_empty ( struct ieee80211_hw * hw ) <nl>  <nl> rc = - ETIMEDOUT ; <nl> } <nl> + priv -> tx_wait = NULL ; <nl> spin_unlock_bh (& priv -> tx_lock ); <nl>  <nl> return rc ;
static int patch_stac922x ( struct hda_codec * codec ) <nl> */ <nl> printk ( KERN_INFO " hda_codec : STAC922x , Apple subsys_id =% x \ n ", codec -> subsystem_id ); <nl> switch ( codec -> subsystem_id ) { <nl> + case 0x106b0a00 : /* MacBook First generatoin */ <nl> + spec -> board_config = STAC_MACBOOK ; <nl> + break ; <nl> case 0x106b0200 : /* MacBook Pro first generation */ <nl> spec -> board_config = STAC_MACBOOK_PRO_V1 ; <nl> break ;
intel_crt_load_detect ( struct drm_crtc * crtc , struct intel_encoder * intel_encoder <nl> if ( IS_I9XX ( dev )) { <nl> uint32_t pipeconf = I915_READ ( pipeconf_reg ); <nl> I915_WRITE ( pipeconf_reg , pipeconf | PIPECONF_FORCE_BORDER ); <nl> + POSTING_READ ( pipeconf_reg ); <nl> /* Wait for next Vblank to substitue <nl> * border color for Color info */ <nl> intel_wait_for_vblank ( dev , pipe );
static void ibmveth_replenish_buffer_pool ( struct ibmveth_adapter * adapter , struc <nl> break ; <nl> } <nl>  <nl> - free_index = pool -> consumer_index ++ % pool -> size ; <nl> - pool -> consumer_index = free_index ; <nl> + free_index = pool -> consumer_index ; <nl> + pool -> consumer_index = ( pool -> consumer_index + 1 ) % pool -> size ; <nl> index = pool -> free_map [ free_index ]; <nl>  <nl> ibmveth_assert ( index != IBM_VETH_INVALID_MAP ); <nl> static void ibmveth_remove_buffer_from_pool ( struct ibmveth_adapter * adapter , u64 <nl> adapter -> rx_buff_pool [ pool ]. buff_size , <nl> DMA_FROM_DEVICE ); <nl>  <nl> - free_index = adapter -> rx_buff_pool [ pool ]. producer_index ++ % adapter -> rx_buff_pool [ pool ]. size ; <nl> - adapter -> rx_buff_pool [ pool ]. producer_index = free_index ; <nl> + free_index = adapter -> rx_buff_pool [ pool ]. producer_index ; <nl> + adapter -> rx_buff_pool [ pool ]. producer_index <nl> + = ( adapter -> rx_buff_pool [ pool ]. producer_index + 1 ) <nl> + % adapter -> rx_buff_pool [ pool ]. size ; <nl> adapter -> rx_buff_pool [ pool ]. free_map [ free_index ] = index ; <nl>  <nl> mb ();
static int pci_netmos_init ( struct pci_dev * dev ) <nl> /* subdevice 0x00PS means < P > parallel , < S > serial */ <nl> unsigned int num_serial = dev -> subsystem_device & 0xf ; <nl>  <nl> + if ( dev -> subsystem_vendor == PCI_VENDOR_ID_IBM && <nl> + dev -> subsystem_device == 0x0299 ) <nl> + return 0 ; <nl> + <nl> if ( num_serial == 0 ) <nl> return - ENODEV ; <nl> return num_serial ; <nl> static struct pci_device_id serial_pci_tbl [] = { <nl> 0 , <nl> pbn_b0_8_115200 }, <nl>  <nl> + { PCI_VENDOR_ID_NETMOS , PCI_DEVICE_ID_NETMOS_9835 , <nl> + PCI_VENDOR_ID_IBM , 0x0299 , <nl> + 0 , 0 , pbn_b0_bt_2_115200 }, <nl> + <nl> /* <nl> * These entries match devices with class COMMUNICATION_SERIAL , <nl> * COMMUNICATION_MODEM or COMMUNICATION_MULTISERIAL
# include < linux / list . h > <nl> # include < linux / module . h > <nl> # include < linux / slab . h > <nl> +# include < linux / string . h > <nl>  <nl> # include < asm / hvcall . h > <nl> # include < asm / hvcserver . h > <nl> int hvcs_get_partner_info ( uint32_t unit_address , struct list_head * head , <nl> = ( unsigned int ) last_p_partition_ID ; <nl>  <nl> /* copy the Null - term char too */ <nl> - strncpy (& next_partner_info -> location_code [ 0 ], <nl> + strlcpy (& next_partner_info -> location_code [ 0 ], <nl> ( char *)& pi_buff [ 2 ], <nl> - strlen (( char *)& pi_buff [ 2 ]) + 1 ); <nl> + sizeof ( next_partner_info -> location_code )); <nl>  <nl> list_add_tail (&( next_partner_info -> node ), head ); <nl> next_partner_info = NULL ;
static struct vfsmount * nfs_do_root_mount ( struct file_system_type * fs_type , <nl> char * root_devname ; <nl> size_t len ; <nl>  <nl> - len = strlen ( hostname ) + 3 ; <nl> + len = strlen ( hostname ) + 5 ; <nl> root_devname = kmalloc ( len , GFP_KERNEL ); <nl> if ( root_devname == NULL ) <nl> return ERR_PTR (- ENOMEM ); <nl> - snprintf ( root_devname , len , "% s :/", hostname ); <nl> + /* Does hostname needs to be enclosed in brackets ? */ <nl> + if ( strchr ( hostname , ':')) <nl> + snprintf ( root_devname , len , "[% s ]:/", hostname ); <nl> + else <nl> + snprintf ( root_devname , len , "% s :/", hostname ); <nl> root_mnt = vfs_kern_mount ( fs_type , flags , root_devname , data ); <nl> kfree ( root_devname ); <nl> return root_mnt ;
static void reset_connection ( struct ceph_connection * con ) <nl> con -> out_msg = NULL ; <nl> } <nl> con -> in_seq = 0 ; <nl> + con -> in_seq_acked = 0 ; <nl> } <nl>  <nl> /*
static int zram_bvec_read ( struct zram * zram , struct bio_vec * bvec , <nl> return 0 ; <nl> } <nl>  <nl> - user_mem = kmap_atomic ( page ); <nl> if ( is_partial_io ( bvec )) <nl> /* Use a temporary buffer to decompress the page */ <nl> - uncmem = kmalloc ( PAGE_SIZE , GFP_KERNEL ); <nl> - else <nl> + uncmem = kmalloc ( PAGE_SIZE , GFP_NOIO ); <nl> + <nl> + user_mem = kmap_atomic ( page ); <nl> + if (! is_partial_io ( bvec )) <nl> uncmem = user_mem ; <nl>  <nl> if (! uncmem ) { <nl> static int zram_bvec_write ( struct zram * zram , struct bio_vec * bvec , u32 index , <nl> * This is a partial IO . We need to read the full page <nl> * before to write the changes . <nl> */ <nl> - uncmem = kmalloc ( PAGE_SIZE , GFP_KERNEL ); <nl> + uncmem = kmalloc ( PAGE_SIZE , GFP_NOIO ); <nl> if (! uncmem ) { <nl> pr_info (" Error allocating temp memory !\ n "); <nl> ret = - ENOMEM ;
static int parse_gfp_flags ( struct perf_evsel * evsel , struct perf_sample * sample , <nl> . size = sample -> raw_size , <nl> }; <nl> struct trace_seq seq ; <nl> - char * str , * pos ; <nl> + char * str , * pos = NULL ; <nl>  <nl> if ( nr_gfps ) { <nl> struct gfp_flag key = {
int pci_hotplug ( struct device * dev , char ** envp , int num_envp , <nl> if (( buffer_size - length <= 0 ) || ( i >= num_envp )) <nl> return - ENOMEM ; <nl>  <nl> + envp [ i ++] = scratch ; <nl> + length += scnprintf ( scratch , buffer_size - length , <nl> + " MODALIAS = pci : v % 08Xd % 08Xsv % 08Xsd % 08Xbc % 02Xsc % 02Xi % 02x \ n ", <nl> + pdev -> vendor , pdev -> device , <nl> + pdev -> subsystem_vendor , pdev -> subsystem_device , <nl> + ( u8 )( pdev -> class >> 16 ), ( u8 )( pdev -> class >> 8 ), <nl> + ( u8 )( pdev -> class )); <nl> + if (( buffer_size - length <= 0 ) || ( i >= num_envp )) <nl> + return - ENOMEM ; <nl> + <nl> envp [ i ] = NULL ; <nl>  <nl> return 0 ;
EXPORT_SYMBOL ( ipv6_chk_prefix ); <nl> struct inet6_ifaddr * ipv6_get_ifaddr ( struct net * net , const struct in6_addr * addr , <nl> struct net_device * dev , int strict ) <nl> { <nl> - struct inet6_ifaddr * ifp = NULL ; <nl> - struct hlist_node * node ; <nl> + struct inet6_ifaddr * ifp , * result = NULL ; <nl> unsigned int hash = ipv6_addr_hash ( addr ); <nl> + struct hlist_node * node ; <nl>  <nl> rcu_read_lock_bh (); <nl> hlist_for_each_entry_rcu ( ifp , node , & inet6_addr_lst [ hash ], addr_lst ) { <nl> struct inet6_ifaddr * ipv6_get_ifaddr ( struct net * net , const struct in6_addr * add <nl> if ( ipv6_addr_equal (& ifp -> addr , addr )) { <nl> if ( dev == NULL || ifp -> idev -> dev == dev || <nl> !( ifp -> scope &( IFA_LINK | IFA_HOST ) || strict )) { <nl> + result = ifp ; <nl> in6_ifa_hold ( ifp ); <nl> break ; <nl> } <nl> struct inet6_ifaddr * ipv6_get_ifaddr ( struct net * net , const struct in6_addr * add <nl> } <nl> rcu_read_unlock_bh (); <nl>  <nl> - return ifp ; <nl> + return result ; <nl> } <nl>  <nl> /* Gets referenced address , destroys ifaddr */
static const struct snd_soc_dapm_widget ak4641_dapm_widgets [] = { <nl> SND_SOC_DAPM_PGA (" Mono Out 2 ", AK4641_PM2 , 3 , 0 , NULL , 0 ), <nl>  <nl> SND_SOC_DAPM_ADC (" Voice ADC ", " Voice Capture ", AK4641_BTIF , 0 , 0 ), <nl> - SND_SOC_DAPM_ADC (" Voice DAC ", " Voice Playback ", AK4641_BTIF , 1 , 0 ), <nl> + SND_SOC_DAPM_DAC (" Voice DAC ", " Voice Playback ", AK4641_BTIF , 1 , 0 ), <nl>  <nl> SND_SOC_DAPM_MICBIAS (" Mic Int Bias ", AK4641_MIC , 3 , 0 ), <nl> SND_SOC_DAPM_MICBIAS (" Mic Ext Bias ", AK4641_MIC , 4 , 0 ),
static void unlock_two_stripes ( struct stripe_head * sh1 , struct stripe_head * sh2 ) <nl> /* Only freshly new full stripe normal write stripe can be added to a batch list */ <nl> static bool stripe_can_batch ( struct stripe_head * sh ) <nl> { <nl> + struct r5conf * conf = sh -> raid_conf ; <nl> + <nl> + if ( conf -> log ) <nl> + return false ; <nl> return test_bit ( STRIPE_BATCH_READY , & sh -> state ) && <nl> ! test_bit ( STRIPE_BITMAP_PENDING , & sh -> state ) && <nl> is_full_stripe_write ( sh );
static int __devinit sc6000_init_board ( char __iomem * vport , int irq , int dma , <nl> return err ; <nl> } <nl>  <nl> + memset ( answer , 0 , sizeof ( answer )); <nl> err = sc6000_dsp_get_answer ( vport , GET_DSP_COPYRIGHT , answer , 15 ); <nl> if ( err <= 0 ) { <nl> snd_printk ( KERN_ERR " sc6000_dsp_copyright : failed !\ n "); <nl> static int __devinit snd_sc6000_probe ( struct device * devptr , unsigned int dev ) <nl> snd_printk ( KERN_ERR PFX <nl> " SC - 6000 port I / O port region is already in use .\ n "); <nl> err = - EBUSY ; <nl> - goto err_unmap2 ; <nl> + goto err_unmap1 ; <nl> } <nl> vmss_port = devm_ioport_map ( devptr , mss_port [ dev ], 4 ); <nl> if (! vport ) {
static void perf_event__process_sample ( struct perf_tool * tool , <nl> " Kernel address maps (/ proc /{ kallsyms , modules }) are restricted .\ n \ n " <nl> " Check / proc / sys / kernel / kptr_restrict .\ n \ n " <nl> " Kernel % s samples will not be resolved .\ n ", <nl> - ! RB_EMPTY_ROOT (& al . map -> dso -> symbols [ MAP__FUNCTION ]) ? <nl> + al . map && ! RB_EMPTY_ROOT (& al . map -> dso -> symbols [ MAP__FUNCTION ]) ? <nl> " modules " : ""); <nl> if ( use_browser <= 0 ) <nl> sleep ( 5 );
static void __init of_omap2_apll_setup ( struct device_node * node ) <nl> const char * parent_name ; <nl> u32 val ; <nl>  <nl> - ad = kzalloc ( sizeof (* clk_hw ), GFP_KERNEL ); <nl> + ad = kzalloc ( sizeof (* ad ), GFP_KERNEL ); <nl> clk_hw = kzalloc ( sizeof (* clk_hw ), GFP_KERNEL ); <nl> init = kzalloc ( sizeof (* init ), GFP_KERNEL ); <nl> 
static int cryptd_create_blkcipher ( struct crypto_template * tmpl , <nl> return PTR_ERR ( alg ); <nl>  <nl> inst = cryptd_alloc_instance ( alg , 0 , sizeof (* ctx )); <nl> + err = PTR_ERR ( inst ); <nl> if ( IS_ERR ( inst )) <nl> goto out_put_alg ; <nl>  <nl> static int cryptd_create_hash ( struct crypto_template * tmpl , struct rtattr ** tb , <nl> alg = & salg -> base ; <nl> inst = cryptd_alloc_instance ( alg , ahash_instance_headroom (), <nl> sizeof (* ctx )); <nl> + err = PTR_ERR ( inst ); <nl> if ( IS_ERR ( inst )) <nl> goto out_put_alg ; <nl> 
void bcm43xx_phy_set_baseband_attenuation ( struct bcm43xx_private * bcm , <nl> return ; <nl> } <nl>  <nl> - if ( phy -> analog > 1 ) { <nl> + if ( phy -> analog == 1 ) { <nl> value = bcm43xx_phy_read ( bcm , 0x0060 ) & ~ 0x003C ; <nl> value |= ( baseband_attenuation << 2 ) & 0x003C ; <nl> } else {
static struct dmi_system_id acer_quirks [] = { <nl> }, <nl> . driver_data = & quirk_lenovo_ideapad_s205 , <nl> }, <nl> + { <nl> + . callback = dmi_matched , <nl> + . ident = " Lenovo Ideapad S205 - 1038DPG ", <nl> + . matches = { <nl> + DMI_MATCH ( DMI_SYS_VENDOR , " LENOVO "), <nl> + DMI_MATCH ( DMI_PRODUCT_NAME , " 1038DPG "), <nl> + }, <nl> + . driver_data = & quirk_lenovo_ideapad_s205 , <nl> + }, <nl> {} <nl> }; <nl> 
acpi_ds_build_internal_package_obj ( struct acpi_walk_state * walk_state , <nl> arg = arg -> common . next ; <nl> } <nl>  <nl> - ACPI_ERROR (( AE_INFO , <nl> + ACPI_WARNING (( AE_INFO , <nl> " Package List length (% X ) larger than NumElements count (% X ), truncated \ n ", <nl> i , element_count )); <nl> } else if ( i < element_count ) {
device_release_WPADEV ( pDevice ); <nl> free_netdev ( pDevice -> dev ); <nl> } <nl>  <nl> - kfree ( pDevice ); <nl> DBG_PRT ( MSG_LEVEL_DEBUG , KERN_INFO " device_disconnect3 .. \ n "); <nl> } <nl> 
static int rj54n1_s_crop ( struct v4l2_subdev * sd , struct v4l2_crop * a ) <nl> struct i2c_client * client = sd -> priv ; <nl> struct rj54n1 * rj54n1 = to_rj54n1 ( client ); <nl> struct v4l2_rect * rect = & a -> c ; <nl> - unsigned int dummy , output_w , output_h , <nl> + unsigned int dummy = 0 , output_w , output_h , <nl> input_w = rect -> width , input_h = rect -> height ; <nl> int ret ; <nl> 
void em28xx_uninit_isoc ( struct em28xx * dev ) <nl> */ <nl> int em28xx_init_isoc ( struct em28xx * dev ) <nl> { <nl> - /* change interface to 3 which allowes the biggest packet sizes */ <nl> + /* change interface to 3 which allows the biggest packet sizes */ <nl> int i , errCode ; <nl> const int sb_size = EM28XX_NUM_PACKETS * dev -> max_pkt_size ; <nl>  <nl> int em28xx_init_isoc ( struct em28xx * dev ) <nl> (" unable to allocate % i bytes for transfer buffer % i \ n ", <nl> sb_size , i ); <nl> em28xx_uninit_isoc ( dev ); <nl> + usb_free_urb ( urb ); <nl> return - ENOMEM ; <nl> } <nl> memset ( dev -> transfer_buffer [ i ], 0 , sb_size );
static int bcmgenet_probe ( struct platform_device * pdev ) <nl> struct resource * r ; <nl> int err = - EIO ; <nl>  <nl> - /* Up to GENET_MAX_MQ_CNT + 1 TX queues and a single RX queue */ <nl> - dev = alloc_etherdev_mqs ( sizeof (* priv ), GENET_MAX_MQ_CNT + 1 , 1 ); <nl> + /* Up to GENET_MAX_MQ_CNT + 1 TX queues and RX queues */ <nl> + dev = alloc_etherdev_mqs ( sizeof (* priv ), GENET_MAX_MQ_CNT + 1 , <nl> + GENET_MAX_MQ_CNT + 1 ); <nl> if (! dev ) { <nl> dev_err (& pdev -> dev , " can ' t allocate net device \ n "); <nl> return - ENOMEM ;
static long btrfs_ioctl_dev_info ( struct btrfs_root * root , void __user * arg ) <nl>  <nl> mutex_lock (& fs_devices -> device_list_mutex ); <nl> dev = btrfs_find_device ( root -> fs_info , di_args -> devid , s_uuid , NULL ); <nl> - mutex_unlock (& fs_devices -> device_list_mutex ); <nl>  <nl> if (! dev ) { <nl> ret = - ENODEV ; <nl> static long btrfs_ioctl_dev_info ( struct btrfs_root * root , void __user * arg ) <nl> } <nl>  <nl> out : <nl> + mutex_unlock (& fs_devices -> device_list_mutex ); <nl> if ( ret == 0 && copy_to_user ( arg , di_args , sizeof (* di_args ))) <nl> ret = - EFAULT ; <nl> 
twobyte_insn : <nl> | (( u64 ) c -> regs [ VCPU_REGS_RDX ] << 32 ); <nl> if ( kvm_set_msr ( ctxt -> vcpu , c -> regs [ VCPU_REGS_RCX ], msr_data )) { <nl> kvm_inject_gp ( ctxt -> vcpu , 0 ); <nl> - c -> eip = ctxt -> eip ; <nl> + goto done ; <nl> } <nl> rc = X86EMUL_CONTINUE ; <nl> c -> dst . type = OP_NONE ; <nl> twobyte_insn : <nl> /* rdmsr */ <nl> if ( kvm_get_msr ( ctxt -> vcpu , c -> regs [ VCPU_REGS_RCX ], & msr_data )) { <nl> kvm_inject_gp ( ctxt -> vcpu , 0 ); <nl> - c -> eip = ctxt -> eip ; <nl> + goto done ; <nl> } else { <nl> c -> regs [ VCPU_REGS_RAX ] = ( u32 ) msr_data ; <nl> c -> regs [ VCPU_REGS_RDX ] = msr_data >> 32 ;
static int cgroup_attach_proc ( struct cgroup * cgrp , struct task_struct * leader ) <nl> if (! group ) <nl> return - ENOMEM ; <nl> /* pre - allocate to guarantee space while iterating in rcu read - side . */ <nl> - retval = flex_array_prealloc ( group , 0 , group_size - 1 , GFP_KERNEL ); <nl> + retval = flex_array_prealloc ( group , 0 , group_size , GFP_KERNEL ); <nl> if ( retval ) <nl> goto out_free_group_list ; <nl> 
static ssize_t hid_debug_events_read ( struct file * file , char __user * buffer , <nl>  <nl> if (! list -> hdev || ! list -> hdev -> debug ) { <nl> ret = - EIO ; <nl> - break ; <nl> + set_current_state ( TASK_RUNNING ); <nl> + goto out ; <nl> } <nl>  <nl> /* allow O_NONBLOCK from other threads */
static int pcf2123_probe ( struct spi_device * spi ) <nl>  <nl> if (!( rxbuf [ 0 ] & 0x20 )) { <nl> dev_err (& spi -> dev , " chip not found \ n "); <nl> + ret = - ENODEV ; <nl> goto kfree_exit ; <nl> } <nl> 
int pstore_register ( struct pstore_info * psi ) <nl> add_timer (& pstore_timer ); <nl> } <nl>  <nl> + /* <nl> + * Update the module parameter backend , so it is visible <nl> + * through / sys / module / pstore / parameters / backend <nl> + */ <nl> + backend = psi -> name ; <nl> + <nl> pr_info (" Registered % s as persistent store backend \ n ", psi -> name ); <nl>  <nl> return 0 ;
static int __init ubi_mtd_param_parse ( const char * val , struct kernel_param * kp ) <nl> char * pbuf = & buf [ 0 ]; <nl> char * tokens [ 3 ] = { NULL , NULL , NULL }; <nl>  <nl> + if (! val ) <nl> + return - EINVAL ; <nl> + <nl> if ( mtd_devs == UBI_MAX_DEVICES ) { <nl> printk (" UBI error : too many parameters , max . is % d \ n ", <nl> UBI_MAX_DEVICES );
int ocfs2_cluster_connect ( const char * stack_name , <nl>  <nl> strlcpy ( new_conn -> cc_name , group , GROUP_NAME_MAX + 1 ); <nl> new_conn -> cc_namelen = grouplen ; <nl> - strlcpy ( new_conn -> cc_cluster_name , cluster_name , CLUSTER_NAME_MAX + 1 ); <nl> + if ( cluster_name_len ) <nl> + strlcpy ( new_conn -> cc_cluster_name , cluster_name , <nl> + CLUSTER_NAME_MAX + 1 ); <nl> new_conn -> cc_cluster_name_len = cluster_name_len ; <nl> new_conn -> cc_recovery_handler = recovery_handler ; <nl> new_conn -> cc_recovery_data = recovery_data ;
ssize_t spk_var_store ( struct kobject * kobj , struct kobj_attribute * attr , <nl> * If voice was just changed , we might need to reset our default <nl> * pitch and volume . <nl> */ <nl> - if ( param -> var_id == VOICE ) { <nl> + if ( param -> var_id == VOICE && synth && <nl> + ( ret == 0 || ret == - ERESTART )) { <nl> + var_data = param -> data ; <nl> + value = var_data -> u . n . value ; <nl> spk_reset_default_value (" pitch ", synth -> default_pitch , <nl> value ); <nl> spk_reset_default_value (" vol ", synth -> default_vol ,
int usb_register_device_driver ( struct usb_device_driver * new_udriver , <nl> return - ENODEV ; <nl>  <nl> new_udriver -> drvwrap . for_devices = 1 ; <nl> - new_udriver -> drvwrap . driver . name = ( char *) new_udriver -> name ; <nl> + new_udriver -> drvwrap . driver . name = new_udriver -> name ; <nl> new_udriver -> drvwrap . driver . bus = & usb_bus_type ; <nl> new_udriver -> drvwrap . driver . probe = usb_probe_device ; <nl> new_udriver -> drvwrap . driver . remove = usb_unbind_device ; <nl> int usb_register_driver ( struct usb_driver * new_driver , struct module * owner , <nl> return - ENODEV ; <nl>  <nl> new_driver -> drvwrap . for_devices = 0 ; <nl> - new_driver -> drvwrap . driver . name = ( char *) new_driver -> name ; <nl> + new_driver -> drvwrap . driver . name = new_driver -> name ; <nl> new_driver -> drvwrap . driver . bus = & usb_bus_type ; <nl> new_driver -> drvwrap . driver . probe = usb_probe_interface ; <nl> new_driver -> drvwrap . driver . remove = usb_unbind_interface ;
static int aer_hest_parse ( struct acpi_hest_header * hest_hdr , void * data ) <nl>  <nl> p = ( struct acpi_hest_aer_common *)( hest_hdr + 1 ); <nl> if ( p -> flags & ACPI_HEST_GLOBAL ) { <nl> - if (( pci_is_pcie ( info -> pci_dev ) && <nl> - pci_pcie_type ( info -> pci_dev ) == pcie_type ) || bridge ) <nl> + if (( pci_pcie_type ( info -> pci_dev ) == pcie_type ) || bridge ) <nl> ff = !!( p -> flags & ACPI_HEST_FIRMWARE_FIRST ); <nl> } else <nl> if ( hest_match_pci ( p , info -> pci_dev )) <nl> static void aer_set_firmware_first ( struct pci_dev * pci_dev ) <nl>  <nl> int pcie_aer_get_firmware_first ( struct pci_dev * dev ) <nl> { <nl> + if (! pci_is_pcie ( dev )) <nl> + return 0 ; <nl> + <nl> if (! dev -> __aer_firmware_first_valid ) <nl> aer_set_firmware_first ( dev ); <nl> return dev -> __aer_firmware_first ;
static int perf_pmu__parse_scale ( struct perf_pmu_alias * alias , char * dir , char * <nl> char scale [ 128 ]; <nl> int fd , ret = - 1 ; <nl> char path [ PATH_MAX ]; <nl> - const char * lc ; <nl> + char * lc ; <nl>  <nl> snprintf ( path , PATH_MAX , "% s /% s . scale ", dir , name ); <nl>  <nl> static int perf_pmu__parse_scale ( struct perf_pmu_alias * alias , char * dir , char * <nl> /* restore locale */ <nl> setlocale ( LC_NUMERIC , lc ); <nl>  <nl> - free (( char *) lc ); <nl> + free ( lc ); <nl>  <nl> ret = 0 ; <nl> error :
static int vq_memory_access_ok ( void __user * log_base , struct vhost_memory * mem , <nl> int log_all ) <nl> { <nl> int i ; <nl> + <nl> + if (! mem ) <nl> + return 0 ; <nl> + <nl> for ( i = 0 ; i < mem -> nregions ; ++ i ) { <nl> struct vhost_memory_region * m = mem -> regions + i ; <nl> unsigned long a = m -> userspace_addr ;
ahc_done ( struct ahc_softc * ahc , struct scb * scb ) <nl> untagged_q = &( ahc -> untagged_queues [ target_offset ]); <nl> TAILQ_REMOVE ( untagged_q , scb , links . tqe ); <nl> BUG_ON (! TAILQ_EMPTY ( untagged_q )); <nl> - } <nl> - <nl> - if (( scb -> flags & SCB_ACTIVE ) == 0 ) { <nl> + } else if (( scb -> flags & SCB_ACTIVE ) == 0 ) { <nl> + /* <nl> + * Transactions aborted from the untagged queue may <nl> + * not have been dispatched to the controller , so <nl> + * only check the SCB_ACTIVE flag for tagged transactions . <nl> + */ <nl> printf (" SCB % d done ' d twice \ n ", scb -> hscb -> tag ); <nl> ahc_dump_card_state ( ahc ); <nl> panic (" Stopping for safety ");
requeue : <nl> else <nl> q -> ops -> requeue ( skb , q ); <nl> netif_schedule ( dev ); <nl> - return 0 ; <nl> } <nl> + return 0 ; <nl>  <nl> out : <nl> BUG_ON (( int ) q -> q . qlen < 0 );
static int mxcmci_probe ( struct platform_device * pdev ) <nl> goto out_release_mem ; <nl> } <nl>  <nl> - mmc_of_parse ( mmc ); <nl> + ret = mmc_of_parse ( mmc ); <nl> + if ( ret ) <nl> + goto out_free ; <nl> mmc -> ops = & mxcmci_ops ; <nl>  <nl> /* For devicetree parsing , the bus width is read from devicetree */
again : <nl> space_info -> flush = 1 ; <nl> } else if (! ret && space_info -> flags & BTRFS_BLOCK_GROUP_METADATA ) { <nl> used += orig_bytes ; <nl> - if ( need_do_async_reclaim ( space_info , root -> fs_info , used ) && <nl> + /* <nl> + * We will do the space reservation dance during log replay , <nl> + * which means we won ' t have fs_info -> fs_root set , so don ' t do <nl> + * the async reclaim as we will panic . <nl> + */ <nl> + if (! root -> fs_info -> log_root_recovering && <nl> + need_do_async_reclaim ( space_info , root -> fs_info , used ) && <nl> ! work_busy (& root -> fs_info -> async_reclaim_work )) <nl> queue_work ( system_unbound_wq , <nl> & root -> fs_info -> async_reclaim_work );
static int bp_device_event ( struct notifier_block * unused , <nl> memcpy (& cbuf , drvinfo . bus_info , 32 ); <nl> buf = & cbuf [ 0 ]; <nl>  <nl> - while (* buf ++ != ':') ; <nl> + while (* buf ++ != ':'); <nl> for ( i = 0 ; i < 10 ; i ++, buf ++) { <nl> if (* buf == ':') <nl> break ; <nl> static void bp75_release_phy ( bpctl_dev_t * pbpctl_dev ) <nl> if (( pbpctl_dev -> func == 1 ) || ( pbpctl_dev -> func == 3 )) <nl> mask = BPCTLI_SWFW_PHY1_SM ; <nl>  <nl> - while ( bp75_get_hw_semaphore_generic ( pbpctl_dev ) != 0 ) ; <nl> + while ( bp75_get_hw_semaphore_generic ( pbpctl_dev ) != 0 ); <nl> /* Empty */ <nl>  <nl> swfw_sync = BPCTL_READ_REG ( pbpctl_dev , SW_FW_SYNC ); <nl> static void if_scan_init ( void ) <nl> memcpy (& cbuf , drvinfo . bus_info , 32 ); <nl> buf = & cbuf [ 0 ]; <nl>  <nl> - while (* buf ++ != ':') ; <nl> + while (* buf ++ != ':'); <nl> for ( i = 0 ; i < 10 ; i ++, buf ++) { <nl> if (* buf == ':') <nl> break ;
static u8 smp_cmd_security_req ( struct l2cap_conn * conn , struct sk_buff * skb ) <nl>  <nl> BT_DBG (" conn % p ", conn ); <nl>  <nl> + if (!( conn -> hcon -> link_mode & HCI_LM_MASTER )) <nl> + return SMP_CMD_NOTSUPP ; <nl> + <nl> hcon -> pending_sec_level = authreq_to_seclevel ( rp -> auth_req ); <nl>  <nl> if ( smp_ltk_encrypt ( conn , hcon -> pending_sec_level ))
static inline void ata_tf_init ( struct ata_device * dev , struct ata_taskfile * tf ) <nl>  <nl> static inline void ata_qc_reinit ( struct ata_queued_cmd * qc ) <nl> { <nl> + qc -> dma_dir = DMA_NONE ; <nl> qc -> __sg = NULL ; <nl> qc -> flags = 0 ; <nl> qc -> cursect = qc -> cursg = qc -> cursg_ofs = 0 ;
static __be32 nfsd4_new_conn ( struct svc_rqst * rqstp , struct nfsd4_session * ses , <nl> if ( ret ) <nl> /* oops ; xprt is already down : */ <nl> nfsd4_conn_lost (& conn -> cn_xpt_user ); <nl> + if ( ses -> se_client -> cl_cb_state == NFSD4_CB_DOWN && <nl> + dir & NFS4_CDFC4_BACK ) { <nl> + /* callback channel may be back up */ <nl> + nfsd4_probe_callback ( ses -> se_client ); <nl> + } <nl> return nfs_ok ; <nl> } <nl> 
# define OP_31_XOP_SLBIA 498 <nl> # define OP_31_XOP_MFSR 595 <nl> # define OP_31_XOP_MFSRIN 659 <nl> +# define OP_31_XOP_DCBA 758 <nl> # define OP_31_XOP_SLBMFEV 851 <nl> # define OP_31_XOP_EIOIO 854 <nl> # define OP_31_XOP_SLBMFEE 915 <nl> int kvmppc_core_emulate_op ( struct kvm_run * run , struct kvm_vcpu * vcpu , <nl> kvmppc_set_gpr ( vcpu , get_rt ( inst ), t ); <nl> } <nl> break ; <nl> + case OP_31_XOP_DCBA : <nl> + /* Gets treated as NOP */ <nl> + break ; <nl> case OP_31_XOP_DCBZ : <nl> { <nl> ulong rb = kvmppc_get_gpr ( vcpu , get_rb ( inst ));
void rtl92e_tx_enable ( struct net_device * dev ) <nl> } <nl>  <nl>  <nl> - static void rtl8192_free_rx_ring ( struct net_device * dev ) <nl> + static void _rtl92e_free_rx_ring ( struct net_device * dev ) <nl> { <nl> struct r8192_priv * priv = rtllib_priv ( dev ); <nl> int i , rx_queue_idx ; <nl> static short _rtl92e_pci_initdescring ( struct net_device * dev ) <nl> return 0 ; <nl>  <nl> err_free_rings : <nl> - rtl8192_free_rx_ring ( dev ); <nl> + _rtl92e_free_rx_ring ( dev ); <nl> for ( i = 0 ; i < MAX_TX_QUEUE_COUNT ; i ++) <nl> if ( priv -> tx_ring [ i ]. desc ) <nl> rtl8192_free_tx_ring ( dev , i ); <nl> static void _rtl92e_pci_disconnect ( struct pci_dev * pdev ) <nl> priv -> pFirmware = NULL ; <nl> } <nl> destroy_workqueue ( priv -> priv_wq ); <nl> - rtl8192_free_rx_ring ( dev ); <nl> + _rtl92e_free_rx_ring ( dev ); <nl> for ( i = 0 ; i < MAX_TX_QUEUE_COUNT ; i ++) <nl> rtl8192_free_tx_ring ( dev , i ); <nl> 
static int smack_inode_unlink ( struct inode * dir , struct dentry * dentry ) <nl> /* <nl> * You also need write access to the containing directory <nl> */ <nl> - smk_ad_setfield_u_fs_path_dentry (& ad , NULL ); <nl> + smk_ad_init (& ad , __func__ , LSM_AUDIT_DATA_INODE ); <nl> smk_ad_setfield_u_fs_inode (& ad , dir ); <nl> rc = smk_curacc ( smk_of_inode ( dir ), MAY_WRITE , & ad ); <nl> } <nl> static int smack_inode_rmdir ( struct inode * dir , struct dentry * dentry ) <nl> /* <nl> * You also need write access to the containing directory <nl> */ <nl> - smk_ad_setfield_u_fs_path_dentry (& ad , NULL ); <nl> + smk_ad_init (& ad , __func__ , LSM_AUDIT_DATA_INODE ); <nl> smk_ad_setfield_u_fs_inode (& ad , dir ); <nl> rc = smk_curacc ( smk_of_inode ( dir ), MAY_WRITE , & ad ); <nl> }
static int bpf_jit_insn ( struct bpf_jit * jit , struct sock_filter * filter , <nl> /* o % r5 ,< d ( K )>(% r13 ) */ <nl> EMIT4_DISP ( 0x5650d000 , EMIT_CONST ( K )); <nl> break ; <nl> + case BPF_S_ANC_ALU_XOR_X : /* A ^= X ; */ <nl> + jit -> seen |= SEEN_XREG ; <nl> + /* xr % r5 ,% r12 */ <nl> + EMIT2 ( 0x175c ); <nl> + break ; <nl> case BPF_S_ALU_LSH_X : /* A <<= X ; */ <nl> jit -> seen |= SEEN_XREG ; <nl> /* sll % r5 , 0 (% r12 ) */
int snd_soc_dapm_new_dai_widgets ( struct snd_soc_dapm_context * dapm , <nl> if (! w ) { <nl> dev_err ( dapm -> dev , " ASoC : Failed to create % s widget \ n ", <nl> dai -> driver -> playback . stream_name ); <nl> + return - ENOMEM ; <nl> } <nl>  <nl> w -> priv = dai ; <nl> int snd_soc_dapm_new_dai_widgets ( struct snd_soc_dapm_context * dapm , <nl> if (! w ) { <nl> dev_err ( dapm -> dev , " ASoC : Failed to create % s widget \ n ", <nl> dai -> driver -> capture . stream_name ); <nl> + return - ENOMEM ; <nl> } <nl>  <nl> w -> priv = dai ;
int ipv6_rcv ( struct sk_buff * skb , struct net_device * dev , struct packet_type * pt <nl> ipv6_addr_loopback (& hdr -> daddr )) <nl> goto err ; <nl>  <nl> + /* <nl> + * RFC4291 2 . 7 <nl> + * Multicast addresses must not be used as source addresses in IPv6 <nl> + * packets or appear in any Routing header . <nl> + */ <nl> + if ( ipv6_addr_is_multicast (& hdr -> saddr )) <nl> + goto err ; <nl> + <nl> skb -> transport_header = skb -> network_header + sizeof (* hdr ); <nl> IP6CB ( skb )-> nhoff = offsetof ( struct ipv6hdr , nexthdr ); <nl> 
void atari_kbd_leds ( unsigned int leds ) <nl>  <nl> static int atari_keyb_done = 0 ; <nl>  <nl> - int __init atari_keyb_init ( void ) <nl> + int atari_keyb_init ( void ) <nl> { <nl> if ( atari_keyb_done ) <nl> return 0 ; <nl> int __init atari_keyb_init ( void ) <nl> atari_keyb_done = 1 ; <nl> return 0 ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( atari_keyb_init ); <nl>  <nl> int atari_kbd_translate ( unsigned char keycode , unsigned char * keycodep , char raw_mode ) <nl> {
static void storvsc_handle_error ( struct vmscsi_request * vm_srb , <nl> do_work = true ; <nl> process_err_fn = storvsc_remove_lun ; <nl> break ; <nl> - case ( SRB_STATUS_ABORTED | SRB_STATUS_AUTOSENSE_VALID ): <nl> - if (( asc == 0x2a ) && ( ascq == 0x9 )) { <nl> + case SRB_STATUS_ABORTED : <nl> + if ( vm_srb -> srb_status & SRB_STATUS_AUTOSENSE_VALID && <nl> + ( asc == 0x2a ) && ( ascq == 0x9 )) { <nl> do_work = true ; <nl> process_err_fn = storvsc_device_scan ; <nl> /*
static struct ocfs2_lock_res_ops ocfs2_inode_meta_lops = { <nl> . get_osb = ocfs2_get_inode_osb , <nl> . check_downconvert = ocfs2_check_meta_downconvert , <nl> . set_lvb = ocfs2_set_meta_lvb , <nl> + . downconvert_worker = ocfs2_data_convert_worker , <nl> . flags = LOCK_TYPE_REQUIRES_REFRESH | LOCK_TYPE_USES_LVB , <nl> }; <nl>  <nl> static int ocfs2_data_convert_worker ( struct ocfs2_lock_res * lockres , <nl> inode = ocfs2_lock_res_inode ( lockres ); <nl> mapping = inode -> i_mapping ; <nl>  <nl> + if ( S_ISREG ( inode -> i_mode )) <nl> + goto out ; <nl> + <nl> /* <nl> * We need this before the filemap_fdatawrite () so that it can <nl> * transfer the dirty bit from the PTE to the <nl> static int ocfs2_data_convert_worker ( struct ocfs2_lock_res * lockres , <nl> filemap_fdatawait ( mapping ); <nl> } <nl>  <nl> + out : <nl> return UNBLOCK_CONTINUE ; <nl> } <nl> 
int ext3_group_add ( struct super_block * sb , struct ext3_new_group_data * input ) <nl> if ( input -> group != EXT3_SB ( sb )-> s_groups_count ) { <nl> ext3_warning ( sb , __FUNCTION__ , <nl> " multiple resizers run on filesystem !\ n "); <nl> + err = - EBUSY ; <nl> goto exit_journal ; <nl> } <nl> 
static irqreturn_t st21nfca_hci_irq_thread_fn ( int irq , void * phy_id ) <nl> msleep ( wait_tab [ phy -> crc_trials ]); <nl> phy -> crc_trials ++; <nl> phy -> current_read_len = 0 ; <nl> + kfree_skb ( phy -> pending_skb ); <nl> } else if ( r > 0 ) { <nl> /* <nl> * We succeeded to read data from the CLF and
static const char * get_input_type ( struct hda_gnode * node , unsigned int * pinctl ) <nl> return " Front Aux "; <nl> return " Aux "; <nl> case AC_JACK_MIC_IN : <nl> - if ( node -> pin_caps & <nl> - ( AC_PINCAP_VREF_80 << AC_PINCAP_VREF_SHIFT )) <nl> + if ( pinctl && <nl> + ( node -> pin_caps & <nl> + ( AC_PINCAP_VREF_80 << AC_PINCAP_VREF_SHIFT ))) <nl> * pinctl |= AC_PINCTL_VREF_80 ; <nl> if (( location & 0x0f ) == AC_JACK_LOC_FRONT ) <nl> return " Front Mic ";
static int ibmvfc_map_sg_data ( struct scsi_cmnd * scmd , <nl> & evt -> ext_list_token ); <nl>  <nl> if (! evt -> ext_list ) { <nl> - scmd_printk ( KERN_ERR , scmd , " Can ' t allocate memory for scatterlist \ n "); <nl> + scsi_dma_unmap ( scmd ); <nl> + if ( vhost -> log_level > IBMVFC_DEFAULT_LOG_LEVEL ) <nl> + scmd_printk ( KERN_ERR , scmd , " Can ' t allocate memory for scatterlist \ n "); <nl> return - ENOMEM ; <nl> } <nl> }
int sk_stream_wait_memory ( struct sock * sk , long * timeo_p ) <nl>  <nl> set_bit ( SOCK_NOSPACE , & sk -> sk_socket -> flags ); <nl> sk -> sk_write_pending ++; <nl> - sk_wait_event ( sk , & current_timeo , ! sk -> sk_err && <nl> - !( sk -> sk_shutdown & SEND_SHUTDOWN ) && <nl> - sk_stream_memory_free ( sk ) && <nl> - vm_wait ); <nl> + sk_wait_event ( sk , & current_timeo , sk -> sk_err || <nl> + ( sk -> sk_shutdown & SEND_SHUTDOWN ) || <nl> + ( sk_stream_memory_free ( sk ) && <nl> + ! vm_wait )); <nl> sk -> sk_write_pending --; <nl>  <nl> if ( vm_wait ) {
cfq_update_io_seektime ( struct cfq_data * cfqd , struct cfq_io_context * cic , <nl> sector_t sdist ; <nl> u64 total ; <nl>  <nl> - if ( cic -> last_request_pos < rq -> sector ) <nl> + if (! cic -> last_request_pos ) <nl> + sdist = 0 ; <nl> + else if ( cic -> last_request_pos < rq -> sector ) <nl> sdist = rq -> sector - cic -> last_request_pos ; <nl> else <nl> sdist = cic -> last_request_pos - rq -> sector ;
static int __access_remote_vm ( struct task_struct * tsk , struct mm_struct * mm , <nl> ret = get_user_pages ( tsk , mm , addr , 1 , <nl> write , 1 , & page , & vma ); <nl> if ( ret <= 0 ) { <nl> +# ifndef CONFIG_HAVE_IOREMAP_PROT <nl> + break ; <nl> +# else <nl> /* <nl> * Check if this is a VM_IO | VM_PFNMAP VMA , which <nl> * we can access using slightly different code . <nl> */ <nl> -# ifdef CONFIG_HAVE_IOREMAP_PROT <nl> vma = find_vma ( mm , addr ); <nl> if (! vma || vma -> vm_start > addr ) <nl> break ; <nl> static int __access_remote_vm ( struct task_struct * tsk , struct mm_struct * mm , <nl> ret = vma -> vm_ops -> access ( vma , addr , buf , <nl> len , write ); <nl> if ( ret <= 0 ) <nl> -# endif <nl> break ; <nl> bytes = ret ; <nl> +# endif <nl> } else { <nl> bytes = len ; <nl> offset = addr & ( PAGE_SIZE - 1 );
int drxj_dap_atomic_read_reg32 ( struct i2c_device_addr * dev_addr , <nl> rc = drxj_dap_atomic_read_write_block ( dev_addr , addr , <nl> sizeof (* data ), buf , true ); <nl>  <nl> + if ( rc < 0 ) <nl> + return 0 ; <nl> + <nl> word = ( u32 ) buf [ 3 ]; <nl> word <<= 8 ; <nl> word |= ( u32 ) buf [ 2 ]; <nl> int drxj_dap_scu_atomic_read_reg16 ( struct i2c_device_addr * dev_addr , <nl> } <nl>  <nl> rc = drxj_dap_scu_atomic_read_write_block ( dev_addr , addr , 2 , buf , true ); <nl> + if ( rc < 0 ) <nl> + return rc ; <nl>  <nl> word = ( u16 ) ( buf [ 0 ] + ( buf [ 1 ] << 8 )); <nl> 
static void basic_destroy ( struct tcf_proto * tp ) <nl> list_del (& f -> link ); <nl> basic_delete_filter ( tp , f ); <nl> } <nl> + kfree ( head ); <nl> } <nl>  <nl> static int basic_delete ( struct tcf_proto * tp , unsigned long arg )
static int selinux_get_mnt_opts ( const struct super_block * sb , <nl> if (! ss_initialized ) <nl> return - EINVAL ; <nl>  <nl> + /* make sure we always check enough bits to cover the mask */ <nl> + BUILD_BUG_ON ( SE_MNTMASK >= ( 1 << NUM_SEL_MNT_OPTS )); <nl> + <nl> tmp = sbsec -> flags & SE_MNTMASK ; <nl> /* count the number of mount options for this sb */ <nl> - for ( i = 0 ; i < 8 ; i ++) { <nl> + for ( i = 0 ; i < NUM_SEL_MNT_OPTS ; i ++) { <nl> if ( tmp & 0x01 ) <nl> opts -> num_mnt_opts ++; <nl> tmp >>= 1 ;
static void qdi6580dp_set_piomode ( struct ata_port * ap , struct ata_device * adev ) <nl> outb ( timing , ld_qdi -> timing + 2 * ap -> port_no ); <nl> /* Clear the FIFO */ <nl> if ( adev -> class != ATA_DEV_ATA ) <nl> - outb ( 0x5F , ld_qdi -> timing + 3 ); <nl> + outb ( 0x5F , ( ld_qdi -> timing & 0xFFF0 ) + 3 ); <nl> } <nl>  <nl> /** <nl> static void qdi6580_set_piomode ( struct ata_port * ap , struct ata_device * adev ) <nl> outb ( timing , ld_qdi -> timing + 2 * adev -> devno ); <nl> /* Clear the FIFO */ <nl> if ( adev -> class != ATA_DEV_ATA ) <nl> - outb ( 0x5F , ld_qdi -> timing + 3 ); <nl> + outb ( 0x5F , ( ld_qdi -> timing & 0xFFF0 ) + 3 ); <nl> } <nl>  <nl> /**
static ssize_t eisa_eeprom_read ( struct file * file , <nl> ssize_t ret ; <nl> int i ; <nl>  <nl> - if (* ppos >= HPEE_MAX_LENGTH ) <nl> + if (* ppos < 0 || * ppos >= HPEE_MAX_LENGTH ) <nl> return 0 ; <nl>  <nl> count = * ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - * ppos ;
hfcsusb_ph_info ( struct hfcsusb * hw ) <nl> _queue_data (& dch -> dev . D , MPH_INFORMATION_IND , MISDN_ID_ANY , <nl> sizeof ( struct ph_info_dch ) + dch -> dev . nrbchan * <nl> sizeof ( struct ph_info_ch ), phi , GFP_ATOMIC ); <nl> + kfree ( phi ); <nl> } <nl>  <nl> /*
static inline void dev_set_cma_area ( struct device * dev , struct cma * cma ) <nl> { <nl> if ( dev ) <nl> dev -> cma_area = cma ; <nl> - if (! dev || ! dma_contiguous_default_area ) <nl> + if (! dev && ! dma_contiguous_default_area ) <nl> dma_contiguous_default_area = cma ; <nl> } <nl> 
static ssize_t w1_seq_show ( struct device * device , <nl> w1_write_8 ( sl -> master , W1_42_COND_READ ); <nl> rv = w1_read_block ( sl -> master , ( u8 *)& rn , 8 ); <nl> reg_num = ( struct w1_reg_num *) & rn ; <nl> - if (( char ) reg_num -> family == W1_42_FINISHED_BYTE ) <nl> + if ( reg_num -> family == W1_42_FINISHED_BYTE ) <nl> break ; <nl> if ( sl -> reg_num . id == reg_num -> id ) <nl> seq = i ;
static int set_multi_io ( struct hda_codec * codec , int idx , bool output ) <nl> snd_hda_activate_path ( codec , path , false , true ); <nl> set_pin_target ( codec , nid , spec -> multi_io [ idx ]. ctl_in , true ); <nl> } <nl> + <nl> + /* update jack retasking in case it modifies any of them */ <nl> + snd_hda_gen_hp_automute ( codec , NULL ); <nl> + snd_hda_gen_line_automute ( codec , NULL ); <nl> + snd_hda_gen_mic_autoswitch ( codec , NULL ); <nl> + <nl> return 0 ; <nl> } <nl> 
SYSCALL_DEFINE5 ( fchownat , int , dfd , const char __user *, filename , uid_t , user , <nl> lookup_flags = ( flag & AT_SYMLINK_NOFOLLOW ) ? 0 : LOOKUP_FOLLOW ; <nl> if ( flag & AT_EMPTY_PATH ) <nl> lookup_flags |= LOOKUP_EMPTY ; <nl> + retry : <nl> error = user_path_at ( dfd , filename , lookup_flags , & path ); <nl> if ( error ) <nl> goto out ; <nl> SYSCALL_DEFINE5 ( fchownat , int , dfd , const char __user *, filename , uid_t , user , <nl> mnt_drop_write ( path . mnt ); <nl> out_release : <nl> path_put (& path ); <nl> + if ( retry_estale ( error , lookup_flags )) { <nl> + lookup_flags |= LOOKUP_REVAL ; <nl> + goto retry ; <nl> + } <nl> out : <nl> return error ; <nl> }
int prism2_scan ( struct wiphy * wiphy , struct net_device * dev , <nl> msg1 . msgcode = DIDmsg_dot11req_scan ; <nl> msg1 . bsstype . data = P80211ENUM_bsstype_any ; <nl>  <nl> - memset (&( msg1 . bssid . data ), 0xFF , sizeof ( p80211item_pstr6_t )); <nl> + memset (& msg1 . bssid . data , 0xFF , sizeof ( msg1 . bssid . data )); <nl> msg1 . bssid . data . len = 6 ; <nl>  <nl> if ( request -> n_ssids > 0 ) {
static int run ( mddev_t * mddev ) <nl> int i ; <nl>  <nl> conf_t * conf = kmalloc ( sizeof (* conf ), GFP_KERNEL ); <nl> + if (! conf ) <nl> + return - ENOMEM ; <nl>  <nl> for ( i = 0 ; i < Modes ; i ++) { <nl> atomic_set (& conf -> counters [ i ], 0 );
static void dwc3_endpoint_interrupt ( struct dwc3 * dwc , <nl>  <nl> dep = dwc -> eps [ epnum ]; <nl>  <nl> + if (!( dep -> flags & DWC3_EP_ENABLED )) <nl> + return ; <nl> + <nl> dev_vdbg ( dwc -> dev , "% s : % s \ n ", dep -> name , <nl> dwc3_ep_event_string ( event -> endpoint_event )); <nl> 
struct e1000_nvm_operations { <nl>  <nl> struct e1000_mac_info { <nl> struct e1000_mac_operations ops ; <nl> - <nl> - u8 addr [ 6 ]; <nl> - u8 perm_addr [ 6 ]; <nl> + u8 addr [ ETH_ALEN ]; <nl> + u8 perm_addr [ ETH_ALEN ]; <nl>  <nl> enum e1000_mac_type type ; <nl> 
xfs_zero_remaining_bytes ( <nl> bp = xfs_buf_get_noaddr ( mp -> m_sb . sb_blocksize , <nl> XFS_IS_REALTIME_INODE ( ip ) ? <nl> mp -> m_rtdev_targp : mp -> m_ddev_targp ); <nl> + if (! bp ) <nl> + return XFS_ERROR ( ENOMEM ); <nl>  <nl> for ( offset = startoff ; offset <= endoff ; offset = lastoffset + 1 ) { <nl> offset_fsb = XFS_B_TO_FSBT ( mp , offset );
void thread__delete ( struct thread * thread ) <nl> { <nl> struct comm * comm , * tmp ; <nl>  <nl> - map_groups__put ( thread -> mg ); <nl> - thread -> mg = NULL ; <nl> + if ( thread -> mg ) { <nl> + map_groups__put ( thread -> mg ); <nl> + thread -> mg = NULL ; <nl> + } <nl> list_for_each_entry_safe ( comm , tmp , & thread -> comm_list , list ) { <nl> list_del (& comm -> list ); <nl> comm__free ( comm );
int do_sys_settimeofday ( struct timespec * tv , struct timezone * tz ) <nl> static int firsttime = 1 ; <nl> int error = 0 ; <nl>  <nl> + if (! timespec_valid ( tv )) <nl> + return - EINVAL ; <nl> + <nl> error = security_settime ( tv , tz ); <nl> if ( error ) <nl> return error ;
static int nl80211_set_wiphy ( struct sk_buff * skb , struct genl_info * info ) <nl>  <nl> rdev = __cfg80211_drv_from_info ( info ); <nl> if ( IS_ERR ( rdev )) { <nl> + mutex_unlock (& cfg80211_mutex ); <nl> result = PTR_ERR ( rdev ); <nl> goto unlock ; <nl> }
int ieee80211_request_sched_scan_start ( struct ieee80211_sub_if_data * sdata , <nl> for ( i = 0 ; i < IEEE80211_NUM_BANDS ; i ++) { <nl> local -> sched_scan_ies . ie [ i ] = kzalloc ( 2 + <nl> IEEE80211_MAX_SSID_LEN + <nl> - local -> scan_ies_len , <nl> + local -> scan_ies_len + <nl> + req -> ie_len , <nl> GFP_KERNEL ); <nl> if (! local -> sched_scan_ies . ie [ i ]) { <nl> ret = - ENOMEM ;
mt7601u_extra_power_over_mac ( struct mt7601u_dev * dev ) <nl> static void <nl> mt7601u_set_power_rate ( struct power_per_rate * rate , s8 delta , u8 value ) <nl> { <nl> + /* Invalid ? Note : vendor driver does not handle this */ <nl> + if ( value == 0xff ) <nl> + return ; <nl> + <nl> rate -> raw = s6_validate ( value ); <nl> rate -> bw20 = s6_to_int ( value ); <nl> /* Note : vendor driver does cap the value to s6 right away */
static ssize_t show_fw_ver ( struct device * dev , struct device_attribute * attr , ch <nl> struct net_device * lldev = iwch_dev -> rdev . t3cdev_p -> lldev ; <nl>  <nl> PDBG ("% s dev 0x % p \ n ", __func__ , dev ); <nl> + rtnl_lock (); <nl> lldev -> ethtool_ops -> get_drvinfo ( lldev , & info ); <nl> + rtnl_unlock (); <nl> return sprintf ( buf , "% s \ n ", info . fw_version ); <nl> } <nl>  <nl> static ssize_t show_hca ( struct device * dev , struct device_attribute * attr , <nl> struct net_device * lldev = iwch_dev -> rdev . t3cdev_p -> lldev ; <nl>  <nl> PDBG ("% s dev 0x % p \ n ", __func__ , dev ); <nl> + rtnl_lock (); <nl> lldev -> ethtool_ops -> get_drvinfo ( lldev , & info ); <nl> + rtnl_unlock (); <nl> return sprintf ( buf , "% s \ n ", info . driver ); <nl> } <nl> 
static void mac80211_hwsim_tx_frame_nl ( struct ieee80211_hw * hw , <nl> if ( skb_queue_len (& data -> pending ) >= MAX_QUEUE ) { <nl> /* Droping until WARN_QUEUE level */ <nl> while ( skb_queue_len (& data -> pending ) >= WARN_QUEUE ) <nl> - skb_dequeue (& data -> pending ); <nl> + ieee80211_free_txskb ( hw , skb_dequeue (& data -> pending )); <nl> } <nl>  <nl> skb = genlmsg_new ( GENLMSG_DEFAULT_SIZE , GFP_ATOMIC ); <nl> static void mac80211_hwsim_tx_frame_nl ( struct ieee80211_hw * hw , <nl>  <nl> nla_put_failure : <nl> printk ( KERN_DEBUG " mac80211_hwsim : error occurred in % s \ n ", __func__ ); <nl> + ieee80211_free_txskb ( hw , my_skb ); <nl> } <nl>  <nl> static bool hwsim_chans_compat ( struct ieee80211_channel * c1 ,
int cx25821_video_register ( struct cx25821_dev * dev ) <nl>  <nl> spin_lock_init (& dev -> slock ); <nl>  <nl> - for ( i = 0 ; i < MAX_VID_CHANNEL_NUM - 1 ; ++ i ) { <nl> + for ( i = 0 ; i < VID_CHANNEL_NUM ; ++ i ) { <nl> cx25821_init_controls ( dev , i ); <nl>  <nl> cx25821_risc_stopper ( dev -> pci , & dev -> channels [ i ]. vidq . stopper ,
errout : <nl>  <nl> if ( send_addr_notify ) <nl> call_netdevice_notifiers ( NETDEV_CHANGEADDR , dev ); <nl> + min_ifinfo_dump_size = max_t ( u16 , if_nlmsg_size ( dev ), <nl> + min_ifinfo_dump_size ); <nl> + <nl> return err ; <nl> } <nl> 
uart_get_baud_rate ( struct uart_port * port , struct ktermios * termios , <nl> * The spd_hi , spd_vhi , spd_shi , spd_warp kludge ... <nl> * Die ! Die ! Die ! <nl> */ <nl> - if ( baud == 38400 ) <nl> + if ( try == 0 && baud == 38400 ) <nl> baud = altbaud ; <nl>  <nl> /*
# include < linux / types . h > <nl> # include < linux / kernel . h > <nl> # include < linux / spinlock . h > <nl> +# include < linux / smp . h > <nl> # include < asm / bootinfo . h > <nl> # include < asm / fw / cfe / cfe_api . h > <nl> # include < asm / fw / cfe / cfe_error . h > <nl> static __init void prom_init_mem ( void ) <nl> { <nl> unsigned long mem ; <nl> unsigned long max ; <nl> + struct cpuinfo_mips * c = & current_cpu_data ; <nl>  <nl> /* Figure out memory size by finding aliases . <nl> * <nl> static __init void prom_init_mem ( void ) <nl> break ; <nl> } <nl>  <nl> + /* Ignoring the last page when ddr size is 128M . Cached <nl> + * accesses to last page is causing the processor to prefetch <nl> + * using address above 128M stepping out of the ddr address <nl> + * space . <nl> + */ <nl> + if ( c -> cputype == CPU_74K && ( mem == ( 128 << 20 ))) <nl> + mem -= 0x1000 ; <nl> + <nl> add_memory_region ( 0 , mem , BOOT_MEM_RAM ); <nl> } <nl> 
int perf_event_init_context ( struct task_struct * child , int ctxn ) <nl> * swapped under us . <nl> */ <nl> parent_ctx = perf_pin_task_context ( parent , ctxn ); <nl> + if (! parent_ctx ) <nl> + return 0 ; <nl>  <nl> /* <nl> * No need to check if parent_ctx != NULL here ; since we saw
static void as_update_iohist ( struct as_data * ad , struct as_io_context * aic , <nl> static int as_close_req ( struct as_data * ad , struct as_io_context * aic , <nl> struct request * rq ) <nl> { <nl> - unsigned long delay ; /* milliseconds */ <nl> + unsigned long delay ; /* jiffies */ <nl> sector_t last = ad -> last_sector [ ad -> batch_data_dir ]; <nl> sector_t next = rq -> sector ; <nl> sector_t delta ; /* acceptable close offset ( in sectors ) */ <nl> static int as_close_req ( struct as_data * ad , struct as_io_context * aic , <nl> if ( ad -> antic_status == ANTIC_OFF || ! ad -> ioc_finished ) <nl> delay = 0 ; <nl> else <nl> - delay = (( jiffies - ad -> antic_start ) * 1000 ) / HZ ; <nl> + delay = jiffies - ad -> antic_start ; <nl>  <nl> if ( delay == 0 ) <nl> delta = 8192 ; <nl> - else if ( delay <= 20 && delay <= ad -> antic_expire ) <nl> + else if ( delay <= ( 20 * HZ / 1000 ) && delay <= ad -> antic_expire ) <nl> delta = 8192 << delay ; <nl> else <nl> return 1 ;
int ip6_xmit ( struct sock * sk , struct sk_buff * skb , struct flowi * fl , <nl> skb_reset_network_header ( skb ); <nl> hdr = ipv6_hdr ( skb ); <nl>  <nl> + /* Allow local fragmentation . */ <nl> + if ( ipfragok ) <nl> + skb -> local_df = 1 ; <nl> + <nl> /* <nl> * Fill in the IPv6 header <nl> */
static int do_ipv6_getsockopt ( struct sock * sk , int level , int optname , <nl> return - EINVAL ; <nl> if ( copy_from_user (& gsf , optval , GROUP_FILTER_SIZE ( 0 ))) <nl> return - EFAULT ; <nl> + if ( gsf . gf_group . ss_family != AF_INET6 ) <nl> + return - EADDRNOTAVAIL ; <nl> lock_sock ( sk ); <nl> err = ip6_mc_msfget ( sk , & gsf , <nl> ( struct group_filter __user *) optval , optlen );
static void resample_shrink ( struct snd_pcm_plugin * plugin , <nl> while ( dst_frames1 > 0 ) { <nl> S1 = S2 ; <nl> if ( src_frames1 -- > 0 ) { <nl> - S1 = * src ; <nl> + S2 = * src ; <nl> src += src_step ; <nl> } <nl> if ( pos & ~ R_MASK ) {
static int eth_setup ( char * str ) <nl> int n , err ; <nl>  <nl> err = eth_parse ( str , & n , & str ); <nl> - if ( err ) return ( 1 ); <nl> + if ( err ) <nl> + return 1 ; <nl>  <nl> - new = alloc_bootmem ( sizeof ( new )); <nl> + new = alloc_bootmem ( sizeof (* new )); <nl> if ( new == NULL ){ <nl> printk (" eth_init : alloc_bootmem failed \ n "); <nl> - return ( 1 ); <nl> + return 1 ; <nl> } <nl>  <nl> INIT_LIST_HEAD (& new -> list ); <nl> static int eth_setup ( char * str ) <nl> new -> init = str ; <nl>  <nl> list_add_tail (& new -> list , & eth_cmd_line ); <nl> - return ( 1 ); <nl> + return 1 ; <nl> } <nl>  <nl> __setup (" eth ", eth_setup );
static int <nl> ov51x_init_isoc ( struct usb_ov511 * ov ) <nl> { <nl> struct urb * urb ; <nl> - int fx , err , n , size ; <nl> + int fx , err , n , i , size ; <nl>  <nl> PDEBUG ( 3 , "*** Initializing capture ***"); <nl>  <nl> ov51x_init_isoc ( struct usb_ov511 * ov ) <nl> urb = usb_alloc_urb ( FRAMES_PER_DESC , GFP_KERNEL ); <nl> if (! urb ) { <nl> err (" init isoc : usb_alloc_urb ret . NULL "); <nl> + for ( i = 0 ; i < n ; i ++) <nl> + usb_free_urb ( ov -> sbuf [ i ]. urb ); <nl> return - ENOMEM ; <nl> } <nl> ov -> sbuf [ n ]. urb = urb ;
int intel_framebuffer_init ( struct drm_device * dev , <nl> switch ( mode_cmd -> bpp ) { <nl> case 8 : <nl> case 16 : <nl> + /* Only pre - ILK can handle 5 : 5 : 5 */ <nl> + if ( mode_cmd -> depth == 15 && ! HAS_PCH_SPLIT ( dev )) <nl> + return - EINVAL ; <nl> + break ; <nl> + <nl> case 24 : <nl> case 32 : <nl> break ;
Dot11d_UpdateCountryIe ( <nl> pTriple = ( PCHNL_TXPOWER_TRIPLE )(( u8 *) pTriple + 3 ); <nl> } <nl> printk (" Channel List :"); <nl> - for ( i = 1 ; i <= MAX_CHANNEL_NUMBER ; i ++) <nl> - if ( pDot11dInfo -> channel_map [ i ] > 0 ) <nl> + for ( i = 1 ; i <= MAX_CHANNEL_NUMBER ; i ++) <nl> + if ( pDot11dInfo -> channel_map [ i ] > 0 ) <nl> printk (" % d ", i ); <nl> printk ("\ n "); <nl>  <nl> UPDATE_CIE_SRC ( dev , pTaddr ); <nl>  <nl> pDot11dInfo -> CountryIeLen = CoutryIeLen ; <nl> - memcpy ( pDot11dInfo -> CountryIeBuf , pCoutryIe , CoutryIeLen ); <nl> + memcpy ( pDot11dInfo -> CountryIeBuf , pCoutryIe , CoutryIeLen ); <nl> pDot11dInfo -> State = DOT11D_STATE_LEARNED ; <nl> } <nl>  <nl> int IsLegalChannel ( <nl> printk (" IsLegalChannel (): Invalid Channel \ n "); <nl> return 0 ; <nl> } <nl> - if ( pDot11dInfo -> channel_map [ channel ] > 0 ) <nl> + if ( pDot11dInfo -> channel_map [ channel ] > 0 ) <nl> return 1 ; <nl> return 0 ; <nl> } <nl> int ToLegalChannel ( <nl> return default_chn ; <nl> } <nl>  <nl> - if ( pDot11dInfo -> channel_map [ channel ] > 0 ) <nl> + if ( pDot11dInfo -> channel_map [ channel ] > 0 ) <nl> return channel ; <nl>  <nl> return default_chn ;
static int mem_cgroup_try_charge ( struct mem_cgroup * memcg , <nl> bool oom ) <nl> { <nl> unsigned int batch = max ( CHARGE_BATCH , nr_pages ); <nl> - int nr_oom_retries = MEM_CGROUP_RECLAIM_RETRIES ; <nl> + int nr_retries = MEM_CGROUP_RECLAIM_RETRIES ; <nl> struct mem_cgroup * mem_over_limit ; <nl> struct res_counter * fail_res ; <nl> unsigned long nr_reclaimed ; <nl> retry : <nl> if ( mem_cgroup_wait_acct_move ( mem_over_limit )) <nl> goto retry ; <nl>  <nl> + if ( nr_retries --) <nl> + goto retry ; <nl> + <nl> if ( gfp_mask & __GFP_NOFAIL ) <nl> goto bypass ; <nl>  <nl> retry : <nl> if (! oom ) <nl> goto nomem ; <nl>  <nl> - if ( nr_oom_retries --) <nl> - goto retry ; <nl> - <nl> mem_cgroup_oom ( mem_over_limit , gfp_mask , get_order ( batch )); <nl> nomem : <nl> if (!( gfp_mask & __GFP_NOFAIL ))
static int sdhci_adma_table_pre ( struct sdhci_host * host , <nl>  <nl> BUG_ON ( len > 65536 ); <nl>  <nl> - /* tran , valid */ <nl> - sdhci_adma_write_desc ( host , desc , addr , len , ADMA2_TRAN_VALID ); <nl> - desc += host -> desc_sz ; <nl> + if ( len ) { <nl> + /* tran , valid */ <nl> + sdhci_adma_write_desc ( host , desc , addr , len , <nl> + ADMA2_TRAN_VALID ); <nl> + desc += host -> desc_sz ; <nl> + } <nl>  <nl> /* <nl> * If this triggers then we have a calculation bug
static bool snd_soc_set_cache_val ( void * base , unsigned int idx , <nl> static unsigned int snd_soc_get_cache_val ( const void * base , unsigned int idx , <nl> unsigned int word_size ) <nl> { <nl> + if (! base ) <nl> + return - 1 ; <nl> + <nl> switch ( word_size ) { <nl> case 1 : { <nl> const u8 * cache = base ;
static u64 bpf_get_current_comm ( u64 r1 , u64 size , u64 r3 , u64 r4 , u64 r5 ) <nl> if (! task ) <nl> return - EINVAL ; <nl>  <nl> - memcpy ( buf , task -> comm , min_t ( size_t , size , sizeof ( task -> comm ))); <nl> + strlcpy ( buf , task -> comm , min_t ( size_t , size , sizeof ( task -> comm ))); <nl> return 0 ; <nl> } <nl> 
static void brcmf_term_iscan ( struct brcmf_cfg80211_priv * cfg_priv ) <nl> if ( cfg_priv -> iscan_on && iscan -> tsk ) { <nl> iscan -> state = WL_ISCAN_STATE_IDLE ; <nl> send_sig ( SIGTERM , iscan -> tsk , 1 ); <nl> + <nl> + /* <nl> + * The iscan task may want to acquire the rtnl_lock <nl> + * so release it here upon stopping the task . <nl> + */ <nl> + rtnl_unlock (); <nl> kthread_stop ( iscan -> tsk ); <nl> + rtnl_lock (); <nl> iscan -> tsk = NULL ; <nl>  <nl> /* Abort iscan running in FW */
scsi_reset_provider ( struct scsi_device * dev , int flag ) <nl> rtn = FAILED ; <nl> } <nl>  <nl> - scsi_delete_timer ( scmd ); <nl> scsi_next_command ( scmd ); <nl> return rtn ; <nl> }
static int vmx_vcpu_setup ( struct vcpu_vmx * vmx ) <nl> vmcs_writel ( CR0_GUEST_HOST_MASK , ~ 0UL ); <nl> vmcs_writel ( CR4_GUEST_HOST_MASK , KVM_GUEST_CR4_MASK ); <nl>  <nl> - if ( vm_need_virtualize_apic_accesses ( vmx -> vcpu . kvm )) <nl> - if ( alloc_apic_access_page ( vmx -> vcpu . kvm ) != 0 ) <nl> - return - ENOMEM ; <nl>  <nl> return 0 ; <nl> } <nl> static struct kvm_vcpu * vmx_create_vcpu ( struct kvm * kvm , unsigned int id ) <nl> put_cpu (); <nl> if ( err ) <nl> goto free_vmcs ; <nl> + if ( vm_need_virtualize_apic_accesses ( kvm )) <nl> + if ( alloc_apic_access_page ( kvm ) != 0 ) <nl> + goto free_vmcs ; <nl>  <nl> return & vmx -> vcpu ; <nl> 
static struct s3c_gpio_cfg gpio_2bit_cfg_eint11 = { <nl> . get_pull = s3c_gpio_getpull_updown , <nl> }; <nl>  <nl> + int s3c64xx_gpio2int_gpn ( struct gpio_chip * chip , unsigned pin ) <nl> +{ <nl> + return IRQ_EINT ( 0 ) + pin ; <nl> +} <nl> + <nl> static struct s3c_gpio_chip gpio_2bit [] = { <nl> { <nl> . base = S3C64XX_GPF_BASE , <nl> static struct s3c_gpio_chip gpio_2bit [] = { <nl> . base = S3C64XX_GPN ( 0 ), <nl> . ngpio = S3C64XX_GPIO_N_NR , <nl> . label = " GPN ", <nl> + . to_irq = s3c64xx_gpio2int_gpn , <nl> }, <nl> }, { <nl> . base = S3C64XX_GPO_BASE ,
static ssize_t dlpar_cpu_probe ( const char * buf , size_t count ) <nl> return - ENODEV ; <nl>  <nl> dn = dlpar_configure_connector ( cpu_to_be32 ( drc_index ), parent ); <nl> + of_node_put ( parent ); <nl> if (! dn ) <nl> return - EINVAL ; <nl>  <nl> - of_node_put ( parent ); <nl> - <nl> rc = dlpar_attach_node ( dn ); <nl> if ( rc ) { <nl> dlpar_release_drc ( drc_index );
static ssize_t mei_dbgfs_read_devstate ( struct file * fp , char __user * ubuf , <nl> pos += scnprintf ( buf + pos , bufsz - pos , " hbm : % s \ n ", <nl> mei_hbm_state_str ( dev -> hbm_state )); <nl>  <nl> - if ( dev -> hbm_state == MEI_HBM_STARTED ) { <nl> + if ( dev -> hbm_state >= MEI_HBM_ENUM_CLIENTS && <nl> + dev -> hbm_state <= MEI_HBM_STARTED ) { <nl> pos += scnprintf ( buf + pos , bufsz - pos , " hbm features :\ n "); <nl> pos += scnprintf ( buf + pos , bufsz - pos , "\ tPG : % 01d \ n ", <nl> dev -> hbm_f_pg_supported );
static void perf_callchain_user_64 ( struct perf_callchain_entry * entry , <nl> { <nl> unsigned long ufp ; <nl>  <nl> - perf_callchain_store ( entry , regs -> tpc ); <nl> - <nl> ufp = regs -> u_regs [ UREG_I6 ] + STACK_BIAS ; <nl> do { <nl> struct sparc_stackf * usf , sf ; <nl> static void perf_callchain_user_32 ( struct perf_callchain_entry * entry , <nl> { <nl> unsigned long ufp ; <nl>  <nl> - perf_callchain_store ( entry , regs -> tpc ); <nl> - <nl> ufp = regs -> u_regs [ UREG_I6 ] & 0xffffffffUL ; <nl> do { <nl> struct sparc_stackf32 * usf , sf ; <nl> static void perf_callchain_user_32 ( struct perf_callchain_entry * entry , <nl> void <nl> perf_callchain_user ( struct perf_callchain_entry * entry , struct pt_regs * regs ) <nl> { <nl> + perf_callchain_store ( entry , regs -> tpc ); <nl> + <nl> + if (! current -> mm ) <nl> + return ; <nl> + <nl> flushw_user (); <nl> if ( test_thread_flag ( TIF_32BIT )) <nl> perf_callchain_user_32 ( entry , regs );
static int ivtv_video_command ( struct ivtv * itv , struct ivtv_open_id * id , <nl> case V4L2_DEC_CMD_PAUSE : <nl> dc -> flags &= V4L2_DEC_CMD_PAUSE_TO_BLACK ; <nl> if ( try ) break ; <nl> + if (! atomic_read (& itv -> decoding )) <nl> + return - EPERM ; <nl> if ( itv -> output_mode != OUT_MPG ) <nl> return - EBUSY ; <nl> if ( atomic_read (& itv -> decoding ) > 0 ) { <nl> static int ivtv_video_command ( struct ivtv * itv , struct ivtv_open_id * id , <nl> case V4L2_DEC_CMD_RESUME : <nl> dc -> flags = 0 ; <nl> if ( try ) break ; <nl> + if (! atomic_read (& itv -> decoding )) <nl> + return - EPERM ; <nl> if ( itv -> output_mode != OUT_MPG ) <nl> return - EBUSY ; <nl> if ( test_and_clear_bit ( IVTV_F_I_DEC_PAUSED , & itv -> i_flags )) { <nl> static int ivtv_g_enc_index ( struct file * file , void * fh , struct v4l2_enc_idx * id <nl> if ( entries > V4L2_ENC_IDX_ENTRIES ) <nl> entries = V4L2_ENC_IDX_ENTRIES ; <nl> idx -> entries = 0 ; <nl> + idx -> entries_cap = IVTV_MAX_PGM_INDEX ; <nl> + if (! atomic_read (& itv -> capturing )) <nl> + return 0 ; <nl> for ( i = 0 ; i < entries ; i ++) { <nl> * e = itv -> pgm_info [( itv -> pgm_info_read_idx + i ) % IVTV_MAX_PGM_INDEX ]; <nl> if (( e -> flags & V4L2_ENC_IDX_FRAME_MASK ) <= V4L2_ENC_IDX_FRAME_B ) {
static __devinit int hpsa_kdump_hard_reset_controller ( struct pci_dev * pdev ) <nl> * likely not be happy . Just forbid resetting this conjoined mess . <nl> * The 640x isn ' t really supported by hpsa anyway . <nl> */ <nl> - hpsa_lookup_board_id ( pdev , & board_id ); <nl> + rc = hpsa_lookup_board_id ( pdev , & board_id ); <nl> + if ( rc < 0 ) { <nl> + dev_warn (& pdev -> dev , " Not resetting device .\ n "); <nl> + return - ENODEV ; <nl> + } <nl> if ( board_id == 0x409C0E11 || board_id == 0x409D0E11 ) <nl> return - ENOTSUPP ; <nl> 
out_dio : <nl> * async dio is going to do it in the future or an end_io after an <nl> * error has already done it . <nl> */ <nl> - if ( ret == - EIOCBQUEUED || ! ocfs2_iocb_is_rw_locked ( iocb )) { <nl> + if (( ret == - EIOCBQUEUED ) || (! ocfs2_iocb_is_rw_locked ( iocb ))) { <nl> rw_level = - 1 ; <nl> have_alloc_sem = 0 ; <nl> }
static int r820t_set_tv_standard ( struct r820t_priv * priv , <nl> return rc ; <nl> msleep ( 1 ); <nl> } <nl> - priv -> int_freq = if_khz ; <nl> + priv -> int_freq = if_khz * 1000 ; <nl>  <nl> /* Check if standard changed . If so , filter calibration is needed */ <nl> if ( type != priv -> type )
int dlpar_detach_node ( struct device_node * dn ) <nl> if ( rc ) <nl> return rc ; <nl>  <nl> - of_node_put ( dn ); /* Must decrement the refcount */ <nl> return 0 ; <nl> } <nl> 
static void _gb_power_supplies_release ( struct gb_power_supplies * supplies ) <nl> { <nl> int i ; <nl>  <nl> + if (! supplies -> supply ) <nl> + return ; <nl> + <nl> mutex_lock (& supplies -> supplies_lock ); <nl> for ( i = 0 ; i < supplies -> supplies_count ; i ++) <nl> _gb_power_supply_release (& supplies -> supply [ i ]);
static void ati_remote_input_report ( struct urb * urb , struct pt_regs * regs ) <nl> input_regs ( dev , regs ); <nl> input_event ( dev , ati_remote_tbl [ index ]. type , <nl> ati_remote_tbl [ index ]. code , 1 ); <nl> + input_sync ( dev ); <nl> input_event ( dev , ati_remote_tbl [ index ]. type , <nl> ati_remote_tbl [ index ]. code , 0 ); <nl> input_sync ( dev );
static int vb2_internal_streamon ( struct vb2_queue * q , enum v4l2_buf_type type ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + if (! q -> num_buffers ) { <nl> + dprintk ( 1 , " streamon : no buffers have been allocated \ n "); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> /* <nl> * If any buffers were queued before streamon , <nl> * we can now pass them to driver for processing .
static inline void slb_shadow_update ( unsigned long ea , int ssize , <nl> unsigned long flags , <nl> enum slb_index index ) <nl> { <nl> + struct slb_shadow * p = get_slb_shadow (); <nl> + <nl> /* <nl> * Clear the ESID first so the entry is not valid while we are <nl> * updating it . No write barriers are needed here , provided <nl> * we only update the current CPU ' s SLB shadow buffer . <nl> */ <nl> - get_slb_shadow ()-> save_area [ index ]. esid = 0 ; <nl> - get_slb_shadow ()-> save_area [ index ]. vsid = <nl> - cpu_to_be64 ( mk_vsid_data ( ea , ssize , flags )); <nl> - get_slb_shadow ()-> save_area [ index ]. esid = <nl> - cpu_to_be64 ( mk_esid_data ( ea , ssize , index )); <nl> + p -> save_area [ index ]. esid = 0 ; <nl> + p -> save_area [ index ]. vsid = cpu_to_be64 ( mk_vsid_data ( ea , ssize , flags )); <nl> + p -> save_area [ index ]. esid = cpu_to_be64 ( mk_esid_data ( ea , ssize , index )); <nl> } <nl>  <nl> static inline void slb_shadow_clear ( enum slb_index index )
static const struct x86_cpu_id rapl_ids [] = { <nl> RAPL_CPU ( 0x45 , rapl_defaults_core ),/* Haswell ULT */ <nl> RAPL_CPU ( 0x4C , rapl_defaults_atom ),/* Braswell */ <nl> RAPL_CPU ( 0x4A , rapl_defaults_atom ),/* Tangier */ <nl> + RAPL_CPU ( 0x56 , rapl_defaults_core ),/* Future Xeon */ <nl> RAPL_CPU ( 0x5A , rapl_defaults_atom ),/* Annidale */ <nl> {} <nl> };
omap_i2c_probe ( struct platform_device * pdev ) <nl> struct omap_i2c_dev * dev ; <nl> struct i2c_adapter * adap ; <nl> struct resource * mem , * irq , * ioarea ; <nl> - struct omap_i2c_bus_platform_data * pdata = pdev -> dev . platform_data ; <nl> + const struct omap_i2c_bus_platform_data * pdata = <nl> + pdev -> dev . platform_data ; <nl> struct device_node * node = pdev -> dev . of_node ; <nl> const struct of_device_id * match ; <nl> irq_handler_t isr ;
static s16 * read_rds_samples ( struct cx88_core * core , u32 * N ) <nl> current_address , <nl> current_address - srch -> fifo_start , sample_count , <nl> cx_read ( MO_AUD_INTSTAT )); <nl> - <nl> - samples = kmalloc ( sizeof ( s16 )* sample_count , GFP_KERNEL ); <nl> + samples = kmalloc_array ( sample_count , sizeof (* samples ), GFP_KERNEL ); <nl> if (! samples ) <nl> return NULL ; <nl> 
static size_t jffs2_trusted_listxattr ( struct dentry * dentry , char * list , <nl> { <nl> size_t retlen = XATTR_TRUSTED_PREFIX_LEN + name_len + 1 ; <nl>  <nl> + if (! capable ( CAP_SYS_ADMIN )) <nl> + return 0 ; <nl> + <nl> if ( list && retlen <= list_size ) { <nl> strcpy ( list , XATTR_TRUSTED_PREFIX ); <nl> strcpy ( list + XATTR_TRUSTED_PREFIX_LEN , name );
static void megasas_detach_one ( struct pci_dev * pdev ) <nl> break ; <nl> default : <nl> megasas_release_mfi ( instance ); <nl> - pci_free_consistent ( pdev , <nl> - sizeof ( struct megasas_evt_detail ), <nl> - instance -> evt_detail , <nl> - instance -> evt_detail_h ); <nl> pci_free_consistent ( pdev , sizeof ( u32 ), <nl> instance -> producer , <nl> instance -> producer_h ); <nl> static void megasas_detach_one ( struct pci_dev * pdev ) <nl> break ; <nl> } <nl>  <nl> + if ( instance -> evt_detail ) <nl> + pci_free_consistent ( pdev , sizeof ( struct megasas_evt_detail ), <nl> + instance -> evt_detail , instance -> evt_detail_h ); <nl> scsi_host_put ( host ); <nl>  <nl> pci_set_drvdata ( pdev , NULL );
static int __devinit agp_sgi_init ( void ) <nl> else <nl> return 0 ; <nl>  <nl> - sgi_tioca_agp_bridges = <nl> - ( struct agp_bridge_data **) kmalloc ( tioca_gart_found * <nl> - sizeof ( struct agp_bridge_data *), <nl> - GFP_KERNEL ); <nl> + sgi_tioca_agp_bridges = kmalloc ( tioca_gart_found * <nl> + sizeof ( struct agp_bridge_data *), <nl> + GFP_KERNEL ); <nl> + if (! sgi_tioca_agp_bridges ) <nl> + return - ENOMEM ; <nl>  <nl> j = 0 ; <nl> list_for_each_entry ( info , & tioca_list , ca_list ) {
static void conf_message_callback ( const char * fmt , va_list ap ) <nl>  <nl> static void show_help ( struct menu * menu ) <nl> { <nl> - struct gstr help = str_new (); <nl> + struct gstr help ; <nl> + <nl> + if (! menu ) <nl> + return ; <nl> + <nl> + help = str_new (); <nl> menu_get_ext_help ( menu , & help ); <nl> show_scroll_win ( main_window , _ ( menu_get_prompt ( menu )), str_get (& help )); <nl> str_free (& help );
int ib_modify_srq ( struct ib_srq * srq , <nl> struct ib_srq_attr * srq_attr , <nl> enum ib_srq_attr_mask srq_attr_mask ) <nl> { <nl> - return srq -> device -> modify_srq ( srq , srq_attr , srq_attr_mask , NULL ); <nl> + return srq -> device -> modify_srq ? <nl> + srq -> device -> modify_srq ( srq , srq_attr , srq_attr_mask , NULL ) : <nl> + - ENOSYS ; <nl> } <nl> EXPORT_SYMBOL ( ib_modify_srq ); <nl>  <nl> struct ib_mr * ib_reg_phys_mr ( struct ib_pd * pd , <nl> { <nl> struct ib_mr * mr ; <nl>  <nl> + if (! pd -> device -> reg_phys_mr ) <nl> + return ERR_PTR (- ENOSYS ); <nl> + <nl> mr = pd -> device -> reg_phys_mr ( pd , phys_buf_array , num_phys_buf , <nl> mr_access_flags , iova_start ); <nl> 
static void udf_sb_free_partitions ( struct super_block * sb ) <nl> { <nl> struct udf_sb_info * sbi = UDF_SB ( sb ); <nl> int i ; <nl> - <nl> + if ( sbi -> s_partmaps == NULL ) <nl> + return ; <nl> for ( i = 0 ; i < sbi -> s_partitions ; i ++) <nl> udf_free_partition (& sbi -> s_partmaps [ i ]); <nl> kfree ( sbi -> s_partmaps );
int hfsplus_find_cat ( struct super_block * sb , u32 cnid , <nl> return - EIO ; <nl> } <nl>  <nl> + if ( be16_to_cpu ( tmp . thread . nodeName . length ) > 255 ) { <nl> + printk ( KERN_ERR " hfs : catalog name length corrupted \ n "); <nl> + return - EIO ; <nl> + } <nl> + <nl> hfsplus_cat_build_key_uni ( fd -> search_key , be32_to_cpu ( tmp . thread . parentID ), <nl> & tmp . thread . nodeName ); <nl> return hfs_brec_find ( fd );
int mlx4_en_process_rx_cq ( struct net_device * dev , struct mlx4_en_cq * cq , int bud <nl> gro_skb -> ip_summed = CHECKSUM_UNNECESSARY ; <nl>  <nl> if ( l2_tunnel ) <nl> - gro_skb -> encapsulation = 1 ; <nl> + gro_skb -> csum_level = 1 ; <nl> if (( cqe -> vlan_my_qpn & <nl> cpu_to_be32 ( MLX4_CQE_VLAN_PRESENT_MASK )) && <nl> ( dev -> features & NETIF_F_HW_VLAN_CTAG_RX )) { <nl> int mlx4_en_process_rx_cq ( struct net_device * dev , struct mlx4_en_cq * cq , int bud <nl> skb -> protocol = eth_type_trans ( skb , dev ); <nl> skb_record_rx_queue ( skb , cq -> ring ); <nl>  <nl> - if ( l2_tunnel ) <nl> - skb -> encapsulation = 1 ; <nl> + if ( l2_tunnel && ip_summed == CHECKSUM_UNNECESSARY ) <nl> + skb -> csum_level = 1 ; <nl>  <nl> if ( dev -> features & NETIF_F_RXHASH ) <nl> skb_set_hash ( skb ,
static int perf_swevent_add ( struct perf_event * event , int flags ) <nl> } <nl>  <nl> hlist_add_head_rcu (& event -> hlist_entry , head ); <nl> + perf_event_update_userpage ( event ); <nl>  <nl> return 0 ; <nl> } <nl> static int cpu_clock_event_add ( struct perf_event * event , int flags ) <nl> { <nl> if ( flags & PERF_EF_START ) <nl> cpu_clock_event_start ( event , flags ); <nl> + perf_event_update_userpage ( event ); <nl>  <nl> return 0 ; <nl> } <nl> static int task_clock_event_add ( struct perf_event * event , int flags ) <nl> { <nl> if ( flags & PERF_EF_START ) <nl> task_clock_event_start ( event , flags ); <nl> + perf_event_update_userpage ( event ); <nl>  <nl> return 0 ; <nl> }
resend : <nl> /* For flock requests we immediatelly return without further <nl> delay and let caller deal with the rest , since rest of <nl> this function metadata processing makes no sense for flock <nl> - requests anyway */ <nl> + requests anyway . But in case of problem during comms with <nl> + Server ( ETIMEDOUT ) or any signal / kill attempt ( EINTR ), we <nl> + can not rely on caller and this mainly for F_UNLCKs <nl> + ( explicits or automatically generated by Kernel to clean <nl> + current FLocks upon exit ) that can ' t be trashed */ <nl> + if (( rc == - EINTR ) || ( rc == - ETIMEDOUT )) <nl> + goto resend ; <nl> RETURN ( rc ); <nl> } <nl> 
static ktime_t tick_nohz_stop_sched_tick ( struct tick_sched * ts , <nl> */ <nl> if ( delta == 0 ) { <nl> tick_nohz_restart ( ts , now ); <nl> + /* <nl> + * Make sure next tick stop doesn ' t get fooled by past <nl> + * clock deadline <nl> + */ <nl> + ts -> next_tick = 0 ; <nl> goto out ; <nl> } <nl> }
static int set_dev_class ( struct sock * sk , struct hci_dev * hdev , void * data , <nl>  <nl> hci_dev_lock ( hdev ); <nl>  <nl> + if (! lmp_bredr_capable ( hdev )) { <nl> + err = cmd_status ( sk , hdev -> id , MGMT_OP_SET_DEV_CLASS , <nl> + MGMT_STATUS_NOT_SUPPORTED ); <nl> + goto unlock ; <nl> + } <nl> + <nl> if ( test_bit ( HCI_PENDING_CLASS , & hdev -> dev_flags )) { <nl> err = cmd_status ( sk , hdev -> id , MGMT_OP_SET_DEV_CLASS , <nl> MGMT_STATUS_BUSY );
static void _clkdm_add_autodeps ( struct clockdomain * clkdm ) <nl> if ( IS_ERR ( autodep -> pwrdm . ptr )) <nl> continue ; <nl>  <nl> + if (! omap_chip_is ( autodep -> omap_chip )) <nl> + continue ; <nl> + <nl> pr_debug (" clockdomain : adding % s sleepdep / wkdep for " <nl> " pwrdm % s \ n ", autodep -> pwrdm . ptr -> name , <nl> clkdm -> pwrdm . ptr -> name ); <nl> static void _clkdm_del_autodeps ( struct clockdomain * clkdm ) <nl> if ( IS_ERR ( autodep -> pwrdm . ptr )) <nl> continue ; <nl>  <nl> + if (! omap_chip_is ( autodep -> omap_chip )) <nl> + continue ; <nl> + <nl> pr_debug (" clockdomain : removing % s sleepdep / wkdep for " <nl> " pwrdm % s \ n ", autodep -> pwrdm . ptr -> name , <nl> clkdm -> pwrdm . ptr -> name );
* <nl> * For licensing information , see the file ' LICENCE ' in this directory . <nl> * <nl> - * $ Id : super . c , v 1 . 105 2005 / 02 / 09 09 : 23 : 54 pavlov Exp $ <nl> + * $ Id : super . c , v 1 . 106 2005 / 05 / 18 11 : 37 : 25 dedekind Exp $ <nl> * <nl> */ <nl>  <nl> static void jffs2_put_super ( struct super_block * sb ) <nl>  <nl> D2 ( printk ( KERN_DEBUG " jffs2 : jffs2_put_super ()\ n ")); <nl>  <nl> - if (!( sb -> s_flags & MS_RDONLY )) <nl> - jffs2_stop_garbage_collect_thread ( c ); <nl> down (& c -> alloc_sem ); <nl> jffs2_flush_wbuf_pad ( c ); <nl> up (& c -> alloc_sem ); <nl> static void jffs2_put_super ( struct super_block * sb ) <nl> static void jffs2_kill_sb ( struct super_block * sb ) <nl> { <nl> struct jffs2_sb_info * c = JFFS2_SB_INFO ( sb ); <nl> + if (!( sb -> s_flags & MS_RDONLY )) <nl> + jffs2_stop_garbage_collect_thread ( c ); <nl> generic_shutdown_super ( sb ); <nl> put_mtd_device ( c -> mtd ); <nl> kfree ( c );
struct cs42l56_private { <nl> }; <nl>  <nl> static const struct reg_default cs42l56_reg_defaults [] = { <nl> - { 1 , 0x56 }, /* r01 - ID 1 */ <nl> - { 2 , 0x04 }, /* r02 - ID 2 */ <nl> { 3 , 0x7f }, /* r03 - Power Ctl 1 */ <nl> { 4 , 0xff }, /* r04 - Power Ctl 2 */ <nl> { 5 , 0x00 }, /* ro5 - Clocking Ctl 1 */ <nl> static int cs42l56_i2c_probe ( struct i2c_client * i2c_client , <nl> return ret ; <nl> } <nl>  <nl> - regcache_cache_bypass ( cs42l56 -> regmap , true ); <nl> - <nl> ret = regmap_read ( cs42l56 -> regmap , CS42L56_CHIP_ID_1 , & reg ); <nl> devid = reg & CS42L56_CHIP_ID_MASK ; <nl> if ( devid != CS42L56_DEVID ) { <nl> static int cs42l56_i2c_probe ( struct i2c_client * i2c_client , <nl> dev_info (& i2c_client -> dev , " Alpha Rev % X Metal Rev % X \ n ", <nl> alpha_rev , metal_rev ); <nl>  <nl> - regcache_cache_bypass ( cs42l56 -> regmap , false ); <nl> - <nl> if ( cs42l56 -> pdata . ain1a_ref_cfg ) <nl> regmap_update_bits ( cs42l56 -> regmap , CS42L56_AIN_REFCFG_ADC_MUX , <nl> CS42L56_AIN1A_REF_MASK , 1 );
static int __cpufreq_set_policy ( struct cpufreq_policy * data , <nl> memcpy (& policy -> cpuinfo , & data -> cpuinfo , <nl> sizeof ( struct cpufreq_cpuinfo )); <nl>  <nl> - if ( policy -> min > data -> min && policy -> min > policy -> max ) { <nl> + if ( policy -> min > data -> max || policy -> max < data -> min ) { <nl> ret = - EINVAL ; <nl> goto error_out ; <nl> }
static int enum_fmt ( void * priv , struct v4l2_fmtdesc * f , <nl> fmt = & formats [ i ]; <nl> strlcpy ( f -> description , fmt -> name , sizeof ( f -> description )); <nl> f -> pixelformat = fmt -> fourcc ; <nl> + if (! coda_format_is_yuv ( fmt -> fourcc )) <nl> + f -> flags |= V4L2_FMT_FLAG_COMPRESSED ; <nl> return 0 ; <nl> } <nl> 
static int perf_config_global ( void ) <nl> int perf_config ( config_fn_t fn , void * data ) <nl> { <nl> int ret = 0 , found = 0 ; <nl> - char * repo_config = NULL ; <nl> const char * home = NULL ; <nl>  <nl> /* Setting $ PERF_CONFIG makes perf read _only_ the given config file . */ <nl> int perf_config ( config_fn_t fn , void * data ) <nl> free ( user_config ); <nl> } <nl>  <nl> - repo_config = perf_pathdup (" config "); <nl> - if (! access ( repo_config , R_OK )) { <nl> - ret += perf_config_from_file ( fn , repo_config , data ); <nl> - found += 1 ; <nl> - } <nl> - free ( repo_config ); <nl> if ( found == 0 ) <nl> return - 1 ; <nl> return ret ;
int ieee80211_wx_set_encodeext ( struct ieee80211_device * ieee , <nl> crypt = & ieee -> crypt [ idx ]; <nl> group_key = 1 ; <nl> } else { <nl> - if ( idx != 0 ) <nl> + /* some Cisco APs use idx > 0 for unicast in dynamic WEP */ <nl> + if ( idx != 0 && ext -> alg != IW_ENCODE_ALG_WEP ) <nl> return - EINVAL ; <nl> if ( ieee -> iw_mode == IW_MODE_INFRA ) <nl> crypt = & ieee -> crypt [ idx ]; <nl> int ieee80211_wx_get_encodeext ( struct ieee80211_device * ieee , <nl> } else <nl> idx = ieee -> tx_keyidx ; <nl>  <nl> - if (! ext -> ext_flags & IW_ENCODE_EXT_GROUP_KEY ) <nl> + if (! ext -> ext_flags & IW_ENCODE_EXT_GROUP_KEY && <nl> + ext -> alg != IW_ENCODE_ALG_WEP ) <nl> if ( idx != 0 || ieee -> iw_mode != IW_MODE_INFRA ) <nl> return - EINVAL ; <nl> 
void eth_header_cache_update ( struct hh_cache * hh , struct net_device * dev , <nl> static int eth_mac_addr ( struct net_device * dev , void * p ) <nl> { <nl> struct sockaddr * addr = p ; <nl> + <nl> if ( netif_running ( dev )) <nl> return - EBUSY ; <nl> + if (! is_valid_ether_addr ( addr -> sa_data )) <nl> + return - EADDRNOTAVAIL ; <nl> memcpy ( dev -> dev_addr , addr -> sa_data , dev -> addr_len ); <nl> return 0 ; <nl> }
u8 omap2_init_dpll_parent ( struct clk_hw * hw ) <nl> */ <nl> unsigned long omap2_get_dpll_rate ( struct clk_hw_omap * clk ) <nl> { <nl> - long long dpll_clk ; <nl> + u64 dpll_clk ; <nl> u32 dpll_mult , dpll_div , v ; <nl> struct dpll_data * dd ; <nl>  <nl> unsigned long omap2_get_dpll_rate ( struct clk_hw_omap * clk ) <nl> dpll_div = v & dd -> div1_mask ; <nl> dpll_div >>= __ffs ( dd -> div1_mask ); <nl>  <nl> - dpll_clk = ( long long ) clk_get_rate ( dd -> clk_ref ) * dpll_mult ; <nl> + dpll_clk = ( u64 ) clk_get_rate ( dd -> clk_ref ) * dpll_mult ; <nl> do_div ( dpll_clk , dpll_div + 1 ); <nl>  <nl> return dpll_clk ;
int __init mxc_register_gpios ( void ) <nl> # ifdef CONFIG_MACH_MX21 <nl> static struct resource mx21_usbhc_resources [] = { <nl> { <nl> - . start = MX21_BASE_ADDR , <nl> - . end = MX21_BASE_ADDR + 0x1FFF , <nl> + . start = MX21_USBOTG_BASE_ADDR , <nl> + . end = MX21_USBOTG_BASE_ADDR + SZ_8K - 1 , <nl> . flags = IORESOURCE_MEM , <nl> }, <nl> {
struct mxs_mmc_host { <nl> unsigned char bus_width ; <nl> spinlock_t lock ; <nl> int sdio_irq_en ; <nl> + bool broken_cd ; <nl> }; <nl>  <nl> static int mxs_mmc_get_cd ( struct mmc_host * mmc ) <nl> static int mxs_mmc_get_cd ( struct mmc_host * mmc ) <nl> struct mxs_ssp * ssp = & host -> ssp ; <nl> int present , ret ; <nl>  <nl> + if ( host -> broken_cd ) <nl> + return - ENOSYS ; <nl> + <nl> ret = mmc_gpio_get_cd ( mmc ); <nl> if ( ret >= 0 ) <nl> return ret ; <nl> static int mxs_mmc_probe ( struct platform_device * pdev ) <nl> { <nl> const struct of_device_id * of_id = <nl> of_match_device ( mxs_mmc_dt_ids , & pdev -> dev ); <nl> + struct device_node * np = pdev -> dev . of_node ; <nl> struct mxs_mmc_host * host ; <nl> struct mmc_host * mmc ; <nl> struct resource * iores ; <nl> static int mxs_mmc_probe ( struct platform_device * pdev ) <nl> mmc -> caps = MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED | <nl> MMC_CAP_SDIO_IRQ | MMC_CAP_NEEDS_POLL ; <nl>  <nl> + host -> broken_cd = of_property_read_bool ( np , " broken - cd "); <nl> + <nl> mmc -> f_min = 400000 ; <nl> mmc -> f_max = 288000000 ; <nl> 
static u8 parse_subframe ( struct sk_buff * skb , <nl> # else <nl> /* Allocate new skb for releasing to upper layer */ <nl> sub_skb = dev_alloc_skb ( nSubframe_Length + 12 ); <nl> + if (! sub_skb ) <nl> + return 0 ; <nl> skb_reserve ( sub_skb , 12 ); <nl> data_ptr = ( u8 *) skb_put ( sub_skb , nSubframe_Length ); <nl> memcpy ( data_ptr , skb -> data , nSubframe_Length );
static int old_capi_manufacturer ( unsigned int cmd , void __user * data ) <nl> return - EFAULT ; <nl> } <nl> card = get_capi_ctr_by_nr ( ldef . contr ); <nl> + if (! card ) <nl> + return - EINVAL ; <nl> card = capi_ctr_get ( card ); <nl> if (! card ) <nl> return - ESRCH ;
int iptunnel_xmit ( struct rtable * rt , struct sk_buff * skb , <nl> memset ( IPCB ( skb ), 0 , sizeof (* IPCB ( skb ))); <nl>  <nl> /* Push down and install the IP header . */ <nl> - __skb_push ( skb , sizeof ( struct iphdr )); <nl> + skb_push ( skb , sizeof ( struct iphdr )); <nl> skb_reset_network_header ( skb ); <nl>  <nl> iph = ip_hdr ( skb );
tso_sq_no_longer_full : <nl> nesnic -> sq_head &= nesnic -> sq_size - 1 ; <nl> } <nl> } else { <nl> - nesvnic -> linearized_skbs ++; <nl> hoffset = skb_transport_header ( skb ) - skb -> data ; <nl> nhoffset = skb_network_header ( skb ) - skb -> data ; <nl> - skb_linearize ( skb ); <nl> + if ( skb_linearize ( skb )) { <nl> + nesvnic -> tx_sw_dropped ++; <nl> + kfree_skb ( skb ); <nl> + return NETDEV_TX_OK ; <nl> + } <nl> + nesvnic -> linearized_skbs ++; <nl> skb_set_transport_header ( skb , hoffset ); <nl> skb_set_network_header ( skb , nhoffset ); <nl> if (! nes_nic_send ( skb , netdev ))
static int ecryptfs_setattr ( struct dentry * dentry , struct iattr * ia ) <nl> } <nl> } <nl> mutex_unlock (& crypt_stat -> cs_mutex ); <nl> + if ( S_ISREG ( inode -> i_mode )) { <nl> + rc = filemap_write_and_wait ( inode -> i_mapping ); <nl> + if ( rc ) <nl> + goto out ; <nl> + fsstack_copy_attr_all ( inode , lower_inode ); <nl> + } <nl> memcpy (& lower_ia , ia , sizeof ( lower_ia )); <nl> if ( ia -> ia_valid & ATTR_FILE ) <nl> lower_ia . ia_file = ecryptfs_file_to_lower ( ia -> ia_file );
static int w5300_hw_probe ( struct platform_device * pdev ) <nl> if (! mem ) <nl> return - ENXIO ; <nl> mem_size = resource_size ( mem ); <nl> - if (! devm_request_mem_region (& pdev -> dev , mem -> start , mem_size , name )) <nl> - return - EBUSY ; <nl> - priv -> base = devm_ioremap (& pdev -> dev , mem -> start , mem_size ); <nl> - if (! priv -> base ) <nl> - return - EBUSY ; <nl> + <nl> + priv -> base = devm_ioremap_resource (& pdev -> dev , mem ); <nl> + if ( IS_ERR ( priv -> base )) <nl> + return PTR_ERR ( priv -> base ); <nl>  <nl> spin_lock_init (& priv -> reg_lock ); <nl> priv -> indirect = mem_size < W5300_BUS_DIRECT_SIZE ;
int arizona_set_fll ( struct arizona_fll * fll , int source , <nl> if ( ena ) <nl> pm_runtime_put_autosuspend ( arizona -> dev ); <nl>  <nl> + fll -> fref = Fref ; <nl> + fll -> fout = Fout ; <nl> + <nl> return 0 ; <nl> } <nl> 
static int pn533_target_found ( struct pn533 * dev , <nl> if ( resp -> tg != 1 ) <nl> return - EPROTO ; <nl>  <nl> + memset (& nfc_tgt , 0 , sizeof ( struct nfc_target )); <nl> + <nl> target_data_len = resp_len - sizeof ( struct pn533_poll_response ); <nl>  <nl> switch ( dev -> poll_mod_curr ) {
static int cp2112_gpio_direction_input ( struct gpio_chip * chip , unsigned offset ) <nl>  <nl> exit : <nl> mutex_unlock (& dev -> lock ); <nl> - return ret <= 0 ? ret : - EIO ; <nl> + return ret < 0 ? ret : - EIO ; <nl> } <nl>  <nl> static void cp2112_gpio_set ( struct gpio_chip * chip , unsigned offset , int value )
static int mmci_probe ( struct amba_device * dev , <nl> dev_dbg ( mmc_dev ( mmc ), " clocking block at % u Hz \ n ", mmc -> f_max ); <nl>  <nl> /* Get regulators and the supported OCR mask */ <nl> - mmc_regulator_get_supply ( mmc ); <nl> + ret = mmc_regulator_get_supply ( mmc ); <nl> + if ( ret == - EPROBE_DEFER ) <nl> + goto clk_disable ; <nl> + <nl> if (! mmc -> ocr_avail ) <nl> mmc -> ocr_avail = plat -> ocr_mask ; <nl> else if ( plat -> ocr_mask )
static int selinux_setprocattr ( struct task_struct * p , <nl> return error ; <nl>  <nl> /* Obtain a SID for the context , if one was specified . */ <nl> - if ( size && str [ 1 ] && str [ 1 ] != '\ n ') { <nl> + if ( size && str [ 0 ] && str [ 0 ] != '\ n ') { <nl> if ( str [ size - 1 ] == '\ n ') { <nl> str [ size - 1 ] = 0 ; <nl> size --;
regulator_register ( const struct regulator_desc * regulator_desc , <nl> const struct regulator_init_data * init_data ; <nl> static atomic_t regulator_no = ATOMIC_INIT ( 0 ); <nl> struct regulator_dev * rdev ; <nl> - struct device * dev = config -> dev ; <nl> + struct device * dev ; <nl> int ret , i ; <nl> const char * supply = NULL ; <nl>  <nl> if ( regulator_desc == NULL || config == NULL ) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> + dev = config -> dev ; <nl> + <nl> if ( regulator_desc -> name == NULL || regulator_desc -> ops == NULL ) <nl> return ERR_PTR (- EINVAL ); <nl> 
static int hdsp_playback_to_output_key ( struct hdsp * hdsp , int in , int out ) <nl> case Multiface : <nl> case Digiface : <nl> default : <nl> - return ( 64 * out ) + ( 32 + ( in )); <nl> + if ( hdsp -> firmware_rev == 0xa ) <nl> + return ( 64 * out ) + ( 32 + ( in )); <nl> + else <nl> + return ( 52 * out ) + ( 26 + ( in )); <nl> case H9632 : <nl> return ( 32 * out ) + ( 16 + ( in )); <nl> case H9652 : <nl> static int hdsp_input_to_output_key ( struct hdsp * hdsp , int in , int out ) <nl> case Multiface : <nl> case Digiface : <nl> default : <nl> - return ( 64 * out ) + in ; <nl> + if ( hdsp -> firmware_rev == 0xa ) <nl> + return ( 64 * out ) + in ; <nl> + else <nl> + return ( 52 * out ) + in ; <nl> case H9632 : <nl> return ( 32 * out ) + in ; <nl> case H9652 :
static bool ceph_msg_data_bio_advance ( struct ceph_msg_data_cursor * cursor , <nl>  <nl> if (! cursor -> bvec_iter . bi_size ) { <nl> bio = bio -> bi_next ; <nl> - cursor -> bvec_iter = bio -> bi_iter ; <nl> + cursor -> bio = bio ; <nl> + if ( bio ) <nl> + cursor -> bvec_iter = bio -> bi_iter ; <nl> + else <nl> + memset (& cursor -> bvec_iter , 0 , <nl> + sizeof ( cursor -> bvec_iter )); <nl> } <nl> - cursor -> bio = bio ; <nl>  <nl> if (! cursor -> last_piece ) { <nl> BUG_ON (! cursor -> resid );
static int pb0100_start ( struct sd * sd ) <nl>  <nl> intf = usb_ifnum_to_if ( sd -> gspca_dev . dev , sd -> gspca_dev . iface ); <nl> alt = usb_altnum_to_altsetting ( intf , sd -> gspca_dev . alt ); <nl> + if (! alt ) <nl> + return - ENODEV ; <nl> packet_size = le16_to_cpu ( alt -> endpoint [ 0 ]. desc . wMaxPacketSize ); <nl>  <nl> /* If we don ' t have enough bandwidth use a lower framerate */
 <nl> # include < plat / mailbox . h > <nl>  <nl> + static struct workqueue_struct * mboxd ; <nl> static struct omap_mbox * mboxes ; <nl> static DEFINE_RWLOCK ( mboxes_lock ); <nl>  <nl> static void __mbox_rx_interrupt ( struct omap_mbox * mbox ) <nl> /* no more messages in the fifo . clear IRQ source . */ <nl> ack_mbox_irq ( mbox , IRQ_RX ); <nl> nomem : <nl> - schedule_work (& mbox -> rxq -> work ); <nl> + queue_work ( mboxd , & mbox -> rxq -> work ); <nl> } <nl>  <nl> static irqreturn_t mbox_interrupt ( int irq , void * p ) <nl> EXPORT_SYMBOL ( omap_mbox_unregister ); <nl>  <nl> static int __init omap_mbox_init ( void ) <nl> { <nl> + mboxd = create_workqueue (" mboxd "); <nl> + if (! mboxd ) <nl> + return - ENOMEM ; <nl> + <nl> return 0 ; <nl> } <nl> module_init ( omap_mbox_init ); <nl>  <nl> static void __exit omap_mbox_exit ( void ) <nl> { <nl> + destroy_workqueue ( mboxd ); <nl> } <nl> module_exit ( omap_mbox_exit ); <nl> 
static void cleanup_single_sta ( struct sta_info * sta ) <nl> * directly by station destruction . <nl> */ <nl> for ( i = 0 ; i < IEEE80211_NUM_TIDS ; i ++) { <nl> + kfree ( sta -> ampdu_mlme . tid_start_tx [ i ]); <nl> tid_tx = rcu_dereference_raw ( sta -> ampdu_mlme . tid_tx [ i ]); <nl> if (! tid_tx ) <nl> continue ;
static int f7188x_gpio_set_single_ended ( struct gpio_chip * chip , <nl> data &= ~ BIT ( offset ); <nl> else <nl> data |= BIT ( offset ); <nl> - superio_outb ( sio -> addr , gpio_data_mode ( bank -> regbase ), data ); <nl> + superio_outb ( sio -> addr , gpio_out_mode ( bank -> regbase ), data ); <nl>  <nl> superio_exit ( sio -> addr ); <nl> return 0 ;
static ssize_t acpi_ec_write_io ( struct file * f , const char __user * buf , <nl> loff_t init_off = * off ; <nl> int err = 0 ; <nl>  <nl> + if (! write_support ) <nl> + return - EINVAL ; <nl> + <nl> if (* off >= EC_SPACE_SIZE ) <nl> return 0 ; <nl> if (* off + count >= EC_SPACE_SIZE ) {
static int recv_control_msg ( struct au0828_dev * dev , u16 request , u32 value , <nl> u32 au0828_readreg ( struct au0828_dev * dev , u16 reg ) <nl> { <nl> recv_control_msg ( dev , CMD_REQUEST_IN , 0 , reg , dev -> ctrlmsg , 1 ); <nl> - dprintk ( 8 , "% s ( 0x % x ) = 0x % x \ n ", __func__ , reg , dev -> ctrlmsg [ 0 ]); <nl> + dprintk ( 8 , "% s ( 0x % 04x ) = 0x % 02x \ n ", __func__ , reg , dev -> ctrlmsg [ 0 ]); <nl> return dev -> ctrlmsg [ 0 ]; <nl> } <nl>  <nl> u32 au0828_writereg ( struct au0828_dev * dev , u16 reg , u32 val ) <nl> { <nl> - dprintk ( 8 , "% s ( 0x % x , 0x % x )\ n ", __func__ , reg , val ); <nl> + dprintk ( 8 , "% s ( 0x % 04x , 0x % 02x )\ n ", __func__ , reg , val ); <nl> return send_control_msg ( dev , CMD_REQUEST_OUT , val , reg , <nl> dev -> ctrlmsg , 0 ); <nl> }
static int ethoc_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> mmio = devm_request_mem_region (& pdev -> dev , res -> start , <nl> - res -> end - res -> start + 1 , res -> name ); <nl> + resource_size ( res ), res -> name ); <nl> if (! mmio ) { <nl> dev_err (& pdev -> dev , " cannot request I / O memory space \ n "); <nl> ret = - ENXIO ; <nl> static int ethoc_probe ( struct platform_device * pdev ) <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 1 ); <nl> if ( res ) { <nl> mem = devm_request_mem_region (& pdev -> dev , res -> start , <nl> - res -> end - res -> start + 1 , res -> name ); <nl> + resource_size ( res ), res -> name ); <nl> if (! mem ) { <nl> dev_err (& pdev -> dev , " cannot request memory space \ n "); <nl> ret = - ENXIO ; <nl> static int ethoc_probe ( struct platform_device * pdev ) <nl> priv -> dma_alloc = 0 ; <nl>  <nl> priv -> iobase = devm_ioremap_nocache (& pdev -> dev , netdev -> base_addr , <nl> - mmio -> end - mmio -> start + 1 ); <nl> + resource_size ( mmio )); <nl> if (! priv -> iobase ) { <nl> dev_err (& pdev -> dev , " cannot remap I / O memory space \ n "); <nl> ret = - ENXIO ; <nl> static int ethoc_probe ( struct platform_device * pdev ) <nl>  <nl> if ( netdev -> mem_end ) { <nl> priv -> membase = devm_ioremap_nocache (& pdev -> dev , <nl> - netdev -> mem_start , mem -> end - mem -> start + 1 ); <nl> + netdev -> mem_start , resource_size ( mem )); <nl> if (! priv -> membase ) { <nl> dev_err (& pdev -> dev , " cannot remap memory space \ n "); <nl> ret = - ENXIO ;
static int dw_i2c_probe ( struct platform_device * pdev ) <nl> adap = & dev -> adapter ; <nl> i2c_set_adapdata ( adap , dev ); <nl> adap -> owner = THIS_MODULE ; <nl> - adap -> class = I2C_CLASS_HWMON | I2C_CLASS_DEPRECATED ; <nl> + adap -> class = I2C_CLASS_DEPRECATED ; <nl> strlcpy ( adap -> name , " Synopsys DesignWare I2C adapter ", <nl> sizeof ( adap -> name )); <nl> adap -> algo = & i2c_dw_algo ;
static int snd_rawmidi_runtime_free ( struct snd_rawmidi_substream * substream ) <nl>  <nl> static inline void snd_rawmidi_output_trigger ( struct snd_rawmidi_substream * substream , int up ) <nl> { <nl> + if (! substream -> opened ) <nl> + return ; <nl> if ( up ) { <nl> tasklet_hi_schedule (& substream -> runtime -> tasklet ); <nl> } else { <nl> static inline void snd_rawmidi_output_trigger ( struct snd_rawmidi_substream * subs <nl>  <nl> static void snd_rawmidi_input_trigger ( struct snd_rawmidi_substream * substream , int up ) <nl> { <nl> + if (! substream -> opened ) <nl> + return ; <nl> substream -> ops -> trigger ( substream , up ); <nl> if (! up && substream -> runtime -> event ) <nl> tasklet_kill (& substream -> runtime -> tasklet ); <nl> int snd_rawmidi_receive ( struct snd_rawmidi_substream * substream , <nl> int result = 0 , count1 ; <nl> struct snd_rawmidi_runtime * runtime = substream -> runtime ; <nl>  <nl> + if (! substream -> opened ) <nl> + return - EBADFD ; <nl> if ( runtime -> buffer == NULL ) { <nl> snd_printd (" snd_rawmidi_receive : input is not active !!!\ n "); <nl> return - EINVAL ; <nl> int snd_rawmidi_transmit_ack ( struct snd_rawmidi_substream * substream , int count ) <nl> int snd_rawmidi_transmit ( struct snd_rawmidi_substream * substream , <nl> unsigned char * buffer , int count ) <nl> { <nl> + if (! substream -> opened ) <nl> + return - EBADFD ; <nl> count = snd_rawmidi_transmit_peek ( substream , buffer , count ); <nl> if ( count < 0 ) <nl> return count ;
void ath_detach ( struct ath_softc * sc ) <nl>  <nl> ath9k_hw_detach ( sc -> sc_ah ); <nl> ath9k_exit_debug ( sc ); <nl> - ath9k_ps_restore ( sc ); <nl> } <nl>  <nl> static int ath9k_reg_notifier ( struct wiphy * wiphy ,
static int do_vmbus_entry ( const char * filename , struct hv_vmbus_device_id * id , <nl> char * alias ) <nl> { <nl> int i ; <nl> - char guid_name [(( sizeof ( struct hv_vmbus_device_id ) + 1 )) * 2 ]; <nl> + char guid_name [(( sizeof ( id -> guid ) + 1 )) * 2 ]; <nl>  <nl> - for ( i = 0 ; i < ( sizeof ( struct hv_vmbus_device_id ) * 2 ); i += 2 ) <nl> + for ( i = 0 ; i < ( sizeof ( id -> guid ) * 2 ); i += 2 ) <nl> sprintf (& guid_name [ i ], "% 02x ", id -> guid [ i / 2 ]); <nl>  <nl> strcpy ( alias , " vmbus :");
# define DCP_MAX_CHANS 4 <nl> # define DCP_BUF_SZ PAGE_SIZE <nl>  <nl> +# define DCP_ALIGNMENT 64 <nl> + <nl> /* DCP DMA descriptor . */ <nl> struct dcp_dma_desc { <nl> uint32_t next_cmd_addr ; <nl> static int mxs_dcp_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> /* Allocate coherent helper block . */ <nl> - sdcp -> coh = devm_kzalloc ( dev , sizeof (* sdcp -> coh ), GFP_KERNEL ); <nl> + sdcp -> coh = devm_kzalloc ( dev , sizeof (* sdcp -> coh ) + DCP_ALIGNMENT , <nl> + GFP_KERNEL ); <nl> if (! sdcp -> coh ) { <nl> ret = - ENOMEM ; <nl> goto err_mutex ; <nl> } <nl>  <nl> + /* Re - align the structure so it fits the DCP constraints . */ <nl> + sdcp -> coh = PTR_ALIGN ( sdcp -> coh , DCP_ALIGNMENT ); <nl> + <nl> /* Restart the DCP block . */ <nl> ret = stmp_reset_block ( sdcp -> base ); <nl> if ( ret )
static void efx_pci_remove ( struct pci_dev * pci_dev ) <nl> efx_dissociate ( efx ); <nl> dev_close ( efx -> net_dev ); <nl> efx_disable_interrupts ( efx ); <nl> + efx -> state = STATE_UNINIT ; <nl> rtnl_unlock (); <nl>  <nl> if ( efx -> type -> sriov_fini )
 <nl> # define DRV_MODULE_NAME " tg3 " <nl> # define PFX DRV_MODULE_NAME ": " <nl> -# define DRV_MODULE_VERSION " 3 . 81 " <nl> -# define DRV_MODULE_RELDATE " September 5 , 2007 " <nl> +# define DRV_MODULE_VERSION " 3 . 82 " <nl> +# define DRV_MODULE_RELDATE " October 5 , 2007 " <nl>  <nl> # define TG3_DEF_MAC_MODE 0 <nl> # define TG3_DEF_RX_MODE 0
static void printl ( const char * fmt , ...) <nl>  <nl> kfifo_put ( tcpw . fifo , tbuf , len ); <nl> wake_up (& tcpw . wait ); <nl> -} <nl> +} __attribute__ (( format ( printf , 1 , 2 ))); <nl> + <nl>  <nl> /* <nl> * Hook inserted to be called before each receive packet .
 <nl> # define _NETXEN_NIC_LINUX_MAJOR 4 <nl> # define _NETXEN_NIC_LINUX_MINOR 0 <nl> -# define _NETXEN_NIC_LINUX_SUBVERSION 65 <nl> -# define NETXEN_NIC_LINUX_VERSIONID " 4 . 0 . 65 " <nl> +# define _NETXEN_NIC_LINUX_SUBVERSION 72 <nl> +# define NETXEN_NIC_LINUX_VERSIONID " 4 . 0 . 72 " <nl>  <nl> # define NETXEN_VERSION_CODE ( a , b , c ) ((( a ) << 24 ) + (( b ) << 16 ) + ( c )) <nl> # define _major ( v ) ((( v ) >> 24 ) & 0xff )
int ath9k_hw_init ( struct ath_hw * ah ) <nl> struct ath_common * common = ath9k_hw_common ( ah ); <nl> int r = 0 ; <nl>  <nl> - if (! ath9k_hw_devid_supported ( ah -> hw_version . devid )) <nl> + if (! ath9k_hw_devid_supported ( ah -> hw_version . devid )) { <nl> + ath_print ( common , ATH_DBG_FATAL , <nl> + " Unsupported device ID : 0x % 0x \ n ", <nl> + ah -> hw_version . devid ); <nl> return - EOPNOTSUPP ; <nl> + } <nl>  <nl> ath9k_hw_init_defaults ( ah ); <nl> ath9k_hw_init_config ( ah );
static void ql_update_sbq ( struct ql_adapter * qdev , struct rx_ring * rx_ring ) <nl> sbq_desc -> p . skb -> data , <nl> rx_ring -> sbq_buf_size / <nl> 2 , PCI_DMA_FROMDEVICE ); <nl> + if ( pci_dma_mapping_error ( qdev -> pdev , map )) { <nl> + QPRINTK ( qdev , IFUP , ERR , " PCI mapping failed .\ n "); <nl> + rx_ring -> sbq_clean_idx = clean_idx ; <nl> + return ; <nl> + } <nl> pci_unmap_addr_set ( sbq_desc , mapaddr , map ); <nl> pci_unmap_len_set ( sbq_desc , maplen , <nl> rx_ring -> sbq_buf_size / 2 );
void __init pxa_set_mci_info ( struct pxamci_platform_data * info ) <nl> } <nl>  <nl>  <nl> - static struct pxa2xx_udc_mach_info pxa_udc_info ; <nl> + static struct pxa2xx_udc_mach_info pxa_udc_info = { <nl> + . gpio_pullup = - 1 , <nl> + . gpio_vbus = - 1 , <nl> +}; <nl>  <nl> void __init pxa_set_udc_info ( struct pxa2xx_udc_mach_info * info ) <nl> {
static int __init mod_init ( void ) <nl> if ( err ) { <nl> printk ( KERN_ERR PFX " RNG registering failed (% d )\ n ", <nl> err ); <nl> - goto out ; <nl> + goto err_unmap ; <nl> } <nl> out : <nl> return err ;
static int nfc_genl_send_target ( struct sk_buff * msg , struct nfc_target * target , <nl> target -> sensf_res )) <nl> goto nla_put_failure ; <nl>  <nl> + if ( target -> is_iso15693 ) { <nl> + if ( nla_put_u8 ( msg , NFC_ATTR_TARGET_ISO15693_DSFID , <nl> + target -> iso15693_dsfid ) || <nl> + nla_put ( msg , NFC_ATTR_TARGET_ISO15693_UID , <nl> + sizeof ( target -> iso15693_uid ), target -> iso15693_uid )) <nl> + goto nla_put_failure ; <nl> + } <nl> + <nl> return genlmsg_end ( msg , hdr ); <nl>  <nl> nla_put_failure :
static int fn_trie_insert ( struct fib_table * tb , struct fib_config * cfg ) <nl> struct fib_info * fi_drop ; <nl> u8 state ; <nl>  <nl> + if ( fi -> fib_treeref > 1 ) <nl> + goto out ; <nl> + <nl> err = - ENOBUFS ; <nl> new_fa = kmem_cache_alloc ( fn_alias_kmem , GFP_KERNEL ); <nl> if ( new_fa == NULL )
int drbd_adm_resize ( struct sk_buff * skb , struct genl_info * info ) <nl> mutex_unlock (& device -> resource -> conf_update ); <nl> synchronize_rcu (); <nl> kfree ( old_disk_conf ); <nl> + new_disk_conf = NULL ; <nl> } <nl>  <nl> ddsf = ( rs . resize_force ? DDSF_FORCED : 0 ) | ( rs . no_resync ? DDSF_NO_RESYNC : 0 ); <nl> int drbd_adm_resize ( struct sk_buff * skb , struct genl_info * info ) <nl>  <nl> fail_ldev : <nl> put_ldev ( device ); <nl> + kfree ( new_disk_conf ); <nl> goto fail ; <nl> } <nl> 
void rtl_8821ae_c2h_command_handle ( struct ieee80211_hw * hw ) <nl> rtl_write_byte ( rtlpriv , 0x1AF , 0x00 ); <nl> return ; <nl> } <nl> - ptmp_buf = ( u8 *) kmalloc ( c2h_event . cmd_len , GFP_KERNEL ); <nl> + ptmp_buf = kmalloc ( c2h_event . cmd_len , GFP_KERNEL ); <nl> if ( ptmp_buf == NULL ) { <nl> RT_TRACE ( COMP_FW , DBG_TRACE , (" malloc cmd buf failed \ n ")); <nl> return ;
void unregister_vlan_dev ( struct net_device * dev ) <nl>  <nl> synchronize_net (); <nl>  <nl> + unregister_netdevice ( dev ); <nl> + <nl> /* If the group is now empty , kill off the group . */ <nl> if ( grp -> nr_vlans == 0 ) { <nl> if ( real_dev -> features & NETIF_F_HW_VLAN_RX ) <nl> void unregister_vlan_dev ( struct net_device * dev ) <nl>  <nl> /* Get rid of the vlan ' s reference to real_dev */ <nl> dev_put ( real_dev ); <nl> - <nl> - unregister_netdevice ( dev ); <nl> } <nl>  <nl> static void vlan_transfer_operstate ( const struct net_device * dev ,
# include " dvb_frontend . h " <nl> # include " au8522_priv . h " <nl>  <nl> + MODULE_LICENSE (" GPL "); <nl> + <nl> static int debug ; <nl>  <nl> # define dprintk ( arg ...)\
static void tenxpress_phy_fini ( struct efx_nic * efx ) <nl> { <nl> int reg ; <nl>  <nl> - if ( efx -> phy_type == PHY_TYPE_SFT9001B ) { <nl> + if ( efx -> phy_type == PHY_TYPE_SFT9001B ) <nl> device_remove_file (& efx -> pci_dev -> dev , <nl> & dev_attr_phy_short_reach ); <nl> - } else { <nl> + <nl> + if ( efx -> phy_type == PHY_TYPE_SFX7101 ) { <nl> /* Power down the LNPGA */ <nl> reg = ( 1 << PMA_PMD_LNPGA_POWERDOWN_LBN ); <nl> mdio_clause45_write ( efx , efx -> mii . phy_id , MDIO_MMD_PMAPMD ,
static void __devexit pm2fb_remove ( struct pci_dev * pdev ) <nl> release_mem_region ( fix -> mmio_start , fix -> mmio_len ); <nl>  <nl> pci_set_drvdata ( pdev , NULL ); <nl> + fb_dealloc_cmap (& info -> cmap ); <nl> kfree ( info -> pixmap . addr ); <nl> kfree ( info ); <nl> }
static void add_pin_to_irq_node ( struct irq_cfg * cfg , int node , int apic , int pin <nl> } <nl>  <nl> entry = get_one_free_irq_2_pin ( node ); <nl> + if (! entry ) { <nl> + printk ( KERN_ERR " can not alloc irq_pin_list \ n "); <nl> + BUG_ON ( 1 ); <nl> + } <nl> entry -> apic = apic ; <nl> entry -> pin = pin ; <nl> 
static irqreturn_t interrupt_pcl816 ( int irq , void * d ) <nl> } <nl>  <nl> outb ( 0 , dev -> iobase + PCL816_CLRINT ); /* clear INT request */ <nl> - if ((! dev -> irq ) | (! devpriv -> irq_free ) | (! devpriv -> irq_blocked ) | <nl> - (! devpriv -> int816_mode )) { <nl> + if (! dev -> irq || ! devpriv -> irq_free || ! devpriv -> irq_blocked || <nl> + ! devpriv -> int816_mode ) { <nl> if ( devpriv -> irq_was_now_closed ) { <nl> devpriv -> irq_was_now_closed = 0 ; <nl> /* comedi_error ( dev ," last IRQ .."); */
static int saa7134_try_get_set_fmt_vbi_cap ( struct file * file , void * priv , <nl> struct saa7134_dev * dev = fh -> dev ; <nl> struct saa7134_tvnorm * norm = dev -> tvnorm ; <nl>  <nl> + memset (& f -> fmt . vbi . reserved , 0 , sizeof ( f -> fmt . vbi . reserved )); <nl> f -> fmt . vbi . sampling_rate = 6750000 * 4 ; <nl> f -> fmt . vbi . samples_per_line = 2048 /* VBI_LINE_LENGTH */; <nl> f -> fmt . vbi . sample_format = V4L2_PIX_FMT_GREY ;
static bool radeon_apply_legacy_quirks ( struct drm_device * dev , <nl> return false ; <nl> } <nl>  <nl> - /* Some RV100 cards with 2 VGA ports show up with DVI + VGA */ <nl> - if ( dev -> pdev -> device == 0x5159 && <nl> - dev -> pdev -> subsystem_vendor == 0x1002 && <nl> - dev -> pdev -> subsystem_device == 0x013a ) { <nl> - if (* legacy_connector == CONNECTOR_DVI_I_LEGACY ) <nl> - * legacy_connector = CONNECTOR_CRT_LEGACY ; <nl> - <nl> - } <nl> - <nl> /* X300 card with extra non - existent DVI port */ <nl> if ( dev -> pdev -> device == 0x5B60 && <nl> dev -> pdev -> subsystem_vendor == 0x17af &&
static int __init atmel_nand_probe ( struct platform_device * pdev ) <nl> } <nl> } <nl> if ( use_dma ) <nl> - dev_info ( host -> dev , " Using DMA for NAND access .\ n "); <nl> + dev_info ( host -> dev , " Using % s for DMA transfers .\ n ", <nl> + dma_chan_name ( host -> dma_chan )); <nl> else <nl> dev_info ( host -> dev , " No DMA support for NAND access .\ n "); <nl> 
static int emulate_pop_sreg ( struct x86_emulate_ctxt * ctxt , <nl> if ( rc != X86EMUL_CONTINUE ) <nl> return rc ; <nl>  <nl> - rc = kvm_load_segment_descriptor ( ctxt -> vcpu , ( u16 ) selector , seg ); <nl> + rc = load_segment_descriptor ( ctxt , ops , ( u16 ) selector , seg ); <nl> return rc ; <nl> } <nl>  <nl> static int emulate_ret_far ( struct x86_emulate_ctxt * ctxt , <nl> rc = emulate_pop ( ctxt , ops , & cs , c -> op_bytes ); <nl> if ( rc != X86EMUL_CONTINUE ) <nl> return rc ; <nl> - rc = kvm_load_segment_descriptor ( ctxt -> vcpu , ( u16 ) cs , VCPU_SREG_CS ); <nl> + rc = load_segment_descriptor ( ctxt , ops , ( u16 ) cs , VCPU_SREG_CS ); <nl> return rc ; <nl> } <nl>  <nl> special_insn : <nl> if ( c -> modrm_reg == VCPU_SREG_SS ) <nl> toggle_interruptibility ( ctxt , KVM_X86_SHADOW_INT_MOV_SS ); <nl>  <nl> - rc = kvm_load_segment_descriptor ( ctxt -> vcpu , sel , c -> modrm_reg ); <nl> + rc = load_segment_descriptor ( ctxt , ops , sel , c -> modrm_reg ); <nl>  <nl> c -> dst . type = OP_NONE ; /* Disable writeback . */ <nl> break ; <nl> special_insn : <nl> goto jmp ; <nl> case 0xea : /* jmp far */ <nl> jump_far : <nl> - if ( kvm_load_segment_descriptor ( ctxt -> vcpu , c -> src2 . val , <nl> - VCPU_SREG_CS )) <nl> + if ( load_segment_descriptor ( ctxt , ops , c -> src2 . val , <nl> + VCPU_SREG_CS )) <nl> goto done ; <nl>  <nl> c -> eip = c -> src . val ;
static int hns_mac_get_info ( struct hns_mac_cb * mac_cb ) <nl> dev_dbg ( mac_cb -> dev , " mac % d phy_node : % s \ n ", <nl> mac_cb -> mac_id , np -> name ); <nl> } <nl> + of_node_put ( np ); <nl>  <nl> return 0 ; <nl> } <nl> static int hns_mac_get_info ( struct hns_mac_cb * mac_cb ) <nl> dev_dbg ( mac_cb -> dev , " mac % d phy_node : % s \ n ", <nl> mac_cb -> mac_id , np -> name ); <nl> } <nl> + of_node_put ( np ); <nl>  <nl> - syscon = syscon_node_to_regmap ( <nl> - of_parse_phandle ( to_of_node ( mac_cb -> fw_port ), <nl> - " serdes - syscon ", 0 )); <nl> + np = of_parse_phandle ( to_of_node ( mac_cb -> fw_port ), <nl> + " serdes - syscon ", 0 ); <nl> + syscon = syscon_node_to_regmap ( np ); <nl> + of_node_put ( np ); <nl> if ( IS_ERR_OR_NULL ( syscon )) { <nl> dev_err ( mac_cb -> dev , " serdes - syscon is needed !\ n "); <nl> return - EINVAL ;
static int mt9t112_probe ( struct i2c_client * client , <nl> v4l2_i2c_subdev_init (& priv -> subdev , client , & mt9t112_subdev_ops ); <nl>  <nl> ret = mt9t112_camera_probe ( client ); <nl> - if ( ret ) <nl> + if ( ret ) { <nl> kfree ( priv ); <nl> + return ret ; <nl> + } <nl>  <nl> /* Cannot fail : using the default supported pixel code */ <nl> mt9t112_set_params ( priv , & rect , V4L2_MBUS_FMT_UYVY8_2X8 );
static void sky2_mac_intr ( struct sky2_hw * hw , unsigned port ) <nl> printk ( KERN_INFO PFX "% s : mac interrupt status 0x % x \ n ", <nl> dev -> name , status ); <nl>  <nl> + if ( status & GM_IS_RX_CO_OV ) <nl> + gma_read16 ( hw , port , GM_RX_IRQ_SRC ); <nl> + <nl> + if ( status & GM_IS_TX_CO_OV ) <nl> + gma_read16 ( hw , port , GM_TX_IRQ_SRC ); <nl> + <nl> if ( status & GM_IS_RX_FF_OR ) { <nl> ++ sky2 -> net_stats . rx_fifo_errors ; <nl> sky2_write8 ( hw , SK_REG ( port , RX_GMF_CTRL_T ), GMF_CLI_RX_FO );
static bool dln2_transfer_complete ( struct dln2_dev * dln2 , struct urb * urb , <nl> struct dln2_rx_context * rxc ; <nl> bool valid_slot = false ; <nl>  <nl> + if ( rx_slot >= DLN2_MAX_RX_SLOTS ) <nl> + goto out ; <nl> + <nl> rxc = & rxs -> slots [ rx_slot ]; <nl>  <nl> /* <nl> static bool dln2_transfer_complete ( struct dln2_dev * dln2 , struct urb * urb , <nl> } <nl> spin_unlock (& rxs -> lock ); <nl>  <nl> + out : <nl> if (! valid_slot ) <nl> dev_warn ( dev , " bad / late response % d /% d \ n ", handle , rx_slot ); <nl> 
__ip_vs_get_dest_entries ( struct net * net , const struct ip_vs_get_dests * get , <nl> struct ip_vs_dest * dest ; <nl> struct ip_vs_dest_entry entry ; <nl>  <nl> + memset (& entry , 0 , sizeof ( entry )); <nl> list_for_each_entry ( dest , & svc -> destinations , n_list ) { <nl> if ( count >= get -> num_dests ) <nl> break ;
static int decode_attr_fs_locations ( struct xdr_stream * xdr , uint32_t * bitmap , st <nl> status = 0 ; <nl> if ( unlikely (!( bitmap [ 0 ] & FATTR4_WORD0_FS_LOCATIONS ))) <nl> goto out ; <nl> + bitmap [ 0 ] &= ~ FATTR4_WORD0_FS_LOCATIONS ; <nl> status = - EIO ; <nl> /* Ignore borken servers that return unrequested attrs */ <nl> if ( unlikely ( res == NULL ))
static void mmci_post_request ( struct mmc_host * mmc , struct mmc_request * mrq , <nl> chan = host -> dma_tx_channel ; <nl> dmaengine_terminate_all ( chan ); <nl>  <nl> + if ( host -> dma_desc_current == next -> dma_desc ) <nl> + host -> dma_desc_current = NULL ; <nl> + <nl> + if ( host -> dma_current == next -> dma_chan ) <nl> + host -> dma_current = NULL ; <nl> + <nl> next -> dma_desc = NULL ; <nl> next -> dma_chan = NULL ; <nl> + data -> host_cookie = 0 ; <nl> } <nl> } <nl> 
extern void __chk_io_ptr ( void __iomem *); <nl> # define __deprecated /* unimplemented */ <nl> # endif <nl>  <nl> +# ifdef MODULE <nl> +# define __deprecated_for_modules __deprecated <nl> +# else <nl> +# define __deprecated_for_modules <nl> +# endif <nl> + <nl> # ifndef __must_check <nl> # define __must_check <nl> # endif
static ssize_t i40e_dbg_command_write ( struct file * filp , <nl> /* check the range on address */ <nl> if ( address > ( pf -> ioremap_len - sizeof ( u32 ))) { <nl> dev_info (& pf -> pdev -> dev , " read reg address 0x % 08x too large , max = 0x % 08lx \ n ", <nl> - address , ( pf -> ioremap_len - sizeof ( u32 ))); <nl> + address , ( unsigned long int )( pf -> ioremap_len - sizeof ( u32 ))); <nl> goto command_write_done ; <nl> } <nl>  <nl> static ssize_t i40e_dbg_command_write ( struct file * filp , <nl> /* check the range on address */ <nl> if ( address > ( pf -> ioremap_len - sizeof ( u32 ))) { <nl> dev_info (& pf -> pdev -> dev , " write reg address 0x % 08x too large , max = 0x % 08lx \ n ", <nl> - address , ( pf -> ioremap_len - sizeof ( u32 ))); <nl> + address , ( unsigned long int )( pf -> ioremap_len - sizeof ( u32 ))); <nl> goto command_write_done ; <nl> } <nl> wr32 (& pf -> hw , address , value );
x86_emulate_insn ( struct x86_emulate_ctxt * ctxt ) <nl> goto done ; <nl> } <nl>  <nl> + if (( c -> d & SrcMask ) == SrcMemFAddr && c -> src . type != OP_MEM ) { <nl> + emulate_ud ( ctxt ); <nl> + goto done ; <nl> + } <nl> + <nl> /* Privileged instruction can be executed only in CPL = 0 */ <nl> if (( c -> d & Priv ) && ops -> cpl ( ctxt -> vcpu )) { <nl> emulate_gp ( ctxt , 0 );
static int bcma_get_next_core ( struct bcma_bus * bus , u32 __iomem ** eromptr , <nl> switch ( core -> id . id ) { <nl> case BCMA_CORE_4706_MAC_GBIT_COMMON : <nl> case BCMA_CORE_NS_CHIPCOMMON_B : <nl> + case BCMA_CORE_PMU : <nl> + case BCMA_CORE_GCI : <nl> /* Not used yet : case BCMA_CORE_OOB_ROUTER : */ <nl> break ; <nl> default :
static int newseg ( struct ipc_namespace * ns , struct ipc_params * params ) <nl> if ( size < SHMMIN || size > ns -> shm_ctlmax ) <nl> return - EINVAL ; <nl>  <nl> + if ( numpages << PAGE_SHIFT < size ) <nl> + return - ENOSPC ; <nl> + <nl> if ( ns -> shm_tot + numpages < ns -> shm_tot || <nl> ns -> shm_tot + numpages > ns -> shm_ctlall ) <nl> return - ENOSPC ;
static struct omap_board_mux board_mux [] __initdata = { <nl> OMAP4_MUX ( DPM_EMU18 , OMAP_PIN_OUTPUT | OMAP_MUX_MODE5 ), <nl> /* dispc2_data0 */ <nl> OMAP4_MUX ( DPM_EMU19 , OMAP_PIN_OUTPUT | OMAP_MUX_MODE5 ), <nl> + /* NIRQ2 for twl6040 */ <nl> + OMAP4_MUX ( SYS_NIRQ2 , OMAP_MUX_MODE0 | <nl> + OMAP_PIN_INPUT_PULLUP | OMAP_PIN_OFF_WAKEUPENABLE ), <nl> { . reg_offset = OMAP_MUX_TERMINATOR }, <nl> }; <nl> 
nouveau_i2c_identify ( struct drm_device * dev , const char * what , <nl>  <nl> NV_DEBUG ( dev , " Probing % ss on I2C bus : % d \ n ", what , index ); <nl>  <nl> - for ( i = 0 ; info [ i ]. addr ; i ++) { <nl> + for ( i = 0 ; i2c && info [ i ]. addr ; i ++) { <nl> if ( nouveau_probe_i2c_addr ( i2c , info [ i ]. addr ) && <nl> (! match || match ( i2c , & info [ i ]))) { <nl> NV_INFO ( dev , " Detected % s : % s \ n ", what , info [ i ]. type );
static int lov_add_target ( struct obd_device * obd , struct obd_uuid * uuidp , <nl> struct lov_tgt_desc ** newtgts , ** old = NULL ; <nl> __u32 newsize , oldsize = 0 ; <nl>  <nl> - newsize = max ( lov -> lov_tgt_size , ( __u32 ) 2 ); <nl> + newsize = max_t ( __u32 , lov -> lov_tgt_size , 2 ); <nl> while ( newsize < index + 1 ) <nl> newsize = newsize << 1 ; <nl> OBD_ALLOC ( newtgts , sizeof (* newtgts ) * newsize );
int ieee80211_if_add ( struct ieee80211_local * local , const char * name , <nl> + IEEE80211_ENCRYPT_HEADROOM ; <nl> ndev -> needed_tailroom = IEEE80211_ENCRYPT_TAILROOM ; <nl>  <nl> + ret = dev_alloc_name ( ndev , ndev -> name ); <nl> + if ( ret < 0 ) <nl> + goto fail ; <nl> + <nl> ieee80211_assign_perm_addr ( local , ndev , type ); <nl> memcpy ( ndev -> dev_addr , ndev -> perm_addr , ETH_ALEN ); <nl> SET_NETDEV_DEV ( ndev , wiphy_dev ( local -> hw . wiphy ));
static struct ib_pd * nes_alloc_pd ( struct ib_device * ibdev , <nl> NES_MAX_USER_DB_REGIONS , nesucontext -> first_free_db ); <nl> nes_debug ( NES_DBG_PD , " find_first_zero_biton doorbells returned % u , mapping pd_id % u .\ n ", <nl> nespd -> mmap_db_index , nespd -> pd_id ); <nl> - if ( nespd -> mmap_db_index > NES_MAX_USER_DB_REGIONS ) { <nl> + if ( nespd -> mmap_db_index >= NES_MAX_USER_DB_REGIONS ) { <nl> nes_debug ( NES_DBG_PD , " mmap_db_index > MAX \ n "); <nl> nes_free_resource ( nesadapter , nesadapter -> allocated_pds , pd_num ); <nl> kfree ( nespd );
static int dummy_udc_probe ( struct platform_device * pdev ) <nl> int rc ; <nl>  <nl> dum = *(( void **) dev_get_platdata (& pdev -> dev )); <nl> + /* Clear usb_gadget region for new registration to udc - core */ <nl> + memzero_explicit (& dum -> gadget , sizeof ( struct usb_gadget )); <nl> dum -> gadget . name = gadget_name ; <nl> dum -> gadget . ops = & dummy_ops ; <nl> dum -> gadget . max_speed = USB_SPEED_SUPER ;
F01_E */ <nl>  <nl> skb = dev_alloc_skb ( len + 1 - 4 ); <nl> /* <nl> - * if frame size , data ptr , or skb ptr are wrong , the get next <nl> + * if frame size , data ptr , or skb ptr are wrong , then get next <nl> * entry . <nl> */ <nl> if (( skb == NULL ) || ( skb -> data == NULL ) || <nl> ( self -> rx_buff . data == NULL ) || ( len < 6 )) { <nl> self -> netdev -> stats . rx_dropped ++; <nl> + kfree_skb ( skb ); <nl> return TRUE ; <nl> } <nl> skb_reserve ( skb , 1 );
# include < linux / pm_runtime . h > <nl> # include < linux / of . h > <nl> # include < linux / platform_data / sc18is602 . h > <nl> +# include < linux / gpio / consumer . h > <nl>  <nl> enum chips { sc18is602 , sc18is602b , sc18is603 }; <nl>  <nl> struct sc18is602 { <nl> u8 buffer [ SC18IS602_BUFSIZ + 1 ]; <nl> int tlen ; /* Data queued for tx in buffer */ <nl> int rindex ; /* Receive data index in buffer */ <nl> + <nl> + struct gpio_desc * reset ; <nl> }; <nl>  <nl> static int sc18is602_wait_ready ( struct sc18is602 * hw , int len ) <nl> static int sc18is602_probe ( struct i2c_client * client , <nl> hw = spi_master_get_devdata ( master ); <nl> i2c_set_clientdata ( client , hw ); <nl>  <nl> + /* assert reset and then release */ <nl> + hw -> reset = devm_gpiod_get_optional ( dev , " reset ", GPIOD_OUT_HIGH ); <nl> + if ( IS_ERR ( hw -> reset )) <nl> + return PTR_ERR ( hw -> reset ); <nl> + gpiod_set_value ( hw -> reset , 0 ); <nl> + <nl> hw -> master = master ; <nl> hw -> client = client ; <nl> hw -> dev = dev ;
int __dax_zero_page_range ( struct block_device * bdev , <nl> void * kaddr ; <nl> pfn_t pfn ; <nl>  <nl> - rc = bdev_dax_pgoff ( bdev , sector , size , & pgoff ); <nl> + rc = bdev_dax_pgoff ( bdev , sector , PAGE_SIZE , & pgoff ); <nl> if ( rc ) <nl> return rc ; <nl>  <nl> id = dax_read_lock (); <nl> - rc = dax_direct_access ( dax_dev , pgoff , PHYS_PFN ( size ), & kaddr , <nl> + rc = dax_direct_access ( dax_dev , pgoff , 1 , & kaddr , <nl> & pfn ); <nl> if ( rc < 0 ) { <nl> dax_read_unlock ( id );
static int device_notifier ( struct notifier_block * nb , <nl> action != BUS_NOTIFY_DEL_DEVICE ) <nl> return 0 ; <nl>  <nl> + /* <nl> + * If the device is still attached to a device driver we can ' t <nl> + * tear down the domain yet as DMA mappings may still be in use . <nl> + * Wait for the BUS_NOTIFY_UNBOUND_DRIVER event to do that . <nl> + */ <nl> + if ( action == BUS_NOTIFY_DEL_DEVICE && dev -> driver != NULL ) <nl> + return 0 ; <nl> + <nl> domain = find_domain ( dev ); <nl> if (! domain ) <nl> return 0 ;
mxm_sor_map ( struct nvkm_bios * bios , u8 conn ) <nl> u16 map = nvbios_rd16 ( bios , mxm + 4 ); <nl> if ( map ) { <nl> ver = nvbios_rd08 ( bios , map ); <nl> - if ( ver == 0x10 ) { <nl> + if ( ver == 0x10 || ver == 0x11 ) { <nl> if ( conn < nvbios_rd08 ( bios , map + 3 )) { <nl> map += nvbios_rd08 ( bios , map + 1 ); <nl> map += conn ;
static int tcm825x_probe ( struct i2c_client * client , <nl> return rval ; <nl> } <nl>  <nl> - static int __exit tcm825x_remove ( struct i2c_client * client ) <nl> + static int tcm825x_remove ( struct i2c_client * client ) <nl> { <nl> struct tcm825x_sensor * sensor = i2c_get_clientdata ( client ); <nl>  <nl> static struct i2c_driver tcm825x_i2c_driver = { <nl> . name = TCM825X_NAME , <nl> }, <nl> . probe = tcm825x_probe , <nl> - . remove = __exit_p ( tcm825x_remove ), <nl> + . remove = tcm825x_remove , <nl> . id_table = tcm825x_id , <nl> }; <nl> 
static int sbp2scsi_slave_alloc ( struct scsi_device * sdev ) <nl> lu -> sdev = sdev ; <nl> sdev -> allow_restart = 1 ; <nl>  <nl> - /* <nl> - * Update the dma alignment ( minimum alignment requirements for <nl> - * start and end of DMA transfers ) to be a sector <nl> - */ <nl> - blk_queue_update_dma_alignment ( sdev -> request_queue , 511 ); <nl> + /* SBP - 2 requires quadlet alignment of the data buffers . */ <nl> + blk_queue_update_dma_alignment ( sdev -> request_queue , 4 - 1 ); <nl>  <nl> if ( lu -> workarounds & SBP2_WORKAROUND_INQUIRY_36 ) <nl> sdev -> inquiry_len = 36 ;
static int dgrp_net_release ( struct inode * inode , struct file * file ) <nl>  <nl> spin_unlock_irqrestore (& dgrp_poll_data . poll_lock , lock_flags ); <nl>  <nl> - done : <nl> down (& nd -> nd_net_semaphore ); <nl>  <nl> dgrp_monitor_message ( nd , " Net Close "); <nl>  <nl> up (& nd -> nd_net_semaphore ); <nl>  <nl> + done : <nl> module_put ( THIS_MODULE ); <nl> file -> private_data = NULL ; <nl> return 0 ;
static int cpuhp_invoke_ap_callback ( int cpu , enum cpuhp_state state , <nl> if (! cpu_online ( cpu )) <nl> return 0 ; <nl>  <nl> + /* <nl> + * If we are up and running , use the hotplug thread . For early calls <nl> + * we invoke the thread function directly . <nl> + */ <nl> + if (! st -> thread ) <nl> + return cpuhp_invoke_callback ( cpu , state , cb ); <nl> + <nl> st -> cb_state = state ; <nl> st -> cb = cb ; <nl> /*
static int _nfs4_do_set_security_label ( struct inode * inode , <nl> struct iattr sattr = { 0 }; <nl> struct nfs_server * server = NFS_SERVER ( inode ); <nl> const u32 bitmask [ 3 ] = { 0 , 0 , FATTR4_WORD2_SECURITY_LABEL }; <nl> - struct nfs_setattrargs args = { <nl> + struct nfs_setattrargs arg = { <nl> . fh = NFS_FH ( inode ), <nl> . iap = & sattr , <nl> . server = server , <nl> static int _nfs4_do_set_security_label ( struct inode * inode , <nl> }; <nl> struct rpc_message msg = { <nl> . rpc_proc = & nfs4_procedures [ NFSPROC4_CLNT_SETATTR ], <nl> - . rpc_argp = & args , <nl> + . rpc_argp = & arg , <nl> . rpc_resp = & res , <nl> }; <nl> int status ; <nl>  <nl> - nfs4_stateid_copy (& args . stateid , & zero_stateid ); <nl> + nfs4_stateid_copy (& arg . stateid , & zero_stateid ); <nl>  <nl> - status = rpc_call_sync ( server -> client , & msg , 0 ); <nl> + status = nfs4_call_sync ( server -> client , server , & msg , & arg . seq_args , & res . seq_res , 1 ); <nl> if ( status ) <nl> dprintk ("% s failed : % d \ n ", __func__ , status ); <nl> 
int osc_queue_sync_pages ( const struct lu_env * env , struct osc_object * obj , <nl> { <nl> struct client_obd * cli = osc_cli ( obj ); <nl> struct osc_extent * ext ; <nl> - struct osc_async_page * oap ; <nl> + struct osc_async_page * oap , * tmp ; <nl> int page_count = 0 ; <nl> int mppr = cli -> cl_max_pages_per_rpc ; <nl> pgoff_t start = CL_PAGE_EOF ; <nl> int osc_queue_sync_pages ( const struct lu_env * env , struct osc_object * obj , <nl>  <nl> ext = osc_extent_alloc ( obj ); <nl> if ( ext == NULL ) { <nl> - list_for_each_entry ( oap , list , oap_pending_item ) { <nl> + list_for_each_entry_safe ( oap , tmp , list , oap_pending_item ) { <nl> list_del_init (& oap -> oap_pending_item ); <nl> osc_ap_completion ( env , cli , oap , 0 , - ENOMEM ); <nl> }
static void __cpuinit init_amd ( struct cpuinfo_x86 * c ) <nl> level = cpuid_eax ( 1 ); <nl> if ( c -> x86 == 15 && (( level >= 0x0f48 && level < 0x0f50 ) || level >= 0x0f58 )) <nl> set_bit ( X86_FEATURE_REP_GOOD , & c -> x86_capability ); <nl> - if ( c -> x86 == 0x10 ) <nl> + if ( c -> x86 == 0x10 || c -> x86 == 0x11 ) <nl> set_bit ( X86_FEATURE_REP_GOOD , & c -> x86_capability ); <nl>  <nl> /* Enable workaround for FXSAVE leak */
static int clcdfb_of_get_mode ( struct device * dev , struct device_node * endpoint , <nl>  <nl> len = clcdfb_snprintf_mode ( NULL , 0 , mode ); <nl> name = devm_kzalloc ( dev , len + 1 , GFP_KERNEL ); <nl> + if (! name ) <nl> + return - ENOMEM ; <nl> + <nl> clcdfb_snprintf_mode ( name , len + 1 , mode ); <nl> mode -> name = name ; <nl> 
static vfio_platform_reset_fn_t vfio_platform_lookup_reset ( const char * compat , <nl> return reset_fn ; <nl> } <nl>  <nl> + static bool vfio_platform_has_reset ( struct vfio_platform_device * vdev ) <nl> +{ <nl> + return vdev -> of_reset ? true : false ; <nl> +} <nl> + <nl> static void vfio_platform_get_reset ( struct vfio_platform_device * vdev ) <nl> { <nl> vdev -> of_reset = vfio_platform_lookup_reset ( vdev -> compat , <nl> static long vfio_platform_ioctl ( void * device_data , <nl> if ( info . argsz < minsz ) <nl> return - EINVAL ; <nl>  <nl> - if ( vdev -> of_reset ) <nl> + if ( vfio_platform_has_reset ( vdev )) <nl> vdev -> flags |= VFIO_DEVICE_FLAGS_RESET ; <nl> info . flags = vdev -> flags ; <nl> info . num_regions = vdev -> num_regions ;
static struct spi_board_info mc13783_dev __initdata = { <nl> . bus_num = 1 , <nl> . chip_select = 0 , <nl> . platform_data = & mc13783_pdata , <nl> + . irq = IOMUX_TO_IRQ ( MX31_PIN_GPIO1_3 ), <nl> }; <nl>  <nl> static int mx31lilly_baseboard ;
static int __init twl4030_pwrbutton_probe ( struct platform_device * pdev ) <nl> return 0 ; <nl>  <nl> free_irq : <nl> - free_irq ( irq , NULL ); <nl> + free_irq ( irq , pwr ); <nl> free_input_dev : <nl> input_free_device ( pwr ); <nl> return err ;
DECLARE_EVENT_CLASS ( gb_interface , <nl> TP_ARGS ( intf ), <nl>  <nl> TP_STRUCT__entry ( <nl> - __field ( u8 , id ) /* Interface id */ <nl> __field ( u8 , module_id ) <nl> + __field ( u8 , id ) /* Interface id */ <nl> __field ( u8 , device_id ) <nl> __field ( int , disconnected ) /* bool */ <nl> __field ( int , ejected ) /* bool */ <nl> DECLARE_EVENT_CLASS ( gb_interface , <nl> ), <nl>  <nl> TP_fast_assign ( <nl> - __entry -> id = intf -> interface_id ; <nl> __entry -> module_id = intf -> module -> module_id ; <nl> + __entry -> id = intf -> interface_id ; <nl> __entry -> device_id = intf -> device_id ; <nl> __entry -> disconnected = intf -> disconnected ; <nl> __entry -> ejected = intf -> ejected ;
static struct phy * tegra_xusb_padctl_xlate ( struct device * dev , <nl> if ( args -> args_count <= 0 ) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> - if ( index > ARRAY_SIZE ( padctl -> phys )) <nl> + if ( index >= ARRAY_SIZE ( padctl -> phys )) <nl> return ERR_PTR (- EINVAL ); <nl>  <nl> return padctl -> phys [ index ];
static int dmaengine_pcm_request_chan_of ( struct dmaengine_pcm * pcm , <nl> ! dev -> of_node ) <nl> return 0 ; <nl>  <nl> - if ( config -> dma_dev ) { <nl> + if ( config && config -> dma_dev ) { <nl> /* <nl> * If this warning is seen , it probably means that your Linux <nl> * device structure does not match your HW device structure . <nl> static int dmaengine_pcm_request_chan_of ( struct dmaengine_pcm * pcm , <nl> name = " rx - tx "; <nl> else <nl> name = dmaengine_pcm_dma_channel_names [ i ]; <nl> - if ( config -> chan_names [ i ]) <nl> + if ( config && config -> chan_names [ i ]) <nl> name = config -> chan_names [ i ]; <nl> chan = dma_request_slave_channel_reason ( dev , name ); <nl> if ( IS_ERR ( chan )) {
struct radeon_i2c_chan * radeon_i2c_create ( struct drm_device * dev , <nl> (( rdev -> family <= CHIP_RS480 ) || <nl> (( rdev -> family >= CHIP_RV515 ) && ( rdev -> family <= CHIP_R580 ))))) { <nl> /* set the radeon hw i2c adapter */ <nl> - sprintf ( i2c -> adapter . name , " Radeon i2c hw bus % s ", name ); <nl> + snprintf ( i2c -> adapter . name , sizeof ( i2c -> adapter . name ), <nl> + " Radeon i2c hw bus % s ", name ); <nl> i2c -> adapter . algo = & radeon_i2c_algo ; <nl> ret = i2c_add_adapter (& i2c -> adapter ); <nl> if ( ret ) { <nl> struct radeon_i2c_chan * radeon_i2c_create ( struct drm_device * dev , <nl> } <nl> } else { <nl> /* set the radeon bit adapter */ <nl> - sprintf ( i2c -> adapter . name , " Radeon i2c bit bus % s ", name ); <nl> + snprintf ( i2c -> adapter . name , sizeof ( i2c -> adapter . name ), <nl> + " Radeon i2c bit bus % s ", name ); <nl> i2c -> adapter . algo_data = & i2c -> algo . bit ; <nl> i2c -> algo . bit . pre_xfer = pre_xfer ; <nl> i2c -> algo . bit . post_xfer = post_xfer ; <nl> struct radeon_i2c_chan * radeon_i2c_create_dp ( struct drm_device * dev , <nl> i2c -> rec = * rec ; <nl> i2c -> adapter . owner = THIS_MODULE ; <nl> i2c -> dev = dev ; <nl> - sprintf ( i2c -> adapter . name , " Radeon aux bus % s ", name ); <nl> + snprintf ( i2c -> adapter . name , sizeof ( i2c -> adapter . name ), <nl> + " Radeon aux bus % s ", name ); <nl> i2c_set_adapdata (& i2c -> adapter , i2c ); <nl> i2c -> adapter . algo_data = & i2c -> algo . dp ; <nl> i2c -> algo . dp . aux_ch = radeon_dp_i2c_aux_ch ;
static void ironlake_irq_uninstall ( struct drm_device * dev ) <nl> I915_WRITE ( GTIMR , 0xffffffff ); <nl> I915_WRITE ( GTIER , 0x0 ); <nl> I915_WRITE ( GTIIR , I915_READ ( GTIIR )); <nl> + <nl> + I915_WRITE ( SDEIMR , 0xffffffff ); <nl> + I915_WRITE ( SDEIER , 0x0 ); <nl> + I915_WRITE ( SDEIIR , I915_READ ( SDEIIR )); <nl> } <nl>  <nl> static void i915_driver_irq_uninstall ( struct drm_device * dev )
int usb_hcd_alloc_bandwidth ( struct usb_device * udev , <nl> } <nl> } <nl> for ( i = 0 ; i < num_intfs ; ++ i ) { <nl> + struct usb_host_interface * first_alt ; <nl> + int iface_num ; <nl> + <nl> + first_alt = & new_config -> intf_cache [ i ]-> altsetting [ 0 ]; <nl> + iface_num = first_alt -> desc . bInterfaceNumber ; <nl> /* Set up endpoints for alternate interface setting 0 */ <nl> - alt = usb_find_alt_setting ( new_config , i , 0 ); <nl> + alt = usb_find_alt_setting ( new_config , iface_num , 0 ); <nl> if (! alt ) <nl> /* No alt setting 0 ? Pick the first setting . */ <nl> - alt = & new_config -> intf_cache [ i ]-> altsetting [ 0 ]; <nl> + alt = first_alt ; <nl>  <nl> for ( j = 0 ; j < alt -> desc . bNumEndpoints ; j ++) { <nl> ret = hcd -> driver -> add_endpoint ( hcd , udev , & alt -> endpoint [ j ]);
i915_gem_execbuffer ( struct drm_device * dev , void * data , <nl> ( int ) args -> buffers_ptr , args -> buffer_count , args -> batch_len ); <nl> # endif <nl>  <nl> + if ( args -> buffer_count < 1 ) { <nl> + DRM_ERROR (" execbuf with % d buffers \ n ", args -> buffer_count ); <nl> + return - EINVAL ; <nl> + } <nl> /* Copy in the exec list from userland */ <nl> exec_list = drm_calloc ( sizeof (* exec_list ), args -> buffer_count , <nl> DRM_MEM_DRIVER );
EXPORT_SYMBOL ( genphy_read_status ); <nl>  <nl> static int genphy_config_init ( struct phy_device * phydev ) <nl> { <nl> - u32 val ; <nl> + int val ; <nl> u32 features ; <nl>  <nl> /* For now , I ' ll claim that the generic driver supports
static int __init init_balloon_drv ( void ) <nl> return vmbus_driver_register (& balloon_drv ); <nl> } <nl>  <nl> - static void exit_balloon_drv ( void ) <nl> -{ <nl> - <nl> - vmbus_driver_unregister (& balloon_drv ); <nl> -} <nl> - <nl> module_init ( init_balloon_drv ); <nl> - module_exit ( exit_balloon_drv ); <nl>  <nl> MODULE_DESCRIPTION (" Hyper - V Balloon "); <nl> MODULE_VERSION ( HV_DRV_VERSION );
static int nfqnl_recv_config ( struct net * net , struct sock * ctnl , <nl> break ; <nl> default : <nl> ret = - ENOTSUPP ; <nl> - break ; <nl> + goto err_out_unlock ; <nl> } <nl> } <nl> 
cfg80211_bss_update ( struct cfg80211_registered_device * dev , <nl> memcpy ( ies , res -> pub . information_elements , ielen ); <nl> found -> ies_allocated = true ; <nl> found -> pub . information_elements = ies ; <nl> + found -> pub . len_information_elements = ielen ; <nl> } <nl> } <nl> }
static int <nl> lpfc_parse_vpd ( struct lpfc_hba * phba , uint8_t * vpd , int len ) <nl> { <nl> uint8_t lenlo , lenhi ; <nl> - uint32_t Length ; <nl> + int Length ; <nl> int i , j ; <nl> int finished = 0 ; <nl> int index = 0 ;
static void copy_from_user_policy ( struct xfrm_policy * xp , struct xfrm_userpolicy <nl>  <nl> static void copy_to_user_policy ( struct xfrm_policy * xp , struct xfrm_userpolicy_info * p , int dir ) <nl> { <nl> + memset ( p , 0 , sizeof (* p )); <nl> memcpy (& p -> sel , & xp -> selector , sizeof ( p -> sel )); <nl> memcpy (& p -> lft , & xp -> lft , sizeof ( p -> lft )); <nl> memcpy (& p -> curlft , & xp -> curlft , sizeof ( p -> curlft ));
befs_find_brun_dblindirect ( struct super_block * sb , <nl> struct buffer_head * indir_block ; <nl> befs_block_run indir_run ; <nl> befs_disk_inode_addr * iaddr_array ; <nl> - struct befs_sb_info * befs_sb = BEFS_SB ( sb ); <nl>  <nl> befs_blocknr_t indir_start_blk = <nl> - data -> max_indirect_range >> befs_sb -> block_shift ; <nl> + data -> max_indirect_range >> BEFS_SB ( sb )-> block_shift ; <nl>  <nl> off_t dbl_indir_off = blockno - indir_start_blk ; <nl> 
int ieee80211_radiotap_iterator_init ( <nl> /* find payload start allowing for extended bitmap ( s ) */ <nl>  <nl> if ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> + if (( unsigned long ) iterator -> _arg - <nl> + ( unsigned long ) iterator -> _rtheader + sizeof ( uint32_t ) > <nl> + ( unsigned long ) iterator -> _max_length ) <nl> + return - EINVAL ; <nl> while ( get_unaligned_le32 ( iterator -> _arg ) & <nl> ( 1 << IEEE80211_RADIOTAP_EXT )) { <nl> iterator -> _arg += sizeof ( uint32_t );
 <nl> static int l2_line_sz ; <nl> int ioc_exists ; <nl> - volatile int slc_enable = 1 ; <nl> + volatile int slc_enable = 1 , ioc_enable = 1 ; <nl>  <nl> void (* _cache_line_loop_ic_fn )( unsigned long paddr , unsigned long vaddr , <nl> unsigned long sz , const int cacheop ); <nl> char * arc_cache_mumbojumbo ( int c , char * buf , int len ) <nl> p -> sz_k , p -> line_len , IS_USED_RUN ( slc_enable )); <nl>  <nl> if ( ioc_exists ) <nl> - n += scnprintf ( buf + n , len - n , " IOC \ t \ t : exists \ n "); <nl> + n += scnprintf ( buf + n , len - n , " IOC \ t \ t :% s \ n ", <nl> + IS_USED_RUN ( ioc_enable )); <nl>  <nl> return buf ; <nl> } <nl> slc_chk : <nl> } <nl>  <nl> READ_BCR ( ARC_REG_CLUSTER_BCR , cbcr ); <nl> - if ( cbcr . c ) <nl> + if ( cbcr . c && ioc_enable ) <nl> ioc_exists = 1 ; <nl> } <nl> 
unsigned int oz_dbg_mask = OZ_DEFAULT_DBG_MASK ; <nl> * netcards . Bindings can be added later using an IOCTL . <nl> */ <nl> static char * g_net_dev = ""; <nl> + module_param ( g_net_dev , charp , S_IRUGO ); <nl> + MODULE_PARM_DESC ( g_net_dev , " The device ( s ) to bind to ; " <nl> + "'*' means all , '' ( empty string ; default ) means none ."); <nl>  <nl> /* <nl> * Context : process <nl> static void __exit ozwpan_exit ( void ) <nl> oz_cdev_deregister (); <nl> } <nl>  <nl> - module_param ( g_net_dev , charp , S_IRUGO ); <nl> module_init ( ozwpan_init ); <nl> module_exit ( ozwpan_exit ); <nl> 
int udf_ioctl ( struct inode * inode , struct file * filp , unsigned int cmd , <nl> static int udf_release_file ( struct inode * inode , struct file * filp ) <nl> { <nl> if ( filp -> f_mode & FMODE_WRITE ) { <nl> + mutex_lock (& inode -> i_mutex ); <nl> lock_kernel (); <nl> udf_discard_prealloc ( inode ); <nl> unlock_kernel (); <nl> + mutex_unlock (& inode -> i_mutex ); <nl> } <nl> return 0 ; <nl> }
static int __init r8a66597_probe ( struct platform_device * pdev ) <nl>  <nl> r8a66597 -> ep0_req = r8a66597_alloc_request (& r8a66597 -> ep [ 0 ]. ep , <nl> GFP_KERNEL ); <nl> - if ( r8a66597 -> ep0_req == NULL ) <nl> + if ( r8a66597 -> ep0_req == NULL ) { <nl> + ret = - ENOMEM ; <nl> goto clean_up3 ; <nl> + } <nl> r8a66597 -> ep0_req -> complete = nop_completion ; <nl>  <nl> ret = usb_add_gadget_udc (& pdev -> dev , & r8a66597 -> gadget );
static struct pci_device_id azx_ids [] = { <nl> { PCI_DEVICE ( 0x10de , 0x044b ), . driver_data = AZX_DRIVER_NVIDIA }, <nl> { PCI_DEVICE ( 0x10de , 0x055c ), . driver_data = AZX_DRIVER_NVIDIA }, <nl> { PCI_DEVICE ( 0x10de , 0x055d ), . driver_data = AZX_DRIVER_NVIDIA }, <nl> + { PCI_DEVICE ( 0x10de , 0x0590 ), . driver_data = AZX_DRIVER_NVIDIA }, <nl> { PCI_DEVICE ( 0x10de , 0x0774 ), . driver_data = AZX_DRIVER_NVIDIA }, <nl> { PCI_DEVICE ( 0x10de , 0x0775 ), . driver_data = AZX_DRIVER_NVIDIA }, <nl> { PCI_DEVICE ( 0x10de , 0x0776 ), . driver_data = AZX_DRIVER_NVIDIA },
unsigned fuse_file_poll ( struct file * file , poll_table * wait ) <nl>  <nl> req = fuse_get_req ( fc ); <nl> if ( IS_ERR ( req )) <nl> - return PTR_ERR ( req ); <nl> + return POLLERR ; <nl>  <nl> req -> in . h . opcode = FUSE_POLL ; <nl> req -> in . h . nodeid = ff -> nodeid ;
static struct request * get_request ( request_queue_t * q , int rw , struct bio * bio , <nl> } <nl>  <nl> get_rq : <nl> + /* <nl> + * Only allow batching queuers to allocate up to 50 % over the defined <nl> + * limit of requests , otherwise we could have thousands of requests <nl> + * allocated with any setting of -> nr_requests <nl> + */ <nl> + if ( rl -> count [ rw ] >= ( 3 * q -> nr_requests / 2 )) { <nl> + spin_unlock_irq ( q -> queue_lock ); <nl> + goto out ; <nl> + } <nl> rl -> count [ rw ]++; <nl> rl -> starved [ rw ] = 0 ; <nl> if ( rl -> count [ rw ] >= queue_congestion_on_threshold ( q ))
static int vpfe_enum_input ( struct file * file , void * priv , <nl> return - EINVAL ; <nl> } <nl> sdinfo = & vpfe_dev -> cfg -> sub_devs [ subdev ]; <nl> - memcpy ( inp , & sdinfo -> inputs [ index ], sizeof ( struct v4l2_input )); <nl> + * inp = sdinfo -> inputs [ index ]; <nl> return 0 ; <nl> } <nl> 
void __kprobes recycle_rp_inst ( struct kretprobe_instance * ri , <nl>  <nl> void __kprobes kretprobe_hash_lock ( struct task_struct * tsk , <nl> struct hlist_head ** head , unsigned long * flags ) <nl> + __acquires ( hlist_lock ) <nl> { <nl> unsigned long hash = hash_ptr ( tsk , KPROBE_HASH_BITS ); <nl> spinlock_t * hlist_lock ; <nl> void __kprobes kretprobe_hash_lock ( struct task_struct * tsk , <nl>  <nl> static void __kprobes kretprobe_table_lock ( unsigned long hash , <nl> unsigned long * flags ) <nl> + __acquires ( hlist_lock ) <nl> { <nl> spinlock_t * hlist_lock = kretprobe_table_lock_ptr ( hash ); <nl> spin_lock_irqsave ( hlist_lock , * flags ); <nl> static void __kprobes kretprobe_table_lock ( unsigned long hash , <nl>  <nl> void __kprobes kretprobe_hash_unlock ( struct task_struct * tsk , <nl> unsigned long * flags ) <nl> + __releases ( hlist_lock ) <nl> { <nl> unsigned long hash = hash_ptr ( tsk , KPROBE_HASH_BITS ); <nl> spinlock_t * hlist_lock ; <nl> void __kprobes kretprobe_hash_unlock ( struct task_struct * tsk , <nl>  <nl> static void __kprobes kretprobe_table_unlock ( unsigned long hash , <nl> unsigned long * flags ) <nl> + __releases ( hlist_lock ) <nl> { <nl> spinlock_t * hlist_lock = kretprobe_table_lock_ptr ( hash ); <nl> spin_unlock_irqrestore ( hlist_lock , * flags );
nfulnl_recv_config ( struct sock * ctnl , struct sk_buff * skb , <nl> ret = - EINVAL ; <nl> break ; <nl> } <nl> + <nl> + if (! inst ) <nl> + goto out ; <nl> } else { <nl> if (! inst ) { <nl> UDEBUG (" no config command , and no instance for " <nl> nfulnl_recv_config ( struct sock * ctnl , struct sk_buff * skb , <nl>  <nl> out_put : <nl> instance_put ( inst ); <nl> + out : <nl> return ret ; <nl> } <nl> 
struct gen_pool * devm_gen_pool_create ( struct device * dev , int min_alloc_order , <nl> struct gen_pool ** ptr , * pool ; <nl>  <nl> ptr = devres_alloc ( devm_gen_pool_release , sizeof (* ptr ), GFP_KERNEL ); <nl> + if (! ptr ) <nl> + return NULL ; <nl>  <nl> pool = gen_pool_create ( min_alloc_order , nid ); <nl> if ( pool ) {
static void _rtl88e_fw_block_write ( struct adapter * adapt , <nl>  <nl> offset = FW_8192C_START_ADDRESS ; <nl>  <nl> - for ( i = 0 ; i < blk_cnt ; i ++, offset += blk_sz ) { <nl> + for ( i = 0 ; i < blk_cnt ; i ++, offset += blk_sz ) <nl> usb_write32 ( adapt , offset , pu4BytePtr [ i ]); <nl> - } <nl>  <nl> buf_ptr = buffer + blk_cnt * blk_sz ; <nl> - for ( i = 0 ; i < remain ; i ++, offset ++) { <nl> + for ( i = 0 ; i < remain ; i ++, offset ++) <nl> usb_write8 ( adapt , offset , buf_ptr [ i ]); <nl> - } <nl> } <nl>  <nl> static void _rtl88e_fill_dummy ( u8 * pfwbuf , u32 * pfwlen )
static int btmtk_usb_io_read32 ( struct btmtk_usb_data * data , u32 reg , u32 * val ) <nl> u8 request = data -> r_request ; <nl> struct usb_device * udev = data -> udev ; <nl> int ret ; <nl> + __le32 val_le ; <nl>  <nl> ret = usb_control_msg ( udev , usb_rcvctrlpipe ( udev , 0 ), request , <nl> DEVICE_VENDOR_REQUEST_IN , 0x0 , reg , data -> io_buf , <nl> static int btmtk_usb_io_read32 ( struct btmtk_usb_data * data , u32 reg , u32 * val ) <nl> return ret ; <nl> } <nl>  <nl> - memmove ( val , data -> io_buf , 4 ); <nl> + memmove (& val_le , data -> io_buf , 4 ); <nl>  <nl> - * val = le32_to_cpu (* val ); <nl> + * val = le32_to_cpu ( val_le ); <nl>  <nl> if ( ret > 0 ) <nl> ret = 0 ; <nl> static u16 btmtk_usb_get_crc ( struct btmtk_usb_data * data ) <nl> int ret = 0 ; <nl> struct usb_device * udev = data -> udev ; <nl> u16 crc , count = 0 ; <nl> + __le16 crc_le ; <nl>  <nl> BT_DBG ("% s \ n ", __func__ ); <nl>  <nl> static u16 btmtk_usb_get_crc ( struct btmtk_usb_data * data ) <nl> BT_ERR ("% s error (% d )\ n ", __func__ , ret ); <nl> } <nl>  <nl> - memmove (& crc , data -> io_buf , 2 ); <nl> + memmove (& crc_le , data -> io_buf , 2 ); <nl>  <nl> - crc = le16_to_cpu ( crc ); <nl> + crc = le16_to_cpu ( crc_le ); <nl>  <nl> if ( crc != 0xFFFF ) <nl> break ;
static void amdgpu_gem_va_update_vm ( struct amdgpu_device * adev , <nl> if ( domain == AMDGPU_GEM_DOMAIN_CPU ) <nl> goto error_unreserve ; <nl> } <nl> + r = amdgpu_vm_update_page_directory ( adev , bo_va -> vm ); <nl> + if ( r ) <nl> + goto error_unreserve ; <nl>  <nl> r = amdgpu_vm_clear_freed ( adev , bo_va -> vm ); <nl> if ( r )
static int may_create ( struct inode * dir , <nl> return rc ; <nl>  <nl> if (! newsid || !( sbsec -> flags & SE_SBLABELSUPP )) { <nl> - rc = security_transition_sid ( sid , dsec -> sid , tclass , NULL , & newsid ); <nl> + rc = security_transition_sid ( sid , dsec -> sid , tclass , <nl> + & dentry -> d_name , & newsid ); <nl> if ( rc ) <nl> return rc ; <nl> }
static void ixgbe_free_irq ( struct ixgbe_adapter * adapter ) <nl>  <nl> i --; <nl> for (; i >= 0 ; i --) { <nl> + /* free only the irqs that were actually requested */ <nl> + if (! adapter -> q_vector [ i ]-> rxr_count && <nl> + ! adapter -> q_vector [ i ]-> txr_count ) <nl> + continue ; <nl> + <nl> free_irq ( adapter -> msix_entries [ i ]. vector , <nl> adapter -> q_vector [ i ]); <nl> }
int i40e_ndo_get_vf_config ( struct net_device * netdev , <nl> else <nl> ivi -> linkstate = IFLA_VF_LINK_STATE_DISABLE ; <nl> ivi -> spoofchk = vf -> spoofchk ; <nl> + ivi -> trusted = vf -> trusted ; <nl> ret = 0 ; <nl>  <nl> error_param :
static ssize_t port_fops_read ( struct file * filp , char __user * ubuf , <nl> if ( ret < 0 ) <nl> return ret ; <nl> } <nl> + /* Port got hot - unplugged . */ <nl> + if (! port -> guest_connected ) <nl> + return - ENODEV ; <nl> /* <nl> * We could ' ve received a disconnection message while we were <nl> * waiting for more data .
static int led_classdev_next_name ( const char * init_name , char * name , <nl> { <nl> unsigned int i = 0 ; <nl> int ret = 0 ; <nl> + struct device * dev ; <nl>  <nl> strlcpy ( name , init_name , len ); <nl>  <nl> - while ( class_find_device ( leds_class , NULL , name , match_name ) && <nl> - ( ret < len )) <nl> + while (( ret < len ) && <nl> + ( dev = class_find_device ( leds_class , NULL , name , match_name ))) { <nl> + put_device ( dev ); <nl> ret = snprintf ( name , len , "% s_ % u ", init_name , ++ i ); <nl> + } <nl>  <nl> if ( ret >= len ) <nl> return - ENOMEM ;
static void sil_host_intr ( struct ata_port * ap , u32 bmdma2 ) <nl> u8 status ; <nl>  <nl> if ( unlikely ( bmdma2 & SIL_DMA_SATA_IRQ )) { <nl> - u32 serror ; <nl> + u32 serror = 0xffffffff ; <nl>  <nl> /* SIEN doesn ' t mask SATA IRQs on some 3112s . Those <nl> * controllers continue to assert IRQ as long as
static int open ( struct tty_struct * tty , struct file * filp ) <nl> if ( info -> port . count == 1 ) { <nl> /* 1st open on this device , init hardware */ <nl> retval = startup ( info ); <nl> - if ( retval < 0 ) <nl> + if ( retval < 0 ) { <nl> + mutex_unlock (& info -> port . mutex ); <nl> goto cleanup ; <nl> + } <nl> } <nl> mutex_unlock (& info -> port . mutex ); <nl> retval = block_til_ready ( tty , filp , info );
static int ioc4_serial_remove_one ( struct ioc4_driver_data * idd ) <nl> if ( soft ) { <nl> free_irq ( control -> ic_irq , soft ); <nl> if ( soft -> is_ioc4_serial_addr ) { <nl> + iounmap ( soft -> is_ioc4_serial_addr ); <nl> release_region (( unsigned long ) <nl> soft -> is_ioc4_serial_addr , <nl> sizeof ( struct ioc4_serial )); <nl> out4 : <nl> out3 : <nl> kfree ( control ); <nl> out2 : <nl> + if ( serial ) <nl> + iounmap ( serial ); <nl> release_region ( tmp_addr1 , sizeof ( struct ioc4_serial )); <nl> out1 : <nl> 
* Copyright ( C ) 2005 - 2006 Andrey Volkov < avolkov @ varma - el . com >, <nl> * Varma Electronics Oy <nl> * Copyright ( C ) 2008 - 2009 Wolfgang Grandegger < wg @ grandegger . com > <nl> - * Copytight ( C ) 2008 - 2009 Pengutronix < kernel @ pengutronix . de > <nl> + * Copyright ( C ) 2008 - 2009 Pengutronix < kernel @ pengutronix . de > <nl> * <nl> * This program is free software ; you can redistribute it and / or modify <nl> * it under the terms of the version 2 of the GNU General Public License <nl> static netdev_tx_t mscan_start_xmit ( struct sk_buff * skb , struct net_device * dev ) <nl> int i , rtr , buf_id ; <nl> u32 can_id ; <nl>  <nl> - if ( frame -> can_dlc > 8 ) <nl> - return - EINVAL ; <nl> + if ( skb -> len != sizeof (* frame ) || frame -> can_dlc > 8 ) { <nl> + kfree_skb ( skb ); <nl> + dev -> stats . tx_dropped ++; <nl> + return NETDEV_TX_OK ; <nl> + } <nl>  <nl> out_8 (& regs -> cantier , 0 ); <nl> 
static int musb_probe ( struct platform_device * pdev ) <nl> struct resource * iomem ; <nl> void __iomem * base ; <nl>  <nl> - iomem = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> - if (! iomem || irq <= 0 ) <nl> + if ( irq <= 0 ) <nl> return - ENODEV ; <nl>  <nl> + iomem = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> base = devm_ioremap_resource ( dev , iomem ); <nl> if ( IS_ERR ( base )) <nl> return PTR_ERR ( base );
static void bus_reset_work ( struct work_struct * work ) <nl> { <nl> struct fw_ohci * ohci = <nl> container_of ( work , struct fw_ohci , bus_reset_work ); <nl> - int self_id_count , i , j , reg ; <nl> - int generation , new_generation ; <nl> + int self_id_count , generation , new_generation , i , j ; <nl> + u32 reg ; <nl> unsigned long flags ; <nl> void * free_rom = NULL ; <nl> dma_addr_t free_rom_bus = 0 ;
+# ifndef _ASM_SECCOMP_H <nl> + <nl> +# include < linux / unistd . h > <nl> + <nl> +# define __NR_seccomp_read __NR_read <nl> +# define __NR_seccomp_write __NR_write <nl> +# define __NR_seccomp_exit __NR_exit <nl> +# define __NR_seccomp_sigreturn __NR_rt_sigreturn <nl> + <nl> +# endif /* _ASM_SECCOMP_H */
find_prev_fhdr ( struct sk_buff * skb , u8 * prevhdrp , int * prevhoff , int * fhoff ) <nl> if (! ipv6_ext_hdr ( nexthdr )) { <nl> return - 1 ; <nl> } <nl> - if ( len < ( int ) sizeof ( struct ipv6_opt_hdr )) { <nl> - pr_debug (" too short \ n "); <nl> - return - 1 ; <nl> - } <nl> if ( nexthdr == NEXTHDR_NONE ) { <nl> pr_debug (" next header is none \ n "); <nl> return - 1 ; <nl> } <nl> + if ( len < ( int ) sizeof ( struct ipv6_opt_hdr )) { <nl> + pr_debug (" too short \ n "); <nl> + return - 1 ; <nl> + } <nl> if ( skb_copy_bits ( skb , start , & hdr , sizeof ( hdr ))) <nl> BUG (); <nl> if ( nexthdr == NEXTHDR_AUTH )
int metag_rp_state_copyin ( struct pt_regs * regs , <nl> unsigned long long * ptr ; <nl> int ret , i ; <nl>  <nl> + if ( count < 4 * 13 ) <nl> + return - EINVAL ; <nl> /* Read the entire pipeline before making any changes */ <nl> ret = user_regset_copyin (& pos , & count , & kbuf , & ubuf , <nl> & rp , 0 , 4 * 13 );
int wil_vring_init_tx ( struct wil6210_priv * wil , int id , int size , <nl> if ( rc ) <nl> goto out ; <nl>  <nl> + wil -> vring2cid_tid [ id ][ 0 ] = cid ; <nl> + wil -> vring2cid_tid [ id ][ 1 ] = tid ; <nl> + <nl> cmd . vring_cfg . tx_sw_ring . ring_mem_base = cpu_to_le64 ( vring -> pa ); <nl>  <nl> rc = wmi_call ( wil , WMI_VRING_CFG_CMDID , & cmd , sizeof ( cmd ), <nl> int wil_vring_init_tx ( struct wil6210_priv * wil , int id , int size , <nl> } <nl> vring -> hwtail = le32_to_cpu ( reply . cmd . tx_vring_tail_ptr ); <nl>  <nl> - wil -> vring2cid_tid [ id ][ 0 ] = cid ; <nl> - wil -> vring2cid_tid [ id ][ 1 ] = tid ; <nl> - <nl> return 0 ; <nl> out_free : <nl> wil_vring_free ( wil , vring , 1 );
static int InterpretBSSDescriptionWithIE ( struct bss_descriptor * pBSSEntry , <nl> pBSSEntry -> ssid . ssidlength = elemlen ; <nl> memcpy ( pBSSEntry -> ssid . ssid , ( pcurrentptr + 2 ), <nl> elemlen ); <nl> - lbs_deb_scan (" ssid : % 32s ", pBSSEntry -> ssid . ssid ); <nl> + lbs_deb_scan (" ssid '% s '\ n ", pBSSEntry -> ssid . ssid ); <nl> break ; <nl>  <nl> case SUPPORTED_RATES : <nl> int libertas_get_scan ( struct net_device * dev , struct iw_request_info * info , <nl> } <nl>  <nl> if ( adapter -> connect_status == libertas_connected ) <nl> - lbs_deb_scan (" Current ssid : % 32s \ n ", <nl> + lbs_deb_scan (" current ssid '% s '\ n ", <nl> adapter -> curbssparams . ssid . ssid ); <nl>  <nl> lbs_deb_scan (" Scan : Get : numinscantable = % d \ n ", <nl> int libertas_get_scan ( struct net_device * dev , struct iw_request_info * info , <nl>  <nl> pscantable = & adapter -> scantable [ i ]; <nl>  <nl> - lbs_deb_scan (" i =% d ssid : % 32s \ n ", i , pscantable -> ssid . ssid ); <nl> + lbs_deb_scan (" i % d , ssid '% s '\ n ", i , pscantable -> ssid . ssid ); <nl>  <nl> cfp = <nl> libertas_find_cfp_by_band_and_channel ( adapter , 0 ,
static ssize_t mdc_kuc_write ( struct file * file , <nl> /* for mockup below */ 2 * cfs_size_round ( sizeof (* hai )); <nl>  <nl> OBD_ALLOC ( lh , len ); <nl> + if (! lh ) <nl> + return - ENOMEM ; <nl>  <nl> lh -> kuc_magic = KUC_MAGIC ; <nl> lh -> kuc_transport = KUC_TRANSPORT_HSM ;
static int hidp_setup_hid ( struct hidp_session * session , <nl> hid -> version = req -> version ; <nl> hid -> country = req -> country ; <nl>  <nl> - strncpy ( hid -> name , req -> name , 128 ); <nl> + strncpy ( hid -> name , req -> name , sizeof ( req -> name ) - 1 ); <nl>  <nl> snprintf ( hid -> phys , sizeof ( hid -> phys ), "% pMR ", <nl> & bt_sk ( session -> ctrl_sock -> sk )-> src );
# include < linux / init . h > <nl> # include < linux / delay . h > <nl> # include < linux / slab . h > <nl> +# include < linux / moduleparam . h > <nl> # include < sound / core . h > <nl> # include " hda_codec . h " <nl> # include " hda_local . h " <nl>  <nl> + static bool static_hdmi_pcm ; <nl> + module_param ( static_hdmi_pcm , bool , 0644 ); <nl> + MODULE_PARM_DESC ( static_hdmi_pcm , " Don ' t restrict PCM parameters per ELD info "); <nl> + <nl> /* <nl> * The HDMI / DisplayPort configuration can be highly dynamic . A graphics device <nl> * could support two independent pipes , each of them can be connected to one or <nl> static int hdmi_pcm_open ( struct hda_pcm_stream * hinfo , <nl> * codec_pars = * hinfo ; <nl>  <nl> eld = & spec -> sink_eld [ idx ]; <nl> - if ( eld -> eld_valid && eld -> sad_count > 0 ) { <nl> + if (! static_hdmi_pcm && eld -> eld_valid && eld -> sad_count > 0 ) { <nl> hdmi_eld_update_pcm_info ( eld , hinfo , codec_pars ); <nl> if ( hinfo -> channels_min > hinfo -> channels_max || <nl> ! hinfo -> rates || ! hinfo -> formats )
sleeping_thread_to_gdb_regs ( unsigned long * gdb_regs , struct task_struct * task ) <nl> return ; <nl>  <nl> /* Initialize to zero */ <nl> - for ( regno = 0 ; regno < GDB_MAX_REGS ; regno ++) <nl> + for ( regno = 0 ; regno < DBG_MAX_REG_NUM ; regno ++) <nl> gdb_regs [ regno ] = 0 ; <nl>  <nl> /* Otherwise , we have only some registers from switch_to () */
static void r8a66597_check_detect_child ( struct r8a66597 * r8a66597 , <nl>  <nl> memset ( now_map , 0 , sizeof ( now_map )); <nl>  <nl> + mutex_lock (& usb_bus_idr_lock ); <nl> bus = idr_find (& usb_bus_idr , hcd -> self . busnum ); <nl> if ( bus && bus -> root_hub ) { <nl> collect_usb_address_map ( bus -> root_hub , now_map ); <nl> update_usb_address_map ( r8a66597 , bus -> root_hub , now_map ); <nl> } <nl> + mutex_unlock (& usb_bus_idr_lock ); <nl> } <nl>  <nl> static int r8a66597_hub_status_data ( struct usb_hcd * hcd , char * buf )
unhash_session ( struct nfsd4_session * ses ) <nl> static int <nl> STALE_CLIENTID ( clientid_t * clid , struct nfsd_net * nn ) <nl> { <nl> - if ( clid -> cl_boot == nn -> boot_time ) <nl> + /* <nl> + * We ' re assuming the clid was not given out from a boot <nl> + * precisely 2 ^ 32 ( about 136 years ) before this one . That seems <nl> + * a safe assumption : <nl> + */ <nl> + if ( clid -> cl_boot == ( u32 ) nn -> boot_time ) <nl> return 0 ; <nl> dprintk (" NFSD stale clientid (% 08x /% 08x ) boot_time % 08lx \ n ", <nl> clid -> cl_boot , clid -> cl_id , nn -> boot_time );
static enum power_supply_property max17042_battery_props [] = { <nl> POWER_SUPPLY_PROP_VOLTAGE_OCV , <nl> POWER_SUPPLY_PROP_CAPACITY , <nl> POWER_SUPPLY_PROP_CHARGE_FULL , <nl> + POWER_SUPPLY_PROP_CHARGE_COUNTER , <nl> POWER_SUPPLY_PROP_TEMP , <nl> POWER_SUPPLY_PROP_CURRENT_NOW , <nl> POWER_SUPPLY_PROP_CURRENT_AVG , <nl> static int max17042_get_property ( struct power_supply * psy , <nl> if ( ret < 0 ) <nl> return ret ; <nl>  <nl> + val -> intval = ret * 1000 / 2 ; <nl> + break ; <nl> + case POWER_SUPPLY_PROP_CHARGE_COUNTER : <nl> + ret = max17042_read_reg ( chip -> client , MAX17042_QH ); <nl> + if ( ret < 0 ) <nl> + return ret ; <nl> + <nl> val -> intval = ret * 1000 / 2 ; <nl> break ; <nl> case POWER_SUPPLY_PROP_TEMP :
static int at76_iw_handler_get_scan ( struct net_device * netdev , <nl> if (! iwe ) <nl> return - ENOMEM ; <nl>  <nl> - if ( priv -> scan_state != SCAN_COMPLETED ) <nl> + if ( priv -> scan_state != SCAN_COMPLETED ) { <nl> /* scan not yet finished */ <nl> + kfree ( iwe ); <nl> return - EAGAIN ; <nl> + } <nl>  <nl> spin_lock_irqsave (& priv -> bss_list_spinlock , flags ); <nl> 
static int sanitize_enable_ppgtt ( struct drm_device * dev , int enable_ppgtt ) <nl> } <nl> # endif <nl>  <nl> + /* Early VLV doesn ' t have this */ <nl> + if ( IS_VALLEYVIEW ( dev ) && dev -> pdev -> revision < 0xb ) { <nl> + DRM_DEBUG_DRIVER (" disabling PPGTT on pre - B3 step VLV \ n "); <nl> + return 0 ; <nl> + } <nl> + <nl> return HAS_ALIASING_PPGTT ( dev ) ? 1 : 0 ; <nl> } <nl> 
struct flow_cache_entry { <nl> struct hlist_node hlist ; <nl> struct list_head gc_list ; <nl> } u ; <nl> + struct net * net ; <nl> u16 family ; <nl> u8 dir ; <nl> u32 genid ; <nl> flow_cache_lookup ( struct net * net , const struct flowi * key , u16 family , u8 dir , <nl>  <nl> hash = flow_hash_code ( fc , fcp , key ); <nl> hlist_for_each_entry ( tfle , entry , & fcp -> hash_table [ hash ], u . hlist ) { <nl> - if ( tfle -> family == family && <nl> + if ( tfle -> net == net && <nl> + tfle -> family == family && <nl> tfle -> dir == dir && <nl> flow_key_compare ( key , & tfle -> key ) == 0 ) { <nl> fle = tfle ; <nl> flow_cache_lookup ( struct net * net , const struct flowi * key , u16 family , u8 dir , <nl>  <nl> fle = kmem_cache_alloc ( flow_cachep , GFP_ATOMIC ); <nl> if ( fle ) { <nl> + fle -> net = net ; <nl> fle -> family = family ; <nl> fle -> dir = dir ; <nl> memcpy (& fle -> key , key , sizeof (* key ));
static void hci_simple_pair_complete_evt ( struct hci_dev * hdev , <nl> if (! conn ) <nl> goto unlock ; <nl>  <nl> + /* Reset the authentication requirement to unknown */ <nl> + conn -> remote_auth = 0xff ; <nl> + <nl> /* To avoid duplicate auth_failed events to user space we check <nl> * the HCI_CONN_AUTH_PEND flag which will be set if we <nl> * initiated the authentication . A traditional auth_complete
qla24xx_pci_config ( scsi_qla_host_t * vha ) <nl>  <nl> /* PCIe -- adjust Maximum Read Request Size ( 2048 ). */ <nl> if ( pci_is_pcie ( ha -> pdev )) <nl> - pcie_set_readrq ( ha -> pdev , 2048 ); <nl> + pcie_set_readrq ( ha -> pdev , 4096 ); <nl>  <nl> pci_disable_rom ( ha -> pdev ); <nl>  <nl> qla25xx_pci_config ( scsi_qla_host_t * vha ) <nl>  <nl> /* PCIe -- adjust Maximum Read Request Size ( 2048 ). */ <nl> if ( pci_is_pcie ( ha -> pdev )) <nl> - pcie_set_readrq ( ha -> pdev , 2048 ); <nl> + pcie_set_readrq ( ha -> pdev , 4096 ); <nl>  <nl> pci_disable_rom ( ha -> pdev ); <nl> 
struct file_info { <nl>  <nl> struct hpsb_host * host ; <nl>  <nl> - struct list_head req_pending ; <nl> - struct list_head req_complete ; <nl> + struct list_head req_pending ; /* protected by reqlists_lock */ <nl> + struct list_head req_complete ; /* protected by reqlists_lock */ <nl> spinlock_t reqlists_lock ; <nl> wait_queue_head_t wait_complete ; <nl>  <nl> - struct list_head addr_list ; <nl> + struct list_head addr_list ; /* protected by host_info_lock */ <nl>  <nl> u8 __user * fcp_buffer ; <nl>  <nl> struct arm_addr { <nl> u8 client_transactions ; <nl> u64 recvb ; <nl> u16 rec_length ; <nl> - u8 * addr_space_buffer ; /* accessed by read / write / lock */ <nl> + u8 * addr_space_buffer ; /* accessed by read / write / lock requests */ <nl> }; <nl>  <nl> struct pending_request { <nl> struct pending_request { <nl> struct host_info { <nl> struct list_head list ; <nl> struct hpsb_host * host ; <nl> - struct list_head file_info_list ; <nl> + struct list_head file_info_list ; /* protected by host_info_lock */ <nl> }; <nl>  <nl> # endif /* IEEE1394_RAW1394_PRIVATE_H */
static DECLARE_WAIT_QUEUE_HEAD ( vt_activate_queue ); <nl>  <nl> /* <nl> * Sleeps until a vt is activated , or the task is interrupted . Returns <nl> - * 0 if activation , - EINTR if interrupted . <nl> + * 0 if activation , - EINTR if interrupted by a signal handler . <nl> */ <nl> int vt_waitactive ( int vt ) <nl> { <nl> int vt_waitactive ( int vt ) <nl> break ; <nl> } <nl> release_console_sem (); <nl> - retval = - EINTR ; <nl> + retval = - ERESTARTNOHAND ; <nl> if ( signal_pending ( current )) <nl> break ; <nl> schedule ();
* <nl> */ <nl>  <nl> +# include < linux / kconfig . h > <nl> +# include < linux / stddef . h > <nl> # include < linux / acpi . h > <nl>  <nl> /* translation fron HID to I2C name , needed for DAI codec_name */ <nl> +# if IS_ENABLED ( CONFIG_ACPI ) <nl> const char * sst_acpi_find_name_from_hid ( const u8 hid [ ACPI_ID_LEN ]); <nl> +# else <nl> + inline const char * sst_acpi_find_name_from_hid ( const u8 hid [ ACPI_ID_LEN ]) <nl> +{ <nl> + return NULL ; <nl> +} <nl> +# endif <nl>  <nl> /* acpi match */ <nl> struct sst_acpi_mach * sst_acpi_find_machine ( struct sst_acpi_mach * machines );
static void ap192_set_rate_val ( struct snd_akm4xxx * ak , unsigned int rate ) <nl> revo_set_rate_val ( ak , rate ); <nl>  <nl> /* reset CKS */ <nl> - snd_ice1712_gpio_write_bits ( ice , 1 << 8 , rate > 96000 ? 1 : 0 ); <nl> + snd_ice1712_gpio_write_bits ( ice , 1 << 8 , rate > 96000 ? 1 << 8 : 0 ); <nl> /* reset DFS pins of AK5385A for ADC , too */ <nl> if ( rate > 96000 ) <nl> dfs = 2 ; <nl> static void ap192_set_rate_val ( struct snd_akm4xxx * ak , unsigned int rate ) <nl> snd_ice1712_gpio_write_bits ( ice , 3 << 9 , dfs << 9 ); <nl> /* reset ADC */ <nl> snd_ice1712_gpio_write_bits ( ice , 1 << 11 , 0 ); <nl> - snd_ice1712_gpio_write_bits ( ice , 1 << 11 , 1 ); <nl> + snd_ice1712_gpio_write_bits ( ice , 1 << 11 , 1 << 11 ); <nl> } <nl>  <nl> static const struct snd_akm4xxx_dac_channel ap192_dac [] = {
static int fbcon_blank ( struct vc_data * vc , int blank , int mode_switch ) <nl> update_screen ( vc ); <nl> } <nl>  <nl> - if ( fbcon_is_inactive ( vc , info ) || <nl> + if ( mode_switch || fbcon_is_inactive ( vc , info ) || <nl> ops -> blank_state != FB_BLANK_UNBLANK ) <nl> fbcon_del_cursor_timer ( info ); <nl> else
static int __devinit sis900_probe ( struct pci_dev * pci_dev , <nl> else <nl> ret = sis900_get_mac_addr ( pci_dev , net_dev ); <nl>  <nl> - if ( ret == 0 ) { <nl> - printk ( KERN_WARNING "% s : Cannot read MAC address .\ n ", dev_name ); <nl> - ret = - ENODEV ; <nl> - goto err_unmap_rx ; <nl> + if (! ret || ! is_valid_ether_addr ( net_dev -> dev_addr )) { <nl> + random_ether_addr ( net_dev -> dev_addr ); <nl> + printk ( KERN_WARNING "% s : Unreadable or invalid MAC address ," <nl> + " using random generated one \ n ", dev_name ); <nl> } <nl>  <nl> /* 630ET : set the mii access mode as software - mode */
static inline uint8_t elf_sym__type ( const GElf_Sym * sym ) <nl>  <nl> static inline int elf_sym__is_function ( const GElf_Sym * sym ) <nl> { <nl> - return elf_sym__type ( sym ) == STT_FUNC && <nl> + return ( elf_sym__type ( sym ) == STT_FUNC || <nl> + elf_sym__type ( sym ) == STT_GNU_IFUNC ) && <nl> sym -> st_name != 0 && <nl> sym -> st_shndx != SHN_UNDEF ; <nl> }
static int rr_init_one ( struct pci_dev * pdev , const struct pci_device_id * ent ) <nl> return 0 ; <nl>  <nl> out : <nl> + if ( rrpriv -> evt_ring ) <nl> + pci_free_consistent ( pdev , EVT_RING_SIZE , rrpriv -> evt_ring , <nl> + rrpriv -> evt_ring_dma ); <nl> if ( rrpriv -> rx_ring ) <nl> pci_free_consistent ( pdev , RX_TOTAL_SIZE , rrpriv -> rx_ring , <nl> rrpriv -> rx_ring_dma );
int arch_decode_instruction ( struct elf * elf , struct section * sec , <nl> * type = INSN_FP_SETUP ; <nl> break ; <nl>  <nl> + case 0x8d : <nl> + if ( insn . rex_prefix . bytes && <nl> + insn . rex_prefix . bytes [ 0 ] == 0x48 && <nl> + insn . modrm . nbytes && insn . modrm . bytes [ 0 ] == 0x2c && <nl> + insn . sib . nbytes && insn . sib . bytes [ 0 ] == 0x24 ) <nl> + /* lea %( rsp ), % rbp */ <nl> + * type = INSN_FP_SETUP ; <nl> + break ; <nl> + <nl> case 0x90 : <nl> * type = INSN_NOP ; <nl> break ;
netdev_tx_t ieee80211_subif_start_xmit ( struct sk_buff * skb , <nl> __le16 fc ; <nl> struct ieee80211_hdr hdr ; <nl> struct ieee80211s_hdr mesh_hdr __maybe_unused ; <nl> - struct mesh_path * mppath = NULL ; <nl> + struct mesh_path __maybe_unused * mppath = NULL ; <nl> const u8 * encaps_data ; <nl> int encaps_len , skip_header_bytes ; <nl> int nh_pos , h_pos ;
static int davinci_gpio_probe ( struct platform_device * pdev ) <nl> spin_lock_init (& chips [ i ]. lock ); <nl>  <nl> regs = gpio2regs ( base ); <nl> + if (! regs ) <nl> + return - ENXIO ; <nl> chips [ i ]. regs = regs ; <nl> chips [ i ]. set_data = & regs -> set_data ; <nl> chips [ i ]. clr_data = & regs -> clr_data ;
static void dma_ops_free_addresses ( struct dma_ops_domain * dom , <nl> return ; <nl> # endif <nl>  <nl> - if ( amd_iommu_unmap_flush || <nl> - ( address + pages > range -> next_bit )) { <nl> + if ( amd_iommu_unmap_flush ) { <nl> domain_flush_tlb (& dom -> domain ); <nl> domain_flush_complete (& dom -> domain ); <nl> } <nl> static void dma_ops_free_addresses ( struct dma_ops_domain * dom , <nl> address = ( address % APERTURE_RANGE_SIZE ) >> PAGE_SHIFT ; <nl>  <nl> spin_lock_irqsave (& range -> bitmap_lock , flags ); <nl> + if ( address + pages > range -> next_bit ) <nl> + range -> next_bit = address + pages ; <nl> bitmap_clear ( range -> bitmap , address , pages ); <nl> spin_unlock_irqrestore (& range -> bitmap_lock , flags ); <nl> 
static void pci_dio_detach ( struct comedi_device * dev ) <nl> if ( devpriv ) { <nl> if ( devpriv -> valid ) <nl> pci_dio_reset ( dev ); <nl> + } <nl> + if ( dev -> subdevices ) { <nl> for ( i = 0 ; i < dev -> n_subdevices ; i ++) { <nl> s = dev -> subdevices + i ; <nl> if ( s -> type == COMEDI_SUBD_DIO )
void nf_ct_iterate_cleanup ( struct net * net , <nl>  <nl> might_sleep (); <nl>  <nl> + if ( atomic_read (& net -> ct . count ) == 0 ) <nl> + return ; <nl> + <nl> while (( ct = get_next_corpse ( net , iter , data , & bucket )) != NULL ) { <nl> /* Time to push up daises ... */ <nl> if ( del_timer (& ct -> timeout ))
static int macronix_quad_enable ( struct spi_nor * nor ) <nl> val = read_sr ( nor ); <nl> if ( val < 0 ) <nl> return val ; <nl> + if ( val & SR_QUAD_EN_MX ) <nl> + return 0 ; <nl> + <nl> write_enable ( nor ); <nl>  <nl> write_sr ( nor , val | SR_QUAD_EN_MX );
int cfg80211_wext_siwscan ( struct net_device * dev , <nl> wext_freq_not_found : ; <nl> } <nl> } <nl> + /* No channels found ? */ <nl> + if (! i ) { <nl> + err = - EINVAL ; <nl> + goto out ; <nl> + } <nl>  <nl> /* Set real number of channels specified in creq -> channels [] */ <nl> creq -> n_channels = i ;
static struct pci_driver driver = { <nl> . name = " ITE8213_IDE ", <nl> . id_table = it8213_pci_tbl , <nl> . probe = it8213_init_one , <nl> + . remove = ide_pci_remove , <nl> }; <nl>  <nl> static int __init it8213_ide_init ( void ) <nl> static int __init it8213_ide_init ( void ) <nl> return ide_pci_register_driver (& driver ); <nl> } <nl>  <nl> + static void __exit it8213_ide_exit ( void ) <nl> +{ <nl> + pci_unregister_driver (& driver ); <nl> +} <nl> + <nl> module_init ( it8213_ide_init ); <nl> + module_exit ( it8213_ide_exit ); <nl>  <nl> MODULE_AUTHOR (" Jack Lee , Alan Cox "); <nl> MODULE_DESCRIPTION (" PCI driver module for the ITE 8213 ");
call_connect_status ( struct rpc_task * task ) <nl> static void <nl> call_transmit ( struct rpc_task * task ) <nl> { <nl> + int is_retrans = RPC_WAS_SENT ( task ); <nl> + <nl> dprint_status ( task ); <nl>  <nl> task -> tk_action = call_status ; <nl> call_transmit ( struct rpc_task * task ) <nl> xprt_transmit ( task ); <nl> if ( task -> tk_status < 0 ) <nl> return ; <nl> + if ( is_retrans ) <nl> + task -> tk_client -> cl_stats -> rpcretrans ++; <nl> /* <nl> * On success , ensure that we call xprt_end_transmit () before sleeping <nl> * in order to allow access to the socket to other RPC requests . <nl> call_timeout ( struct rpc_task * task ) <nl> rpcauth_invalcred ( task ); <nl>  <nl> retry : <nl> - clnt -> cl_stats -> rpcretrans ++; <nl> task -> tk_action = call_bind ; <nl> task -> tk_status = 0 ; <nl> } <nl> call_decode ( struct rpc_task * task ) <nl> if ( req -> rq_rcv_buf . len < 12 ) { <nl> if (! RPC_IS_SOFT ( task )) { <nl> task -> tk_action = call_bind ; <nl> - clnt -> cl_stats -> rpcretrans ++; <nl> goto out_retry ; <nl> } <nl> dprintk (" RPC : % s : too small RPC reply size (% d bytes )\ n ",
static struct sh_eth_cpu_data sh7734_data = { <nl> . tsu = 1 , <nl> . hw_checksum = 1 , <nl> . select_mii = 1 , <nl> + . magic = 1 , <nl> }; <nl>  <nl> /* SH7763 */
static s32 igb_get_invariants_82575 ( struct e1000_hw * hw ) <nl> */ <nl> size += NVM_WORD_SIZE_BASE_SHIFT ; <nl>  <nl> + /* <nl> + * Check for invalid size <nl> + */ <nl> + if (( hw -> mac . type == e1000_82576 ) && ( size > 15 )) { <nl> + printk (" igb : The NVM size is not valid , " <nl> + " defaulting to 32K .\ n "); <nl> + size = 15 ; <nl> + } <nl> nvm -> word_size = 1 << size ; <nl> if ( nvm -> word_size == ( 1 << 15 )) <nl> nvm -> page_size = 128 ;
static void delete_netdev ( struct work_struct * work ) <nl>  <nl> unregister_netdev ( entry -> netdev ); <nl>  <nl> - /* The entry pointer is deleted in device_event () */ <nl> + /* The entry pointer is deleted by the netdev destructor . */ <nl> } <nl>  <nl> static void chan_close_cb ( struct l2cap_chan * chan ) <nl> static int device_event ( struct notifier_block * unused , <nl> BT_DBG (" Unregistered netdev % s % p ", <nl> netdev -> name , netdev ); <nl> list_del (& entry -> list ); <nl> - kfree ( entry ); <nl> break ; <nl> } <nl> }
void perf_evsel__config ( struct perf_evsel * evsel , struct perf_record_opts * opts , <nl> struct perf_event_attr * attr = & evsel -> attr ; <nl> int track = ! evsel -> idx ; /* only the first counter needs these */ <nl>  <nl> + attr -> disabled = 1 ; <nl> attr -> sample_id_all = opts -> sample_id_all_missing ? 0 : 1 ; <nl> attr -> inherit = ! opts -> no_inherit ; <nl> attr -> read_format = PERF_FORMAT_TOTAL_TIME_ENABLED | <nl> void perf_evsel__config ( struct perf_evsel * evsel , struct perf_record_opts * opts , <nl>  <nl> if ( perf_target__none (& opts -> target ) && <nl> (! opts -> group || evsel == first )) { <nl> - attr -> disabled = 1 ; <nl> attr -> enable_on_exec = 1 ; <nl> } <nl> }
struct atmel_spi { <nl> int irq ; <nl> struct clk * clk ; <nl> struct platform_device * pdev ; <nl> + unsigned long spi_clk ; <nl>  <nl> struct spi_transfer * current_transfer ; <nl> int current_remaining_bytes ; <nl> static int atmel_spi_set_xfer_speed ( struct atmel_spi * as , <nl> unsigned long bus_hz ; <nl>  <nl> /* v1 chips start out at half the peripheral bus speed . */ <nl> - bus_hz = clk_get_rate ( as -> clk ); <nl> + bus_hz = as -> spi_clk ; <nl> if (! atmel_spi_is_v2 ( as )) <nl> bus_hz /= 2 ; <nl>  <nl> static int atmel_spi_probe ( struct platform_device * pdev ) <nl> ret = clk_prepare_enable ( clk ); <nl> if ( ret ) <nl> goto out_free_irq ; <nl> + <nl> + as -> spi_clk = clk_get_rate ( clk ); <nl> + <nl> spi_writel ( as , CR , SPI_BIT ( SWRST )); <nl> spi_writel ( as , CR , SPI_BIT ( SWRST )); /* AT91SAM9263 Rev B workaround */ <nl> if ( as -> caps . has_wdrbt ) {
static int sunxi_mmc_clk_set_rate ( struct sunxi_mmc_host * host , <nl> u32 rval , clock = ios -> clock ; <nl> int ret ; <nl>  <nl> + ret = sunxi_mmc_oclk_onoff ( host , 0 ); <nl> + if ( ret ) <nl> + return ret ; <nl> + <nl> /* 8 bit DDR requires a higher module clock */ <nl> if ( ios -> timing == MMC_TIMING_MMC_DDR52 && <nl> ios -> bus_width == MMC_BUS_WIDTH_8 ) <nl> static int sunxi_mmc_clk_set_rate ( struct sunxi_mmc_host * host , <nl> return ret ; <nl> } <nl>  <nl> - ret = sunxi_mmc_oclk_onoff ( host , 0 ); <nl> - if ( ret ) <nl> - return ret ; <nl> - <nl> /* clear internal divider */ <nl> rval = mmc_readl ( host , REG_CLKCR ); <nl> rval &= ~ 0xff ;
static int ak8975_probe ( struct i2c_client * client , <nl> indio_dev -> channels = ak8975_channels ; <nl> indio_dev -> num_channels = ARRAY_SIZE ( ak8975_channels ); <nl> indio_dev -> info = & ak8975_info ; <nl> + indio_dev -> name = id -> name ; <nl> indio_dev -> modes = INDIO_DIRECT_MODE ; <nl>  <nl> err = iio_device_register ( indio_dev );
static int __init rs_init ( void ) <nl> state -> baud_base = amiga_colorclock ; <nl> state -> xmit_fifo_size = 1 ; <nl>  <nl> - local_irq_save ( flags ); <nl> - <nl> /* set ISRs , and then disable the rx interrupts */ <nl> error = request_irq ( IRQ_AMIGA_TBE , ser_tx_int , 0 , " serial TX ", state ); <nl> if ( error ) <nl> static int __init rs_init ( void ) <nl> if ( error ) <nl> goto fail_free_irq ; <nl>  <nl> + local_irq_save ( flags ); <nl> + <nl> /* turn off Rx and Tx interrupts */ <nl> custom . intena = IF_RBF | IF_TBE ; <nl> mb ();
void radeon_audio_detect ( struct drm_connector * connector , <nl> return ; <nl>  <nl> rdev = connector -> encoder -> dev -> dev_private ; <nl> + <nl> + if (! radeon_audio_chipset_supported ( rdev )) <nl> + return ; <nl> + <nl> radeon_encoder = to_radeon_encoder ( connector -> encoder ); <nl> dig = radeon_encoder -> enc_priv ; <nl> 
xfs_setattr_nonsize ( <nl> } <nl> if (! gid_eq ( igid , gid )) { <nl> if ( XFS_IS_QUOTA_RUNNING ( mp ) && XFS_IS_GQUOTA_ON ( mp )) { <nl> - ASSERT (! XFS_IS_PQUOTA_ON ( mp )); <nl> + ASSERT ( xfs_sb_version_has_pquotino (& mp -> m_sb ) || <nl> + ! XFS_IS_PQUOTA_ON ( mp )); <nl> ASSERT ( mask & ATTR_GID ); <nl> ASSERT ( gdqp ); <nl> olddquot2 = xfs_qm_vop_chown ( tp , ip ,
void oz_apps_term ( void ) <nl> void oz_handle_app_elt ( struct oz_pd * pd , u8 app_id , struct oz_elt * elt ) <nl> { <nl> struct oz_app_if * ai ; <nl> - if ( app_id > OZ_APPID_MAX ) <nl> + if ( app_id == 0 || app_id > OZ_APPID_MAX ) <nl> return ; <nl> ai = & g_app_if [ app_id - 1 ]; <nl> ai -> rx ( pd , elt );
static int __devinit rtsx_probe ( struct pci_dev * pci , <nl> th = kthread_create ( rtsx_scan_thread , dev , " rtsx - scan "); <nl> if ( IS_ERR ( th )) { <nl> printk ( KERN_ERR " Unable to start the device - scanning thread \ n "); <nl> + complete (& dev -> scanning_done ); <nl> quiesce_and_remove_host ( dev ); <nl> err = PTR_ERR ( th ); <nl> goto errout ;
static ssize_t spufs_mfc_write ( struct file * file , const char __user * buffer , <nl> if ( ret ) <nl> goto out ; <nl>  <nl> - spu_acquire_runnable ( ctx , 0 ); <nl> + ret = spu_acquire_runnable ( ctx , 0 ); <nl> + if ( ret ) <nl> + goto out ; <nl> + <nl> if ( file -> f_flags & O_NONBLOCK ) { <nl> ret = ctx -> ops -> send_mfc_command ( ctx , & cmd ); <nl> } else {
static int __init early_get_pnodeid ( void ) <nl> break ; <nl> case UV3_HUB_PART_NUMBER : <nl> case UV3_HUB_PART_NUMBER_X : <nl> - uv_min_hub_revision_id += UV3_HUB_REVISION_BASE - 1 ; <nl> + uv_min_hub_revision_id += UV3_HUB_REVISION_BASE ; <nl> break ; <nl> } <nl> 
static int __init gt641xx_timer0_clockevent_init ( void ) <nl>  <nl> cd = & gt641xx_timer0_clockevent ; <nl> cd -> rating = 200 + gt641xx_base_clock / 10000000 ; <nl> + clockevent_set_clock ( cd , gt641xx_base_clock ); <nl> cd -> max_delta_ns = clockevent_delta2ns ( 0x7fffffff , cd ); <nl> cd -> min_delta_ns = clockevent_delta2ns ( 0x300 , cd ); <nl> - clockevent_set_clock ( cd , gt641xx_base_clock ); <nl>  <nl> clockevents_register_device (& gt641xx_timer0_clockevent ); <nl> 
int skb_gro_receive ( struct sk_buff ** head , struct sk_buff * skb ) <nl> * NAPI_GRO_CB ( nskb ) = * NAPI_GRO_CB ( p ); <nl> skb_shinfo ( nskb )-> frag_list = p ; <nl> skb_shinfo ( nskb )-> gso_size = pinfo -> gso_size ; <nl> + pinfo -> gso_size = 0 ; <nl> skb_header_release ( p ); <nl> nskb -> prev = p ; <nl> 
static int be_get_config ( struct be_adapter * adapter ) <nl> if ( status ) <nl> return status ; <nl>  <nl> - /* primary mac needs 1 pmac entry */ <nl> - adapter -> pmac_id = kcalloc ( be_max_uc ( adapter ) + 1 , sizeof ( u32 ), <nl> - GFP_KERNEL ); <nl> + adapter -> pmac_id = kcalloc ( be_max_uc ( adapter ), <nl> + sizeof (* adapter -> pmac_id ), GFP_KERNEL ); <nl> if (! adapter -> pmac_id ) <nl> return - ENOMEM ; <nl> 
static int radeon_get_shared_nondp_ppll ( struct drm_crtc * crtc ) <nl> if (( crtc -> mode . clock == test_crtc -> mode . clock ) && <nl> ( adjusted_clock == test_adjusted_clock ) && <nl> ( radeon_crtc -> ss_enabled == test_radeon_crtc -> ss_enabled ) && <nl> - ( test_radeon_crtc -> pll_id != ATOM_PPLL_INVALID ) && <nl> - ( drm_detect_monitor_audio ( radeon_connector_edid ( test_radeon_crtc -> connector )) == <nl> - drm_detect_monitor_audio ( radeon_connector_edid ( radeon_crtc -> connector )))) <nl> + ( test_radeon_crtc -> pll_id != ATOM_PPLL_INVALID )) <nl> return test_radeon_crtc -> pll_id ; <nl> } <nl> }
static void qlcnic_get_ethtool_stats ( struct net_device * dev , <nl> tx_ring = & adapter -> tx_ring [ ring ]; <nl> data = qlcnic_fill_tx_queue_stats ( data , tx_ring ); <nl> qlcnic_update_stats ( adapter ); <nl> + } else { <nl> + data += QLCNIC_TX_STATS_LEN ; <nl> } <nl> } <nl> 
static int _sp2d_alloc ( unsigned pages_in_unit , unsigned group_width , <nl> num_a1pa = min_t ( unsigned , PAGE_SIZE / sizeof__a1pa , <nl> pages_in_unit - i ); <nl>  <nl> - __a1pa = kzalloc ( num_a1pa * sizeof__a1pa , GFP_KERNEL ); <nl> + __a1pa = kcalloc ( num_a1pa , sizeof__a1pa , GFP_KERNEL ); <nl> if ( unlikely (! __a1pa )) { <nl> ORE_DBGMSG ("!! Failed to _alloc_1p_arrays =% d \ n ", <nl> num_a1pa );
static void esdhc_writew_le ( struct sdhci_host * host , u16 val , int reg ) <nl> new_val |= ESDHC_VENDOR_SPEC_FRC_SDCLK_ON ; <nl> else <nl> new_val &= ~ ESDHC_VENDOR_SPEC_FRC_SDCLK_ON ; <nl> - writel ( new_val , host -> ioaddr + ESDHC_VENDOR_SPEC ); <nl> + writel ( new_val , host -> ioaddr + ESDHC_VENDOR_SPEC ); <nl> return ; <nl> case SDHCI_HOST_CONTROL2 : <nl> new_val = readl ( host -> ioaddr + ESDHC_VENDOR_SPEC );
static void ext3_put_super ( struct super_block * sb ) <nl> } <nl> sb -> s_fs_info = NULL ; <nl> kfree ( sbi -> s_blockgroup_lock ); <nl> + mutex_destroy (& sbi -> s_orphan_lock ); <nl> + mutex_destroy (& sbi -> s_resize_lock ); <nl> kfree ( sbi ); <nl> } <nl> 
int snd_hda_create_dig_out_ctls ( struct hda_codec * codec , <nl> return - EBUSY ; <nl> } <nl> spdif = snd_array_new (& codec -> spdif_out ); <nl> + if (! spdif ) <nl> + return - ENOMEM ; <nl> for ( dig_mix = dig_mixes ; dig_mix -> name ; dig_mix ++) { <nl> kctl = snd_ctl_new1 ( dig_mix , codec ); <nl> if (! kctl )
static void jpeg_define ( u8 * jpeg_hdr , <nl> memcpy ( jpeg_hdr , jpeg_head , sizeof jpeg_head ); <nl> # ifndef CONEX_CAM <nl> jpeg_hdr [ JPEG_HEIGHT_OFFSET + 0 ] = height >> 8 ; <nl> - jpeg_hdr [ JPEG_HEIGHT_OFFSET + 1 ] = height & 0xff ; <nl> + jpeg_hdr [ JPEG_HEIGHT_OFFSET + 1 ] = height ; <nl> jpeg_hdr [ JPEG_HEIGHT_OFFSET + 2 ] = width >> 8 ; <nl> - jpeg_hdr [ JPEG_HEIGHT_OFFSET + 3 ] = width & 0xff ; <nl> + jpeg_hdr [ JPEG_HEIGHT_OFFSET + 3 ] = width ; <nl> jpeg_hdr [ JPEG_HEIGHT_OFFSET + 6 ] = samplesY ; <nl> # endif <nl> }
static const struct key_entry eeepc_wmi_keymap [] = { <nl> { KE_KEY , 0xcc , { KEY_SWITCHVIDEOMODE } }, <nl> { KE_KEY , 0xe0 , { KEY_PROG1 } }, <nl> { KE_KEY , 0xe1 , { KEY_F14 } }, <nl> - { KE_KEY , 0xe9 , { KEY_DISPLAY_OFF } }, <nl> + { KE_KEY , 0xe9 , { KEY_BRIGHTNESS_ZERO } }, <nl> { KE_END , 0 }, <nl> }; <nl> 
asmlinkage long sys_fcntl ( unsigned int fd , unsigned int cmd , unsigned long arg ); <nl> asmlinkage long sys_fcntl64 ( unsigned int fd , <nl> unsigned int cmd , unsigned long arg ); <nl> # endif <nl> + asmlinkage long sys_pipe ( int __user * fildes ); <nl> asmlinkage long sys_pipe2 ( int __user * fildes , int flags ); <nl> asmlinkage long sys_dup ( unsigned int fildes ); <nl> asmlinkage long sys_dup2 ( unsigned int oldfd , unsigned int newfd ); <nl> asmlinkage long sys_pselect6 ( int , fd_set __user *, fd_set __user *, <nl> asmlinkage long sys_ppoll ( struct pollfd __user *, unsigned int , <nl> struct timespec __user *, const sigset_t __user *, <nl> size_t ); <nl> - asmlinkage long sys_pipe2 ( int __user *, int ); <nl> - asmlinkage long sys_pipe ( int __user *); <nl>  <nl> int kernel_execve ( const char * filename , char * const argv [], char * const envp []); <nl> 
static int ravb_close ( struct net_device * ndev ) <nl> priv -> phydev = NULL ; <nl> } <nl>  <nl> + if ( priv -> chip_id == RCAR_GEN3 ) <nl> + free_irq ( priv -> emac_irq , ndev ); <nl> free_irq ( ndev -> irq , ndev ); <nl>  <nl> napi_disable (& priv -> napi [ RAVB_NC ]);
MODULE_PARM_DESC ( msi , " attempt to use MSI if nonzero "); <nl>  <nl> # endif /* CONFIG_PCI_MSI */ <nl>  <nl> + static int tune_pci = 0 ; <nl> + module_param ( tune_pci , int , 0444 ); <nl> + MODULE_PARM_DESC ( tune_pci , " increase PCI burst from the default set by BIOS if nonzero "); <nl> + <nl> static const char mthca_version [] __devinitdata = <nl> DRV_NAME ": Mellanox InfiniBand HCA driver v " <nl> DRV_VERSION " (" DRV_RELDATE ")\ n "; <nl> static int __devinit mthca_tune_pci ( struct mthca_dev * mdev ) <nl> int cap ; <nl> u16 val ; <nl>  <nl> + if (! tune_pci ) <nl> + return 0 ; <nl> + <nl> /* First try to max out Read Byte Count */ <nl> cap = pci_find_capability ( mdev -> pdev , PCI_CAP_ID_PCIX ); <nl> if ( cap ) {
int mei_cl_connect ( struct mei_cl * cl , struct file * file ) <nl> mutex_lock (& dev -> device_lock ); <nl>  <nl> if ( cl -> state != MEI_FILE_CONNECTED ) { <nl> + cl -> state = MEI_FILE_DISCONNECTED ; <nl> /* something went really wrong */ <nl> if (! cl -> status ) <nl> cl -> status = - EFAULT ;
static int pio_in_emulated ( struct x86_emulate_ctxt * ctxt , <nl> in_page = ( ctxt -> eflags & EFLG_DF ) ? <nl> offset_in_page ( reg_read ( ctxt , VCPU_REGS_RDI )) : <nl> PAGE_SIZE - offset_in_page ( reg_read ( ctxt , VCPU_REGS_RDI )); <nl> - n = min ( min ( in_page , ( unsigned int ) sizeof ( rc -> data )) / size , <nl> - count ); <nl> + n = min3 ( in_page , ( unsigned int ) sizeof ( rc -> data ) / size , count ); <nl> if ( n == 0 ) <nl> n = 1 ; <nl> rc -> pos = rc -> end = 0 ;
static int mv643xx_eth_receive_queue ( struct net_device * dev ) <nl> netif_rx ( skb ); <nl> # endif <nl> } <nl> + dev -> last_rx = jiffies ; <nl> } <nl>  <nl> return received_packets ;
int inet_recv_error ( struct sock * sk , struct msghdr * msg , int len , <nl>  <nl> static inline void inet_ctl_sock_destroy ( struct sock * sk ) <nl> { <nl> - sock_release ( sk -> sk_socket ); <nl> + if ( sk ) <nl> + sock_release ( sk -> sk_socket ); <nl> } <nl>  <nl> # endif
static int ascot2e_write_regs ( struct ascot2e_priv * priv , <nl> } <nl> }; <nl>  <nl> - if ( len + 1 >= sizeof ( buf )) { <nl> + if ( len + 1 > sizeof ( buf )) { <nl> dev_warn (& priv -> i2c -> dev ," wr reg =% 04x : len =% d is too big !\ n ", <nl> reg , len + 1 ); <nl> return - E2BIG ;
void rt2x00link_update_stats ( struct rt2x00_dev * rt2x00dev , <nl> struct link_ant * ant = & rt2x00dev -> link . ant ; <nl> struct ieee80211_hdr * hdr = ( struct ieee80211_hdr *) skb -> data ; <nl>  <nl> + /* <nl> + * No need to update the stats for != STA interfaces <nl> + */ <nl> + if (! rt2x00dev -> intf_sta_count ) <nl> + return ; <nl> + <nl> /* <nl> * Frame was received successfully since non - succesfull <nl> * frames would have been dropped by the hardware .
static int c_can_start ( struct net_device * dev ) <nl> { <nl> struct c_can_priv * priv = netdev_priv ( dev ); <nl> int err ; <nl> + struct pinctrl * p ; <nl>  <nl> /* basic c_can configuration */ <nl> err = c_can_chip_config ( dev ); <nl> static int c_can_start ( struct net_device * dev ) <nl>  <nl> priv -> can . state = CAN_STATE_ERROR_ACTIVE ; <nl>  <nl> - /* activate pins */ <nl> - pinctrl_pm_select_default_state ( dev -> dev . parent ); <nl> + /* Attempt to use " active " if available else use " default " */ <nl> + p = pinctrl_get_select ( priv -> device , " active "); <nl> + if (! IS_ERR ( p )) <nl> + pinctrl_put ( p ); <nl> + else <nl> + pinctrl_pm_select_default_state ( priv -> device ); <nl> + <nl> return 0 ; <nl> } <nl> 
MODULE_PARM_DESC ( debug , " Debug level ( 0 - 1 )"); <nl>  <nl> /* ----------------------------------------------------------------------- */ <nl>  <nl> +# define SAA7111_NR_REG 0x18 <nl> + <nl> struct saa7111 { <nl> - unsigned char reg [ 32 ]; <nl> + unsigned char reg [ SAA7111_NR_REG ]; <nl>  <nl> int norm ; <nl> int input ; <nl> saa7111_command ( struct i2c_client * client , <nl> { <nl> int i ; <nl>  <nl> - for ( i = 0 ; i < 32 ; i += 16 ) { <nl> + for ( i = 0 ; i < SAA7111_NR_REG ; i += 16 ) { <nl> int j ; <nl>  <nl> printk ( KERN_DEBUG "% s : % 03x ", I2C_NAME ( client ), i ); <nl> - for ( j = 0 ; j < 16 ; ++ j ) { <nl> + for ( j = 0 ; j < 16 && i + j < SAA7111_NR_REG ; ++ j ) { <nl> printk (" % 02x ", <nl> saa7111_read ( client , i + j )); <nl> }
static irqreturn_t iwl_isr ( int irq , void * data ) <nl> if (( inta == 0xFFFFFFFF ) || (( inta & 0xFFFFFFF0 ) == 0xa5a5a5a0 )) { <nl> /* Hardware disappeared */ <nl> IWL_WARNING (" HARDWARE GONE ?? INTA == 0x % 080x \ n ", inta ); <nl> - goto none ; <nl> + goto unplugged ; <nl> } <nl>  <nl> IWL_DEBUG_ISR (" ISR inta 0x % 08x , enabled 0x % 08x , fh 0x % 08x \ n ", <nl> static irqreturn_t iwl_isr ( int irq , void * data ) <nl>  <nl> /* iwl_irq_tasklet () will service interrupts and re - enable them */ <nl> tasklet_schedule (& priv -> irq_tasklet ); <nl> + unplugged : <nl> spin_unlock (& priv -> lock ); <nl>  <nl> return IRQ_HANDLED ;
static __inline__ ssize_t tun_get_user ( struct tun_struct * tun , <nl> { <nl> struct tun_pi pi = { 0 , cpu_to_be16 ( ETH_P_IP ) }; <nl> struct sk_buff * skb ; <nl> - size_t len = count , align = 0 ; <nl> + size_t len = count , align = NET_SKB_PAD ; <nl> struct virtio_net_hdr gso = { 0 }; <nl> int offset = 0 ; <nl>  <nl> static __inline__ ssize_t tun_get_user ( struct tun_struct * tun , <nl> } <nl>  <nl> if (( tun -> flags & TUN_TYPE_MASK ) == TUN_TAP_DEV ) { <nl> - align = NET_IP_ALIGN ; <nl> + align += NET_IP_ALIGN ; <nl> if ( unlikely ( len < ETH_HLEN || <nl> ( gso . hdr_len && gso . hdr_len < ETH_HLEN ))) <nl> return - EINVAL ;
bool gw_out_of_range ( struct bat_priv * bat_priv , <nl> } <nl>  <nl> neigh_old = find_router ( bat_priv , orig_dst_node , NULL ); <nl> - if (!! neigh_old ) <nl> + if (! neigh_old ) <nl> goto out ; <nl>  <nl> if ( curr_tq_avg - neigh_old -> tq_avg > GW_THRESHOLD )
void __init find_legacy_serial_ports ( void ) <nl> } <nl>  <nl> /* First fill our array with opb bus ports */ <nl> - for ( np = NULL ; ( np = of_find_compatible_node ( np , " serial ", " ns16750 ")) != NULL ;) { <nl> + for ( np = NULL ; ( np = of_find_compatible_node ( np , " serial ", " ns16550 ")) != NULL ;) { <nl> struct device_node * opb = of_get_parent ( np ); <nl> - if ( opb && ! strcmp ( opb -> type , " opb ")) { <nl> + if ( opb && (! strcmp ( opb -> type , " opb ") || <nl> + of_device_is_compatible ( opb , " ibm , opb "))) { <nl> index = add_legacy_soc_port ( np , np ); <nl> if ( index >= 0 && np == stdout ) <nl> legacy_serial_console = index ;
noinline int slow_avc_audit ( u32 ssid , u32 tsid , u16 tclass , <nl> * @ perms based on @ tclass . Returns % 0 on success or <nl> * -% ENOMEM if insufficient memory exists to add the callback . <nl> */ <nl> - int avc_add_callback ( int (* callback )( u32 event , u32 ssid , u32 tsid , <nl> + int __init avc_add_callback ( int (* callback )( u32 event , u32 ssid , u32 tsid , <nl> u16 tclass , u32 perms , <nl> u32 * out_retained ), <nl> u32 events , u32 ssid , u32 tsid , <nl> int avc_add_callback ( int (* callback )( u32 event , u32 ssid , u32 tsid , <nl> struct avc_callback_node * c ; <nl> int rc = 0 ; <nl>  <nl> - c = kmalloc ( sizeof (* c ), GFP_ATOMIC ); <nl> + c = kmalloc ( sizeof (* c ), GFP_KERNEL ); <nl> if (! c ) { <nl> rc = - ENOMEM ; <nl> goto out ;
static long __init sclp_hsa_size_init ( struct sdias_sccb * sccb ) <nl> sccb_init_eq_size ( sccb ); <nl> if ( sclp_cmd_early ( SCLP_CMDW_WRITE_EVENT_DATA , sccb )) <nl> return - EIO ; <nl> - if ( sccb -> evbuf . blk_cnt != 0 ) <nl> - return ( sccb -> evbuf . blk_cnt - 1 ) * PAGE_SIZE ; <nl> - return 0 ; <nl> + if ( sccb -> evbuf . blk_cnt == 0 ) <nl> + return 0 ; <nl> + return ( sccb -> evbuf . blk_cnt - 1 ) * PAGE_SIZE ; <nl> } <nl>  <nl> static long __init sclp_hsa_copy_wait ( struct sccb_header * sccb ) <nl> static long __init sclp_hsa_copy_wait ( struct sccb_header * sccb ) <nl> sccb -> length = PAGE_SIZE ; <nl> if ( sclp_cmd_early ( SCLP_CMDW_READ_EVENT_DATA , sccb )) <nl> return - EIO ; <nl> + if ((( struct sdias_sccb *) sccb )-> evbuf . blk_cnt == 0 ) <nl> + return 0 ; <nl> return ((( struct sdias_sccb *) sccb )-> evbuf . blk_cnt - 1 ) * PAGE_SIZE ; <nl> } <nl> 
static int __rfcomm_dlc_close ( struct rfcomm_dlc * d , int err ) <nl> rfcomm_dlc_unlock ( d ); <nl>  <nl> skb_queue_purge (& d -> tx_queue ); <nl> - rfcomm_session_put ( s ); <nl> - <nl> rfcomm_dlc_unlink ( d ); <nl> } <nl>  <nl> static struct rfcomm_session * rfcomm_session_create ( bdaddr_t * src , bdaddr_t * dst <nl> goto failed ; <nl> } <nl>  <nl> - rfcomm_session_hold ( s ); <nl> - <nl> s -> initiator = 1 ; <nl>  <nl> bacpy (& addr . l2_bdaddr , dst );
static ssize_t dfs_file_write ( struct file * file , const char __user * user_buf , <nl> } else if ( dent == d -> dfs_emulate_power_cut ) { <nl> if ( kstrtoint ( buf , 0 , & val ) != 0 ) <nl> count = - EINVAL ; <nl> - d -> emulate_power_cut = val ; <nl> + else <nl> + d -> emulate_power_cut = val ; <nl> goto out ; <nl> } <nl> 
static int nft_range_init ( const struct nft_ctx * ctx , const struct nft_expr * expr <nl> int err ; <nl> u32 op ; <nl>  <nl> + if (! tb [ NFTA_RANGE_SREG ] || <nl> + ! tb [ NFTA_RANGE_OP ] || <nl> + ! tb [ NFTA_RANGE_FROM_DATA ] || <nl> + ! tb [ NFTA_RANGE_TO_DATA ]) <nl> + return - EINVAL ; <nl> + <nl> err = nft_data_init ( NULL , & priv -> data_from , sizeof ( priv -> data_from ), <nl> & desc_from , tb [ NFTA_RANGE_FROM_DATA ]); <nl> if ( err < 0 )
static void tilcdc_crtc_destroy ( struct drm_crtc * crtc ) <nl> struct tilcdc_crtc * tilcdc_crtc = to_tilcdc_crtc ( crtc ); <nl> struct tilcdc_drm_private * priv = crtc -> dev -> dev_private ; <nl>  <nl> + drm_modeset_lock_crtc ( crtc , NULL ); <nl> tilcdc_crtc_disable ( crtc ); <nl> + drm_modeset_unlock_crtc ( crtc ); <nl>  <nl> flush_workqueue ( priv -> wq ); <nl> 
static const struct mfd_cell s5m8767_devs [] = { <nl> . name = " s5m - rtc ", <nl> }, { <nl> . name = " s5m8767 - clk ", <nl> + . of_compatible = " samsung , s5m8767 - clk ", <nl> } <nl> }; <nl>  <nl> static const struct mfd_cell s2mps11_devs [] = { <nl> . name = " s2mps11 - pmic ", <nl> }, { <nl> . name = " s2mps11 - clk ", <nl> + . of_compatible = " samsung , s2mps11 - clk ", <nl> } <nl> }; <nl>  <nl> static const struct mfd_cell s2mps14_devs [] = { <nl> . name = " s2mps14 - rtc ", <nl> }, { <nl> . name = " s2mps14 - clk ", <nl> + . of_compatible = " samsung , s2mps14 - clk ", <nl> } <nl> }; <nl> 
static int jr3_pci_auto_attach ( struct comedi_device * dev , <nl> if ( ret ) <nl> return ret ; <nl>  <nl> + if ( pci_resource_len ( pcidev , 0 ) < board -> n_subdevs * sizeof (* block )) <nl> + return - ENXIO ; <nl> + <nl> dev -> mmio = pci_ioremap_bar ( pcidev , 0 ); <nl> if (! dev -> mmio ) <nl> return - ENOMEM ;
static long vop_ioctl ( struct file * f , unsigned int cmd , unsigned long arg ) <nl> ret = - EFAULT ; <nl> goto free_ret ; <nl> } <nl> + /* Ensure desc has not changed between the two reads */ <nl> + if ( memcmp (& dd , dd_config , sizeof ( dd ))) { <nl> + ret = - EINVAL ; <nl> + goto free_ret ; <nl> + } <nl> mutex_lock (& vdev -> vdev_mutex ); <nl> mutex_lock (& vi -> vop_mutex ); <nl> ret = vop_virtio_add_device ( vdev , dd_config );
static int evm_protect_xattr ( struct dentry * dentry , const char * xattr_name , <nl> goto out ; <nl> } <nl> evm_status = evm_verify_current_integrity ( dentry ); <nl> + if ( evm_status == INTEGRITY_NOXATTRS ) { <nl> + struct integrity_iint_cache * iint ; <nl> + <nl> + iint = integrity_iint_find ( dentry -> d_inode ); <nl> + if ( iint && ( iint -> flags & IMA_NEW_FILE )) <nl> + return 0 ; <nl> + } <nl> out : <nl> if ( evm_status != INTEGRITY_PASS ) <nl> integrity_audit_msg ( AUDIT_INTEGRITY_METADATA , dentry -> d_inode ,
static int max_subband_chan ( int orig_cur_chan , <nl> break ; <nl> } <nl>  <nl> + if ( triplet -> chans . num_channels == 0 ) <nl> + return 0 ; <nl> + <nl> /* Monitonically increasing channel order */ <nl> if ( triplet -> chans . first_channel <= end_subband_chan ) <nl> return 0 ; <nl> static struct ieee80211_regdomain * country_ie_2_rd ( <nl> break ; <nl> } <nl>  <nl> + if ( triplet -> chans . num_channels == 0 ) <nl> + return NULL ; <nl> + <nl> /* 2 GHz */ <nl> if ( triplet -> chans . first_channel <= 14 ) <nl> end_channel = triplet -> chans . first_channel +
static int i2s_pll_clk_probe ( struct platform_device * pdev ) <nl> if ( IS_ERR ( pll_clk -> base )) <nl> return PTR_ERR ( pll_clk -> base ); <nl>  <nl> + memset (& init , 0 , sizeof ( init )); <nl> clk_name = node -> name ; <nl> init . name = clk_name ; <nl> init . ops = & i2s_pll_ops ;
static void EChannel_proc_rcv ( struct hisax_d_if * d_if ) <nl> # ifdef CONFIG_PCI <nl> # include < linux / pci . h > <nl>  <nl> - static struct pci_device_id hisax_pci_tbl [] __devinitdata = { <nl> + static struct pci_device_id hisax_pci_tbl [] __devinitdata __used = { <nl> # ifdef CONFIG_HISAX_FRITZPCI <nl> { PCI_VDEVICE ( AVM , PCI_DEVICE_ID_AVM_A1 ) }, <nl> # endif
int walk_system_ram_range ( unsigned long start_pfn , unsigned long nr_pages , <nl> void * arg , int (* func )( unsigned long , unsigned long , void *)) <nl> { <nl> struct resource res ; <nl> - unsigned long pfn , len ; <nl> + unsigned long pfn , end_pfn ; <nl> u64 orig_end ; <nl> int ret = - 1 ; <nl>  <nl> int walk_system_ram_range ( unsigned long start_pfn , unsigned long nr_pages , <nl> orig_end = res . end ; <nl> while (( res . start < res . end ) && <nl> ( find_next_system_ram (& res , " System RAM ") >= 0 )) { <nl> - pfn = ( unsigned long )( res . start >> PAGE_SHIFT ); <nl> - len = ( unsigned long )(( res . end + 1 - res . start ) >> PAGE_SHIFT ); <nl> - ret = (* func )( pfn , len , arg ); <nl> + pfn = ( res . start + PAGE_SIZE - 1 ) >> PAGE_SHIFT ; <nl> + end_pfn = ( res . end + 1 ) >> PAGE_SHIFT ; <nl> + if ( end_pfn > pfn ) <nl> + ret = (* func )( pfn , end_pfn - pfn , arg ); <nl> if ( ret ) <nl> break ; <nl> res . start = res . end + 1 ;
static int assign_guest_irq ( struct kvm * kvm , <nl> dev -> irq_requested_type |= guest_irq_type ; <nl> if ( dev -> ack_notifier . gsi != - 1 ) <nl> kvm_register_irq_ack_notifier ( kvm , & dev -> ack_notifier ); <nl> - } else <nl> + } else { <nl> kvm_free_irq_source_id ( kvm , dev -> irq_source_id ); <nl> + dev -> irq_source_id = - 1 ; <nl> + } <nl>  <nl> return r ; <nl> }
static void cyberjack_read_int_callback ( struct urb * urb ) <nl>  <nl> old_rdtodo = priv -> rdtodo ; <nl>  <nl> - if ( old_rdtodo + size < old_rdtodo ) { <nl> + if ( old_rdtodo > SHRT_MAX - size ) { <nl> dev_dbg ( dev , " To many bulk_in urbs to do .\ n "); <nl> spin_unlock (& priv -> lock ); <nl> goto resubmit ;
void hid_sensor_remove_trigger ( struct iio_dev * indio_dev ) <nl> { <nl> iio_trigger_unregister ( indio_dev -> trig ); <nl> iio_trigger_free ( indio_dev -> trig ); <nl> + indio_dev -> trig = NULL ; <nl> } <nl> EXPORT_SYMBOL ( hid_sensor_remove_trigger ); <nl> 
struct wm8994_ldo_pdata { <nl> int enable ; <nl>  <nl> const char * supply ; <nl> - struct regulator_init_data * init_data ; <nl> + const struct regulator_init_data * init_data ; <nl> }; <nl>  <nl> # define WM8994_CONFIGURE_GPIO 0x10000
static void get_new_segment ( struct f2fs_sb_info * sbi , <nl> if (! new_sec && ((* newseg + 1 ) % sbi -> segs_per_sec )) { <nl> segno = find_next_zero_bit ( free_i -> free_segmap , <nl> TOTAL_SEGS ( sbi ), * newseg + 1 ); <nl> - if ( segno < TOTAL_SEGS ( sbi )) <nl> + if ( segno - * newseg < sbi -> segs_per_sec - <nl> + (* newseg % sbi -> segs_per_sec )) <nl> goto got_it ; <nl> } <nl> find_other_zone :
static int imx_thermal_probe ( struct platform_device * pdev ) <nl> data -> tempmon = map ; <nl>  <nl> data -> socdata = of_device_get_match_data (& pdev -> dev ); <nl> + if (! data -> socdata ) { <nl> + dev_err (& pdev -> dev , " no device match found \ n "); <nl> + return - ENODEV ; <nl> + } <nl>  <nl> /* make sure the IRQ flag is clear before enabling irq on i . MX6SX */ <nl> if ( data -> socdata -> version == TEMPMON_IMX6SX ) {
static int pcm3168a_set_dai_sysclk ( struct snd_soc_dai * dai , <nl> int clk_id , unsigned int freq , int dir ) <nl> { <nl> struct pcm3168a_priv * pcm3168a = snd_soc_codec_get_drvdata ( dai -> codec ); <nl> + int ret ; <nl>  <nl> if ( freq > PCM1368A_MAX_SYSCLK ) <nl> return - EINVAL ; <nl>  <nl> + ret = clk_set_rate ( pcm3168a -> scki , freq ); <nl> + if ( ret ) <nl> + return ret ; <nl> + <nl> pcm3168a -> sysclk = freq ; <nl>  <nl> return 0 ;
__acquires ( musb -> lock ) <nl> : NULL <nl> ); <nl>  <nl> - /* report disconnect , if we didn ' t already ( flushing EP state ) */ <nl> - if ( musb -> g . speed != USB_SPEED_UNKNOWN ) <nl> - musb_g_disconnect ( musb ); <nl> + /* report reset , if we didn ' t already ( flushing EP state ) */ <nl> + if ( musb -> gadget_driver && musb -> g . speed != USB_SPEED_UNKNOWN ) { <nl> + spin_unlock (& musb -> lock ); <nl> + usb_gadget_udc_reset (& musb -> g , musb -> gadget_driver ); <nl> + spin_lock (& musb -> lock ); <nl> + } <nl>  <nl> /* clear HR */ <nl> else if ( devctl & MUSB_DEVCTL_HR )
static ssize_t read_mem ( struct file * file , char __user * buf , <nl> ssize_t read , sz ; <nl> char * ptr ; <nl>  <nl> + if ( p != * ppos ) <nl> + return 0 ; <nl> + <nl> if (! valid_phys_addr_range ( p , count )) <nl> return - EFAULT ; <nl> read = 0 ; <nl> static ssize_t write_mem ( struct file * file , const char __user * buf , <nl> unsigned long copied ; <nl> void * ptr ; <nl>  <nl> + if ( p != * ppos ) <nl> + return - EFBIG ; <nl> + <nl> if (! valid_phys_addr_range ( p , count )) <nl> return - EFAULT ; <nl> 
/* Maximum number of comma - separated items in the ' mtd =' parameter */ <nl> # define MTD_PARAM_MAX_COUNT 2 <nl>  <nl> +/* Maximum value for the number of bad PEBs per 1024 PEBs */ <nl> +# define MAX_MTD_UBI_BEB_LIMIT 768 <nl> + <nl> # ifdef CONFIG_MTD_UBI_MODULE <nl> # define ubi_is_module () 1 <nl> # else <nl> int ubi_attach_mtd_dev ( struct mtd_info * mtd , int ubi_num , <nl> struct ubi_device * ubi ; <nl> int i , err , ref = 0 ; <nl>  <nl> + if ( max_beb_per1024 < 0 || max_beb_per1024 > MAX_MTD_UBI_BEB_LIMIT ) <nl> + return - EINVAL ; <nl> + <nl> + if (! max_beb_per1024 ) <nl> + max_beb_per1024 = CONFIG_MTD_UBI_BEB_LIMIT ; <nl> + <nl> /* <nl> * Check if we already have the same MTD device attached . <nl> *
static int proc_pid_fill_cache ( struct file * filp , void * dirent , filldir_t filldi <nl> /* for the / proc / directory itself , after non - process stuff has been done */ <nl> int proc_pid_readdir ( struct file * filp , void * dirent , filldir_t filldir ) <nl> { <nl> - unsigned int nr = filp -> f_pos - FIRST_PROCESS_ENTRY ; <nl> - struct task_struct * reaper = get_proc_task ( filp -> f_path . dentry -> d_inode ); <nl> + unsigned int nr ; <nl> + struct task_struct * reaper ; <nl> struct tgid_iter iter ; <nl> struct pid_namespace * ns ; <nl>  <nl> + if ( filp -> f_pos >= PID_MAX_LIMIT + TGID_OFFSET ) <nl> + goto out_no_task ; <nl> + nr = filp -> f_pos - FIRST_PROCESS_ENTRY ; <nl> + <nl> + reaper = get_proc_task ( filp -> f_path . dentry -> d_inode ); <nl> if (! reaper ) <nl> goto out_no_task ; <nl> 
static int __devinit rtl8180_pci_probe ( struct pci_dev * pdev , <nl> struct net_device * dev = NULL ; <nl> struct r8180_priv * priv = NULL ; <nl> u8 unit = 0 ; <nl> + int ret = - ENODEV ; <nl>  <nl> unsigned long pmem_start , pmem_len , pmem_flags ; <nl>  <nl> static int __devinit rtl8180_pci_probe ( struct pci_dev * pdev , <nl> pci_set_dma_mask ( pdev , 0xffffff00ULL ); <nl> pci_set_consistent_dma_mask ( pdev , 0xffffff00ULL ); <nl> dev = alloc_ieee80211 ( sizeof ( struct r8180_priv )); <nl> - if (! dev ) <nl> - return - ENOMEM ; <nl> + if (! dev ) { <nl> + ret = - ENOMEM ; <nl> + goto fail_free ; <nl> + } <nl> priv = ieee80211_priv ( dev ); <nl> priv -> ieee80211 = netdev_priv ( dev ); <nl>  <nl> fail : <nl> free_ieee80211 ( dev ); <nl> } <nl>  <nl> + fail_free : <nl> pci_disable_device ( pdev ); <nl>  <nl> DMESG (" wlan driver load failed \ n "); <nl> pci_set_drvdata ( pdev , NULL ); <nl> - return - ENODEV ; <nl> + return ret ; <nl> } <nl>  <nl> static void __devexit rtl8180_pci_remove ( struct pci_dev * pdev )
get_static_power ( struct devfreq_cooling_device * dfc , unsigned long freq ) <nl> dev_pm_opp_put ( opp ); <nl>  <nl> if ( voltage == 0 ) { <nl> - dev_warn_ratelimited ( dev , <nl> - " Failed to get voltage for frequency % lu : % ld \ n ", <nl> - freq , IS_ERR ( opp ) ? PTR_ERR ( opp ) : 0 ); <nl> + dev_err_ratelimited ( dev , <nl> + " Failed to get voltage for frequency % lu : % ld \ n ", <nl> + freq , IS_ERR ( opp ) ? PTR_ERR ( opp ) : 0 ); <nl> return 0 ; <nl> } <nl> 
SYSCALL_DEFINE5 ( linkat , int , olddfd , const char __user *, oldname , <nl>  <nl> if ( flags & AT_SYMLINK_FOLLOW ) <nl> how |= LOOKUP_FOLLOW ; <nl> - <nl> + retry : <nl> error = user_path_at ( olddfd , oldname , how , & old_path ); <nl> if ( error ) <nl> return error ; <nl>  <nl> - new_dentry = user_path_create ( newdfd , newname , & new_path , 0 ); <nl> + new_dentry = user_path_create ( newdfd , newname , & new_path , <nl> + ( how & LOOKUP_REVAL )); <nl> error = PTR_ERR ( new_dentry ); <nl> if ( IS_ERR ( new_dentry )) <nl> goto out ; <nl> SYSCALL_DEFINE5 ( linkat , int , olddfd , const char __user *, oldname , <nl> error = vfs_link ( old_path . dentry , new_path . dentry -> d_inode , new_dentry ); <nl> out_dput : <nl> done_path_create (& new_path , new_dentry ); <nl> + if ( retry_estale ( error , how )) { <nl> + how |= LOOKUP_REVAL ; <nl> + goto retry ; <nl> + } <nl> out : <nl> path_put (& old_path ); <nl> 
static int orion_mdio_write ( struct mii_bus * bus , int mii_id , <nl> mutex_lock (& dev -> lock ); <nl>  <nl> ret = orion_mdio_wait_ready ( bus ); <nl> - if ( ret < 0 ) { <nl> - mutex_unlock (& dev -> lock ); <nl> - return ret ; <nl> - } <nl> + if ( ret < 0 ) <nl> + goto out ; <nl>  <nl> writel ((( mii_id << MVMDIO_SMI_PHY_ADDR_SHIFT ) | <nl> ( regnum << MVMDIO_SMI_PHY_REG_SHIFT ) | <nl> static int orion_mdio_write ( struct mii_bus * bus , int mii_id , <nl> ( value << MVMDIO_SMI_DATA_SHIFT )), <nl> dev -> regs ); <nl>  <nl> + out : <nl> mutex_unlock (& dev -> lock ); <nl> - <nl> - return 0 ; <nl> + return ret ; <nl> } <nl>  <nl> static int orion_mdio_reset ( struct mii_bus * bus )
acpi_parse_lapic ( struct acpi_subtable_header * header , const unsigned long end ) <nl>  <nl> acpi_table_print_madt_entry ( header ); <nl>  <nl> + /* Ignore invalid ID */ <nl> + if ( processor -> id == 0xff ) <nl> + return 0 ; <nl> + <nl> /* <nl> * We need to register disabled CPU as well to permit <nl> * counting disabled CPUs . This allows us to size
static int et131x_phy_mii_read ( struct et131x_adapter * adapter , u8 addr , <nl> mii_indicator ); <nl>  <nl> status = - EIO ; <nl> + goto out ; <nl> } <nl>  <nl> /* If we hit here we were able to read the register and we need to <nl> static int et131x_phy_mii_read ( struct et131x_adapter * adapter , u8 addr , <nl> */ <nl> * value = readl (& mac -> mii_mgmt_stat ) & ET_MAC_MIIMGMT_STAT_PHYCRTL_MASK ; <nl>  <nl> + out : <nl> /* Stop the read operation */ <nl> writel ( 0 , & mac -> mii_mgmt_cmd ); <nl> 
static int fusbh200_hcd_fusbh200_probe ( struct platform_device * pdev ) <nl>  <nl> retval = fusbh200_setup ( hcd ); <nl> if ( retval ) <nl> - return retval ; <nl> + goto fail_add_hcd ; <nl>  <nl> fusbh200_init ( fusbh200 ); <nl> 
static int llc_ui_recvmsg ( struct kiocb * iocb , struct socket * sock , <nl> struct sk_buff * skb = NULL ; <nl> struct sock * sk = sock -> sk ; <nl> struct llc_sock * llc = llc_sk ( sk ); <nl> + unsigned long cpu_flags ; <nl> size_t copied = 0 ; <nl> u32 peek_seq = 0 ; <nl> u32 * seq ; <nl> static int llc_ui_recvmsg ( struct kiocb * iocb , struct socket * sock , <nl> goto copy_uaddr ; <nl>  <nl> if (!( flags & MSG_PEEK )) { <nl> + spin_lock_irqsave (& sk -> sk_receive_queue . lock , cpu_flags ); <nl> sk_eat_skb ( sk , skb , 0 ); <nl> + spin_unlock_irqrestore (& sk -> sk_receive_queue . lock , cpu_flags ); <nl> * seq = 0 ; <nl> } <nl>  <nl> copy_uaddr : <nl> llc_cmsg_rcv ( msg , skb ); <nl>  <nl> if (!( flags & MSG_PEEK )) { <nl> + spin_lock_irqsave (& sk -> sk_receive_queue . lock , cpu_flags ); <nl> sk_eat_skb ( sk , skb , 0 ); <nl> + spin_unlock_irqrestore (& sk -> sk_receive_queue . lock , cpu_flags ); <nl> * seq = 0 ; <nl> } <nl> 
static int t4_sched_queue_bind ( struct port_info * pi , struct ch_sched_queue * p ) <nl>  <nl> /* Unbind queue from any existing class */ <nl> err = t4_sched_queue_unbind ( pi , p ); <nl> - if ( err ) <nl> + if ( err ) { <nl> + t4_free_mem ( qe ); <nl> goto out ; <nl> + } <nl>  <nl> /* Bind queue to specified class */ <nl> memset ( qe , 0 , sizeof (* qe ));
void mlx4_cmd_event ( struct mlx4_dev * dev , u16 token , u8 status , u64 out_param ) <nl> context -> result = mlx4_status_to_errno ( status ); <nl> context -> out_param = out_param ; <nl>  <nl> - context -> token += priv -> cmd . token_mask + 1 ; <nl> - <nl> complete (& context -> done ); <nl> } <nl>  <nl> static int mlx4_cmd_wait ( struct mlx4_dev * dev , u64 in_param , u64 * out_param , <nl> spin_lock (& cmd -> context_lock ); <nl> BUG_ON ( cmd -> free_head < 0 ); <nl> context = & cmd -> context [ cmd -> free_head ]; <nl> + context -> token += cmd -> token_mask + 1 ; <nl> cmd -> free_head = context -> next ; <nl> spin_unlock (& cmd -> context_lock ); <nl> 
void __init early_fixup_exception ( struct pt_regs * regs , int trapnr ) <nl> if ( early_recursion_flag > 2 ) <nl> goto halt_loop ; <nl>  <nl> - if ( regs -> cs != __KERNEL_CS ) <nl> + /* <nl> + * Old CPUs leave the high bits of CS on the stack <nl> + * undefined . I ' m not sure which CPUs do this , but at least <nl> + * the 486 DX works this way . <nl> + */ <nl> + if (( regs -> cs & 0xFFFF ) != __KERNEL_CS ) <nl> goto fail ; <nl>  <nl> /*
ieee80211_sta_process_chanswitch ( struct ieee80211_sub_if_data * sdata , <nl> case - 1 : <nl> cfg80211_chandef_create (& new_chandef , new_chan , <nl> NL80211_CHAN_NO_HT ); <nl> + /* keep width for 5 / 10 MHz channels */ <nl> + switch ( sdata -> vif . bss_conf . chandef . width ) { <nl> + case NL80211_CHAN_WIDTH_5 : <nl> + case NL80211_CHAN_WIDTH_10 : <nl> + new_chandef . width = sdata -> vif . bss_conf . chandef . width ; <nl> + break ; <nl> + default : <nl> + break ; <nl> + } <nl> break ; <nl> } <nl> 
# include < syslog . h > <nl> # endif <nl>  <nl> -# define S8 int8_t <nl> # define S16 int16_t <nl> # define S32 int32_t <nl> # define S64 int64_t
static int fs_open ( struct atm_vcc * atm_vcc ) <nl> /* Docs are vague about this atm_hdr field . By the way , the FS <nl> * chip makes odd errors if lower bits are set .... -- REW */ <nl> tc -> atm_hdr = ( vpi << 20 ) | ( vci << 4 ); <nl> + tmc0 = 0 ; <nl> { <nl> int pcr = atm_pcr_goal ( txtp ); <nl> 
static ssize_t devkmsg_read ( struct file * file , char __user * buf , <nl> for ( i = 0 ; i < msg -> text_len ; i ++) { <nl> unsigned char c = log_text ( msg )[ i ]; <nl>  <nl> - if ( c < ' ' || c >= 128 ) <nl> + if ( c < ' ' || c >= 127 || c == '\\') <nl> len += sprintf ( user -> buf + len , "\\ x % 02x ", c ); <nl> else <nl> user -> buf [ len ++] = c ; <nl> static ssize_t devkmsg_read ( struct file * file , char __user * buf , <nl> continue ; <nl> } <nl>  <nl> - if ( c < ' ' || c >= 128 ) { <nl> + if ( c < ' ' || c >= 127 || c == '\\') { <nl> len += sprintf ( user -> buf + len , "\\ x % 02x ", c ); <nl> continue ; <nl> }
static int rt5645_irq_detection ( struct rt5645_priv * rt5645 ) <nl> { <nl> int val , btn_type , gpio_state = 0 , report = 0 ; <nl>  <nl> + if (! rt5645 -> codec ) <nl> + return - EINVAL ; <nl> + <nl> switch ( rt5645 -> pdata . jd_mode ) { <nl> case 0 : /* Not using rt5645 JD */ <nl> if ( rt5645 -> gpiod_hp_det ) {
int filter_add_pred ( struct ftrace_event_call * call , struct filter_pred * pred ) <nl> pred -> offset = field -> offset ; <nl>  <nl> if ( is_string_field ( field -> type )) { <nl> + if (! pred -> str_val ) <nl> + return - EINVAL ; <nl> pred -> fn = filter_pred_string ; <nl> pred -> str_len = field -> size ; <nl> return __filter_add_pred ( call , pred ); <nl> + } else { <nl> + if ( pred -> str_val ) <nl> + return - EINVAL ; <nl> } <nl>  <nl> switch ( field -> size ) {
static void ib_sa_remove_one ( struct ib_device * device ) <nl>  <nl> for ( i = 0 ; i <= sa_dev -> end_port - sa_dev -> start_port ; ++ i ) { <nl> ib_unregister_mad_agent ( sa_dev -> port [ i ]. agent ); <nl> - kref_put (& sa_dev -> port [ i ]. sm_ah -> ref , free_sm_ah ); <nl> + if ( sa_dev -> port [ i ]. sm_ah ) <nl> + kref_put (& sa_dev -> port [ i ]. sm_ah -> ref , free_sm_ah ); <nl> } <nl>  <nl> kfree ( sa_dev );
static void squashfs_put_super ( struct super_block * sb ) <nl> kfree ( sbi -> id_table ); <nl> kfree ( sbi -> fragment_index ); <nl> kfree ( sbi -> meta_index ); <nl> + kfree ( sbi -> inode_lookup_table ); <nl> kfree ( sb -> s_fs_info ); <nl> sb -> s_fs_info = NULL ; <nl> }
static const struct syscfg_reset_channel_data stih407_powerdowns [] = { <nl> }; <nl>  <nl> /* Reset Generator control 0 / 1 */ <nl> +# define SYSCFG_5128 0x200 <nl> # define SYSCFG_5131 0x20c <nl> # define SYSCFG_5132 0x210 <nl>  <nl> static const struct syscfg_reset_channel_data stih407_softresets [] = { <nl> [ STIH407_ERAM_HVA_SOFTRESET ] = STIH407_SRST_CORE ( SYSCFG_5132 , 1 ), <nl> [ STIH407_LPM_SOFTRESET ] = STIH407_SRST_SBC ( SYSCFG_4002 , 2 ), <nl> [ STIH407_KEYSCAN_SOFTRESET ] = STIH407_SRST_LPM ( LPM_SYSCFG_1 , 8 ), <nl> + [ STIH407_ST231_AUD_SOFTRESET ] = STIH407_SRST_CORE ( SYSCFG_5131 , 26 ), <nl> + [ STIH407_ST231_DMU_SOFTRESET ] = STIH407_SRST_CORE ( SYSCFG_5131 , 27 ), <nl> + [ STIH407_ST231_GP0_SOFTRESET ] = STIH407_SRST_CORE ( SYSCFG_5131 , 28 ), <nl> + [ STIH407_ST231_GP1_SOFTRESET ] = STIH407_SRST_CORE ( SYSCFG_5128 , 2 ), <nl> }; <nl>  <nl> /* PicoPHY reset / control */
i915_gem_set_tiling ( struct drm_device * dev , void * data , <nl> } <nl>  <nl> mutex_lock (& dev -> struct_mutex ); <nl> - if ( i915_gem_obj_is_pinned ( obj ) || obj -> framebuffer_references ) { <nl> + if ( obj -> pin_display || obj -> framebuffer_references ) { <nl> ret = - EBUSY ; <nl> goto err ; <nl> }
void wiphy_regulatory_deregister ( struct wiphy * wiphy ) <nl> static void reg_timeout_work ( struct work_struct * work ) <nl> { <nl> REG_DBG_PRINT (" Timeout while waiting for CRDA to reply , restoring regulatory settings \ n "); <nl> + rtnl_lock (); <nl> restore_regulatory_settings ( true ); <nl> + rtnl_unlock (); <nl> } <nl>  <nl> int __init regulatory_init ( void )
int mmap_min_addr_handler ( struct ctl_table * table , int write , <nl> { <nl> int ret ; <nl>  <nl> + if (! capable ( CAP_SYS_RAWIO )) <nl> + return - EPERM ; <nl> + <nl> ret = proc_doulongvec_minmax ( table , write , buffer , lenp , ppos ); <nl>  <nl> update_mmap_min_addr ();
static void ext4_free_data ( handle_t * handle , struct inode * inode , <nl> * block pointed to itself , it would have been detached when <nl> * the block was cleared . Check for this instead of OOPSing . <nl> */ <nl> - if ( bh2jh ( this_bh )) <nl> + if (( EXT4_JOURNAL ( inode ) == NULL ) || bh2jh ( this_bh )) <nl> ext4_handle_dirty_metadata ( handle , inode , this_bh ); <nl> else <nl> ext4_error ( inode -> i_sb , __func__ ,
static void ironlake_enable_pch_transcoder ( struct drm_i915_private * dev_priv , <nl> val |= TRANS_PROGRESSIVE ; <nl>  <nl> I915_WRITE ( reg , val | TRANS_ENABLE ); <nl> - if ( wait_for ( I915_READ ( reg ) & TRANS_STATE_ENABLE , 100 )) <nl> + if ( intel_wait_for_register ( dev_priv , <nl> + reg , TRANS_STATE_ENABLE , TRANS_STATE_ENABLE , <nl> + 100 )) <nl> DRM_ERROR (" failed to enable transcoder % c \ n ", pipe_name ( pipe )); <nl> } <nl> 
static void snapshot_merge_next_chunks ( struct dm_snapshot * s ) <nl> s -> num_merging_chunks = 1 ; <nl> up_write (& s -> lock ); <nl>  <nl> - /* !!! FIXME : wait until writes to this chunk drain */ <nl> + __check_for_conflicting_io ( s , old_chunk ); <nl>  <nl> dm_kcopyd_copy ( s -> kcopyd_client , & src , 1 , & dest , 0 , merge_callback , s ); <nl> return ; <nl> static int snapshot_merge_map ( struct dm_target * ti , struct bio * bio , <nl> r = DM_MAPIO_SUBMITTED ; <nl> goto out_unlock ; <nl> } <nl> + <nl> remap_exception ( s , e , bio , chunk ); <nl> + <nl> + if ( bio_rw ( bio ) == WRITE ) <nl> + map_context -> ptr = track_chunk ( s , chunk ); <nl> goto out_unlock ; <nl> } <nl> 
static struct inotify_watch * create_watch ( struct inotify_device * dev , <nl> return ERR_PTR ( ret ); <nl> } <nl>  <nl> - dev -> last_wd = ret ; <nl> + dev -> last_wd = watch -> wd ; <nl> watch -> mask = mask ; <nl> atomic_set (& watch -> count , 0 ); <nl> INIT_LIST_HEAD (& watch -> d_list );
static void get_detailed_timing ( unsigned char * block , <nl> mode -> sync |= FB_SYNC_VERT_HIGH_ACT ; <nl> mode -> refresh = PIXEL_CLOCK /(( H_ACTIVE + H_BLANKING ) * <nl> ( V_ACTIVE + V_BLANKING )); <nl> - mode -> vmode = 0 ; <nl> + if ( INTERLACED ) { <nl> + mode -> yres *= 2 ; <nl> + mode -> upper_margin *= 2 ; <nl> + mode -> lower_margin *= 2 ; <nl> + mode -> vsync_len *= 2 ; <nl> + mode -> vmode |= FB_VMODE_INTERLACED ; <nl> + } <nl> mode -> flag = FB_MODE_IS_DETAILED ; <nl>  <nl> DPRINTK (" % d MHz ", PIXEL_CLOCK / 1000000 );
# include < linux / pci . h > <nl> # include < linux / acpi . h > <nl> # include < linux / list . h > <nl> +# include < linux / bitmap . h > <nl> # include < linux / slab . h > <nl> # include < linux / syscore_ops . h > <nl> # include < linux / interrupt . h > <nl> static int __init early_amd_iommu_init ( void ) <nl> * never allocate domain 0 because its used as the non - allocated and <nl> * error value placeholder <nl> */ <nl> - amd_iommu_pd_alloc_bitmap [ 0 ] = 1 ; <nl> + __set_bit ( 0 , amd_iommu_pd_alloc_bitmap ); <nl>  <nl> spin_lock_init (& amd_iommu_pd_lock ); <nl> 
int mg_get_local_EKB ( struct scsi_cmnd * srb , struct rtsx_chip * chip ) <nl> set_sense_type ( chip , lun , SENSE_TYPE_MG_KEY_FAIL_NOT_AUTHEN ); <nl> rtsx_clear_ms_error ( chip ); <nl> rtsx_trace ( chip ); <nl> - return STATUS_FAIL ; <nl> + retval = STATUS_FAIL ; <nl> + goto free_buffer ; <nl> } <nl>  <nl> bufflen = min_t ( int , 1052 , scsi_bufflen ( srb )); <nl> int mg_get_ICV ( struct scsi_cmnd * srb , struct rtsx_chip * chip ) <nl> set_sense_type ( chip , lun , SENSE_TYPE_MEDIA_UNRECOVER_READ_ERR ); <nl> rtsx_clear_ms_error ( chip ); <nl> rtsx_trace ( chip ); <nl> - return STATUS_FAIL ; <nl> + retval = STATUS_FAIL ; <nl> + goto free_buffer ; <nl> } <nl>  <nl> bufflen = min_t ( int , 1028 , scsi_bufflen ( srb ));
static inline int phy_set_mode ( struct phy * phy , enum phy_mode mode ) <nl> return - ENOSYS ; <nl> } <nl>  <nl> + static inline int phy_reset ( struct phy * phy ) <nl> +{ <nl> + if (! phy ) <nl> + return 0 ; <nl> + return - ENOSYS ; <nl> +} <nl> + <nl> static inline int phy_get_bus_width ( struct phy * phy ) <nl> { <nl> return - ENOSYS ;
int btrfs_reserve_extent ( struct btrfs_root * root , <nl> u64 empty_size , u64 hint_byte , <nl> struct btrfs_key * ins , int is_data , int delalloc ) <nl> { <nl> - bool final_tried = false ; <nl> + bool final_tried = num_bytes == min_alloc_size ; <nl> u64 flags ; <nl> int ret ; <nl> 
static int bond_release_and_destroy ( struct net_device * bond_dev , <nl> bond_dev -> priv_flags |= IFF_DISABLE_NETPOLL ; <nl> netdev_info ( bond_dev , " Destroying bond % s \ n ", <nl> bond_dev -> name ); <nl> + bond_remove_proc_entry ( bond ); <nl> unregister_netdevice ( bond_dev ); <nl> } <nl> return ret ;
static long gfs2_fallocate ( struct file * file , int mode , loff_t offset , <nl> if ( bytes == 0 ) <nl> bytes = sdp -> sd_sb . sb_bsize ; <nl>  <nl> + error = gfs2_rindex_update ( sdp ); <nl> + if ( error ) { <nl> + fs_warn ( sdp , " rindex update returns % d \ n ", error ); <nl> + return error ; <nl> + } <nl> gfs2_holder_init ( ip -> i_gl , LM_ST_EXCLUSIVE , 0 , & ip -> i_gh ); <nl> error = gfs2_glock_nq (& ip -> i_gh ); <nl> if ( unlikely ( error ))
struct bcm2835_audio_instance { <nl> short peer_version ; <nl> }; <nl>  <nl> - bool force_bulk = false ; <nl> + static bool force_bulk ; <nl>  <nl> /* ---- Private Variables ---------------------------------------------------- */ <nl> 
static void gb_tty_set_termios ( struct tty_struct * tty , <nl>  <nl> if ( C_BAUD ( tty ) == B0 ) { <nl> newline . rate = gb_tty -> line_coding . rate ; <nl> - newctrl &= GB_UART_CTRL_DTR ; <nl> + newctrl &= ~ GB_UART_CTRL_DTR ; <nl> } else if ( termios_old && ( termios_old -> c_cflag & CBAUD ) == B0 ) { <nl> newctrl |= GB_UART_CTRL_DTR ; <nl> }
static bool nested_vmx_exit_handled_msr ( struct kvm_vcpu * vcpu , <nl> u32 msr_index = vcpu -> arch . regs [ VCPU_REGS_RCX ]; <nl> gpa_t bitmap ; <nl>  <nl> - if (! nested_cpu_has ( get_vmcs12 ( vcpu ), CPU_BASED_USE_MSR_BITMAPS )) <nl> + if (! nested_cpu_has ( vmcs12 , CPU_BASED_USE_MSR_BITMAPS )) <nl> return 1 ; <nl>  <nl> /*
static void nfs_increment_seqid ( int status , struct nfs_seqid * seqid ) <nl> case - NFS4ERR_BADXDR : <nl> case - NFS4ERR_RESOURCE : <nl> case - NFS4ERR_NOFILEHANDLE : <nl> + case - NFS4ERR_MOVED : <nl> /* Non - seqid mutating errors */ <nl> return ; <nl> };
UEA_ATTR ( firmid , 0 ); <nl>  <nl> /* Retrieve the device End System Identifier ( MAC ) */ <nl>  <nl> - static int uea_getesi ( struct uea_softc * sc , u_char * esi ) <nl> + static int uea_getesi ( struct uea_softc * sc , u_char * esi ) <nl> { <nl> unsigned char mac_str [ 2 * ETH_ALEN + 1 ]; <nl> int i ;
__cmpxchg_u32 ( volatile unsigned int * p , unsigned int old , unsigned int new ) <nl> " bra 2f ; \ n " <nl> " . fillinsn \ n " <nl> " 1 :" <nl> - M32R_UNLOCK " % 2 , @% 1 ; \ n " <nl> + M32R_UNLOCK " % 0 , @% 1 ; \ n " <nl> " . fillinsn \ n " <nl> " 2 :" <nl> : "=& r " ( retval )
static int nes_destroy_cq ( struct ib_cq * ib_cq ) <nl> static u32 root_256 ( struct nes_device * nesdev , <nl> struct nes_root_vpbl * root_vpbl , <nl> struct nes_root_vpbl * new_root , <nl> - u16 pbl_count_4k , <nl> - u16 pbl_count_256 ) <nl> + u16 pbl_count_4k ) <nl> { <nl> u64 leaf_pbl ; <nl> int i , j , k ; <nl> static int nes_reg_mr ( struct nes_device * nesdev , struct nes_pd * nespd , <nl> } <nl>  <nl> if ( use_256_pbls && use_two_level ) { <nl> - if ( root_256 ( nesdev , root_vpbl , & new_root , pbl_count_4k , pbl_count_256 ) == 1 ) { <nl> + if ( root_256 ( nesdev , root_vpbl , & new_root , pbl_count_4k ) == 1 ) { <nl> if ( new_root . pbl_pbase != 0 ) <nl> root_vpbl = & new_root ; <nl> } else {
static void smk_rule_show ( struct seq_file * s , struct smack_rule * srp , int max ) <nl> if ( strlen ( srp -> smk_subject ) >= max || strlen ( srp -> smk_object ) >= max ) <nl> return ; <nl>  <nl> + if ( srp -> smk_access == 0 ) <nl> + return ; <nl> + <nl> seq_printf ( s , "% s % s ", srp -> smk_subject , srp -> smk_object ); <nl>  <nl> seq_putc ( s , ' '); <nl> static void smk_rule_show ( struct seq_file * s , struct smack_rule * srp , int max ) <nl> seq_putc ( s , ' a '); <nl> if ( srp -> smk_access & MAY_TRANSMUTE ) <nl> seq_putc ( s , ' t '); <nl> - if ( srp -> smk_access == 0 ) <nl> - seq_putc ( s , '-'); <nl>  <nl> seq_putc ( s , '\ n '); <nl> }
static int b43_wireless_core_init ( struct b43_wldev * dev ) <nl> if (! dev -> suspend_in_progress ) <nl> b43_rng_init ( wl ); <nl>  <nl> + ieee80211_wake_queues ( dev -> wl -> hw ); <nl> + <nl> b43_set_status ( dev , B43_STAT_INITIALIZED ); <nl>  <nl> if (! dev -> suspend_in_progress )
static int hpfs_remount_fs ( struct super_block * s , int * flags , char * data ) <nl> int o ; <nl> struct hpfs_sb_info * sbi = hpfs_sb ( s ); <nl> char * new_opts = kstrdup ( data , GFP_KERNEL ); <nl> - <nl> + <nl> + if (! new_opts ) <nl> + return - ENOMEM ; <nl> + <nl> sync_filesystem ( s ); <nl>  <nl> * flags |= MS_NOATIME ; <nl> - <nl> + <nl> hpfs_lock ( s ); <nl> uid = sbi -> sb_uid ; gid = sbi -> sb_gid ; <nl> umask = 0777 & ~ sbi -> sb_mode ;
static int s3c64xx_i2s_set_sysclk ( struct snd_soc_dai * cpu_dai , <nl> struct clk * s3c64xx_i2s_get_clock ( struct snd_soc_dai * dai ) <nl> { <nl> struct s3c_i2sv2_info * i2s = to_info ( dai ); <nl> + u32 iismod = readl ( i2s -> regs + S3C2412_IISMOD ); <nl>  <nl> - return i2s -> iis_cclk ; <nl> + if ( iismod & S3C64XX_IISMOD_IMS_SYSMUX ) <nl> + return i2s -> iis_cclk ; <nl> + else <nl> + return i2s -> iis_pclk ; <nl> } <nl> EXPORT_SYMBOL_GPL ( s3c64xx_i2s_get_clock ); <nl> 
static int ath9k_add_interface ( struct ieee80211_hw * hw , <nl> } <nl> } <nl>  <nl> - if (( vif -> type == NL80211_IFTYPE_ADHOC ) && <nl> - sc -> nvifs > 0 ) { <nl> + if (( ah -> opmode == NL80211_IFTYPE_ADHOC ) || <nl> + (( vif -> type == NL80211_IFTYPE_ADHOC ) && <nl> + sc -> nvifs > 0 )) { <nl> ath_err ( common , " Cannot create ADHOC interface when other " <nl> " interfaces already exist .\ n "); <nl> ret = - EINVAL ;
int perf_session__cpu_bitmap ( struct perf_session * session , <nl> } <nl>  <nl> map = cpu_map__new ( cpu_list ); <nl> + if ( map == NULL ) { <nl> + pr_err (" Invalid cpu_list \ n "); <nl> + return - 1 ; <nl> + } <nl>  <nl> for ( i = 0 ; i < map -> nr ; i ++) { <nl> int cpu = map -> map [ i ];
int saa7134_g_ctrl ( struct file * file , void * priv , struct v4l2_control * c ) <nl> } <nl> return 0 ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( saa7134_g_ctrl ); <nl>  <nl> int saa7134_s_ctrl ( struct file * file , void * f , struct v4l2_control * c ) <nl> { <nl> error : <nl> mutex_unlock (& dev -> lock ); <nl> return err ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( saa7134_s_ctrl ); <nl>  <nl> /* ------------------------------------------------------------------ */ <nl>  <nl> int saa7134_queryctrl ( struct file * file , void * priv , struct v4l2_queryctrl * c ) <nl> * c = ( NULL != ctrl ) ? * ctrl : no_ctrl ; <nl> return 0 ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( saa7134_queryctrl ); <nl>  <nl> static int saa7134_enum_input ( struct file * file , void * priv , <nl> struct v4l2_input * i )
static int lowpan_newlink ( struct net * src_net , struct net_device * dev , <nl> real_dev = dev_get_by_index ( src_net , nla_get_u32 ( tb [ IFLA_LINK ])); <nl> if (! real_dev ) <nl> return - ENODEV ; <nl> + if ( real_dev -> type != ARPHRD_IEEE802154 ) <nl> + return - EINVAL ; <nl>  <nl> lowpan_dev_info ( dev )-> real_dev = real_dev ; <nl> lowpan_dev_info ( dev )-> fragment_tag = 0 ;
static int reada_start_machine_dev ( struct btrfs_fs_info * fs_info , <nl> } <nl> logical = re -> logical ; <nl>  <nl> - reada_extent_put ( fs_info , re ); <nl> - <nl> atomic_inc (& dev -> reada_in_flight ); <nl> ret = reada_tree_block_flagged ( fs_info -> extent_root , logical , <nl> mirror_num , & eb ); <nl> static int reada_start_machine_dev ( struct btrfs_fs_info * fs_info , <nl> if ( eb ) <nl> free_extent_buffer ( eb ); <nl>  <nl> + reada_extent_put ( fs_info , re ); <nl> + <nl> return 1 ; <nl>  <nl> }
next_extent : <nl> error = xfs_btree_decrement ( cur , 0 , & i ); <nl> if ( error ) <nl> goto out_del_cursor ; <nl> + <nl> + if ( fatal_signal_pending ( current )) { <nl> + error = - ERESTARTSYS ; <nl> + goto out_del_cursor ; <nl> + } <nl> } <nl>  <nl> out_del_cursor : <nl> xfs_ioc_trim ( <nl> for ( agno = start_agno ; agno <= end_agno ; agno ++) { <nl> error = xfs_trim_extents ( mp , agno , start , end , minlen , <nl> & blocks_trimmed ); <nl> - if ( error ) <nl> + if ( error ) { <nl> last_error = error ; <nl> + if ( error == - ERESTARTSYS ) <nl> + break ; <nl> + } <nl> } <nl>  <nl> if ( last_error )
int __fatal_signal_pending ( struct task_struct * tsk ) <nl> } <nl> EXPORT_SYMBOL ( __fatal_signal_pending ); <nl>  <nl> -/* <nl> - * Must be called under rcu_read_lock () or with tasklist_lock read - held . <nl> - */ <nl> struct sighand_struct * lock_task_sighand ( struct task_struct * tsk , unsigned long * flags ) <nl> { <nl> struct sighand_struct * sighand ; <nl>  <nl> + rcu_read_lock (); <nl> for (;;) { <nl> sighand = rcu_dereference ( tsk -> sighand ); <nl> if ( unlikely ( sighand == NULL )) <nl> struct sighand_struct * lock_task_sighand ( struct task_struct * tsk , unsigned long <nl> break ; <nl> spin_unlock_irqrestore (& sighand -> siglock , * flags ); <nl> } <nl> + rcu_read_unlock (); <nl>  <nl> return sighand ; <nl> }
void audit_log_hex ( struct audit_buffer * ab , const unsigned char * buf , <nl> struct sk_buff * skb ; <nl> static const unsigned char * hex = " 0123456789ABCDEF "; <nl>  <nl> + if (! ab ) <nl> + return ; <nl> + <nl> BUG_ON (! ab -> skb ); <nl> skb = ab -> skb ; <nl> avail = skb_tailroom ( skb ); <nl> static void audit_log_n_string ( struct audit_buffer * ab , size_t slen , <nl> unsigned char * ptr ; <nl> struct sk_buff * skb ; <nl>  <nl> + if (! ab ) <nl> + return ; <nl> + <nl> BUG_ON (! ab -> skb ); <nl> skb = ab -> skb ; <nl> avail = skb_tailroom ( skb );
static int __devinit mei_probe ( struct pci_dev * pdev , <nl> err = request_threaded_irq ( pdev -> irq , <nl> NULL , <nl> mei_interrupt_thread_handler , <nl> - 0 , mei_driver_name , dev ); <nl> + IRQF_ONESHOT , mei_driver_name , dev ); <nl> else <nl> err = request_threaded_irq ( pdev -> irq , <nl> mei_interrupt_quick_handler ,
static inline int is_selected ( int dor , int unit ) <nl>  <nl> static int set_dor ( int fdc , char mask , char data ) <nl> { <nl> - register unsigned char drive , unit , newdor , olddor ; <nl> + unsigned char unit ; <nl> + unsigned char drive ; <nl> + unsigned char newdor ; <nl> + unsigned char olddor ; <nl>  <nl> if ( FDCS -> address == - 1 ) <nl> return - 1 ; <nl> static void motor_off_callback ( unsigned long nr ) <nl> static void floppy_off ( unsigned int drive ) <nl> { <nl> unsigned long volatile delta ; <nl> - register int fdc = FDC ( drive ); <nl> + int fdc = FDC ( drive ); <nl>  <nl> if (!( FDCS -> dor & ( 0x10 << UNIT ( drive )))) <nl> return ;
static int gpio_fan_probe ( struct platform_device * pdev ) <nl> return 0 ; <nl> } <nl>  <nl> + static void gpio_fan_shutdown ( struct platform_device * pdev ) <nl> +{ <nl> + struct gpio_fan_data * fan_data = dev_get_drvdata (& pdev -> dev ); <nl> + <nl> + if ( fan_data -> ctrl ) <nl> + set_fan_speed ( fan_data , 0 ); <nl> +} <nl> + <nl> # ifdef CONFIG_PM_SLEEP <nl> static int gpio_fan_suspend ( struct device * dev ) <nl> { <nl> static SIMPLE_DEV_PM_OPS ( gpio_fan_pm , gpio_fan_suspend , gpio_fan_resume ); <nl>  <nl> static struct platform_driver gpio_fan_driver = { <nl> . probe = gpio_fan_probe , <nl> + . shutdown = gpio_fan_shutdown , <nl> . driver = { <nl> . name = " gpio - fan ", <nl> . pm = GPIO_FAN_PM ,
static void ether3_setmulticastlist ( struct net_device * dev ) <nl> if ( dev -> flags & IFF_PROMISC ) { <nl> /* promiscuous mode */ <nl> priv ( dev )-> regs . config1 |= CFG1_RECVPROMISC ; <nl> - } else if ( dev -> flags & IFF_ALLMULTI ) { <nl> + } else if ( dev -> flags & IFF_ALLMULTI || dev -> mc_count ) { <nl> priv ( dev )-> regs . config1 |= CFG1_RECVSPECBRMULTI ; <nl> } else <nl> priv ( dev )-> regs . config1 |= CFG1_RECVSPECBROAD ;
static void _rocker_neigh_add ( struct rocker * rocker , <nl> enum switchdev_trans trans , <nl> struct rocker_neigh_tbl_entry * entry ) <nl> { <nl> - entry -> index = rocker -> neigh_tbl_next_index ; <nl> + if ( trans != SWITCHDEV_TRANS_COMMIT ) <nl> + entry -> index = rocker -> neigh_tbl_next_index ++; <nl> if ( trans == SWITCHDEV_TRANS_PREPARE ) <nl> return ; <nl> - rocker -> neigh_tbl_next_index ++; <nl> entry -> ref_count ++; <nl> hash_add ( rocker -> neigh_tbl , & entry -> entry , <nl> be32_to_cpu ( entry -> ip_addr ));
static void tpacket_destruct_skb ( struct sk_buff * skb ) <nl> struct packet_sock * po = pkt_sk ( skb -> sk ); <nl> void * ph ; <nl>  <nl> - BUG_ON ( skb == NULL ); <nl> - <nl> if ( likely ( po -> tx_ring . pg_vec )) { <nl> ph = skb_shinfo ( skb )-> destructor_arg ; <nl> BUG_ON ( __packet_get_status ( po , ph ) != TP_STATUS_SENDING );
intel_dp_mode_valid ( struct drm_connector * connector , <nl> if ( mode -> clock < 10000 ) <nl> return MODE_CLOCK_LOW ; <nl>  <nl> + if ( mode -> flags & DRM_MODE_FLAG_DBLCLK ) <nl> + return MODE_H_ILLEGAL ; <nl> + <nl> return MODE_OK ; <nl> } <nl>  <nl> intel_dp_mode_fixup ( struct drm_encoder * encoder , struct drm_display_mode * mode , <nl> mode -> clock = intel_dp -> panel_fixed_mode -> clock ; <nl> } <nl>  <nl> + if ( mode -> flags & DRM_MODE_FLAG_DBLCLK ) <nl> + return false ; <nl> + <nl> DRM_DEBUG_KMS (" DP link computation with max lane count % i " <nl> " max bw % 02x pixel clock % iKHz \ n ", <nl> max_lane_count , bws [ max_clock ], mode -> clock );
static struct ab8500_regulator_info <nl> . voltage_bank = 0x03 , <nl> . voltage_reg = 0x83 , <nl> . voltage_mask = 0xc0 , <nl> + . voltage_shift = 6 , <nl> }, <nl>  <nl> /*
static int amdgpu_ttm_io_mem_reserve ( struct ttm_bo_device * bdev , struct ttm_mem_ <nl> mem -> bus . addr = <nl> ioremap_nocache ( mem -> bus . base + mem -> bus . offset , <nl> mem -> bus . size ); <nl> + if (! mem -> bus . addr ) <nl> + return - ENOMEM ; <nl>  <nl> /* <nl> * Alpha : Use just the bus offset plus
static void pic_clear_isr ( struct kvm_kpic_state * s , int irq ) <nl> void kvm_pic_clear_isr_ack ( struct kvm * kvm ) <nl> { <nl> struct kvm_pic * s = pic_irqchip ( kvm ); <nl> + pic_lock ( s ); <nl> s -> pics [ 0 ]. isr_ack = 0xff ; <nl> s -> pics [ 1 ]. isr_ack = 0xff ; <nl> + pic_unlock ( s ); <nl> } <nl>  <nl> /*
fastcall void __kprobes do_general_protection ( struct pt_regs * regs , <nl> tss -> io_bitmap_max - thread -> io_bitmap_max ); <nl> tss -> io_bitmap_max = thread -> io_bitmap_max ; <nl> tss -> io_bitmap_base = IO_BITMAP_OFFSET ; <nl> + tss -> io_bitmap_owner = thread ; <nl> put_cpu (); <nl> return ; <nl> }
static struct davinci_nand_pdata davinci_nand_data = { <nl> . nr_parts = ARRAY_SIZE ( davinci_nand_partitions ), <nl> . ecc_mode = NAND_ECC_HW , <nl> . options = NAND_USE_FLASH_BBT , <nl> + . ecc_bits = 4 , <nl> }; <nl>  <nl> static struct resource davinci_nand_resources [] = {
int percpu_ref_init ( struct percpu_ref * ref , percpu_ref_func_t * release ) <nl> ref -> release = release ; <nl> return 0 ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( percpu_ref_init ); <nl>  <nl> /** <nl> * percpu_ref_cancel_init - cancel percpu_ref_init () <nl> void percpu_ref_cancel_init ( struct percpu_ref * ref ) <nl> free_percpu ( ref -> pcpu_count ); <nl> } <nl> } <nl> + EXPORT_SYMBOL_GPL ( percpu_ref_cancel_init ); <nl>  <nl> static void percpu_ref_kill_rcu ( struct rcu_head * rcu ) <nl> { <nl> void percpu_ref_kill_and_confirm ( struct percpu_ref * ref , <nl>  <nl> call_rcu_sched (& ref -> rcu , percpu_ref_kill_rcu ); <nl> } <nl> + EXPORT_SYMBOL_GPL ( percpu_ref_kill_and_confirm );
static int cipso_v4_map_cat_rbm_hton ( const struct cipso_v4_doi * doi_def , <nl>  <nl> switch ( doi_def -> type ) { <nl> case CIPSO_V4_MAP_PASS : <nl> - net_spot_max = host_cat_len - 1 ; <nl> - while ( net_spot_max > 0 && host_cat [ net_spot_max ] == 0 ) <nl> + net_spot_max = host_cat_len ; <nl> + while ( net_spot_max > 0 && host_cat [ net_spot_max - 1 ] == 0 ) <nl> net_spot_max --; <nl> if ( net_spot_max > net_cat_len ) <nl> return - EINVAL ;
struct device * soc_device_to_device ( struct soc_device * soc_dev ) <nl> } <nl>  <nl> static umode_t soc_attribute_mode ( struct kobject * kobj , <nl> - struct attribute * attr , <nl> - int index ) <nl> + struct attribute * attr , <nl> + int index ) <nl> { <nl> struct device * dev = container_of ( kobj , struct device , kobj ); <nl> struct soc_device * soc_dev = container_of ( dev , struct soc_device , dev ); <nl> static umode_t soc_attribute_mode ( struct kobject * kobj , <nl> return attr -> mode ; <nl> if (( attr == & dev_attr_soc_id . attr ) <nl> && ( soc_dev -> attr -> soc_id != NULL )) <nl> - return attr -> mode ; <nl> + return attr -> mode ; <nl>  <nl> /* Unknown or unfilled attribute . */ <nl> return 0 ; <nl> struct soc_device * soc_device_register ( struct soc_device_attribute * soc_dev_attr <nl>  <nl> soc_dev = kzalloc ( sizeof (* soc_dev ), GFP_KERNEL ); <nl> if (! soc_dev ) { <nl> - ret = - ENOMEM ; <nl> + ret = - ENOMEM ; <nl> goto out1 ; <nl> } <nl>  <nl> struct soc_device * soc_device_register ( struct soc_device_attribute * soc_dev_attr <nl> } while ( ret == - EAGAIN ); <nl>  <nl> if ( ret ) <nl> - goto out2 ; <nl> + goto out2 ; <nl>  <nl> soc_dev -> attr = soc_dev_attr ; <nl> soc_dev -> dev . bus = & soc_bus_type ;
int oxygen_pci_probe ( struct pci_dev * pci , int index , char * id , <nl> goto err_pci_regions ; <nl>  <nl> if ( chip -> model . model_data_size ) { <nl> - chip -> model_data = kmalloc ( chip -> model . model_data_size , <nl> + chip -> model_data = kzalloc ( chip -> model . model_data_size , <nl> GFP_KERNEL ); <nl> if (! chip -> model_data ) { <nl> err = - ENOMEM ;
int dev_hard_start_xmit ( struct sk_buff * skb , struct net_device * dev , <nl> dev_queue_xmit_nit ( skb , dev ); <nl>  <nl> skb_len = skb -> len ; <nl> - rc = ops -> ndo_start_xmit ( skb , dev ); <nl> - <nl> + rc = ops -> ndo_start_xmit ( skb , dev ); <nl> trace_net_dev_xmit ( skb , rc , dev , skb_len ); <nl> if ( rc == NETDEV_TX_OK ) <nl> txq_trans_update ( txq );
static int uvc_v4l2_open ( struct file * file ) <nl> if ( atomic_inc_return (& stream -> dev -> users ) == 1 ) { <nl> ret = uvc_status_start ( stream -> dev ); <nl> if ( ret < 0 ) { <nl> - usb_autopm_put_interface ( stream -> dev -> intf ); <nl> atomic_dec (& stream -> dev -> users ); <nl> + usb_autopm_put_interface ( stream -> dev -> intf ); <nl> kfree ( handle ); <nl> return ret ; <nl> }
struct rxrpc_call * rxrpc_new_incoming_call ( struct rxrpc_local * local , <nl>  <nl> /* Get the socket providing the service */ <nl> rx = rcu_dereference ( local -> service ); <nl> - if ( service_id == rx -> srx . srx_service ) <nl> + if ( rx && service_id == rx -> srx . srx_service ) <nl> goto found_service ; <nl>  <nl> trace_rxrpc_abort (" INV ", sp -> hdr . cid , sp -> hdr . callNumber , sp -> hdr . seq ,
found : <nl>  <nl> if ( codec -> reg_cache ) <nl> kfree ( codec -> reg_cache ); <nl> + kfree ( codec -> name ); <nl> kfree ( codec ); <nl> } <nl> EXPORT_SYMBOL_GPL ( snd_soc_unregister_codec );
int cvmx_usb_initialize ( struct cvmx_usb_state * state , int usb_port_number , <nl> } <nl> } <nl>  <nl> - memset ( usb , 0 , sizeof ( usb )); <nl> + memset ( usb , 0 , sizeof (* usb )); <nl> usb -> init_flags = flags ; <nl>  <nl> /* Initialize the USB state structure */
static int gmap_alloc_table ( struct gmap * gmap , unsigned long * table , <nl> static unsigned long __gmap_segment_gaddr ( unsigned long * entry ) <nl> { <nl> struct page * page ; <nl> - unsigned long offset ; <nl> + unsigned long offset , mask ; <nl>  <nl> offset = ( unsigned long ) entry / sizeof ( unsigned long ); <nl> offset = ( offset & ( PTRS_PER_PMD - 1 )) * PMD_SIZE ; <nl> - page = pmd_to_page (( pmd_t *) entry ); <nl> + mask = ~( PTRS_PER_PMD * sizeof ( pmd_t ) - 1 ); <nl> + page = virt_to_page (( void *)(( unsigned long ) entry & mask )); <nl> return page -> index + offset ; <nl> } <nl> 
static int tpacket_snd ( struct packet_sock * po , struct msghdr * msg ) <nl> } <nl> tp_len = tpacket_fill_skb ( po , skb , ph , dev , size_max , proto , <nl> addr , hlen ); <nl> - if ( tp_len > dev -> mtu + dev -> hard_header_len ) { <nl> + if ( likely ( tp_len >= 0 ) && <nl> + tp_len > dev -> mtu + dev -> hard_header_len ) { <nl> struct ethhdr * ehdr ; <nl> /* Earlier code assumed this would be a VLAN pkt , <nl> * double - check this now that we have the actual
void __init mpic_init ( struct mpic * mpic ) <nl> num_timers = 8 ; <nl> } <nl>  <nl> - /* FSL mpic error interrupt intialization */ <nl> - if ( mpic -> flags & MPIC_FSL_HAS_EIMR ) <nl> - mpic_err_int_init ( mpic , MPIC_FSL_ERR_INT ); <nl> - <nl> /* Initialize timers to our reserved vectors and mask them for now */ <nl> for ( i = 0 ; i < num_timers ; i ++) { <nl> unsigned int offset = mpic_tm_offset ( mpic , i ); <nl> void __init mpic_init ( struct mpic * mpic ) <nl> irq_set_chained_handler ( virq , & mpic_cascade ); <nl> } <nl> } <nl> + <nl> + /* FSL mpic error interrupt intialization */ <nl> + if ( mpic -> flags & MPIC_FSL_HAS_EIMR ) <nl> + mpic_err_int_init ( mpic , MPIC_FSL_ERR_INT ); <nl> } <nl>  <nl> void __init mpic_set_clk_ratio ( struct mpic * mpic , u32 clock_ratio )
static u32 gart_unmapped_entry ; <nl> # define AGPEXTERN <nl> # endif <nl>  <nl> +/* GART can only remap to physical addresses < 1TB */ <nl> +# define GART_MAX_PHYS_ADDR ( 1ULL << 40 ) <nl> + <nl> /* backdoor interface to AGP driver */ <nl> AGPEXTERN int agp_memory_reserved ; <nl> AGPEXTERN __u32 * agp_gatt_table ; <nl> static dma_addr_t dma_map_area ( struct device * dev , dma_addr_t phys_mem , <nl> size_t size , int dir , unsigned long align_mask ) <nl> { <nl> unsigned long npages = iommu_num_pages ( phys_mem , size , PAGE_SIZE ); <nl> - unsigned long iommu_page = alloc_iommu ( dev , npages , align_mask ); <nl> + unsigned long iommu_page ; <nl> int i ; <nl>  <nl> + if ( unlikely ( phys_mem + size > GART_MAX_PHYS_ADDR )) <nl> + return bad_dma_addr ; <nl> + <nl> + iommu_page = alloc_iommu ( dev , npages , align_mask ); <nl> if ( iommu_page == - 1 ) { <nl> if (! nonforced_iommu ( dev , phys_mem , size )) <nl> return phys_mem ;
static void tg_update_disptime ( struct throtl_grp * tg ) <nl> unsigned long read_wait = - 1 , write_wait = - 1 , min_wait = - 1 , disptime ; <nl> struct bio * bio ; <nl>  <nl> - if (( bio = throtl_peek_queued (& sq -> queued [ READ ]))) <nl> + bio = throtl_peek_queued (& sq -> queued [ READ ]); <nl> + if ( bio ) <nl> tg_may_dispatch ( tg , bio , & read_wait ); <nl>  <nl> - if (( bio = throtl_peek_queued (& sq -> queued [ WRITE ]))) <nl> + bio = throtl_peek_queued (& sq -> queued [ WRITE ]); <nl> + if ( bio ) <nl> tg_may_dispatch ( tg , bio , & write_wait ); <nl>  <nl> min_wait = min ( read_wait , write_wait );
* ( you will need to reboot afterwards ) */ <nl> /* # define BNX2X_STOP_ON_ERROR */ <nl>  <nl> -# define DRV_MODULE_VERSION " 1 . 72 . 10 - 0 " <nl> -# define DRV_MODULE_RELDATE " 2012 / 02 / 20 " <nl> +# define DRV_MODULE_VERSION " 1 . 72 . 17 - 0 " <nl> +# define DRV_MODULE_RELDATE " 2012 / 04 / 02 " <nl> # define BNX2X_BC_VER 0x040200 <nl>  <nl> # if defined ( CONFIG_DCB )
static void hotkey_notify ( struct ibm_struct * ibm , u32 event ) <nl> break ; <nl> case 3 : <nl> /* 0x3000 - 0x3FFF : bay - related wakeups */ <nl> - if ( hkey == TP_HKEY_EV_BAYEJ_ACK ) { <nl> + switch ( hkey ) { <nl> + case TP_HKEY_EV_BAYEJ_ACK : <nl> hotkey_autosleep_ack = 1 ; <nl> printk ( TPACPI_INFO <nl> " bay ejected \ n "); <nl> hotkey_wakeup_hotunplug_complete_notify_change (); <nl> known_ev = true ; <nl> - } else { <nl> + break ; <nl> + case TP_HKEY_EV_OPTDRV_EJ : <nl> + /* FIXME : kick libata if SATA link offline */ <nl> + known_ev = true ; <nl> + break ; <nl> + default : <nl> known_ev = false ; <nl> } <nl> break ;
static void __init eva_init ( void ) <nl> platform_add_devices ( eva_devices , <nl> ARRAY_SIZE ( eva_devices )); <nl>  <nl> - eva_clock_init (); <nl> - <nl> rmobile_add_device_to_domain (" A4LC ", & lcdc0_device ); <nl> rmobile_add_device_to_domain (" A4LC ", & hdmi_lcdc_device ); <nl> if ( usb ) <nl> static void __init eva_earlytimer_init ( void ) <nl> { <nl> r8a7740_clock_init ( MD_CK0 | MD_CK2 ); <nl> shmobile_earlytimer_init (); <nl> + <nl> + /* the rate of extal1 clock must be set before late_time_init */ <nl> + eva_clock_init (); <nl> } <nl>  <nl> static void __init eva_add_early_devices ( void )
static int bdc_udc_set_selfpowered ( struct usb_gadget * gadget , <nl> unsigned long flags ; <nl>  <nl> dev_dbg ( bdc -> dev , "% s ()\ n ", __func__ ); <nl> + gadget -> is_selfpowered = ( is_self != 0 ); <nl> spin_lock_irqsave (& bdc -> lock , flags ); <nl> if (! is_self ) <nl> bdc -> devstatus |= 1 << USB_DEVICE_SELF_POWERED ;
static void iscsi_get_ctask ( struct iscsi_cmd_task * ctask ) <nl>  <nl> static void __iscsi_put_ctask ( struct iscsi_cmd_task * ctask ) <nl> { <nl> - struct iscsi_conn * conn = ctask -> conn ; <nl> - <nl> - if ( atomic_dec_and_test (& ctask -> refcount )) { <nl> - conn -> session -> tt -> cleanup_cmd_task ( conn , ctask ); <nl> + if ( atomic_dec_and_test (& ctask -> refcount )) <nl> iscsi_complete_command ( ctask ); <nl> - } <nl> } <nl>  <nl> static void iscsi_put_ctask ( struct iscsi_cmd_task * ctask ) <nl> static void fail_command ( struct iscsi_conn * conn , struct iscsi_cmd_task * ctask , <nl> sc = ctask -> sc ; <nl> if (! sc ) <nl> return ; <nl> + <nl> + conn -> session -> tt -> cleanup_cmd_task ( conn , ctask ); <nl> iscsi_ctask_mtask_cleanup ( ctask ); <nl>  <nl> sc -> result = err ; <nl> sc -> resid = sc -> request_bufflen ; <nl> + /* release ref from queuecommand */ <nl> __iscsi_put_ctask ( ctask ); <nl> } <nl> 
static int __init do_floppy_init ( void ) <nl>  <nl> disks [ dr ]-> queue = blk_init_queue ( do_fd_request , & floppy_lock ); <nl> if (! disks [ dr ]-> queue ) { <nl> + put_disk ( disks [ dr ]); <nl> err = - ENOMEM ; <nl> goto out_put_disk ; <nl> }
int kvm_arch_vcpu_ioctl_get_sregs ( struct kvm_vcpu * vcpu , <nl>  <nl> memset ( sregs -> interrupt_bitmap , 0 , sizeof sregs -> interrupt_bitmap ); <nl>  <nl> - if ( vcpu -> arch . interrupt . pending ) <nl> + if ( vcpu -> arch . interrupt . pending && ! vcpu -> arch . interrupt . soft ) <nl> set_bit ( vcpu -> arch . interrupt . nr , <nl> ( unsigned long *) sregs -> interrupt_bitmap ); <nl> 
void ceph_mdsc_sync ( struct ceph_mds_client * mdsc ) <nl> { <nl> u64 want_tid , want_flush ; <nl>  <nl> + if ( mdsc -> client -> mount_state == CEPH_MOUNT_SHUTDOWN ) <nl> + return ; <nl> + <nl> dout (" sync \ n "); <nl> mutex_lock (& mdsc -> mutex ); <nl> want_tid = mdsc -> last_tid ;
static int drm_getcap ( struct drm_device * dev , void * data , struct drm_file * file_ <nl> req -> value = dev -> mode_config . async_page_flip ; <nl> break ; <nl> case DRM_CAP_PAGE_FLIP_TARGET : <nl> - req -> value = 1 ; <nl> - drm_for_each_crtc ( crtc , dev ) { <nl> - if (! crtc -> funcs -> page_flip_target ) <nl> - req -> value = 0 ; <nl> + if ( drm_core_check_feature ( dev , DRIVER_MODESET )) { <nl> + req -> value = 1 ; <nl> + drm_for_each_crtc ( crtc , dev ) { <nl> + if (! crtc -> funcs -> page_flip_target ) <nl> + req -> value = 0 ; <nl> + } <nl> } <nl> break ; <nl> case DRM_CAP_CURSOR_WIDTH :
static long comedi_unlocked_ioctl ( struct file * file , unsigned int cmd , <nl> /* Device config is special , because it must work on <nl> * an unconfigured device . */ <nl> if ( cmd == COMEDI_DEVCONFIG ) { <nl> + if ( minor >= COMEDI_NUM_BOARD_MINORS ) { <nl> + /* Device config not appropriate on non - board minors . */ <nl> + rc = - ENOTTY ; <nl> + goto done ; <nl> + } <nl> rc = do_devconfig_ioctl ( dev , <nl> ( struct comedi_devconfig __user *) arg ); <nl> if ( rc == 0 )
int snd_pcm_status ( struct snd_pcm_substream * substream , <nl> runtime -> status -> audio_tstamp ; <nl> goto _tstamp_end ; <nl> } <nl> + } else { <nl> + /* get tstamp only in fallback mode and only if enabled */ <nl> + if ( runtime -> tstamp_mode == SNDRV_PCM_TSTAMP_ENABLE ) <nl> + snd_pcm_gettime ( runtime , & status -> tstamp ); <nl> } <nl> - snd_pcm_gettime ( runtime , & status -> tstamp ); <nl> _tstamp_end : <nl> status -> appl_ptr = runtime -> control -> appl_ptr ; <nl> status -> hw_ptr = runtime -> status -> hw_ptr ;
static int tiadc_read_raw ( struct iio_dev * indio_dev , <nl> return - EAGAIN ; <nl> } <nl> } <nl> - map_val = chan -> channel + TOTAL_CHANNELS ; <nl> + map_val = adc_dev -> channel_step [ chan -> scan_index ]; <nl>  <nl> /* <nl> * We check the complete FIFO . We programmed just one entry but in case
static void unfreeze_partials ( struct kmem_cache * s ) <nl>  <nl> new . frozen = 0 ; <nl>  <nl> - if (! new . inuse && (! n || n -> nr_partial < s -> min_partial )) <nl> + if (! new . inuse && (! n || n -> nr_partial > s -> min_partial )) <nl> m = M_FREE ; <nl> else { <nl> struct kmem_cache_node * n2 = get_node ( s ,
static u32 find_khz_freq_from_fid ( u32 fid ) <nl> /* Return a frequency in MHz , given an input fid and did */ <nl> static u32 find_freq_from_fiddid ( u32 fid , u32 did ) <nl> { <nl> - return 100 * ( fid + 0x10 ) >> did ; <nl> + if ( current_cpu_data . x86 == 0x10 ) <nl> + return 100 * ( fid + 0x10 ) >> did ; <nl> + else <nl> + return 100 * ( fid + 0x8 ) >> did ; <nl> } <nl>  <nl> static u32 find_khz_freq_from_fiddid ( u32 fid , u32 did )
static struct sctp_transport * sctp_trans_elect_best ( struct sctp_transport * curr , <nl> { <nl> u8 score_curr , score_best ; <nl>  <nl> - if ( best == NULL ) <nl> + if ( best == NULL || curr == best ) <nl> return curr ; <nl>  <nl> score_curr = sctp_trans_score ( curr );
int __vma_adjust ( struct vm_area_struct * vma , unsigned long start , <nl> * If next doesn ' t have anon_vma , import from vma after <nl> * next , if the vma overlaps with it . <nl> */ <nl> - if ( remove_next == 2 && next && ! next -> anon_vma ) <nl> + if ( remove_next == 2 && ! next -> anon_vma ) <nl> exporter = next -> vm_next ; <nl>  <nl> } else if ( end > next -> vm_start ) {
struct pinctrl_dev * pinctrl_find_and_add_gpio_range ( const char * devname , <nl> { <nl> struct pinctrl_dev * pctldev = get_pinctrl_dev_from_devname ( devname ); <nl>  <nl> + /* <nl> + * If we can ' t find this device , let ' s assume that is because <nl> + * it has not probed yet , so the driver trying to register this <nl> + * range need to defer probing . <nl> + */ <nl> if (! pctldev ) <nl> - return NULL ; <nl> + return ERR_PTR (- EPROBE_DEFER ); <nl>  <nl> pinctrl_add_gpio_range ( pctldev , range ); <nl> return pctldev ;
long vhost_dev_ioctl ( struct vhost_dev * d , unsigned int ioctl , void __user * argp ) <nl> } <nl> if ( eventfp != d -> log_file ) { <nl> filep = d -> log_file ; <nl> + d -> log_file = eventfp ; <nl> ctx = d -> log_ctx ; <nl> d -> log_ctx = eventfp ? <nl> eventfd_ctx_fileget ( eventfp ) : NULL ;
static inline struct sk_buff * sk_stream_alloc_pskb ( struct sock * sk , <nl> { <nl> struct sk_buff * skb ; <nl>  <nl> + /* The TCP header must be at least 32 - bit aligned . */ <nl> + size = ALIGN ( size , 4 ); <nl> + <nl> skb = alloc_skb_fclone ( size + sk -> sk_prot -> max_header , gfp ); <nl> if ( skb ) { <nl> skb -> truesize += mem ;
static ssize_t set_vrm ( struct device * dev , struct device_attribute * attr , <nl> err = kstrtoul ( buf , 10 , & val ); <nl> if ( err ) <nl> return err ; <nl> + <nl> + if ( val > 255 ) <nl> + return - EINVAL ; <nl> + <nl> data -> vrm = val ; <nl> return count ; <nl> }
int pl320_ipc_unregister_notifier ( struct notifier_block * nb ) <nl> } <nl> EXPORT_SYMBOL_GPL ( pl320_ipc_unregister_notifier ); <nl>  <nl> - static int __init pl320_probe ( struct amba_device * adev , <nl> - const struct amba_id * id ) <nl> + static int pl320_probe ( struct amba_device * adev , const struct amba_id * id ) <nl> { <nl> int ret ; <nl> 
read_clk ( struct drm_device * dev , int clk , bool ignore_en ) <nl> u32 sctl , sdiv , sclk ; <nl>  <nl> /* refclk for the 0xe8xx plls is a fixed frequency */ <nl> - if ( clk >= 0x40 ) <nl> + if ( clk >= 0x40 ) { <nl> + if ( dev_priv -> chipset == 0xaf ) { <nl> + /* no joke .. seriously .. sigh .. */ <nl> + return nv_rd32 ( dev , 0x00471c ) * 1000 ; <nl> + } <nl> + <nl> return dev_priv -> crystal ; <nl> + } <nl>  <nl> sctl = nv_rd32 ( dev , 0x4120 + ( clk * 4 )); <nl> if (! ignore_en && !( sctl & 0x00000100 ))
static DEFINE_SEMAPHORE ( console_sem ); <nl> struct console * console_drivers ; <nl> EXPORT_SYMBOL_GPL ( console_drivers ); <nl>  <nl> +# ifdef CONFIG_LOCKDEP <nl> + static struct lockdep_map console_lock_dep_map = { <nl> + . name = " console_lock " <nl> +}; <nl> +# endif <nl> + <nl> /* <nl> * This is used for debugging the mess that is the VT code by <nl> * keeping track if we have the console semaphore held . It ' s <nl> void console_lock ( void ) <nl> return ; <nl> console_locked = 1 ; <nl> console_may_schedule = 1 ; <nl> + mutex_acquire (& console_lock_dep_map , 0 , 0 , _RET_IP_ ); <nl> } <nl> EXPORT_SYMBOL ( console_lock ); <nl>  <nl> int console_trylock ( void ) <nl> } <nl> console_locked = 1 ; <nl> console_may_schedule = 0 ; <nl> + mutex_acquire (& console_lock_dep_map , 0 , 1 , _RET_IP_ ); <nl> return 1 ; <nl> } <nl> EXPORT_SYMBOL ( console_trylock ); <nl> skip : <nl> local_irq_restore ( flags ); <nl> } <nl> console_locked = 0 ; <nl> + mutex_release (& console_lock_dep_map , 1 , _RET_IP_ ); <nl>  <nl> /* Release the exclusive_console once it is used */ <nl> if ( unlikely ( exclusive_console ))
int ath9k_hw_reset ( struct ath_hw * ah , struct ath9k_channel * chan , <nl>  <nl> if ( ah -> hw -> conf . radar_enabled ) { <nl> /* set HW specific DFS configuration */ <nl> + ah -> radar_conf . ext_channel = IS_CHAN_HT40 ( chan ); <nl> ath9k_hw_set_radar_params ( ah ); <nl> } <nl> 
struct zx_dma_dev { <nl> struct dma_pool * pool ; <nl> u32 dma_channels ; <nl> u32 dma_requests ; <nl> + int irq ; <nl> }; <nl>  <nl> # define to_zx_dma ( dmadev ) container_of ( dmadev , struct zx_dma_dev , slave ) <nl> static int zx_dma_probe ( struct platform_device * op ) <nl> { <nl> struct zx_dma_dev * d ; <nl> struct resource * iores ; <nl> - int i , ret = 0 , irq = 0 ; <nl> + int i , ret = 0 ; <nl>  <nl> iores = platform_get_resource ( op , IORESOURCE_MEM , 0 ); <nl> if (! iores ) <nl> static int zx_dma_probe ( struct platform_device * op ) <nl> return PTR_ERR ( d -> clk ); <nl> } <nl>  <nl> - irq = platform_get_irq ( op , 0 ); <nl> - ret = devm_request_irq (& op -> dev , irq , zx_dma_int_handler , <nl> + d -> irq = platform_get_irq ( op , 0 ); <nl> + ret = devm_request_irq (& op -> dev , d -> irq , zx_dma_int_handler , <nl> 0 , DRIVER_NAME , d ); <nl> if ( ret ) <nl> return ret ; <nl> static int zx_dma_remove ( struct platform_device * op ) <nl> struct zx_dma_chan * c , * cn ; <nl> struct zx_dma_dev * d = platform_get_drvdata ( op ); <nl>  <nl> + /* explictly free the irq */ <nl> + devm_free_irq (& op -> dev , d -> irq , d ); <nl> + <nl> dma_async_device_unregister (& d -> slave ); <nl> of_dma_controller_free ((& op -> dev )-> of_node ); <nl> 
bool i40e_is_vsi_in_vlan ( struct i40e_vsi * vsi ) <nl> * so we have to go through all the list in order to make sure <nl> */ <nl> list_for_each_entry ( f , & vsi -> mac_filter_list , list ) { <nl> - if ( f -> vlan >= 0 ) <nl> + if ( f -> vlan >= 0 || vsi -> info . pvid ) <nl> return true ; <nl> } <nl> 
static ssize_t radeon_set_dpm_forced_performance_level ( struct device * dev , <nl> } else if ( strncmp (" auto ", buf , strlen (" auto ")) == 0 ) { <nl> level = RADEON_DPM_FORCED_LEVEL_AUTO ; <nl> } else { <nl> - mutex_unlock (& rdev -> pm . mutex ); <nl> count = - EINVAL ; <nl> goto fail ; <nl> } <nl> if ( rdev -> asic -> dpm . force_performance_level ) { <nl> + if ( rdev -> pm . dpm . thermal_active ) { <nl> + count = - EINVAL ; <nl> + goto fail ; <nl> + } <nl> ret = radeon_dpm_force_performance_level ( rdev , level ); <nl> if ( ret ) <nl> count = - EINVAL ; <nl> } <nl> - mutex_unlock (& rdev -> pm . mutex ); <nl> fail : <nl> + mutex_unlock (& rdev -> pm . mutex ); <nl> + <nl> return count ; <nl> } <nl> 
static void intel_edp_panel_vdd_sanitize ( struct intel_dp * intel_dp ) <nl>  <nl> void intel_dp_encoder_reset ( struct drm_encoder * encoder ) <nl> { <nl> - struct intel_dp * intel_dp ; <nl> + struct drm_i915_private * dev_priv = to_i915 ( encoder -> dev ); <nl> + struct intel_dp * intel_dp = enc_to_intel_dp ( encoder ); <nl> + <nl> + if (! HAS_DDI ( dev_priv )) <nl> + intel_dp -> DP = I915_READ ( intel_dp -> output_reg ); <nl>  <nl> if ( to_intel_encoder ( encoder )-> type != INTEL_OUTPUT_EDP ) <nl> return ; <nl>  <nl> - intel_dp = enc_to_intel_dp ( encoder ); <nl> - <nl> pps_lock ( intel_dp ); <nl>  <nl> /*
int tpm_release ( struct inode * inode , struct file * file ) <nl> flush_work_sync (& chip -> work ); <nl> file -> private_data = NULL ; <nl> atomic_set (& chip -> data_pending , 0 ); <nl> - kfree ( chip -> data_buffer ); <nl> + kzfree ( chip -> data_buffer ); <nl> clear_bit ( 0 , & chip -> is_open ); <nl> put_device ( chip -> dev ); <nl> return 0 ; <nl> ssize_t tpm_read ( struct file * file , char __user * buf , <nl> del_singleshot_timer_sync (& chip -> user_read_timer ); <nl> flush_work_sync (& chip -> work ); <nl> ret_size = atomic_read (& chip -> data_pending ); <nl> - atomic_set (& chip -> data_pending , 0 ); <nl> if ( ret_size > 0 ) { /* relay data */ <nl> ssize_t orig_ret_size = ret_size ; <nl> if ( size < ret_size ) <nl> ssize_t tpm_read ( struct file * file , char __user * buf , <nl> mutex_unlock (& chip -> buffer_mutex ); <nl> } <nl>  <nl> + atomic_set (& chip -> data_pending , 0 ); <nl> + <nl> return ret_size ; <nl> } <nl> EXPORT_SYMBOL_GPL ( tpm_read );
static int ks7010_upload_firmware ( struct ks_sdio_card * card ) <nl> unsigned char * rom_buf ; <nl> unsigned char rw_data = 0 ; <nl> int ret ; <nl> - int length ; <nl> + unsigned int length ; <nl> const struct firmware * fw_entry = NULL ; <nl>  <nl> /* buffer allocate */
static void __of_changeset_entry_invert ( struct of_changeset_entry * ce , <nl> case OF_RECONFIG_UPDATE_PROPERTY : <nl> rce -> old_prop = ce -> prop ; <nl> rce -> prop = ce -> old_prop ; <nl> + /* update was used but original property did not exist */ <nl> + if (! rce -> prop ) { <nl> + rce -> action = OF_RECONFIG_REMOVE_PROPERTY ; <nl> + rce -> prop = ce -> prop ; <nl> + } <nl> break ; <nl> } <nl> }
static int bnx2x_populate_ext_phy ( struct bnx2x * bp , <nl> return - EINVAL ; <nl> default : <nl> * phy = phy_null ; <nl> + /* In case external PHY wasn ' t found */ <nl> + if (( phy_type != PORT_HW_CFG_XGXS_EXT_PHY_TYPE_DIRECT ) && <nl> + ( phy_type != PORT_HW_CFG_XGXS_EXT_PHY_TYPE_NOT_CONN )) <nl> + return - EINVAL ; <nl> return 0 ; <nl> } <nl> 
static int packet_recvmsg ( struct kiocb * iocb , struct socket * sock , <nl>  <nl> err = - EINVAL ; <nl> vnet_hdr_len = sizeof ( vnet_hdr ); <nl> - if (( len -= vnet_hdr_len ) < 0 ) <nl> + if ( len < vnet_hdr_len ) <nl> goto out_free ; <nl>  <nl> + len -= vnet_hdr_len ; <nl> + <nl> if ( skb_is_gso ( skb )) { <nl> struct skb_shared_info * sinfo = skb_shinfo ( skb ); <nl> 
static void estimate_pid_constants ( struct thermal_zone_device * tz , <nl> switch_on_temp = 0 ; <nl>  <nl> temperature_threshold = control_temp - switch_on_temp ; <nl> + /* <nl> + * estimate_pid_constants () tries to find appropriate default <nl> + * values for thermal zones that don ' t provide them . If a <nl> + * system integrator has configured a thermal zone with two <nl> + * passive trip points at the same temperature , that person <nl> + * hasn ' t put any effort to set up the thermal zone properly <nl> + * so just give up . <nl> + */ <nl> + if (! temperature_threshold ) <nl> + return ; <nl>  <nl> if (! tz -> tzp -> k_po || force ) <nl> tz -> tzp -> k_po = int_to_frac ( sustainable_power ) /
long vt_compat_ioctl ( struct tty_struct * tty , struct file * file , <nl>  <nl> case PIO_UNIMAP : <nl> case GIO_UNIMAP : <nl> - ret = do_unimap_ioctl ( cmd , up , perm , vc ); <nl> + ret = compat_unimap_ioctl ( cmd , up , perm , vc ); <nl> break ; <nl>  <nl> /*
static inline void mlx5e_build_rx_skb ( struct mlx5_cqe64 * cqe , <nl> if ( lro_num_seg > 1 ) { <nl> mlx5e_lro_update_hdr ( skb , cqe , cqe_bcnt ); <nl> skb_shinfo ( skb )-> gso_size = DIV_ROUND_UP ( cqe_bcnt , lro_num_seg ); <nl> + /* Subtract one since we already counted this as one <nl> + * " regular " packet in mlx5e_complete_rx_cqe () <nl> + */ <nl> + rq -> stats . packets += lro_num_seg - 1 ; <nl> rq -> stats . lro_packets ++; <nl> rq -> stats . lro_bytes += cqe_bcnt ; <nl> }
static void valleyview_set_cdclk ( struct drm_device * dev , int cdclk ) <nl> static int valleyview_calc_cdclk ( struct drm_i915_private * dev_priv , <nl> int max_pixclk ) <nl> { <nl> + int vco = valleyview_get_vco ( dev_priv ); <nl> + int freq_320 = ( vco << 1 ) % 320000 != 0 ? 333333 : 320000 ; <nl> + <nl> /* <nl> * Really only a few cases to deal with , as only 4 CDclks are supported : <nl> * 200MHz <nl> * 267MHz <nl> - * 320MHz <nl> + * 320 / 333MHz ( depends on HPLL freq ) <nl> * 400MHz <nl> * So we check to see whether we ' re above 90 % of the lower bin and <nl> * adjust if needed . <nl> */ <nl> - if ( max_pixclk > 320000 * 9 / 10 ) <nl> + if ( max_pixclk > freq_320 * 9 / 10 ) <nl> return 400000 ; <nl> else if ( max_pixclk > 266667 * 9 / 10 ) <nl> - return 320000 ; <nl> + return freq_320 ; <nl> else <nl> return 266667 ; <nl> /* Looks like the 200MHz CDclk freq doesn ' t work on some configs */
static DEFINE_SPINLOCK ( nr_list_lock ); <nl>  <nl> static const struct proto_ops nr_proto_ops ; <nl>  <nl> +/* <nl> + * NETROM network devices are virtual network devices encapsulating NETROM <nl> + * frames into AX . 25 which will be sent through an AX . 25 device , so form a <nl> + * special " super class " of normal net devices ; split their locks off into a <nl> + * separate class since they always nest . <nl> + */ <nl> + static struct lock_class_key nr_netdev_xmit_lock_key ; <nl> + <nl> /* <nl> * Socket removal during an interrupt is now safe . <nl> */ <nl> static int __init nr_proto_init ( void ) <nl> free_netdev ( dev ); <nl> goto fail ; <nl> } <nl> + lockdep_set_class (& dev -> _xmit_lock , & nr_netdev_xmit_lock_key ); <nl> dev_nr [ i ] = dev ; <nl> } <nl> 
int __init init_hw_breakpoint ( void ) <nl> err_alloc : <nl> for_each_possible_cpu ( err_cpu ) { <nl> for ( i = 0 ; i < TYPE_MAX ; i ++) <nl> - kfree ( per_cpu ( nr_task_bp_pinned [ i ], cpu )); <nl> + kfree ( per_cpu ( nr_task_bp_pinned [ i ], err_cpu )); <nl> if ( err_cpu == cpu ) <nl> break ; <nl> }
unsigned int <nl> nft_do_chain ( struct nft_pktinfo * pkt , const struct nf_hook_ops * ops ) <nl> { <nl> const struct nft_chain * chain = ops -> priv , * basechain = chain ; <nl> - const struct net * net = read_pnet (& nft_base_chain ( basechain )-> pnet ); <nl> + const struct net * chain_net = read_pnet (& nft_base_chain ( basechain )-> pnet ); <nl> + const struct net * net = dev_net ( pkt -> in ? pkt -> in : pkt -> out ); <nl> const struct nft_rule * rule ; <nl> const struct nft_expr * expr , * last ; <nl> struct nft_regs regs ; <nl> nft_do_chain ( struct nft_pktinfo * pkt , const struct nf_hook_ops * ops ) <nl> int rulenum ; <nl> unsigned int gencursor = nft_genmask_cur ( net ); <nl>  <nl> + /* Ignore chains that are not for the current network namespace */ <nl> + if (! net_eq ( net , chain_net )) <nl> + return NF_ACCEPT ; <nl> + <nl> do_chain : <nl> rulenum = 0 ; <nl> rule = list_entry (& chain -> rules , struct nft_rule , list );
int iwl_mvm_scan_request ( struct iwl_mvm * mvm , <nl> basic_ssid ? 1 : 0 ); <nl>  <nl> cmd -> tx_cmd . tx_flags = cpu_to_le32 ( TX_CMD_FLG_SEQ_CTL | <nl> - TX_CMD_FLG_BT_DIS ); <nl> + 3 << TX_CMD_FLG_BT_PRIO_POS ); <nl> + <nl> cmd -> tx_cmd . sta_id = mvm -> aux_sta . sta_id ; <nl> cmd -> tx_cmd . life_time = cpu_to_le32 ( TX_CMD_LIFE_TIME_INFINITE ); <nl> cmd -> tx_cmd . rate_n_flags =
static int xs_local_send_request ( struct rpc_task * task ) <nl> true , & sent ); <nl> dprintk (" RPC : % s (% u ) = % d \ n ", <nl> __func__ , xdr -> len - req -> rq_bytes_sent , status ); <nl> + <nl> + if ( status == - EAGAIN && sock_writeable ( transport -> inet )) <nl> + status = - ENOBUFS ; <nl> + <nl> if ( likely ( sent > 0 ) || status == 0 ) { <nl> req -> rq_bytes_sent += sent ; <nl> req -> rq_xmit_bytes_sent += sent ; <nl> static int xs_udp_send_request ( struct rpc_task * task ) <nl> if ( status == - EPERM ) <nl> goto process_status ; <nl>  <nl> + if ( status == - EAGAIN && sock_writeable ( transport -> inet )) <nl> + status = - ENOBUFS ; <nl> + <nl> if ( sent > 0 || status == 0 ) { <nl> req -> rq_xmit_bytes_sent += sent ; <nl> if ( sent >= req -> rq_slen ) <nl> static int xs_tcp_send_request ( struct rpc_task * task ) <nl> status = - EAGAIN ; <nl> break ; <nl> } <nl> + if ( status == - EAGAIN && sk_stream_is_writeable ( transport -> inet )) <nl> + status = - ENOBUFS ; <nl>  <nl> switch ( status ) { <nl> case - ENOTSOCK :
static unsigned int xuartps_set_baud_rate ( struct uart_port * port , <nl> unsigned int baud ) <nl> { <nl> unsigned int calc_baud ; <nl> - u32 cd , bdiv ; <nl> + u32 cd = 0 , bdiv = 0 ; <nl> u32 mreg ; <nl> int div8 ; <nl> struct xuartps * xuartps = port -> private_data ;
e1000_set_ringparam ( struct net_device * netdev , <nl> struct e1000_rx_ring * rxdr , * rx_old , * rx_new ; <nl> int i , err , tx_ring_size , rx_ring_size ; <nl>  <nl> + if (( ring -> rx_mini_pending ) || ( ring -> rx_jumbo_pending )) <nl> + return - EINVAL ; <nl> + <nl> tx_ring_size = sizeof ( struct e1000_tx_ring ) * adapter -> num_tx_queues ; <nl> rx_ring_size = sizeof ( struct e1000_rx_ring ) * adapter -> num_rx_queues ; <nl>  <nl> e1000_set_ringparam ( struct net_device * netdev , <nl> txdr = adapter -> tx_ring ; <nl> rxdr = adapter -> rx_ring ; <nl>  <nl> - if (( ring -> rx_mini_pending ) || ( ring -> rx_jumbo_pending )) <nl> - return - EINVAL ; <nl> - <nl> rxdr -> count = max ( ring -> rx_pending ,( uint32_t ) E1000_MIN_RXD ); <nl> rxdr -> count = min ( rxdr -> count ,( uint32_t )( mac_type < e1000_82544 ? <nl> E1000_MAX_RXD : E1000_MAX_82544_RXD ));
static int acct_stack_growth ( struct vm_area_struct * vma , unsigned long size , un <nl> { <nl> struct mm_struct * mm = vma -> vm_mm ; <nl> struct rlimit * rlim = current -> signal -> rlim ; <nl> + unsigned long new_start ; <nl>  <nl> /* address space limit tests */ <nl> if (! may_expand_vm ( mm , grow )) <nl> static int acct_stack_growth ( struct vm_area_struct * vma , unsigned long size , un <nl> return - ENOMEM ; <nl> } <nl>  <nl> + /* Check to ensure the stack will not grow into a hugetlb - only region */ <nl> + new_start = ( vma -> vm_flags & VM_GROWSUP ) ? vma -> vm_start : <nl> + vma -> vm_end - size ; <nl> + if ( is_hugepage_only_range ( vma -> vm_mm , new_start , size )) <nl> + return - EFAULT ; <nl> + <nl> /* <nl> * Overcommit .. This must be the final test , as it will <nl> * update security statistics .
static int btrfs_finish_ordered_io ( struct btrfs_ordered_extent * ordered_extent ) <nl> EXTENT_DEFRAG , 1 , cached_state ); <nl> if ( ret ) { <nl> u64 last_snapshot = btrfs_root_last_snapshot (& root -> root_item ); <nl> - if ( last_snapshot >= BTRFS_I ( inode )-> generation ) <nl> + if ( 0 && last_snapshot >= BTRFS_I ( inode )-> generation ) <nl> /* the inode is shared */ <nl> new = record_old_file_extents ( inode , ordered_extent ); <nl> 
struct key * key_alloc ( struct key_type * type , const char * desc , <nl> } <nl>  <nl> /* allocate and initialise the key and its description */ <nl> - key = kmem_cache_alloc ( key_jar , GFP_KERNEL ); <nl> + key = kmem_cache_zalloc ( key_jar , GFP_KERNEL ); <nl> if (! key ) <nl> goto no_memory_2 ; <nl>  <nl> struct key * key_alloc ( struct key_type * type , const char * desc , <nl> key -> uid = uid ; <nl> key -> gid = gid ; <nl> key -> perm = perm ; <nl> - key -> flags = 0 ; <nl> - key -> expiry = 0 ; <nl> - key -> payload . data = NULL ; <nl> - key -> security = NULL ; <nl>  <nl> if (!( flags & KEY_ALLOC_NOT_IN_QUOTA )) <nl> key -> flags |= 1 << KEY_FLAG_IN_QUOTA ; <nl> if ( flags & KEY_ALLOC_TRUSTED ) <nl> key -> flags |= 1 << KEY_FLAG_TRUSTED ; <nl>  <nl> - memset (& key -> type_data , 0 , sizeof ( key -> type_data )); <nl> - <nl> # ifdef KEY_DEBUGGING <nl> key -> magic = KEY_DEBUG_MAGIC ; <nl> # endif
static int uas_find_endpoints ( struct usb_host_interface * alt , <nl> for ( i = 0 ; i < n_endpoints ; i ++) { <nl> unsigned char * extra = endpoint [ i ]. extra ; <nl> int len = endpoint [ i ]. extralen ; <nl> - while ( len > 1 ) { <nl> + while ( len >= 3 ) { <nl> if ( extra [ 1 ] == USB_DT_PIPE_USAGE ) { <nl> unsigned pipe_id = extra [ 2 ]; <nl> if ( pipe_id > 0 && pipe_id < 5 )
static int skl_probe ( struct pci_dev * pci , <nl> if ( err < 0 ) <nl> goto out_free ; <nl>  <nl> + skl -> nhlt = skl_nhlt_init ( bus -> dev ); <nl> + <nl> + if ( skl -> nhlt == NULL ) <nl> + goto out_free ; <nl> + <nl> pci_set_drvdata ( skl -> pci , ebus ); <nl>  <nl> /* check if dsp is there */
static int __inject_sigp_stop ( struct kvm_s390_local_interrupt * li , int action ) <nl> inti -> type = KVM_S390_SIGP_STOP ; <nl>  <nl> spin_lock_bh (& li -> lock ); <nl> - if (( atomic_read ( li -> cpuflags ) & CPUSTAT_STOPPED )) <nl> + if (( atomic_read ( li -> cpuflags ) & CPUSTAT_STOPPED )) { <nl> + kfree ( inti ); <nl> goto out ; <nl> + } <nl> list_add_tail (& inti -> list , & li -> list ); <nl> atomic_set (& li -> active , 1 ); <nl> atomic_set_mask ( CPUSTAT_STOP_INT , li -> cpuflags );
ecryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , <nl> char * cipher_name , size_t * key_size ) <nl> { <nl> char dummy_key [ ECRYPTFS_MAX_KEY_BYTES ]; <nl> - char * full_alg_name ; <nl> + char * full_alg_name = NULL ; <nl> int rc ; <nl>  <nl> * key_tfm = NULL ; <nl> ecryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , <nl> if ( rc ) <nl> goto out ; <nl> * key_tfm = crypto_alloc_blkcipher ( full_alg_name , 0 , CRYPTO_ALG_ASYNC ); <nl> - kfree ( full_alg_name ); <nl> if ( IS_ERR (* key_tfm )) { <nl> rc = PTR_ERR (* key_tfm ); <nl> printk ( KERN_ERR " Unable to allocate crypto cipher with name " <nl> ecryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , <nl> goto out ; <nl> } <nl> out : <nl> + kfree ( full_alg_name ); <nl> return rc ; <nl> } <nl> 
static int iwl_mvm_bt_coex_reduced_txp ( struct iwl_mvm * mvm , u8 sta_id , <nl> struct iwl_mvm_sta * mvmsta ; <nl> int ret ; <nl>  <nl> - /* This can happen if the station has been removed right now */ <nl> if ( sta_id == IWL_MVM_STATION_COUNT ) <nl> return 0 ; <nl>  <nl> sta = rcu_dereference_protected ( mvm -> fw_id_to_mac_id [ sta_id ], <nl> lockdep_is_held (& mvm -> mutex )); <nl> + <nl> + /* This can happen if the station has been removed right now */ <nl> + if ( IS_ERR_OR_NULL ( sta )) <nl> + return 0 ; <nl> + <nl> mvmsta = ( void *) sta -> drv_priv ; <nl>  <nl> /* nothing to do */
out_cleanup_data : <nl> out_free_dev : <nl> free_netdev ( ndev ); <nl> out_put : <nl> - of_node_put ( fpi -> phy_node ); <nl> if ( fpi -> clk_per ) <nl> clk_disable_unprepare ( fpi -> clk_per ); <nl> out_deregister_fixed_link : <nl> + of_node_put ( fpi -> phy_node ); <nl> if ( of_phy_is_fixed_link ( ofdev -> dev . of_node )) <nl> of_phy_deregister_fixed_link ( ofdev -> dev . of_node ); <nl> out_free_fpi :
parse_dcb20_entry ( struct drm_device * dev , struct dcb_table * dcb , <nl> case 0 : <nl> entry -> dpconf . link_bw = 162000 ; <nl> break ; <nl> - default : <nl> + case 1 : <nl> entry -> dpconf . link_bw = 270000 ; <nl> break ; <nl> + default : <nl> + entry -> dpconf . link_bw = 540000 ; <nl> + break ; <nl> } <nl> switch (( conf & 0x0f000000 ) >> 24 ) { <nl> case 0xf :
static int econet_sendmsg ( struct kiocb * iocb , struct socket * sock , <nl> udpdest . sin_addr . s_addr = htonl ( network | addr . station ); <nl> } <nl>  <nl> + memset (& ah , 0 , sizeof ( ah )); <nl> ah . port = port ; <nl> ah . cb = cb & 0x7f ; <nl> ah . code = 2 ; /* magic */ <nl> - ah . pad = 0 ; <nl>  <nl> /* tack our header on the front of the iovec */ <nl> size = sizeof ( struct aunhdr );
void flush_dcache_page ( struct page * page ) <nl> } <nl> EXPORT_SYMBOL ( flush_dcache_page ); <nl>  <nl> + void flush_kernel_dcache_page ( struct page * page ) <nl> +{ <nl> + __cpuc_flush_dcache_area ( page_address ( page ), PAGE_SIZE ); <nl> +} <nl> + EXPORT_SYMBOL ( flush_kernel_dcache_page ); <nl> + <nl> void copy_to_user_page ( struct vm_area_struct * vma , struct page * page , <nl> unsigned long uaddr , void * dst , const void * src , <nl> unsigned long len )
int opp_add ( struct device * dev , unsigned long freq , unsigned long u_volt ) <nl> srcu_notifier_call_chain (& dev_opp -> head , OPP_EVENT_ADD , new_opp ); <nl> return 0 ; <nl> } <nl> + EXPORT_SYMBOL_GPL ( opp_add ); <nl>  <nl> /** <nl> * opp_set_availability () - helper to set the availability of an opp
int ieee80211_register_hw ( struct ieee80211_hw * hw ) <nl> fail_workqueue : <nl> wiphy_unregister ( local -> hw . wiphy ); <nl> fail_wiphy_register : <nl> - kfree ( local -> int_scan_req -> channels ); <nl> + kfree ( local -> int_scan_req ); <nl> return result ; <nl> } <nl> EXPORT_SYMBOL ( ieee80211_register_hw );
static int fixed_voltage_get_voltage ( struct regulator_dev * dev ) <nl> { <nl> struct fixed_voltage_data * data = rdev_get_drvdata ( dev ); <nl>  <nl> - return data -> microvolts ; <nl> + if ( data -> microvolts ) <nl> + return data -> microvolts ; <nl> + else <nl> + return - EINVAL ; <nl> } <nl>  <nl> static int fixed_voltage_list_voltage ( struct regulator_dev * dev ,
void cfg80211_conn_work ( struct work_struct * work ) <nl> wdev_unlock ( wdev ); <nl> continue ; <nl> } <nl> - if ( wdev -> sme_state != CFG80211_SME_CONNECTING ) { <nl> + if ( wdev -> sme_state != CFG80211_SME_CONNECTING || ! wdev -> conn ) { <nl> wdev_unlock ( wdev ); <nl> continue ; <nl> }
static int nl80211_set_tx_bitrate_mask ( struct sk_buff * skb , <nl> struct nlattr * tx_rates ; <nl> struct ieee80211_supported_band * sband ; <nl>  <nl> - if ( info -> attrs [ NL80211_ATTR_TX_RATES ] == NULL ) <nl> - return - EINVAL ; <nl> - <nl> if (! rdev -> ops -> set_bitrate_mask ) <nl> return - EOPNOTSUPP ; <nl>  <nl> static int nl80211_set_tx_bitrate_mask ( struct sk_buff * skb , <nl> sizeof ( mask . control [ i ]. mcs )); <nl> } <nl>  <nl> + /* if no rates are given set it back to the defaults */ <nl> + if (! info -> attrs [ NL80211_ATTR_TX_RATES ]) <nl> + goto out ; <nl> + <nl> /* <nl> * The nested attribute uses enum nl80211_band as the index . This maps <nl> * directly to the enum ieee80211_band values used in cfg80211 . <nl> static int nl80211_set_tx_bitrate_mask ( struct sk_buff * skb , <nl> } <nl> } <nl>  <nl> + out : <nl> return rdev_set_bitrate_mask ( rdev , dev , NULL , & mask ); <nl> } <nl> 
static ssize_t als_sensing_range_store ( struct device * dev , <nl> struct device_attribute * attr , const char * buf , size_t count ) <nl> { <nl> struct i2c_client * client = to_i2c_client ( dev ); <nl> - unsigned int ret_val ; <nl> + int ret_val ; <nl> unsigned long val ; <nl>  <nl> if ( strict_strtoul ( buf , 10 , & val )) <nl> static ssize_t als_sensing_range_store ( struct device * dev , <nl> val = 4 ; <nl>  <nl> ret_val = i2c_smbus_read_byte_data ( client , 0x00 ); <nl> + if ( ret_val < 0 ) <nl> + return ret_val ; <nl>  <nl> ret_val &= 0xFC ; /* reset the bit before setting them */ <nl> ret_val |= val - 1 ;
static struct platform_driver td_driver = { <nl> . owner = THIS_MODULE , <nl> }, <nl> . probe = td_probe , <nl> - . remove = __exit_p ( td_remove ), <nl> + . remove = td_remove , <nl> }; <nl>  <nl> module_platform_driver ( td_driver );
int gpiochip_add ( struct gpio_chip * chip ) <nl> } <nl> } <nl>  <nl> + spin_unlock_irqrestore (& gpio_lock , flags ); <nl> + <nl> # ifdef CONFIG_PINCTRL <nl> INIT_LIST_HEAD (& chip -> pin_ranges ); <nl> # endif <nl>  <nl> of_gpiochip_add ( chip ); <nl>  <nl> - unlock : <nl> - spin_unlock_irqrestore (& gpio_lock , flags ); <nl> - <nl> if ( status ) <nl> goto fail ; <nl>  <nl> unlock : <nl> chip -> label ? : " generic "); <nl>  <nl> return 0 ; <nl> + <nl> + unlock : <nl> + spin_unlock_irqrestore (& gpio_lock , flags ); <nl> fail : <nl> /* failures here can mean systems won ' t boot ... */ <nl> pr_err (" gpiochip_add : gpios % d ..% d (% s ) failed to register \ n ",
static irqreturn_t sci_er_interrupt ( int irq , void * ptr ) <nl> sci_clear_SCxSR ( port , SCxSR_ERROR_CLEAR ( port )); <nl>  <nl> /* Kick the transmission */ <nl> - sci_tx_interrupt ( irq , ptr ); <nl> + if (! s -> chan_tx ) <nl> + sci_tx_interrupt ( irq , ptr ); <nl>  <nl> return IRQ_HANDLED ; <nl> }
struct iriap_cb * iriap_open ( __u8 slsap_sel , int mode , void * priv , <nl>  <nl> self -> magic = IAS_MAGIC ; <nl> self -> mode = mode ; <nl> - if ( mode == IAS_CLIENT ) <nl> - iriap_register_lsap ( self , slsap_sel , mode ); <nl> + if ( mode == IAS_CLIENT ) { <nl> + if ( iriap_register_lsap ( self , slsap_sel , mode )) { <nl> + kfree ( self ); <nl> + return NULL ; <nl> + } <nl> + } <nl>  <nl> self -> confirm = callback ; <nl> self -> priv = priv ;
out : <nl> pci_write_config_word ( dev , PCI_COMMAND , orig_cmd ); <nl>  <nl> if ( bar_too_big ) <nl> - dev_err (& dev -> dev , " reg % x : can ' t handle 64 - bit BAR \ n ", pos ); <nl> + dev_err (& dev -> dev , " reg 0x % x : can ' t handle 64 - bit BAR \ n ", pos ); <nl> if ( res -> flags && ! bar_disabled ) <nl> - dev_printk ( KERN_DEBUG , & dev -> dev , " reg % x : % pR \ n ", pos , res ); <nl> + dev_printk ( KERN_DEBUG , & dev -> dev , " reg 0x % x : % pR \ n ", pos , res ); <nl>  <nl> return ( res -> flags & IORESOURCE_MEM_64 ) ? 1 : 0 ; <nl> }
static int rbd_get_client ( struct rbd_device * rbd_dev , const char * mon_addr , <nl> rbdc = __rbd_client_find ( opt ); <nl> if ( rbdc ) { <nl> ceph_destroy_options ( opt ); <nl> + kfree ( rbd_opts ); <nl>  <nl> /* using an existing client */ <nl> kref_get (& rbdc -> kref );
# include < linux / module . h > <nl> # include < linux / platform_device . h > <nl> # include < linux / spinlock . h > <nl> + <nl> +# include < asm / mach / irq . h > <nl> + <nl> # include < mach / msm_iomap . h > <nl> # include " gpiomux . h " <nl>  <nl> static int msm_gpio_irq_set_type ( struct irq_data * d , unsigned int flow_type ) <nl> */ <nl> static void msm_summary_irq_handler ( unsigned int irq , struct irq_desc * desc ) <nl> { <nl> - struct irq_data * data = irq_desc_get_irq_data ( desc ); <nl> unsigned long i ; <nl> + struct irq_chip * chip = irq_desc_get_chip ( desc ); <nl> + <nl> + chained_irq_enter ( chip , desc ); <nl>  <nl> for ( i = find_first_bit ( msm_gpio . enabled_irqs , NR_GPIO_IRQS ); <nl> i < NR_GPIO_IRQS ; <nl> static void msm_summary_irq_handler ( unsigned int irq , struct irq_desc * desc ) <nl> generic_handle_irq ( msm_gpio_to_irq (& msm_gpio . gpio_chip , <nl> i )); <nl> } <nl> - data -> chip -> irq_ack ( data ); <nl> + <nl> + chained_irq_exit ( chip , desc ); <nl> } <nl>  <nl> static int msm_gpio_irq_set_wake ( struct irq_data * d , unsigned int on )
static ssize_t sn2_ptc_proc_write ( struct file * file , const char __user * user , si <nl> int cpu ; <nl> char optstr [ 64 ]; <nl>  <nl> + if ( count > sizeof ( optstr )) <nl> + return - EINVAL ; <nl> if ( copy_from_user ( optstr , user , count )) <nl> return - EFAULT ; <nl> optstr [ count - 1 ] = '\ 0 ';
static void WILC_WFI_mon_setup ( struct net_device * dev ) <nl> ether_setup ( dev ); <nl> dev -> tx_queue_len = 0 ; <nl> dev -> type = ARPHRD_IEEE80211_RADIOTAP ; <nl> - memset ( dev -> dev_addr , 0 , ETH_ALEN ); <nl> + eth_zero_addr ( dev -> dev_addr ); <nl>  <nl> # ifdef USE_WIRELESS <nl> {
static void iwlagn_tx_status ( struct iwl_priv * priv , struct sk_buff * skb ) <nl> struct ieee80211_sta * sta ; <nl> struct iwl_station_priv * sta_priv ; <nl>  <nl> + rcu_read_lock (); <nl> sta = ieee80211_find_sta ( priv -> vif , hdr -> addr1 ); <nl> if ( sta ) { <nl> sta_priv = ( void *) sta -> drv_priv ; <nl> static void iwlagn_tx_status ( struct iwl_priv * priv , struct sk_buff * skb ) <nl> atomic_dec_return (& sta_priv -> pending_frames ) == 0 ) <nl> ieee80211_sta_block_awake ( priv -> hw , sta , false ); <nl> } <nl> + rcu_read_unlock (); <nl>  <nl> ieee80211_tx_status_irqsafe ( priv -> hw , skb ); <nl> }
void __cpuinit generic_processor_info ( int apicid , int version ) <nl> num_processors ++; <nl> cpu = cpumask_next_zero (- 1 , cpu_present_mask ); <nl>  <nl> + if ( version != apic_version [ boot_cpu_physical_apicid ]) <nl> + WARN_ONCE ( 1 , <nl> + " ACPI : apic version mismatch , bootcpu : % x cpu % d : % x \ n ", <nl> + apic_version [ boot_cpu_physical_apicid ], cpu , version ); <nl> + <nl> physid_set ( apicid , phys_cpu_present_map ); <nl> if ( apicid == boot_cpu_physical_apicid ) { <nl> /*
static int handle_ctrl ( int has_ac3 , struct saa6752hs_mpeg_params * params , <nl> if ( set && new != V4L2_MPEG_AUDIO_ENCODING_LAYER_2 && <nl> (! has_ac3 || new != V4L2_MPEG_AUDIO_ENCODING_AC3 )) <nl> return - ERANGE ; <nl> - new = old ; <nl> + params -> au_encoding = new ; <nl> break ; <nl> case V4L2_CID_MPEG_AUDIO_L2_BITRATE : <nl> old = params -> au_l2_bitrate ;
static void iwlagn_bt_traffic_change_work ( struct work_struct * work ) <nl> priv -> cfg -> ops -> lib -> update_chain_flags ( priv ); <nl>  <nl> if ( smps_request != - 1 ) { <nl> + priv -> current_ht_config . smps = smps_request ; <nl> for_each_context ( priv , ctx ) { <nl> if ( ctx -> vif && ctx -> vif -> type == NL80211_IFTYPE_STATION ) <nl> ieee80211_request_smps ( ctx -> vif , smps_request );
int sdhci_add_host ( struct sdhci_host * host ) <nl> GFP_KERNEL ); <nl> host -> align_buffer = kmalloc ( host -> align_buffer_sz , GFP_KERNEL ); <nl> if (! host -> adma_table || ! host -> align_buffer ) { <nl> - dma_free_coherent ( mmc_dev ( mmc ), host -> adma_table_sz , <nl> - host -> adma_table , host -> adma_addr ); <nl> + if ( host -> adma_table ) <nl> + dma_free_coherent ( mmc_dev ( mmc ), <nl> + host -> adma_table_sz , <nl> + host -> adma_table , <nl> + host -> adma_addr ); <nl> kfree ( host -> align_buffer ); <nl> pr_warn ("% s : Unable to allocate ADMA buffers - falling back to standard DMA \ n ", <nl> mmc_hostname ( mmc ));
static int snd_timer_user_params ( struct file * file , <nl> if ( tu -> timeri -> flags & SNDRV_TIMER_IFLG_EARLY_EVENT ) { <nl> if ( tu -> tread ) { <nl> struct snd_timer_tread tread ; <nl> + memset (& tread , 0 , sizeof ( tread )); <nl> tread . event = SNDRV_TIMER_EVENT_EARLY ; <nl> tread . tstamp . tv_sec = 0 ; <nl> tread . tstamp . tv_nsec = 0 ;
static int create_trace_kprobe ( int argc , char ** argv ) <nl> pr_info (" Failed to parse symbol .\ n "); <nl> return ret ; <nl> } <nl> + if ( offset && is_return && <nl> + ! arch_function_offset_within_entry ( offset )) { <nl> + pr_info (" Given offset is not valid for return probe .\ n "); <nl> + return - EINVAL ; <nl> + } <nl> } <nl> argc -= 2 ; argv += 2 ; <nl> 
static struct inode * btrfs_new_inode ( struct btrfs_trans_handle * trans , <nl> BUG_ON (! path ); <nl>  <nl> inode = new_inode ( root -> fs_info -> sb ); <nl> - if (! inode ) <nl> + if (! inode ) { <nl> + btrfs_free_path ( path ); <nl> return ERR_PTR (- ENOMEM ); <nl> + } <nl>  <nl> if ( dir ) { <nl> trace_btrfs_inode_request ( dir ); <nl>  <nl> ret = btrfs_set_inode_index ( dir , index ); <nl> if ( ret ) { <nl> + btrfs_free_path ( path ); <nl> iput ( inode ); <nl> return ERR_PTR ( ret ); <nl> }
void flush_tlb_mm ( struct mm_struct * mm ) <nl> { <nl> if ( mm == current -> active_mm ) { <nl> unsigned long flags ; <nl> - local_save_flags ( flags ); <nl> + local_irq_save ( flags ); <nl> __get_new_mmu_context ( mm ); <nl> __load_mmu_context ( mm ); <nl> local_irq_restore ( flags ); <nl> void flush_tlb_range ( struct vm_area_struct * vma , <nl> printk ("[ tlbrange <% 02lx ,% 08lx ,% 08lx >]\ n ", <nl> ( unsigned long ) mm -> context , start , end ); <nl> # endif <nl> - local_save_flags ( flags ); <nl> + local_irq_save ( flags ); <nl>  <nl> if ( end - start + ( PAGE_SIZE - 1 ) <= _TLB_ENTRIES << PAGE_SHIFT ) { <nl> int oldpid = get_rasid_register (); <nl> void flush_tlb_page ( struct vm_area_struct * vma , unsigned long page ) <nl> if ( mm -> context == NO_CONTEXT ) <nl> return ; <nl>  <nl> - local_save_flags ( flags ); <nl> + local_irq_save ( flags ); <nl>  <nl> oldpid = get_rasid_register (); <nl> + set_rasid_register ( ASID_INSERT ( mm -> context )); <nl>  <nl> if ( vma -> vm_flags & VM_EXEC ) <nl> invalidate_itlb_mapping ( page );
static void nvmet_execute_rw ( struct nvmet_req * req ) <nl>  <nl> if ( req -> cmd -> rw . opcode == nvme_cmd_write ) { <nl> op = REQ_OP_WRITE ; <nl> + op_flags = WRITE_ODIRECT ; <nl> if ( req -> cmd -> rw . control & cpu_to_le16 ( NVME_RW_FUA )) <nl> op_flags |= REQ_FUA ; <nl> } else {
int rxrpc_kernel_send_data ( struct socket * sock , struct rxrpc_call * call , <nl> ret = rxrpc_send_data ( rxrpc_sk ( sock -> sk ), call , msg , len ); <nl> break ; <nl> case RXRPC_CALL_COMPLETE : <nl> - /* It ' s too late for this call */ <nl> - ret = - ESHUTDOWN ; <nl> + read_lock_bh (& call -> state_lock ); <nl> + ret = - call -> error ; <nl> + read_unlock_bh (& call -> state_lock ); <nl> break ; <nl> default : <nl> /* Request phase complete for this client call */
int blkdev_ioctl ( struct block_device * bdev , fmode_t mode , unsigned cmd , <nl> * We need to set the startsect first , the driver may <nl> * want to override it . <nl> */ <nl> + memset (& geo , 0 , sizeof ( geo )); <nl> geo . start = get_start_sect ( bdev ); <nl> ret = disk -> fops -> getgeo ( bdev , & geo ); <nl> if ( ret )
# include < libunwind . h > <nl> # include " perf_regs . h " <nl> # include "../../ util / unwind . h " <nl> +# include "../../ util / debug . h " <nl>  <nl> int libunwind__arch_reg_id ( int regnum ) <nl> {
static void saa7164_buffer_deliver ( struct saa7164_buffer * buf ) <nl> struct saa7164_tsport * port = buf -> port ; <nl>  <nl> /* Feed the transport payload into the kernel demux */ <nl> - dvb_dmx_swfilter_packets (& port -> dvb . demux , buf -> cpu , <nl> + dvb_dmx_swfilter_packets (& port -> dvb . demux , ( u8 *) buf -> cpu , <nl> SAA7164_TS_NUMBER_OF_LINES ); <nl>  <nl> }
struct hisi_clock_data * hisi_clk_init ( struct device_node * np , <nl> goto err ; <nl> } <nl> clk_data -> base = base ; <nl> - <nl> - clk_table = kzalloc ( sizeof ( struct clk *) * nr_clks , GFP_KERNEL ); <nl> + clk_table = kcalloc ( nr_clks , sizeof (* clk_table ), GFP_KERNEL ); <nl> if (! clk_table ) { <nl> pr_err ("% s : could not allocate clock lookup table \ n ", __func__ ); <nl> goto err_data ;
static int s3c64xx_cpufreq_set_target ( struct cpufreq_policy * policy , <nl> if ( ret != 0 ) { <nl> pr_err (" Failed to set VDDARM for % dkHz : % d \ n ", <nl> freqs . new , ret ); <nl> - goto err ; <nl> + freqs . new = freqs . old ; <nl> + goto post_notify ; <nl> } <nl> } <nl> # endif <nl> static int s3c64xx_cpufreq_set_target ( struct cpufreq_policy * policy , <nl> if ( ret < 0 ) { <nl> pr_err (" Failed to set rate % dkHz : % d \ n ", <nl> freqs . new , ret ); <nl> - goto err ; <nl> + freqs . new = freqs . old ; <nl> } <nl>  <nl> + post_notify : <nl> cpufreq_notify_transition ( policy , & freqs , CPUFREQ_POSTCHANGE ); <nl> + if ( ret ) <nl> + goto err ; <nl>  <nl> # ifdef CONFIG_REGULATOR <nl> if ( vddarm && freqs . new < freqs . old ) {
xfs_filemap_pmd_fault ( <nl> /* <nl> * pfn_mkwrite was originally inteneded to ensure we capture time stamp <nl> * updates on write faults . In reality , it ' s need to serialise against <nl> - * truncate similar to page_mkwrite . Hence we open - code dax_pfn_mkwrite () <nl> - * here and cycle the XFS_MMAPLOCK_SHARED to ensure we serialise the fault <nl> - * barrier in place . <nl> + * truncate similar to page_mkwrite . Hence we cycle the XFS_MMAPLOCK_SHARED <nl> + * to ensure we serialise the fault barrier in place . <nl> */ <nl> static int <nl> xfs_filemap_pfn_mkwrite ( <nl> xfs_filemap_pfn_mkwrite ( <nl> size = ( i_size_read ( inode ) + PAGE_SIZE - 1 ) >> PAGE_SHIFT ; <nl> if ( vmf -> pgoff >= size ) <nl> ret = VM_FAULT_SIGBUS ; <nl> + else if ( IS_DAX ( inode )) <nl> + ret = dax_pfn_mkwrite ( vma , vmf ); <nl> xfs_iunlock ( ip , XFS_MMAPLOCK_SHARED ); <nl> sb_end_pagefault ( inode -> i_sb ); <nl> return ret ;
static int o2cb_cluster_check ( void ) <nl> set_bit ( node_num , netmap ); <nl> if (! memcmp ( hbmap , netmap , sizeof ( hbmap ))) <nl> return 0 ; <nl> - if ( i < O2CB_MAP_STABILIZE_COUNT ) <nl> + if ( i < O2CB_MAP_STABILIZE_COUNT - 1 ) <nl> msleep ( 1000 ); <nl> } <nl> 
int cdc_ncm_bind_common ( struct usbnet * dev , struct usb_interface * intf , u8 data_ <nl> u8 iface_no ; <nl>  <nl> ctx = kzalloc ( sizeof (* ctx ), GFP_KERNEL ); <nl> - if ( ctx == NULL ) <nl> - return - ENODEV ; <nl> + if (! ctx ) <nl> + return - ENOMEM ; <nl>  <nl> hrtimer_init (& ctx -> tx_timer , CLOCK_MONOTONIC , HRTIMER_MODE_REL ); <nl> ctx -> tx_timer . function = & cdc_ncm_tx_timer_cb ;
nv134_chipset = { <nl> . name = " GP104 ", <nl> . bar = gf100_bar_new , <nl> . bios = nvkm_bios_new , <nl> + . bus = gf100_bus_new , <nl> . devinit = gm200_devinit_new , <nl> . fb = gp104_fb_new , <nl> . imem = nv50_instmem_new ,
void pciback_control_isr ( struct pci_dev * dev , int reset ) <nl> if ( enable ) <nl> dev_data -> irq = dev -> irq ; <nl>  <nl> + /* <nl> + * SR - IOV devices in all use MSI - X and have no legacy <nl> + * interrupts , so inhibit creating a fake IRQ handler for them . <nl> + */ <nl> + if ( dev_data -> irq == 0 ) <nl> + goto out ; <nl> + <nl> dev_dbg (& dev -> dev , "% s : #% d % s % s % s % s -> % s \ n ", <nl> dev_data -> irq_name , <nl> dev_data -> irq ,
static int aesbs_cbc_encrypt ( struct blkcipher_desc * desc , <nl> dst += AES_BLOCK_SIZE ; <nl> } while (-- blocks ); <nl> } <nl> - err = blkcipher_walk_done ( desc , & walk , 0 ); <nl> + err = blkcipher_walk_done ( desc , & walk , walk . nbytes % AES_BLOCK_SIZE ); <nl> } <nl> return err ; <nl> } <nl> static int aesbs_cbc_decrypt ( struct blkcipher_desc * desc , <nl> bsaes_cbc_encrypt ( walk . src . virt . addr , walk . dst . virt . addr , <nl> walk . nbytes , & ctx -> dec , walk . iv ); <nl> kernel_neon_end (); <nl> - err = blkcipher_walk_done ( desc , & walk , 0 ); <nl> + err = blkcipher_walk_done ( desc , & walk , walk . nbytes % AES_BLOCK_SIZE ); <nl> } <nl> while ( walk . nbytes ) { <nl> u32 blocks = walk . nbytes / AES_BLOCK_SIZE ; <nl> static int aesbs_cbc_decrypt ( struct blkcipher_desc * desc , <nl> dst += AES_BLOCK_SIZE ; <nl> src += AES_BLOCK_SIZE ; <nl> } while (-- blocks ); <nl> - err = blkcipher_walk_done ( desc , & walk , 0 ); <nl> + err = blkcipher_walk_done ( desc , & walk , walk . nbytes % AES_BLOCK_SIZE ); <nl> } <nl> return err ; <nl> } <nl> static int aesbs_xts_encrypt ( struct blkcipher_desc * desc , <nl> bsaes_xts_encrypt ( walk . src . virt . addr , walk . dst . virt . addr , <nl> walk . nbytes , & ctx -> enc , walk . iv ); <nl> kernel_neon_end (); <nl> - err = blkcipher_walk_done ( desc , & walk , 0 ); <nl> + err = blkcipher_walk_done ( desc , & walk , walk . nbytes % AES_BLOCK_SIZE ); <nl> } <nl> return err ; <nl> } <nl> static int aesbs_xts_decrypt ( struct blkcipher_desc * desc , <nl> bsaes_xts_decrypt ( walk . src . virt . addr , walk . dst . virt . addr , <nl> walk . nbytes , & ctx -> dec , walk . iv ); <nl> kernel_neon_end (); <nl> - err = blkcipher_walk_done ( desc , & walk , 0 ); <nl> + err = blkcipher_walk_done ( desc , & walk , walk . nbytes % AES_BLOCK_SIZE ); <nl> } <nl> return err ; <nl> }
static int revoke_lo_scan_elements ( struct gfs2_jdesc * jd , unsigned int start , <nl> blkno = be64_to_cpu (*( __be64 *)( bh -> b_data + offset )); <nl>  <nl> error = gfs2_revoke_add ( sdp , blkno , start ); <nl> - if ( error < 0 ) <nl> + if ( error < 0 ) { <nl> + brelse ( bh ); <nl> return error ; <nl> + } <nl> else if ( error ) <nl> sdp -> sd_found_revokes ++; <nl> 
static void wacom_intuos_general ( struct wacom_wac * wacom ) <nl> /* general pen packet */ <nl> if (( data [ 1 ] & 0xb8 ) == 0xa0 ) { <nl> t = ( data [ 6 ] << 2 ) | (( data [ 7 ] >> 6 ) & 3 ); <nl> - if ( features -> type >= INTUOS4S && features -> type <= INTUOS4L ) <nl> + if (( features -> type >= INTUOS4S && features -> type <= INTUOS4L ) || <nl> + features -> type == WACOM_21UX2 ) { <nl> t = ( t << 1 ) | ( data [ 1 ] & 1 ); <nl> + } <nl> input_report_abs ( input , ABS_PRESSURE , t ); <nl> input_report_abs ( input , ABS_TILT_X , <nl> (( data [ 7 ] << 1 ) & 0x7e ) | ( data [ 8 ] >> 7 ));
static int cgroup_get_sb ( struct file_system_type * fs_type , <nl> BUG_ON ( root -> number_of_cgroups != 1 ); <nl>  <nl> cgroup_populate_dir ( root_cgrp ); <nl> - mutex_unlock (& inode -> i_mutex ); <nl> mutex_unlock (& cgroup_mutex ); <nl> + mutex_unlock (& inode -> i_mutex ); <nl> } <nl>  <nl> simple_set_mnt ( mnt , sb );
static int xfrm_get_policy ( struct sk_buff * skb , struct nlmsghdr * nlh , void ** xfr <nl> MSG_DONTWAIT ); <nl> } <nl> } else { <nl> + c . data . byid = p -> index ; <nl> c . event = XFRM_SAP_DELETED ; <nl> c . seq = nlh -> nlmsg_seq ; <nl> c . pid = nlh -> nlmsg_pid ;
int mesh_allocated ; <nl> static struct kmem_cache * rm_cache ; <nl>  <nl> -# ifdef CONFIG_MAC80211_MESH <nl> bool mesh_action_is_path_sel ( struct ieee80211_mgmt * mgmt ) <nl> { <nl> return ( mgmt -> u . action . u . mesh_action . action_code == <nl> WLAN_MESH_ACTION_HWMP_PATH_SELECTION ); <nl> } <nl> -# else <nl> - bool mesh_action_is_path_sel ( struct ieee80211_mgmt * mgmt ) <nl> -{ return false ; } <nl> -# endif <nl>  <nl> void ieee80211s_init ( void ) <nl> {
retry : <nl> } <nl>  <nl> /* Check info buffer */ <nl> - info = ( void *)& msg [ 1 ]; <nl> + info = ( void *)& bcdc -> buf [ 0 ]; <nl>  <nl> /* Copy info buffer */ <nl> if ( buf ) {
static void * raid0_takeover_raid1 ( mddev_t * mddev ) <nl> mddev -> new_layout = 0 ; <nl> mddev -> new_chunk_sectors = 128 ; /* by default set chunk size to 64k */ <nl> mddev -> delta_disks = 1 - mddev -> raid_disks ; <nl> + mddev -> raid_disks = 1 ; <nl> /* make sure it will be not marked as dirty */ <nl> mddev -> recovery_cp = MaxSector ; <nl> 
static struct net_bridge_mdb_entry * __br_mdb_ip_get ( <nl> static struct net_bridge_mdb_entry * br_mdb_ip_get ( <nl> struct net_bridge_mdb_htable * mdb , __be32 dst ) <nl> { <nl> + if (! mdb ) <nl> + return NULL ; <nl> + <nl> return __br_mdb_ip_get ( mdb , dst , br_ip_hash ( mdb , dst )); <nl> } <nl>  <nl> struct net_bridge_mdb_entry * br_mdb_get ( struct net_bridge * br , <nl> struct sk_buff * skb ) <nl> { <nl> - struct net_bridge_mdb_htable * mdb = br -> mdb ; <nl> - <nl> - if (! mdb || br -> multicast_disabled ) <nl> + if ( br -> multicast_disabled ) <nl> return NULL ; <nl>  <nl> switch ( skb -> protocol ) { <nl> case htons ( ETH_P_IP ): <nl> if ( BR_INPUT_SKB_CB ( skb )-> igmp ) <nl> break ; <nl> - return br_mdb_ip_get ( mdb , ip_hdr ( skb )-> daddr ); <nl> + return br_mdb_ip_get ( br -> mdb , ip_hdr ( skb )-> daddr ); <nl> } <nl>  <nl> return NULL ;
static int __ixgbe_shutdown ( struct pci_dev * pdev , bool * enable_wake ) <nl>  <nl> netif_device_detach ( netdev ); <nl>  <nl> + rtnl_lock (); <nl> if ( netif_running ( netdev )) { <nl> - rtnl_lock (); <nl> ixgbe_down ( adapter ); <nl> ixgbe_free_irq ( adapter ); <nl> ixgbe_free_all_tx_resources ( adapter ); <nl> ixgbe_free_all_rx_resources ( adapter ); <nl> - rtnl_unlock (); <nl> } <nl> + rtnl_unlock (); <nl>  <nl> ixgbe_clear_interrupt_scheme ( adapter ); <nl> 
static int ibmvfc_map_sg_data ( struct scsi_cmnd * scmd , <nl> & evt -> ext_list_token ); <nl>  <nl> if (! evt -> ext_list ) { <nl> - scmd_printk ( KERN_ERR , scmd , " Can ' t allocate memory for scatterlist \ n "); <nl> + scsi_dma_unmap ( scmd ); <nl> + if ( vhost -> log_level > IBMVFC_DEFAULT_LOG_LEVEL ) <nl> + scmd_printk ( KERN_ERR , scmd , " Can ' t allocate memory for scatterlist \ n "); <nl> return - ENOMEM ; <nl> } <nl> }
static void dce3_2_afmt_write_sad_regs ( struct drm_encoder * encoder ) <nl> } <nl>  <nl> sad_count = drm_edid_to_sad ( radeon_connector -> edid , & sads ); <nl> - if ( sad_count < 0 ) { <nl> + if ( sad_count <= 0 ) { <nl> DRM_ERROR (" Couldn ' t read SADs : % d \ n ", sad_count ); <nl> return ; <nl> }
static void iwl3945_tx_cmd_complete ( struct iwl_priv * priv , <nl> int cmd_index ; <nl> struct iwl_cmd * cmd ; <nl>  <nl> - BUG_ON ( txq_id != IWL_CMD_QUEUE_NUM ); <nl> + if ( WARN ( txq_id != IWL_CMD_QUEUE_NUM , <nl> + " wrong command queue % d , sequence 0x % X readp =% d writep =% d \ n ", <nl> + txq_id , sequence , <nl> + priv -> txq [ IWL_CMD_QUEUE_NUM ]. q . read_ptr , <nl> + priv -> txq [ IWL_CMD_QUEUE_NUM ]. q . write_ptr )) { <nl> + iwl_print_hex_dump ( priv , IWL_DL_INFO , rxb , 32 ); <nl> + return ; <nl> + } <nl>  <nl> cmd_index = get_cmd_index (& priv -> txq [ IWL_CMD_QUEUE_NUM ]. q , index , huge ); <nl> cmd = priv -> txq [ IWL_CMD_QUEUE_NUM ]. cmd [ cmd_index ];
static int rename_volumes ( struct ubi_device * ubi , <nl> req -> ents [ i ]. name [ req -> ents [ i ]. name_len ] = '\ 0 '; <nl> n = strlen ( req -> ents [ i ]. name ); <nl> if ( n != req -> ents [ i ]. name_len ) <nl> - err = - EINVAL ; <nl> + return - EINVAL ; <nl> } <nl>  <nl> /* Make sure volume IDs and names are unique */
int dm_split_args ( int * argc , char *** argvp , char * input ) <nl> unsigned array_size = 0 ; <nl>  <nl> * argc = 0 ; <nl> + <nl> + if (! input ) { <nl> + * argvp = NULL ; <nl> + return 0 ; <nl> + } <nl> + <nl> argv = realloc_argv (& array_size , argv ); <nl> if (! argv ) <nl> return - ENOMEM ;
void btrfs_clear_lock_blocking ( struct extent_buffer * eb ) <nl> static int btrfs_spin_on_block ( struct extent_buffer * eb ) <nl> { <nl> int i ; <nl> + <nl> for ( i = 0 ; i < 512 ; i ++) { <nl> - cpu_relax (); <nl> if (! test_bit ( EXTENT_BUFFER_BLOCKING , & eb -> bflags )) <nl> return 1 ; <nl> if ( need_resched ()) <nl> break ; <nl> + cpu_relax (); <nl> } <nl> return 0 ; <nl> } <nl> int btrfs_try_spin_lock ( struct extent_buffer * eb ) <nl>  <nl> /* spin for a bit on the BLOCKING flag */ <nl> for ( i = 0 ; i < 2 ; i ++) { <nl> + cpu_relax (); <nl> if (! btrfs_spin_on_block ( eb )) <nl> break ; <nl>  <nl> int btrfs_tree_lock ( struct extent_buffer * eb ) <nl> DEFINE_WAIT ( wait ); <nl> wait . func = btrfs_wake_function ; <nl>  <nl> + if (! btrfs_spin_on_block ( eb )) <nl> + goto sleep ; <nl> + <nl> while ( 1 ) { <nl> spin_nested ( eb ); <nl>  <nl> int btrfs_tree_lock ( struct extent_buffer * eb ) <nl> * spin for a bit , and if the blocking flag goes away , <nl> * loop around <nl> */ <nl> + cpu_relax (); <nl> if ( btrfs_spin_on_block ( eb )) <nl> continue ; <nl> - <nl> + sleep : <nl> prepare_to_wait_exclusive (& eb -> lock_wq , & wait , <nl> TASK_UNINTERRUPTIBLE ); <nl> 
spider_net_prepare_rx_descr ( struct spider_net_card * card , <nl> /* and we need to have it 128 byte aligned , therefore we allocate a <nl> * bit more */ <nl> /* allocate an skb */ <nl> - descr -> skb = dev_alloc_skb ( bufsize + SPIDER_NET_RXBUF_ALIGN - 1 ); <nl> + descr -> skb = netdev_alloc_skb ( card -> netdev , <nl> + bufsize + SPIDER_NET_RXBUF_ALIGN - 1 ); <nl> if (! descr -> skb ) { <nl> if ( netif_msg_rx_err ( card ) && net_ratelimit ()) <nl> pr_err (" Not enough memory to allocate rx buffer \ n ");
static int __maybe_unused mx51_ecspi_config ( struct spi_imx_data * spi_imx , <nl> else <nl> cfg &= ~ MX51_ECSPI_CONFIG_SSBPOL ( config -> cs ); <nl>  <nl> + /* CTRL register always go first to bring out controller from reset */ <nl> + writel ( ctrl , spi_imx -> base + MX51_ECSPI_CTRL ); <nl> + <nl> reg = readl ( spi_imx -> base + MX51_ECSPI_TESTREG ); <nl> if ( config -> mode & SPI_LOOP ) <nl> reg |= MX51_ECSPI_TESTREG_LBC ; <nl> static int __maybe_unused mx51_ecspi_config ( struct spi_imx_data * spi_imx , <nl> reg &= ~ MX51_ECSPI_TESTREG_LBC ; <nl> writel ( reg , spi_imx -> base + MX51_ECSPI_TESTREG ); <nl>  <nl> - writel ( ctrl , spi_imx -> base + MX51_ECSPI_CTRL ); <nl> writel ( cfg , spi_imx -> base + MX51_ECSPI_CONFIG ); <nl>  <nl> /*
static int mwifiex_get_common_rates ( struct mwifiex_private * priv , u8 * rate1 , <nl>  <nl> memset ( rate1 , 0 , rate1_size ); <nl>  <nl> - for ( i = 0 ; rate2 [ i ] && i < rate2_size ; i ++) { <nl> - for ( j = 0 ; tmp [ j ] && j < rate1_size ; j ++) { <nl> + for ( i = 0 ; i < rate2_size && rate2 [ i ]; i ++) { <nl> + for ( j = 0 ; j < rate1_size && tmp [ j ]; j ++) { <nl> /* Check common rate , excluding the bit for <nl> basic rate */ <nl> if (( rate2 [ i ] & 0x7F ) == ( tmp [ j ] & 0x7F )) {
static struct sock * run_bpf ( struct sock_reuseport * reuse , u16 socks , <nl>  <nl> /* temporarily advance data past protocol header */ <nl> if (! pskb_pull ( skb , hdr_len )) { <nl> - consume_skb ( nskb ); <nl> + kfree_skb ( nskb ); <nl> return NULL ; <nl> } <nl> index = bpf_prog_run_save_cb ( prog , skb );
jme_alloc_and_feed_skb ( struct jme_adapter * jme , int idx ) <nl> jme -> jme_vlan_rx ( skb , jme -> vlgrp , <nl> le16_to_cpu ( rxdesc -> descwb . vlan )); <nl> NET_STAT ( jme ). rx_bytes += 4 ; <nl> + } else { <nl> + dev_kfree_skb ( skb ); <nl> } <nl> } else { <nl> jme -> jme_rx ( skb );
enum { DMA_CHAIN_STARTED , DMA_CHAIN_NOTSTARTED }; <nl> # endif <nl>  <nl> # define OMAP_DMA_ACTIVE 0x01 <nl> -# define OMAP2_DMA_CSR_CLEAR_MASK 0xffe <nl> +# define OMAP2_DMA_CSR_CLEAR_MASK 0xffffffff <nl>  <nl> # define OMAP_FUNC_MUX_ARM_BASE ( 0xfffe1000 + 0xec ) <nl>  <nl> static int omap2_dma_handle_ch ( int ch ) <nl> printk ( KERN_INFO " DMA misaligned error with device % d \ n ", <nl> dma_chan [ ch ]. dev_id ); <nl>  <nl> - p -> dma_write ( OMAP2_DMA_CSR_CLEAR_MASK , CSR , ch ); <nl> + p -> dma_write ( status , CSR , ch ); <nl> p -> dma_write ( 1 << ch , IRQSTATUS_L0 , ch ); <nl> /* read back the register to flush the write */ <nl> p -> dma_read ( IRQSTATUS_L0 , ch ); <nl> static int omap2_dma_handle_ch ( int ch ) <nl> OMAP_DMA_CHAIN_INCQHEAD ( chain_id ); <nl>  <nl> status = p -> dma_read ( CSR , ch ); <nl> + p -> dma_write ( status , CSR , ch ); <nl> } <nl>  <nl> - p -> dma_write ( status , CSR , ch ); <nl> - <nl> if ( likely ( dma_chan [ ch ]. callback != NULL )) <nl> dma_chan [ ch ]. callback ( ch , status , dma_chan [ ch ]. data ); <nl> 
int bitmap_copy_from_slot ( struct mddev * mddev , int slot , <nl>  <nl> if ( clear_bits ) { <nl> bitmap_update_sb ( bitmap ); <nl> - /* Setting this for the ev_page should be enough . <nl> - * And we do not require both write_all and PAGE_DIRT either <nl> - */ <nl> + /* BITMAP_PAGE_PENDING is set , but bitmap_unplug needs <nl> + * BITMAP_PAGE_DIRTY or _NEEDWRITE to write ... */ <nl> for ( i = 0 ; i < bitmap -> storage . file_pages ; i ++) <nl> - set_page_attr ( bitmap , i , BITMAP_PAGE_DIRTY ); <nl> - bitmap_write_all ( bitmap ); <nl> + if ( test_page_attr ( bitmap , i , BITMAP_PAGE_PENDING )) <nl> + set_page_attr ( bitmap , i , BITMAP_PAGE_NEEDWRITE ); <nl> bitmap_unplug ( bitmap ); <nl> } <nl> + bitmap_unplug ( mddev -> bitmap ); <nl> * low = lo ; <nl> * high = hi ; <nl> err :
static void raid10d ( mddev_t * mddev ) <nl> sl --; <nl> d = r10_bio -> devs [ sl ]. devnum ; <nl> rdev = conf -> mirrors [ d ]. rdev ; <nl> - atomic_add ( s , & rdev -> corrected_errors ); <nl> if ( rdev && <nl> test_bit ( In_sync , & rdev -> flags )) { <nl> + atomic_add ( s , & rdev -> corrected_errors ); <nl> if ( sync_page_io ( rdev -> bdev , <nl> r10_bio -> devs [ sl ]. addr + <nl> sect + rdev -> data_offset ,
static ssize_t btrfs_label_store ( struct kobject * kobj , <nl> int ret ; <nl> size_t p_len ; <nl>  <nl> + if ( fs_info -> sb -> s_flags & MS_RDONLY ) <nl> + return - EROFS ; <nl> + <nl> /* <nl> * p_len is the len until the first occurrence of either <nl> * '\ n ' or '\ 0 '
static int dspi_request_dma ( struct fsl_dspi * dspi , phys_addr_t phy_addr ) <nl> return 0 ; <nl>  <nl> err_slave_config : <nl> - devm_kfree ( dev , dma -> rx_dma_buf ); <nl> + dma_free_coherent ( dev , DSPI_DMA_BUFSIZE , <nl> + dma -> rx_dma_buf , dma -> rx_dma_phys ); <nl> err_rx_dma_buf : <nl> - devm_kfree ( dev , dma -> tx_dma_buf ); <nl> + dma_free_coherent ( dev , DSPI_DMA_BUFSIZE , <nl> + dma -> tx_dma_buf , dma -> tx_dma_phys ); <nl> err_tx_dma_buf : <nl> dma_release_channel ( dma -> chan_tx ); <nl> err_tx_channel :
int btrfs_open_devices ( struct btrfs_fs_devices * fs_devices , <nl> goto error_brelse ; <nl>  <nl> transid = btrfs_super_generation ( disk_super ); <nl> - if ( transid > latest_transid ) { <nl> + if (! latest_transid || transid > latest_transid ) { <nl> latest_devid = devid ; <nl> latest_transid = transid ; <nl> latest_bdev = bdev ;
extern void numa_initmem_init ( unsigned long start_pfn , unsigned long end_pfn ); <nl> extern unsigned long numa_free_all_bootmem ( void ); <nl>  <nl> extern void reserve_bootmem_generic ( unsigned long phys , unsigned len ); <nl> - extern void free_bootmem_generic ( unsigned long phys , unsigned len ); <nl>  <nl> extern void load_gs_index ( unsigned gs ); <nl> 
static void __init emergency_stack_init ( void ) <nl> */ <nl> limit = min ( 0x10000000UL , lmb . rmo_size ); <nl>  <nl> - for_each_possible_cpu ( i ) <nl> - paca [ i ]. emergency_sp = <nl> - __va ( lmb_alloc_base ( HW_PAGE_SIZE , 128 , limit )) + HW_PAGE_SIZE ; <nl> + for_each_possible_cpu ( i ) { <nl> + unsigned long sp ; <nl> + sp = lmb_alloc_base ( THREAD_SIZE , THREAD_SIZE , limit ); <nl> + sp += THREAD_SIZE ; <nl> + paca [ i ]. emergency_sp = __va ( sp ); <nl> + } <nl> } <nl>  <nl> /*
static u32 crc32c_vpmsum ( u32 crc , unsigned char const * p , size_t len ) <nl> } <nl>  <nl> if ( len & ~ VMX_ALIGN_MASK ) { <nl> + preempt_disable (); <nl> pagefault_disable (); <nl> enable_kernel_altivec (); <nl> crc = __crc32c_vpmsum ( crc , p , len & ~ VMX_ALIGN_MASK ); <nl> + disable_kernel_altivec (); <nl> pagefault_enable (); <nl> + preempt_enable (); <nl> } <nl>  <nl> tail = len & VMX_ALIGN_MASK ;
void __iomem * __arm_ioremap_pfn_caller ( unsigned long pfn , <nl> if (! area ) <nl> return NULL ; <nl> addr = ( unsigned long ) area -> addr ; <nl> + area -> phys_addr = __pfn_to_phys ( pfn ); <nl>  <nl> # if ! defined ( CONFIG_SMP ) && ! defined ( CONFIG_ARM_LPAE ) <nl> if ( DOMAIN_IO == 0 &&
static int qla4xxx_fw_ready ( struct scsi_qla_host * ha ) <nl> DEBUG2 ( printk (" scsi % ld : % s : FW initialized , but " <nl> " auto - discovery still in process \ n ", <nl> ha -> host_no , __func__ )); <nl> + ready = 1 ; <nl> } <nl>  <nl> return ready ;
static void __cpuinit put_core_offline ( unsigned int cpu ) <nl>  <nl> indx = TO_ATTR_NO ( cpu ); <nl>  <nl> + /* The core id is too big , just return */ <nl> + if ( indx > MAX_CORE_DATA - 1 ) <nl> + return ; <nl> + <nl> if ( pdata -> core_data [ indx ] && pdata -> core_data [ indx ]-> cpu == cpu ) <nl> coretemp_remove_core ( pdata , & pdev -> dev , indx ); <nl> 
static unsigned long clk_pllv3_av_recalc_rate ( struct clk_hw * hw , <nl> u32 mfn = readl_relaxed ( pll -> base + PLL_NUM_OFFSET ); <nl> u32 mfd = readl_relaxed ( pll -> base + PLL_DENOM_OFFSET ); <nl> u32 div = readl_relaxed ( pll -> base ) & pll -> div_mask ; <nl> + u64 temp64 = ( u64 ) parent_rate ; <nl>  <nl> - return ( parent_rate * div ) + (( parent_rate / mfd ) * mfn ); <nl> + temp64 *= mfn ; <nl> + do_div ( temp64 , mfd ); <nl> + <nl> + return ( parent_rate * div ) + ( u32 ) temp64 ; <nl> } <nl>  <nl> static long clk_pllv3_av_round_rate ( struct clk_hw * hw , unsigned long rate , <nl> static long clk_pllv3_av_round_rate ( struct clk_hw * hw , unsigned long rate , <nl> do_div ( temp64 , parent_rate ); <nl> mfn = temp64 ; <nl>  <nl> - return parent_rate * div + parent_rate / mfd * mfn ; <nl> + return parent_rate * div + parent_rate * mfn / mfd ; <nl> } <nl>  <nl> static int clk_pllv3_av_set_rate ( struct clk_hw * hw , unsigned long rate ,
static int udf_pc_to_char ( struct super_block * sb , unsigned char * from , <nl> tolen --; <nl> while ( elen < fromlen ) { <nl> pc = ( struct pathComponent *)( from + elen ); <nl> + elen += sizeof ( struct pathComponent ); <nl> switch ( pc -> componentType ) { <nl> case 1 : <nl> /* <nl> * Symlink points to some place which should be agreed <nl> * upon between originator and receiver of the media . Ignore . <nl> */ <nl> - if ( pc -> lengthComponentIdent > 0 ) <nl> + if ( pc -> lengthComponentIdent > 0 ) { <nl> + elen += pc -> lengthComponentIdent ; <nl> break ; <nl> + } <nl> /* Fall through */ <nl> case 2 : <nl> if ( tolen == 0 ) <nl> static int udf_pc_to_char ( struct super_block * sb , unsigned char * from , <nl> /* that would be . - just ignore */ <nl> break ; <nl> case 5 : <nl> + elen += pc -> lengthComponentIdent ; <nl> + if ( elen > fromlen ) <nl> + return - EIO ; <nl> comp_len = udf_get_filename ( sb , pc -> componentIdent , <nl> pc -> lengthComponentIdent , <nl> p , tolen ); <nl> static int udf_pc_to_char ( struct super_block * sb , unsigned char * from , <nl> tolen --; <nl> break ; <nl> } <nl> - elen += sizeof ( struct pathComponent ) + pc -> lengthComponentIdent ; <nl> } <nl> if ( p > to + 1 ) <nl> p [- 1 ] = '\ 0 ';
out : <nl> return err ; <nl> } <nl>  <nl> - static int recover_data ( struct f2fs_sb_info * sbi , <nl> - struct list_head * head , int type ) <nl> + static int recover_data ( struct f2fs_sb_info * sbi , struct list_head * head ) <nl> { <nl> unsigned long long cp_ver = cur_cp_version ( F2FS_CKPT ( sbi )); <nl> struct curseg_info * curseg ; <nl> static int recover_data ( struct f2fs_sb_info * sbi , <nl> block_t blkaddr ; <nl>  <nl> /* get node pages in the current segment */ <nl> - curseg = CURSEG_I ( sbi , type ); <nl> + curseg = CURSEG_I ( sbi , CURSEG_WARM_NODE ); <nl> blkaddr = NEXT_FREE_BLKADDR ( sbi , curseg ); <nl>  <nl> while ( 1 ) { <nl> int recover_fsync_data ( struct f2fs_sb_info * sbi ) <nl> need_writecp = true ; <nl>  <nl> /* step # 2 : recover data */ <nl> - err = recover_data ( sbi , & inode_list , CURSEG_WARM_NODE ); <nl> + err = recover_data ( sbi , & inode_list ); <nl> if (! err ) <nl> f2fs_bug_on ( sbi , ! list_empty (& inode_list )); <nl> out :
static struct usbip_imported_device * imported_device_init ( struct usbip_imported_ <nl> goto err ; <nl>  <nl> memcpy ( new_cdev , cdev , sizeof (* new_cdev )); <nl> - dlist_unshift ( idev -> cdev_list , ( void *) new_cdev ); <nl> + dlist_unshift ( idev -> cdev_list , ( void *) new_cdev ); <nl> } <nl> } <nl> 
static void intel_agp_insert_sg_entries ( struct agp_memory * mem , <nl> off_t pg_start , int mask_type ) <nl> { <nl> int i , j ; <nl> + u32 cache_bits = 0 ; <nl> + <nl> + if ( agp_bridge -> dev -> device == PCI_DEVICE_ID_INTEL_SANDYBRIDGE_HB ) { <nl> + cache_bits = I830_PTE_SYSTEM_CACHED ; <nl> + } <nl>  <nl> for ( i = 0 , j = pg_start ; i < mem -> page_count ; i ++, j ++) { <nl> writel ( agp_bridge -> driver -> mask_memory ( agp_bridge ,
static void qeth_free_qdio_buffers ( struct qeth_card * card ) <nl>  <nl> qeth_free_cq ( card ); <nl> cancel_delayed_work_sync (& card -> buffer_reclaim_work ); <nl> - for ( j = 0 ; j < QDIO_MAX_BUFFERS_PER_Q ; ++ j ) <nl> - dev_kfree_skb_any ( card -> qdio . in_q -> bufs [ j ]. rx_skb ); <nl> + for ( j = 0 ; j < QDIO_MAX_BUFFERS_PER_Q ; ++ j ) { <nl> + if ( card -> qdio . in_q -> bufs [ j ]. rx_skb ) <nl> + dev_kfree_skb_any ( card -> qdio . in_q -> bufs [ j ]. rx_skb ); <nl> + } <nl> kfree ( card -> qdio . in_q ); <nl> card -> qdio . in_q = NULL ; <nl> /* inbound buffer pool */
const struct bond_option * bond_opt_get ( unsigned int option ) <nl> return & bond_opts [ option ]; <nl> } <nl>  <nl> - int bond_option_mode_set ( struct bonding * bond , const struct bond_opt_value * newval ) <nl> + static int bond_option_mode_set ( struct bonding * bond , <nl> + const struct bond_opt_value * newval ) <nl> { <nl> if (! bond_mode_uses_arp ( newval -> value ) && bond -> params . arp_interval ) { <nl> pr_info ("% s : % s mode is incompatible with arp monitoring , start mii monitoring \ n ",
static void timekeeping_adjust ( s64 offset ) <nl> } else /* No adjustment needed */ <nl> return ; <nl>  <nl> - WARN_ONCE ( timekeeper . clock -> maxadj && <nl> - ( timekeeper . mult + adj > timekeeper . clock -> mult + <nl> - timekeeper . clock -> maxadj ), <nl> - " Adjusting % s more then 11 %% (% ld vs % ld )\ n ", <nl> + if ( unlikely ( timekeeper . clock -> maxadj && <nl> + ( timekeeper . mult + adj > <nl> + timekeeper . clock -> mult + timekeeper . clock -> maxadj ))) { <nl> + printk_once ( KERN_WARNING <nl> + " Adjusting % s more than 11 %% (% ld vs % ld )\ n ", <nl> timekeeper . clock -> name , ( long ) timekeeper . mult + adj , <nl> ( long ) timekeeper . clock -> mult + <nl> timekeeper . clock -> maxadj ); <nl> + } <nl> /* <nl> * So the following can be confusing . <nl> *
static int ubifs_xattr_set ( const struct xattr_handler * handler , <nl> return __ubifs_removexattr ( inode , name ); <nl> } <nl>  <nl> - const struct xattr_handler ubifs_user_xattr_handler = { <nl> + static const struct xattr_handler ubifs_user_xattr_handler = { <nl> . prefix = XATTR_USER_PREFIX , <nl> . get = ubifs_xattr_get , <nl> . set = ubifs_xattr_set , <nl> }; <nl>  <nl> - const struct xattr_handler ubifs_trusted_xattr_handler = { <nl> + static const struct xattr_handler ubifs_trusted_xattr_handler = { <nl> . prefix = XATTR_TRUSTED_PREFIX , <nl> . get = ubifs_xattr_get , <nl> . set = ubifs_xattr_set , <nl> }; <nl>  <nl> - const struct xattr_handler ubifs_security_xattr_handler = { <nl> + static const struct xattr_handler ubifs_security_xattr_handler = { <nl> . prefix = XATTR_SECURITY_PREFIX , <nl> . get = ubifs_xattr_get , <nl> . set = ubifs_xattr_set ,
struct sched_domain * build_sched_domain ( struct sched_domain_topology_level * tl , <nl> sd -> level = child -> level + 1 ; <nl> sched_domain_level_max = max ( sched_domain_level_max , sd -> level ); <nl> child -> parent = sd ; <nl> + sd -> child = child ; <nl> } <nl> - sd -> child = child ; <nl> set_domain_attribute ( sd , attr ); <nl>  <nl> return sd ;
static int s5m87xx_i2c_probe ( struct i2c_client * i2c , <nl> s5m87xx -> rtc = i2c_new_dummy ( i2c -> adapter , RTC_I2C_ADDR ); <nl> i2c_set_clientdata ( s5m87xx -> rtc , s5m87xx ); <nl>  <nl> - if ( pdata -> cfg_pmic_irq ) <nl> + if ( pdata && pdata -> cfg_pmic_irq ) <nl> pdata -> cfg_pmic_irq (); <nl>  <nl> s5m_irq_init ( s5m87xx );
cdef 8255 <nl> */ <nl>  <nl> -# define DAS08AO_AO_LSB ( x ) (( x ) ? 0xa : 8 ) <nl> -# define DAS08AO_AO_MSB ( x ) (( x ) ? 0xb : 9 ) <nl> +/* ( W ) analog output l . s . b . registers for 2 channels (" AOx " boards ) */ <nl> +# define DAS08AOX_AO_LSB_REG ( x ) (( x ) ? 0x0a : 0x08 ) <nl> +/* ( W ) analog output m . s . b . registers for 2 channels (" AOx " boards ) */ <nl> +# define DAS08AOX_AO_MSB_REG ( x ) (( x ) ? 0x0b : 0x09 ) <nl> # define DAS08AO_AO_UPDATE 8 <nl>  <nl> /* gainlist same as _pgx_ below */ <nl> static void das08_ao_set_data ( struct comedi_device * dev , <nl> /* load DACs */ <nl> inb ( dev -> iobase + DAS08JR_AO_UPDATE_REG ); <nl> } else { <nl> - outb ( lsb , dev -> iobase + DAS08AO_AO_LSB ( chan )); <nl> - outb ( msb , dev -> iobase + DAS08AO_AO_MSB ( chan )); <nl> + outb ( lsb , dev -> iobase + DAS08AOX_AO_LSB_REG ( chan )); <nl> + outb ( msb , dev -> iobase + DAS08AOX_AO_MSB_REG ( chan )); <nl> /* load DACs */ <nl> inb ( dev -> iobase + DAS08AO_AO_UPDATE ); <nl> }
static int alc882_mux_enum_put ( struct snd_kcontrol * kcontrol , <nl> const struct hda_input_mux * imux = spec -> input_mux ; <nl> unsigned int adc_idx = snd_ctl_get_ioffidx ( kcontrol , & ucontrol -> id ); <nl> static hda_nid_t capture_mixers [ 3 ] = { 0x24 , 0x23 , 0x22 }; <nl> - hda_nid_t nid = capture_mixers [ adc_idx ]; <nl> + hda_nid_t nid ; <nl> unsigned int * cur_val = & spec -> cur_mux [ adc_idx ]; <nl> unsigned int i , idx ; <nl>  <nl> + if ( spec -> num_adc_nids < 3 ) <nl> + nid = capture_mixers [ adc_idx + 1 ]; <nl> + else <nl> + nid = capture_mixers [ adc_idx ]; <nl> idx = ucontrol -> value . enumerated . item [ 0 ]; <nl> if ( idx >= imux -> num_items ) <nl> idx = imux -> num_items - 1 ;
static int gen_pci_parse_map_cfg_windows ( struct gen_pci * pci ) <nl> return err ; <nl> } <nl>  <nl> - pci -> cfg . win = devm_kcalloc ( dev , resource_size (& pci -> cfg . bus_range ), <nl> - sizeof (* pci -> cfg . win ), GFP_KERNEL ); <nl> - if (! pci -> cfg . win ) <nl> - return - ENOMEM ; <nl> - <nl> /* Limit the bus - range to fit within reg */ <nl> bus_max = pci -> cfg . bus_range . start + <nl> ( resource_size (& pci -> cfg . res ) >> pci -> cfg . ops -> bus_shift ) - 1 ; <nl> pci -> cfg . bus_range . end = min_t ( resource_size_t , pci -> cfg . bus_range . end , <nl> bus_max ); <nl>  <nl> + pci -> cfg . win = devm_kcalloc ( dev , resource_size (& pci -> cfg . bus_range ), <nl> + sizeof (* pci -> cfg . win ), GFP_KERNEL ); <nl> + if (! pci -> cfg . win ) <nl> + return - ENOMEM ; <nl> + <nl> /* Map our Configuration Space windows */ <nl> if (! devm_request_mem_region ( dev , pci -> cfg . res . start , <nl> resource_size (& pci -> cfg . res ),
static int mgsl_alloc_intermediate_txbuffer_memory ( struct mgsl_struct * info ) <nl> for ( i = 0 ; i < info -> num_tx_holding_buffers ; ++ i ) { <nl> info -> tx_holding_buffers [ i ]. buffer = <nl> kmalloc ( info -> max_frame_size , GFP_KERNEL ); <nl> - if ( info -> tx_holding_buffers [ i ]. buffer == NULL ) <nl> + if ( info -> tx_holding_buffers [ i ]. buffer == NULL ) { <nl> + for (-- i ; i >= 0 ; i --) { <nl> + kfree ( info -> tx_holding_buffers [ i ]. buffer ); <nl> + info -> tx_holding_buffers [ i ]. buffer = NULL ; <nl> + } <nl> return - ENOMEM ; <nl> + } <nl> } <nl>  <nl> return 0 ;
dio200_inttrig_start_intr ( struct comedi_device * dev , struct comedi_subdevice * s , <nl> subpriv = s -> private ; <nl>  <nl> spin_lock_irqsave (& subpriv -> spinlock , flags ); <nl> - s -> async -> inttrig = 0 ; <nl> + s -> async -> inttrig = NULL ; <nl> if ( subpriv -> active ) <nl> event = dio200_start_intr ( dev , s ); <nl>  <nl> static int dio200_attach ( struct comedi_device * dev , struct comedi_devconfig * it ) <nl> break ; <nl> case sd_8255 : <nl> /* digital i / o subdevice ( 8255 ) */ <nl> - ret = subdev_8255_init ( dev , s , 0 , <nl> + ret = subdev_8255_init ( dev , s , NULL , <nl> iobase + layout -> sdinfo [ n ]); <nl> if ( ret < 0 ) <nl> return ret ;
qla2x00_mark_vp_devices_dead ( scsi_qla_host_t * vha ) <nl> int <nl> qla24xx_disable_vp ( scsi_qla_host_t * vha ) <nl> { <nl> + unsigned long flags ; <nl> int ret ; <nl>  <nl> ret = qla24xx_control_vp ( vha , VCE_COMMAND_DISABLE_VPS_LOGO_ALL ); <nl> qla24xx_disable_vp ( scsi_qla_host_t * vha ) <nl> atomic_set (& vha -> loop_down_timer , LOOP_DOWN_TIME ); <nl>  <nl> /* Remove port id from vp target map */ <nl> + spin_lock_irqsave (& vha -> hw -> vport_slock , flags ); <nl> qlt_update_vp_map ( vha , RESET_AL_PA ); <nl> + spin_unlock_irqrestore (& vha -> hw -> vport_slock , flags ); <nl>  <nl> qla2x00_mark_vp_devices_dead ( vha ); <nl> atomic_set (& vha -> vp_state , VP_FAILED );
static void usX2Y_clients_stop ( struct usX2Ydev * usX2Y ) <nl> struct snd_usX2Y_substream * subs = usX2Y -> subs [ s ]; <nl> if ( subs ) { <nl> if ( atomic_read (& subs -> state ) >= state_PRERUNNING ) { <nl> + unsigned long flags ; <nl> + <nl> + snd_pcm_stream_lock_irqsave ( subs -> pcm_substream , flags ); <nl> snd_pcm_stop ( subs -> pcm_substream , SNDRV_PCM_STATE_XRUN ); <nl> + snd_pcm_stream_unlock_irqrestore ( subs -> pcm_substream , flags ); <nl> } <nl> for ( u = 0 ; u < NRURBS ; u ++) { <nl> struct urb * urb = subs -> urb [ u ];
static int vidioc_reqbufs ( struct file * file , void * priv , <nl> struct v4l2_requestbuffers * rb ) <nl> { <nl> struct gspca_dev * gspca_dev = priv ; <nl> - int i , ret = 0 ; <nl> + int i , ret = 0 , streaming ; <nl>  <nl> switch ( rb -> memory ) { <nl> case GSPCA_MEMORY_READ : /* ( internal call ) */ <nl> static int vidioc_reqbufs ( struct file * file , void * priv , <nl> } <nl>  <nl> /* stop streaming */ <nl> - if ( gspca_dev -> streaming ) { <nl> + streaming = gspca_dev -> streaming ; <nl> + if ( streaming ) { <nl> mutex_lock (& gspca_dev -> usb_lock ); <nl> gspca_dev -> usb_err = 0 ; <nl> gspca_stream_off ( gspca_dev ); <nl> static int vidioc_reqbufs ( struct file * file , void * priv , <nl> if ( ret == 0 ) { <nl> rb -> count = gspca_dev -> nframes ; <nl> gspca_dev -> capt_file = file ; <nl> + if ( streaming ) <nl> + ret = gspca_init_transfer ( gspca_dev ); <nl> } <nl> out : <nl> mutex_unlock (& gspca_dev -> queue_lock );
static int pm_genpd_summary_one ( struct seq_file * s , <nl> struct pm_domain_data * pm_data ; <nl> const char * kobj_path ; <nl> struct gpd_link * link ; <nl> + char state [ 16 ]; <nl> int ret ; <nl>  <nl> ret = mutex_lock_interruptible (& genpd -> lock ); <nl> static int pm_genpd_summary_one ( struct seq_file * s , <nl>  <nl> if ( WARN_ON ( genpd -> status >= ARRAY_SIZE ( status_lookup ))) <nl> goto exit ; <nl> - seq_printf ( s , "%- 30s % s ", genpd -> name , status_lookup [ genpd -> status ]); <nl> - <nl> if ( genpd -> status == GPD_STATE_POWER_OFF ) <nl> - seq_printf ( s , " %- 13d ", genpd -> state_idx ); <nl> + snprintf ( state , sizeof ( state ), "% s % u ", <nl> + status_lookup [ genpd -> status ], genpd -> state_idx ); <nl> else <nl> - seq_printf ( s , " %- 15s ", ""); <nl> + snprintf ( state , sizeof ( state ), "% s ", <nl> + status_lookup [ genpd -> status ]); <nl> + seq_printf ( s , "%- 30s %- 15s ", genpd -> name , state ); <nl>  <nl> /* <nl> * Modifications on the list require holding locks on both
static int mwifiex_host_to_card_mp_aggr ( struct mwifiex_adapter * adapter , <nl> __func__ ); <nl>  <nl> if ( MP_TX_AGGR_IN_PROGRESS ( card )) { <nl> - if (! mp_tx_aggr_port_limit_reached ( card ) && <nl> - MP_TX_AGGR_BUF_HAS_ROOM ( card , pkt_len )) { <nl> + if ( MP_TX_AGGR_BUF_HAS_ROOM ( card , pkt_len )) { <nl> f_precopy_cur_buf = 1 ; <nl>  <nl> if (!( card -> mp_wr_bitmap & <nl> static int mwifiex_host_to_card_mp_aggr ( struct mwifiex_adapter * adapter , <nl> /* No room in Aggr buf , send it */ <nl> f_send_aggr_buf = 1 ; <nl>  <nl> - if ( mp_tx_aggr_port_limit_reached ( card ) || <nl> - !( card -> mp_wr_bitmap & <nl> + if (!( card -> mp_wr_bitmap & <nl> ( 1 << card -> curr_wr_port ))) <nl> f_send_cur_buf = 1 ; <nl> else
static void mt2060_calibrate ( struct mt2060_priv * priv ) <nl> while ( i ++ < 10 && mt2060_readreg ( priv , REG_MISC_STAT , & b ) == 0 && ( b & ( 1 << 6 )) == 0 ) <nl> msleep ( 20 ); <nl>  <nl> - if ( i < 10 ) { <nl> + if ( i <= 10 ) { <nl> mt2060_readreg ( priv , REG_FM_FREQ , & priv -> fmfreq ); // now find out , what is fmreq used for :) <nl> dprintk (" calibration was successful : % d ", ( int ) priv -> fmfreq ); <nl> } else
out0 : <nl>  <nl> static int __devexit nuc900_ac97_drvremove ( struct platform_device * pdev ) <nl> { <nl> - <nl> snd_soc_unregister_dai (& pdev -> dev ); <nl>  <nl> clk_put ( nuc900_ac97_data -> clk ); <nl> static int __devexit nuc900_ac97_drvremove ( struct platform_device * pdev ) <nl> release_mem_region ( nuc900_ac97_data -> res -> start , <nl> resource_size ( nuc900_ac97_data -> res )); <nl>  <nl> + kfree ( nuc900_ac97_data ); <nl> nuc900_ac97_data = NULL ; <nl>  <nl> return 0 ;
# define FIRMWARE_TONGA " amdgpu / tonga_uvd . bin " <nl> # define FIRMWARE_CARRIZO " amdgpu / carrizo_uvd . bin " <nl> # define FIRMWARE_FIJI " amdgpu / fiji_uvd . bin " <nl> +# define FIRMWARE_STONEY " amdgpu / stoney_uvd . bin " <nl>  <nl> /** <nl> * amdgpu_uvd_cs_ctx - Command submission parser context <nl> MODULE_FIRMWARE ( FIRMWARE_MULLINS ); <nl> MODULE_FIRMWARE ( FIRMWARE_TONGA ); <nl> MODULE_FIRMWARE ( FIRMWARE_CARRIZO ); <nl> MODULE_FIRMWARE ( FIRMWARE_FIJI ); <nl> + MODULE_FIRMWARE ( FIRMWARE_STONEY ); <nl>  <nl> static void amdgpu_uvd_note_usage ( struct amdgpu_device * adev ); <nl> static void amdgpu_uvd_idle_work_handler ( struct work_struct * work ); <nl> int amdgpu_uvd_sw_init ( struct amdgpu_device * adev ) <nl> case CHIP_CARRIZO : <nl> fw_name = FIRMWARE_CARRIZO ; <nl> break ; <nl> + case CHIP_STONEY : <nl> + fw_name = FIRMWARE_STONEY ; <nl> + break ; <nl> default : <nl> return - EINVAL ; <nl> }
static int davinci_spi_bufs_dma ( struct spi_device * spi , struct spi_transfer * t ) <nl>  <nl> data1_reg_val = ioread32 ( davinci_spi -> base + SPIDAT1 ); <nl>  <nl> - INIT_COMPLETION ( davinci_spi -> done ); <nl> - <nl> init_completion (& davinci_spi_dma -> dma_rx_completion ); <nl> init_completion (& davinci_spi_dma -> dma_tx_completion ); <nl> 
static int find_probes ( int fd , struct probe_finder * pf ) <nl> . file = pp -> file , <nl> . cu_die = & pf -> cu_die , <nl> . sp_die = & pf -> sp_die , <nl> + . found = 0 , <nl> }; <nl> struct dwarf_callback_param probe_param = { <nl> . data = pf ,
static int cache_block_group ( struct btrfs_root * root , <nl> struct btrfs_block_group_cache * block_group ) <nl> { <nl> struct btrfs_path * path ; <nl> - int ret ; <nl> + int ret = 0 ; <nl> struct btrfs_key key ; <nl> struct extent_buffer * leaf ; <nl> struct extent_io_tree * free_space_cache ; <nl> static int cache_block_group ( struct btrfs_root * root , <nl> btrfs_set_key_type (& key , BTRFS_EXTENT_ITEM_KEY ); <nl> ret = btrfs_search_slot ( NULL , root , & key , path , 0 , 0 ); <nl> if ( ret < 0 ) <nl> - return ret ; <nl> + goto err ; <nl> ret = btrfs_previous_item ( root , path , 0 , BTRFS_EXTENT_ITEM_KEY ); <nl> if ( ret < 0 ) <nl> - return ret ; <nl> + goto err ; <nl> if ( ret == 0 ) { <nl> leaf = path -> nodes [ 0 ]; <nl> btrfs_item_key_to_cpu ( leaf , & key , path -> slots [ 0 ]); <nl> next : <nl> last + hole_size - 1 , GFP_NOFS ); <nl> } <nl> block_group -> cached = 1 ; <nl> + ret = 0 ; <nl> err : <nl> btrfs_free_path ( path ); <nl> - return 0 ; <nl> + return ret ; <nl> } <nl>  <nl> struct btrfs_block_group_cache * btrfs_lookup_first_block_group ( struct
struct omap_dss_output * omap_dss_get_output ( enum omap_dss_output_id id ) <nl>  <nl> return NULL ; <nl> } <nl> + EXPORT_SYMBOL ( omap_dss_get_output ); <nl>  <nl> static const struct dss_mgr_ops * dss_mgr_ops ; <nl> 
int snd_soc_codec_set_cache_io ( struct snd_soc_codec * codec , <nl> enum snd_soc_control_type control ) <nl> { <nl> struct regmap_config config ; <nl> + int ret ; <nl>  <nl> memset (& config , 0 , sizeof ( config )); <nl> codec -> write = hw_write ; <nl> int snd_soc_codec_set_cache_io ( struct snd_soc_codec * codec , <nl> case SND_SOC_REGMAP : <nl> /* Device has made its own regmap arrangements */ <nl> codec -> using_regmap = true ; <nl> + <nl> + ret = regmap_get_val_bytes ( codec -> control_data ); <nl> + /* Errors are legitimate for non - integer byte multiples */ <nl> + if ( ret > 0 ) <nl> + codec -> val_bytes = ret ; <nl> break ; <nl>  <nl> default :
int __init irttp_init ( void ) <nl> if (! irttp -> tsaps ) { <nl> IRDA_ERROR ("% s : can ' t allocate IrTTP hashbin !\ n ", <nl> __FUNCTION__ ); <nl> + kfree ( irttp ); <nl> return - ENOMEM ; <nl> } <nl> 
static int dpcm_add_paths ( struct snd_soc_pcm_runtime * fe , int stream , <nl>  <nl> switch ( list -> widgets [ i ]-> id ) { <nl> case snd_soc_dapm_dai_in : <nl> + if ( stream != SNDRV_PCM_STREAM_PLAYBACK ) <nl> + continue ; <nl> + break ; <nl> case snd_soc_dapm_dai_out : <nl> + if ( stream != SNDRV_PCM_STREAM_CAPTURE ) <nl> + continue ; <nl> break ; <nl> default : <nl> continue ;
struct btrfs_root * btrfs_create_tree ( struct btrfs_trans_handle * trans , <nl> fail : <nl> if ( leaf ) { <nl> btrfs_tree_unlock ( leaf ); <nl> + free_extent_buffer ( root -> commit_root ); <nl> free_extent_buffer ( leaf ); <nl> } <nl> kfree ( root );
extern void cpuidle_disable_device ( struct cpuidle_device * dev ); <nl> # else <nl>  <nl> static inline int cpuidle_register_driver ( struct cpuidle_driver * drv ) <nl> -{ return 0 ;} <nl> +{ return - ENODEV ; } <nl> static inline void cpuidle_unregister_driver ( struct cpuidle_driver * drv ) { } <nl> static inline int cpuidle_register_device ( struct cpuidle_device * dev ) <nl> -{ return 0 ;} <nl> +{ return - ENODEV ; } <nl> static inline void cpuidle_unregister_device ( struct cpuidle_device * dev ) { } <nl>  <nl> static inline void cpuidle_pause_and_lock ( void ) { } <nl> static inline void cpuidle_resume_and_unlock ( void ) { } <nl> static inline int cpuidle_enable_device ( struct cpuidle_device * dev ) <nl> -{ return 0 ;} <nl> +{ return - ENODEV ; } <nl> static inline void cpuidle_disable_device ( struct cpuidle_device * dev ) { } <nl>  <nl> # endif
static int fuse_retrieve ( struct fuse_conn * fc , struct inode * inode , <nl> loff_t file_size ; <nl> unsigned int num ; <nl> unsigned int offset ; <nl> - size_t total_len ; <nl> + size_t total_len = 0 ; <nl>  <nl> req = fuse_get_req ( fc ); <nl> if ( IS_ERR ( req ))
extern int efi_memattr_apply_permissions ( struct mm_struct * mm , <nl> /* Iterate through an efi_memory_map */ <nl> # define for_each_efi_memory_desc_in_map ( m , md ) \ <nl> for (( md ) = ( m )-> map ; \ <nl> - (( void *)( md ) + ( m )-> desc_size ) <= ( m )-> map_end ; \ <nl> + ( md ) && (( void *)( md ) + ( m )-> desc_size ) <= ( m )-> map_end ; \ <nl> ( md ) = ( void *)( md ) + ( m )-> desc_size ) <nl>  <nl> /**
static void process_queued_ios ( struct work_struct * work ) <nl> m -> pg_init_count ++; <nl> m -> pg_init_required = 0 ; <nl> list_for_each_entry ( tmp , & pgpath -> pg -> pgpaths , list ) { <nl> + /* Skip failed paths */ <nl> + if (! tmp -> is_active ) <nl> + continue ; <nl> if ( queue_work ( kmpath_handlerd , & tmp -> activate_path )) <nl> m -> pg_init_in_progress ++; <nl> } <nl> static void pg_init_done ( void * data , int errors ) <nl> errors = 0 ; <nl> break ; <nl> } <nl> - DMERR (" Cannot failover device because scsi_dh_ % s was not " <nl> - " loaded .", m -> hw_handler_name ); <nl> + DMERR (" Could not failover the device : Handler scsi_dh_ % s " <nl> + " Error % d .", m -> hw_handler_name , errors ); <nl> /* <nl> * Fail path for now , so we do not ping pong <nl> */
svga3dsurface_get_mip_size ( surf_size_struct base_level , u32 mip_level ) <nl> size . width = max_t ( u32 , base_level . width >> mip_level , 1 ); <nl> size . height = max_t ( u32 , base_level . height >> mip_level , 1 ); <nl> size . depth = max_t ( u32 , base_level . depth >> mip_level , 1 ); <nl> + size . pad64 = 0 ; <nl> + <nl> return size ; <nl> } <nl> 
static int stmmac_rx ( struct stmmac_priv * priv , int limit ) <nl>  <nl> frame_len = priv -> hw -> desc -> get_rx_frame_len ( p , coe ); <nl>  <nl> + /* check if frame_len fits the preallocated memory */ <nl> + if ( frame_len > priv -> dma_buf_sz ) { <nl> + priv -> dev -> stats . rx_length_errors ++; <nl> + break ; <nl> + } <nl> + <nl> /* ACS is set ; GMAC core strips PAD / FCS for IEEE 802 . 3 <nl> * Type frames ( LLC / LLC - SNAP ) <nl> */
static int __init s3c2410fb_probe ( struct platform_device * pdev ) <nl>  <nl> info = fbinfo -> par ; <nl> info -> fb = fbinfo ; <nl> + info -> dev = & pdev -> dev ; <nl> + <nl> platform_set_drvdata ( pdev , fbinfo ); <nl>  <nl> dprintk (" devinit \ n ");
static int bcm_char_ioctl_buffer_download_stop ( void __user * argp , <nl> static int bcm_char_ioctl_chip_reset ( struct bcm_mini_adapter * ad ) <nl> { <nl> INT status ; <nl> - INT NVMAccess ; <nl> + INT nvm_access ; <nl>  <nl> - NVMAccess = down_trylock (& ad -> NVMRdmWrmLock ); <nl> - if ( NVMAccess ) { <nl> + nvm_access = down_trylock (& ad -> NVMRdmWrmLock ); <nl> + if ( nvm_access ) { <nl> BCM_DEBUG_PRINT ( ad , DBG_TYPE_PRINTK , 0 , 0 , <nl> " IOCTL_BCM_CHIP_RESET not allowed as EEPROM Read / Write is in progress \ n "); <nl> return - EACCES ;
static struct request * get_req ( struct scsi_device * sdev , int cmd , <nl> switch ( cmd ) { <nl> case MODE_SELECT : <nl> len = sizeof ( short_trespass ); <nl> - rq -> cmd_flags |= REQ_RW ; <nl> rq -> cmd [ 1 ] = 0x10 ; <nl> rq -> cmd [ 4 ] = len ; <nl> break ; <nl> case MODE_SELECT_10 : <nl> len = sizeof ( long_trespass ); <nl> - rq -> cmd_flags |= REQ_RW ; <nl> rq -> cmd [ 1 ] = 0x10 ; <nl> rq -> cmd [ 8 ] = len ; <nl> break ;
static int clock_info_cmd_complete ( struct mgmt_pending_cmd * cmd , u8 status ) <nl> int err ; <nl>  <nl> memset (& rp , 0 , sizeof ( rp )); <nl> - memcpy (& rp . addr , & cmd -> param , sizeof ( rp . addr )); <nl> + memcpy (& rp . addr , cmd -> param , sizeof ( rp . addr )); <nl>  <nl> if ( status ) <nl> goto complete ;
static void ath9k_mgd_prepare_tx ( struct ieee80211_hw * hw , <nl> init_completion (& sc -> go_beacon ); <nl>  <nl> mutex_unlock (& sc -> mutex ); <nl> + <nl> if ( wait_for_completion_timeout (& sc -> go_beacon , <nl> - timeout ) == 0 ) <nl> + timeout ) == 0 ) { <nl> ath_dbg ( common , CHAN_CTX , <nl> " Failed to send new NoA \ n "); <nl> + <nl> + spin_lock_bh (& sc -> chan_lock ); <nl> + sc -> sched . mgd_prepare_tx = false ; <nl> + spin_unlock_bh (& sc -> chan_lock ); <nl> + } <nl> + <nl> mutex_lock (& sc -> mutex ); <nl> } <nl> 
struct ima_h_table ima_htable = { <nl> static DEFINE_MUTEX ( ima_extend_list_mutex ); <nl>  <nl> /* lookup up the digest value in the hash table , and return the entry */ <nl> - static struct ima_queue_entry * ima_lookup_digest_entry ( u8 * digest_value ) <nl> + static struct ima_queue_entry * ima_lookup_digest_entry ( u8 * digest_value , <nl> + int pcr ) <nl> { <nl> struct ima_queue_entry * qe , * ret = NULL ; <nl> unsigned int key ; <nl> static struct ima_queue_entry * ima_lookup_digest_entry ( u8 * digest_value ) <nl> rcu_read_lock (); <nl> hlist_for_each_entry_rcu ( qe , & ima_htable . queue [ key ], hnext ) { <nl> rc = memcmp ( qe -> entry -> digest , digest_value , TPM_DIGEST_SIZE ); <nl> - if ( rc == 0 ) { <nl> + if (( rc == 0 ) && ( qe -> entry -> pcr == pcr )) { <nl> ret = qe ; <nl> break ; <nl> } <nl> int ima_add_template_entry ( struct ima_template_entry * entry , int violation , <nl> mutex_lock (& ima_extend_list_mutex ); <nl> if (! violation ) { <nl> memcpy ( digest , entry -> digest , sizeof ( digest )); <nl> - if ( ima_lookup_digest_entry ( digest )) { <nl> + if ( ima_lookup_digest_entry ( digest , entry -> pcr )) { <nl> audit_cause = " hash_exists "; <nl> result = - EEXIST ; <nl> goto out ;
static bool mem_cgroup_same_or_subtree ( const struct mem_cgroup * root_memcg , <nl> bool task_in_mem_cgroup ( struct task_struct * task , <nl> const struct mem_cgroup * memcg ) <nl> { <nl> - struct mem_cgroup * curr = NULL ; <nl> + struct mem_cgroup * curr ; <nl> struct task_struct * p ; <nl> bool ret ; <nl>  <nl> bool task_in_mem_cgroup ( struct task_struct * task , <nl> */ <nl> rcu_read_lock (); <nl> curr = mem_cgroup_from_task ( task ); <nl> - if ( curr ) <nl> - css_get (& curr -> css ); <nl> + css_get (& curr -> css ); <nl> rcu_read_unlock (); <nl> } <nl> /*
static struct intel_uncore_box * uncore_alloc_box ( struct intel_uncore_type * type , <nl> */ <nl> static int uncore_pmu_event_init ( struct perf_event * event ); <nl>  <nl> - static bool is_uncore_event ( struct perf_event * event ) <nl> + static bool is_box_event ( struct intel_uncore_box * box , struct perf_event * event ) <nl> { <nl> - return event -> pmu -> event_init == uncore_pmu_event_init ; <nl> + return & box -> pmu -> pmu == event -> pmu ; <nl> } <nl>  <nl> static int <nl> uncore_collect_events ( struct intel_uncore_box * box , struct perf_event * leader , <nl>  <nl> n = box -> n_events ; <nl>  <nl> - if ( is_uncore_event ( leader )) { <nl> + if ( is_box_event ( box , leader )) { <nl> box -> event_list [ n ] = leader ; <nl> n ++; <nl> } <nl> uncore_collect_events ( struct intel_uncore_box * box , struct perf_event * leader , <nl> return n ; <nl>  <nl> list_for_each_entry ( event , & leader -> sibling_list , group_entry ) { <nl> - if (! is_uncore_event ( event ) || <nl> + if (! is_box_event ( box , event ) || <nl> event -> state <= PERF_EVENT_STATE_OFF ) <nl> continue ; <nl> 
void ivtv_udma_fill_sg_array ( struct ivtv_user_dma * dma , u32 buffer_offset , u32 <nl> int i ; <nl> struct scatterlist * sg ; <nl>  <nl> - for ( i = 0 , sg = dma -> SGlist ; i < dma -> SG_length ; i ++, sg = sg_next ( sg )) { <nl> + for_each_sg ( dma -> SGlist , sg , dma -> SG_length , i ) { <nl> dma -> SGarray [ i ]. size = cpu_to_le32 ( sg_dma_len ( sg )); <nl> dma -> SGarray [ i ]. src = cpu_to_le32 ( sg_dma_address ( sg )); <nl> dma -> SGarray [ i ]. dst = cpu_to_le32 ( buffer_offset );
static int ch7006_encoder_create_resources ( struct drm_encoder * encoder , <nl> drm_mode_create_tv_properties ( dev , NUM_TV_NORMS , ch7006_tv_norm_names ); <nl>  <nl> priv -> scale_property = drm_property_create_range ( dev , 0 , " scale ", 0 , 2 ); <nl> + if (! priv -> scale_property ) <nl> + return - ENOMEM ; <nl>  <nl> drm_object_attach_property (& connector -> base , conf -> tv_select_subconnector_property , <nl> priv -> select_subconnector );
static int flush_sample_queue ( struct perf_session * s , <nl> u64 limit = os -> next_flush ; <nl> u64 last_ts = os -> last_sample ? os -> last_sample -> timestamp : 0ULL ; <nl> unsigned idx = 0 , progress_next = os -> nr_samples / 16 ; <nl> + bool show_progress = limit == ULLONG_MAX ; <nl> int ret ; <nl>  <nl> if (! tool -> ordered_samples || ! limit ) <nl> static int flush_sample_queue ( struct perf_session * s , <nl> os -> last_flush = iter -> timestamp ; <nl> list_del (& iter -> list ); <nl> list_add (& iter -> list , & os -> sample_cache ); <nl> - if (++ idx >= progress_next ) { <nl> + if ( show_progress && (++ idx >= progress_next )) { <nl> progress_next += os -> nr_samples / 16 ; <nl> ui_progress__update ( idx , os -> nr_samples , <nl> " Processing time ordered events ...");
static irqreturn_t twl6030_irq_thread ( int irq , void * data ) <nl> int i , ret ; <nl> union { <nl> u8 bytes [ 4 ]; <nl> - u32 int_sts ; <nl> + __le32 int_sts ; <nl> } sts ; <nl> + u32 int_sts ; /* sts . int_sts converted to CPU endianness */ <nl> struct twl6030_irq * pdata = data ; <nl>  <nl> /* read INT_STS_A , B and C in one shot using a burst read */ <nl> static irqreturn_t twl6030_irq_thread ( int irq , void * data ) <nl> if ( sts . bytes [ 2 ] & 0x10 ) <nl> sts . bytes [ 2 ] |= 0x08 ; <nl>  <nl> - for ( i = 0 ; sts . int_sts ; sts . int_sts >>= 1 , i ++) <nl> - if ( sts . int_sts & 0x1 ) { <nl> + int_sts = le32_to_cpu ( sts . int_sts ); <nl> + for ( i = 0 ; int_sts ; int_sts >>= 1 , i ++) <nl> + if ( int_sts & 0x1 ) { <nl> int module_irq = <nl> irq_find_mapping ( pdata -> irq_domain , <nl> pdata -> irq_mapping_tbl [ i ]);
static int menu_select ( struct cpuidle_driver * drv , struct cpuidle_device * dev ) <nl> * We want to default to C1 ( hlt ), not to busy polling <nl> * unless the timer is happening really really soon . <nl> */ <nl> - if ( data -> next_timer_us > 20 && <nl> + if ( interactivity_req > 20 && <nl> ! drv -> states [ CPUIDLE_DRIVER_STATE_START ]. disabled && <nl> dev -> states_usage [ CPUIDLE_DRIVER_STATE_START ]. disable == 0 ) <nl> data -> last_state_idx = CPUIDLE_DRIVER_STATE_START ;
static void xhci_pci_quirks ( struct device * dev , struct xhci_hcd * xhci ) <nl> xhci -> quirks |= XHCI_RESET_ON_RESUME ; <nl> xhci_dbg ( xhci , " QUIRK : Resetting on resume \ n "); <nl> } <nl> + if ( pdev -> vendor == PCI_VENDOR_ID_VIA ) <nl> + xhci -> quirks |= XHCI_RESET_ON_RESUME ; <nl> } <nl>  <nl> /* called during probe () after chip reset completes */
static ssize_t bcm_char_read ( struct file * filp , <nl> struct bcm_tarang_data * tarang = filp -> private_data ; <nl> struct bcm_mini_adapter * ad = tarang -> Adapter ; <nl> struct sk_buff * Packet = NULL ; <nl> - ssize_t PktLen = 0 ; <nl> + ssize_t pkt_len = 0 ; <nl> int wait_ret_val = 0 ; <nl> unsigned long ret = 0 ; <nl>  <nl> static ssize_t bcm_char_read ( struct file * filp , <nl> up (& ad -> RxAppControlQueuelock ); <nl>  <nl> if ( Packet ) { <nl> - PktLen = Packet -> len ; <nl> + pkt_len = Packet -> len ; <nl> ret = copy_to_user ( buf , Packet -> data , <nl> - min_t ( size_t , PktLen , size )); <nl> + min_t ( size_t , pkt_len , size )); <nl> if ( ret ) { <nl> dev_kfree_skb ( Packet ); <nl> BCM_DEBUG_PRINT ( ad , DBG_TYPE_PRINTK , 0 , 0 , <nl> static ssize_t bcm_char_read ( struct file * filp , <nl> } <nl> BCM_DEBUG_PRINT ( ad , DBG_TYPE_OTHERS , OSAL_DBG , DBG_LVL_ALL , <nl> " Read % zd Bytes From Adapter packet = % p by process % d !\ n ", <nl> - PktLen , Packet , current -> pid ); <nl> + pkt_len , Packet , current -> pid ); <nl> dev_kfree_skb ( Packet ); <nl> } <nl>  <nl> BCM_DEBUG_PRINT ( ad , DBG_TYPE_OTHERS , OSAL_DBG , DBG_LVL_ALL , "<\ n "); <nl> - return PktLen ; <nl> + return pkt_len ; <nl> } <nl>  <nl> static int bcm_char_ioctl_reg_read_private ( void __user * argp ,
static int pull_rt_task ( struct rq * this_rq ) <nl> /* <nl> * Are there still pullable RT tasks ? <nl> */ <nl> - if ( src_rq -> rt . rt_nr_running <= 1 ) { <nl> - spin_unlock (& src_rq -> lock ); <nl> - continue ; <nl> - } <nl> + if ( src_rq -> rt . rt_nr_running <= 1 ) <nl> + goto skip ; <nl>  <nl> p = pick_next_highest_task_rt ( src_rq , this_cpu ); <nl>  <nl> static int pull_rt_task ( struct rq * this_rq ) <nl> */ <nl> if ( p -> prio < src_rq -> curr -> prio || <nl> ( next && next -> prio < src_rq -> curr -> prio )) <nl> - goto out ; <nl> + goto skip ; <nl>  <nl> ret = 1 ; <nl>  <nl> static int pull_rt_task ( struct rq * this_rq ) <nl> next = p ; <nl>  <nl> } <nl> - out : <nl> + skip : <nl> spin_unlock (& src_rq -> lock ); <nl> } <nl> 
int wilc_wlan_handle_txq ( struct net_device * dev , u32 * txq_count ) <nl> if ( tqe -> type == WILC_CFG_PKT ) { <nl> buffer_offset = ETH_CONFIG_PKT_HDR_OFFSET ; <nl> } else if ( tqe -> type == WILC_NET_PKT ) { <nl> - char * pBSSID = (( struct tx_complete_data *)( tqe -> priv ))-> pBssid ; <nl> + char * bssid = (( struct tx_complete_data *)( tqe -> priv ))-> pBssid ; <nl>  <nl> buffer_offset = ETH_ETHERNET_HDR_OFFSET ; <nl> - memcpy (& txb [ offset + 4 ], pBSSID , 6 ); <nl> + memcpy (& txb [ offset + 4 ], bssid , 6 ); <nl> } else { <nl> buffer_offset = HOST_HDR_OFFSET ; <nl> }
static char * res_strings [] = { <nl> " reserved 37 ", <nl> " reserved 38 ", <nl> " reserved 39 ", <nl> - " reseverd 40 ", <nl> + " reserved 40 ", <nl> " reserved 41 ", <nl> " reserved 42 ", <nl> " reserved 43 ",
static void ttm_put_pages ( struct page ** pages , unsigned npages , int flags , <nl> } <nl>  <nl> # ifdef CONFIG_TRANSPARENT_HUGEPAGE <nl> - if (!( flags & TTM_PAGE_FLAG_DMA32 )) { <nl> + if (!( flags & TTM_PAGE_FLAG_DMA32 ) && <nl> + ( npages - i ) >= HPAGE_PMD_NR ) { <nl> for ( j = 0 ; j < HPAGE_PMD_NR ; ++ j ) <nl> if ( p ++ != pages [ i + j ]) <nl> break ; <nl> static void ttm_put_pages ( struct page ** pages , unsigned npages , int flags , <nl> unsigned max_size , n2free ; <nl>  <nl> spin_lock_irqsave (& huge -> lock , irq_flags ); <nl> - while ( i < npages ) { <nl> + while (( npages - i ) >= HPAGE_PMD_NR ) { <nl> struct page * p = pages [ i ]; <nl> unsigned j ; <nl> 
static int do_siocgstamp ( struct net * net , struct socket * sock , <nl> err = sock_do_ioctl ( net , sock , cmd , ( unsigned long )& ktv ); <nl> set_fs ( old_fs ); <nl> if (! err ) <nl> - err = compat_put_timeval ( up , & ktv ); <nl> + err = compat_put_timeval (& ktv , up ); <nl>  <nl> return err ; <nl> } <nl> static int do_siocgstampns ( struct net * net , struct socket * sock , <nl> err = sock_do_ioctl ( net , sock , cmd , ( unsigned long )& kts ); <nl> set_fs ( old_fs ); <nl> if (! err ) <nl> - err = compat_put_timespec ( up , & kts ); <nl> + err = compat_put_timespec (& kts , up ); <nl>  <nl> return err ; <nl> }
static int ntfs_write_mst_block ( struct page * page , <nl> ntfs_volume * vol = ni -> vol ; <nl> u8 * kaddr ; <nl> unsigned int rec_size = ni -> itype . index . block_size ; <nl> - ntfs_inode * locked_nis [ PAGE_SIZE / rec_size ]; <nl> + ntfs_inode * locked_nis [ PAGE_SIZE / NTFS_BLOCK_SIZE ]; <nl> struct buffer_head * bh , * head , * tbh , * rec_start_bh ; <nl> struct buffer_head * bhs [ MAX_BUF_PER_PAGE ]; <nl> runlist_element * rl ; <nl> static int ntfs_write_mst_block ( struct page * page , <nl> bool sync , is_mft , page_is_dirty , rec_is_dirty ; <nl> unsigned char bh_size_bits ; <nl>  <nl> + if ( WARN_ON ( rec_size < NTFS_BLOCK_SIZE )) <nl> + return - EINVAL ; <nl> + <nl> ntfs_debug (" Entering for inode 0x % lx , attribute type 0x % x , page index " <nl> " 0x % lx .", vi -> i_ino , ni -> type , page -> index ); <nl> BUG_ON (! NInoNonResident ( ni ));
static int can_rcv ( struct sk_buff * skb , struct net_device * dev , <nl>  <nl> rcu_read_unlock (); <nl>  <nl> - /* free the skbuff allocated by the netdevice driver */ <nl> - kfree_skb ( skb ); <nl> + /* consume the skbuff allocated by the netdevice driver */ <nl> + consume_skb ( skb ); <nl>  <nl> if ( matches > 0 ) { <nl> can_stats . matches ++;
static int __do_request ( struct ceph_mds_client * mdsc , <nl> int mds = - 1 ; <nl> int err = - EAGAIN ; <nl>  <nl> - if ( req -> r_err || req -> r_got_result ) <nl> + if ( req -> r_err || req -> r_got_result ) { <nl> + if ( req -> r_aborted ) <nl> + __unregister_request ( mdsc , req ); <nl> goto out ; <nl> + } <nl>  <nl> if ( req -> r_timeout && <nl> time_after_eq ( jiffies , req -> r_started + req -> r_timeout )) {
static void gb_gpio_set_value_operation ( struct gb_gpio_controller * ggc , <nl> struct gb_gpio_set_value_request request ; <nl> int ret ; <nl>  <nl> + if ( ggc -> lines [ which ]. direction == 1 ) { <nl> + dev_warn ( ggc -> chip . dev , <nl> + " refusing to set value of input gpio % u \ n ", which ); <nl> + return ; <nl> + } <nl> + <nl> request . which = which ; <nl> request . value = value_high ? 1 : 0 ; <nl> ret = gb_operation_sync ( ggc -> connection , GB_GPIO_TYPE_SET_VALUE , <nl> & request , sizeof ( request ), NULL , 0 ); <nl> - if (! ret ) { <nl> - /* XXX should this set direction to out ? */ <nl> + if (! ret ) <nl> ggc -> lines [ which ]. value = request . value ; <nl> - } <nl> } <nl>  <nl> static int gb_gpio_set_debounce_operation ( struct gb_gpio_controller * ggc ,
static struct kioctx * ioctx_alloc ( unsigned nr_events ) <nl> err_cleanup : <nl> aio_nr_sub ( ctx -> max_reqs ); <nl> err : <nl> - aio_free_ring ( ctx ); <nl> free_percpu ( ctx -> cpu ); <nl> free_percpu ( ctx -> reqs . pcpu_count ); <nl> free_percpu ( ctx -> users . pcpu_count );
void __init init_IRQ ( void ) <nl> struct irq_desc * desc ; <nl> int irq ; <nl>  <nl> - for ( irq = 0 ; irq < nr_irqs ; irq ++) <nl> + for ( irq = 0 ; irq < nr_irqs ; irq ++) { <nl> + desc = irq_to_desc_alloc_node ( irq , 0 ); <nl> desc -> status |= IRQ_NOREQUEST | IRQ_NOPROBE ; <nl> + } <nl>  <nl> init_arch_irq (); <nl> }
static u32 filter_rcv ( struct sock * sk , struct sk_buff * buf ) <nl>  <nl> /* Reject message if it is wrong sort of message for socket */ <nl>  <nl> - /* <nl> - * WOULD IT BE BETTER TO JUST DISCARD THESE MESSAGES INSTEAD ? <nl> - * " NO PORT " ISN ' T REALLY THE RIGHT ERROR CODE , AND THERE MAY <nl> - * BE SECURITY IMPLICATIONS INHERENT IN REJECTING INVALID TRAFFIC <nl> - */ <nl> + if ( msg_type ( msg ) > TIPC_DIRECT_MSG ) <nl> + return TIPC_ERR_NO_PORT ; <nl>  <nl> if ( sock -> state == SS_READY ) { <nl> if ( msg_connected ( msg ))
static int mfd_emmc_probe_slot ( struct sdhci_pci_slot * slot ) <nl> return 0 ; <nl> } <nl>  <nl> + static int mfd_sdio_probe_slot ( struct sdhci_pci_slot * slot ) <nl> +{ <nl> + slot -> host -> mmc -> caps |= MMC_CAP_POWER_OFF_CARD ; <nl> + return 0 ; <nl> +} <nl> + <nl> static const struct sdhci_pci_fixes sdhci_intel_mrst_hc0 = { <nl> . quirks = SDHCI_QUIRK_BROKEN_ADMA | SDHCI_QUIRK_NO_HISPD_BIT , <nl> . probe_slot = mrst_hc_probe_slot , <nl> static const struct sdhci_pci_fixes sdhci_intel_mfd_sd = { <nl> static const struct sdhci_pci_fixes sdhci_intel_mfd_sdio = { <nl> . quirks = SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC , <nl> . allow_runtime_pm = true , <nl> + . probe_slot = mfd_sdio_probe_slot , <nl> }; <nl>  <nl> static const struct sdhci_pci_fixes sdhci_intel_mfd_emmc = {
static void clear_subscriber_list ( struct snd_seq_client * client , <nl> list_del (& subs -> dest_list ); <nl> else <nl> list_del (& subs -> src_list ); <nl> + up_write (& agrp -> list_mutex ); <nl> unsubscribe_port ( c , aport , agrp , & subs -> info , 1 ); <nl> kfree ( subs ); <nl> - up_write (& agrp -> list_mutex ); <nl> snd_seq_port_unlock ( aport ); <nl> snd_seq_client_unlock ( c ); <nl> }
static int __init net_ns_init ( void ) <nl>  <nl> register_pernet_subsys (& net_ns_ops ); <nl>  <nl> - rtnl_register ( PF_UNSPEC , RTM_NEWNSID , rtnl_net_newid , NULL , 0 ); <nl> + rtnl_register ( PF_UNSPEC , RTM_NEWNSID , rtnl_net_newid , NULL , <nl> + RTNL_FLAG_DOIT_UNLOCKED ); <nl> rtnl_register ( PF_UNSPEC , RTM_GETNSID , rtnl_net_getid , rtnl_net_dumpid , <nl> - 0 ); <nl> + RTNL_FLAG_DOIT_UNLOCKED ); <nl>  <nl> return 0 ; <nl> }
static int wm8731_hw_params ( struct snd_pcm_substream * substream , <nl> case 24 : <nl> iface |= 0x0008 ; <nl> break ; <nl> + case 32 : <nl> + iface |= 0x000c ; <nl> + break ; <nl> } <nl>  <nl> wm8731_set_deemph ( codec ); <nl> static int wm8731_startup ( struct snd_pcm_substream * substream , <nl> # define WM8731_RATES SNDRV_PCM_RATE_8000_96000 <nl>  <nl> # define WM8731_FORMATS ( SNDRV_PCM_FMTBIT_S16_LE | SNDRV_PCM_FMTBIT_S20_3LE |\ <nl> - SNDRV_PCM_FMTBIT_S24_LE ) <nl> + SNDRV_PCM_FMTBIT_S24_LE | SNDRV_PCM_FMTBIT_S32_LE ) <nl>  <nl> static const struct snd_soc_dai_ops wm8731_dai_ops = { <nl> . startup = wm8731_startup ,
static int alloc_small_queue_page ( struct ipz_queue * queue , struct ehca_pd * pd ) <nl>  <nl> out : <nl> ehca_err ( pd -> ib_pd . device , " failed to allocate small queue page "); <nl> + mutex_unlock (& pd -> lock ); <nl> return 0 ; <nl> } <nl> 
asmlinkage void __sched schedule ( void ) <nl> printk ( KERN_ERR " BUG : scheduling while atomic : " <nl> "% s / 0x % 08x /% d \ n ", <nl> current -> comm , preempt_count (), current -> pid ); <nl> + debug_show_held_locks ( current ); <nl> dump_stack (); <nl> } <nl> profile_hit ( SCHED_PROFILING , __builtin_return_address ( 0 )); <nl> void __might_sleep ( char * file , int line ) <nl> " context at % s :% d \ n ", file , line ); <nl> printk (" in_atomic ():% d , irqs_disabled ():% d \ n ", <nl> in_atomic (), irqs_disabled ()); <nl> + debug_show_held_locks ( current ); <nl> dump_stack (); <nl> } <nl> # endif
static int rsi_send_beacon ( struct rsi_common * common ) <nl> skb_pull ( skb , ( 64 - dword_align_bytes )); <nl> if ( rsi_prepare_beacon ( common , skb )) { <nl> rsi_dbg ( ERR_ZONE , " Failed to prepare beacon \ n "); <nl> + dev_kfree_skb ( skb ); <nl> return - EINVAL ; <nl> } <nl> skb_queue_tail (& common -> tx_queue [ MGMT_BEACON_Q ], skb );
mv_xor_xor_self_test ( struct mv_xor_chan * mv_chan ) <nl> return err ; <nl> } <nl>  <nl> +/* This driver does not implement any of the optional DMA operations . */ <nl> + static int <nl> + mv_xor_control ( struct dma_chan * chan , enum dma_ctrl_cmd cmd , <nl> + unsigned long arg ) <nl> +{ <nl> + return - ENOSYS ; <nl> +} <nl> + <nl> static int mv_xor_channel_remove ( struct mv_xor_chan * mv_chan ) <nl> { <nl> struct dma_chan * chan , * _chan ; <nl> mv_xor_channel_add ( struct mv_xor_device * xordev , <nl> dma_dev -> device_free_chan_resources = mv_xor_free_chan_resources ; <nl> dma_dev -> device_tx_status = mv_xor_status ; <nl> dma_dev -> device_issue_pending = mv_xor_issue_pending ; <nl> + dma_dev -> device_control = mv_xor_control ; <nl> dma_dev -> dev = & pdev -> dev ; <nl>  <nl> /* set prep routines based on capability */
smb2_unlock_range ( struct cifsFileInfo * cfile , struct file_lock * flock , <nl> return - EINVAL ; <nl>  <nl> max_num = max_buf / sizeof ( struct smb2_lock_element ); <nl> - buf = kzalloc ( max_num * sizeof ( struct smb2_lock_element ), GFP_KERNEL ); <nl> + buf = kcalloc ( max_num , sizeof ( struct smb2_lock_element ), GFP_KERNEL ); <nl> if (! buf ) <nl> return - ENOMEM ; <nl>  <nl> smb2_push_mandatory_locks ( struct cifsFileInfo * cfile ) <nl> } <nl>  <nl> max_num = max_buf / sizeof ( struct smb2_lock_element ); <nl> - buf = kzalloc ( max_num * sizeof ( struct smb2_lock_element ), GFP_KERNEL ); <nl> + buf = kcalloc ( max_num , sizeof ( struct smb2_lock_element ), GFP_KERNEL ); <nl> if (! buf ) { <nl> free_xid ( xid ); <nl> return - ENOMEM ;
static void component_detach_master ( struct master * master , struct component * c ) <nl> c -> master = NULL ; <nl> } <nl>  <nl> +/* <nl> + * Add a component to a master , finding the component via the compare <nl> + * function and compare data . This is safe to call for duplicate matches <nl> + * and will not result in the same component being added multiple times . <nl> + */ <nl> int component_master_add_child ( struct master * master , <nl> int (* compare )( struct device *, void *), void * compare_data ) <nl> { <nl> int component_master_add_child ( struct master * master , <nl> int ret = - ENXIO ; <nl>  <nl> list_for_each_entry ( c , & component_list , node ) { <nl> - if ( c -> master ) <nl> + if ( c -> master && c -> master != master ) <nl> continue ; <nl>  <nl> if ( compare ( c -> dev , compare_data )) { <nl> - component_attach_master ( master , c ); <nl> + if (! c -> master ) <nl> + component_attach_master ( master , c ); <nl> ret = 0 ; <nl> break ; <nl> }
static int soc_cleanup_card_resources ( struct snd_soc_card * card ) <nl> if ( card -> remove ) <nl> card -> remove ( card ); <nl>  <nl> + snd_soc_dapm_free (& card -> dapm ); <nl> + <nl> kfree ( card -> rtd ); <nl> snd_card_free ( card -> snd_card ); <nl> return 0 ;
static int sh_veu_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> * vdev = sh_veu_videodev ; <nl> + vdev -> v4l2_dev = & veu -> v4l2_dev ; <nl> spin_lock_init (& veu -> lock ); <nl> mutex_init (& veu -> fop_lock ); <nl> vdev -> lock = & veu -> fop_lock ;
static int pcnet32_phys_id ( struct net_device * dev , u32 data ) <nl> if ((! data ) || ( data > ( u32 )( MAX_SCHEDULE_TIMEOUT / HZ ))) <nl> data = ( u32 )( MAX_SCHEDULE_TIMEOUT / HZ ); <nl>  <nl> - schedule_timeout ( data * HZ ); <nl> + msleep_interruptible ( data * 1000 ); <nl> del_timer_sync (& lp -> blink_timer ); <nl>  <nl> /* Restore the original value of the bcrs */
static ssize_t sta_ht_capa_read ( struct file * file , char __user * userbuf , <nl> if ( _cond ) \ <nl> p += scnprintf ( p , sizeof ( buf )+ buf - p , "\ t " _str "\ n "); \ <nl> } while ( 0 ) <nl> - char buf [ 1024 ], * p = buf ; <nl> + char buf [ 512 ], * p = buf ; <nl> int i ; <nl> struct sta_info * sta = file -> private_data ; <nl> struct ieee80211_sta_ht_cap * htc = & sta -> sta . ht_cap ;
static int sky2_probe ( struct pci_dev * pdev , const struct pci_device_id * ent ) <nl> } <nl> } <nl>  <nl> + netif_napi_add ( dev , & hw -> napi , sky2_poll , NAPI_WEIGHT ); <nl> + <nl> err = register_netdev ( dev ); <nl> if ( err ) { <nl> dev_err (& pdev -> dev , " cannot register net device \ n "); <nl> static int sky2_probe ( struct pci_dev * pdev , const struct pci_device_id * ent ) <nl>  <nl> netif_carrier_off ( dev ); <nl>  <nl> - netif_napi_add ( dev , & hw -> napi , sky2_poll , NAPI_WEIGHT ); <nl> - <nl> sky2_show_addr ( dev ); <nl>  <nl> if ( hw -> ports > 1 ) {
int wvlan_uil_put_info ( struct uilreq * urq , struct wl_private * lp ) <nl> ltv_t * pLtv ; <nl> bool_t ltvAllocated = FALSE ; <nl> ENCSTRCT sEncryption ; <nl> + size_t len ; <nl>  <nl> # ifdef USE_WDS <nl> hcf_16 hcfPort = HCF_PORT_0 ; <nl> int wvlan_uil_put_info ( struct uilreq * urq , struct wl_private * lp ) <nl> break ; <nl> case CFG_CNF_OWN_NAME : <nl> memset ( lp -> StationName , 0 , sizeof ( lp -> StationName )); <nl> - memcpy (( void *) lp -> StationName , ( void *)& pLtv -> u . u8 [ 2 ], ( size_t ) pLtv -> u . u16 [ 0 ]); <nl> + len = min_t ( size_t , pLtv -> u . u16 [ 0 ], sizeof ( lp -> StationName )); <nl> + strlcpy ( lp -> StationName , & pLtv -> u . u8 [ 2 ], len ); <nl> pLtv -> u . u16 [ 0 ] = CNV_INT_TO_LITTLE ( pLtv -> u . u16 [ 0 ]); <nl> break ; <nl> case CFG_CNF_LOAD_BALANCING : <nl> int wvlan_set_station_nickname ( struct net_device * dev , <nl> { <nl> struct wl_private * lp = wl_priv ( dev ); <nl> unsigned long flags ; <nl> + size_t len ; <nl> int ret = 0 ; <nl> /*------------------------------------------------------------------------*/ <nl>  <nl> int wvlan_set_station_nickname ( struct net_device * dev , <nl> wl_lock ( lp , & flags ); <nl>  <nl> memset ( lp -> StationName , 0 , sizeof ( lp -> StationName )); <nl> - <nl> - memcpy ( lp -> StationName , extra , wrqu -> data . length ); <nl> + len = min_t ( size_t , wrqu -> data . length , sizeof ( lp -> StationName )); <nl> + strlcpy ( lp -> StationName , extra , len ); <nl>  <nl> /* Commit the adapter parameters */ <nl> wl_apply ( lp );
bool dc_stream_set_cursor_position ( <nl> ! pipe_ctx -> ipp || ! pipe_ctx -> surface ) <nl> continue ; <nl>  <nl> + if ( pipe_ctx -> surface -> public . address . type <nl> + == PLN_ADDR_TYPE_VIDEO_PROGRESSIVE ) <nl> + pos_cpy . enable = false ; <nl> + <nl> if ( pipe_ctx -> top_pipe && pipe_ctx -> surface != pipe_ctx -> top_pipe -> surface ) <nl> pos_cpy . enable = false ; <nl> 
nv140_chipset = { <nl> . i2c = gm200_i2c_new , <nl> . ibus = gm200_ibus_new , <nl> . imem = nv50_instmem_new , <nl> + . ltc = gp102_ltc_new , <nl> . mc = gp100_mc_new , <nl> . pci = gp100_pci_new , <nl> . timer = gk20a_timer_new ,
static int add_uuid ( struct sock * sk , struct hci_dev * hdev , void * data , u16 len ) <nl> goto failed ; <nl> } <nl>  <nl> - uuid = kmalloc ( sizeof (* uuid ), GFP_ATOMIC ); <nl> + uuid = kmalloc ( sizeof (* uuid ), GFP_KERNEL ); <nl> if (! uuid ) { <nl> err = - ENOMEM ; <nl> goto failed ; <nl> static int get_connections ( struct sock * sk , struct hci_dev * hdev , void * data , <nl> } <nl>  <nl> rp_len = sizeof (* rp ) + ( i * sizeof ( struct mgmt_addr_info )); <nl> - rp = kmalloc ( rp_len , GFP_ATOMIC ); <nl> + rp = kmalloc ( rp_len , GFP_KERNEL ); <nl> if (! rp ) { <nl> err = - ENOMEM ; <nl> goto unlock ;
static int rfcomm_sock_getsockopt ( struct socket * sock , int level , int optname , c <nl> } <nl>  <nl> sec . level = rfcomm_pi ( sk )-> sec_level ; <nl> + sec . key_size = 0 ; <nl>  <nl> len = min_t ( unsigned int , len , sizeof ( sec )); <nl> if ( copy_to_user ( optval , ( char *) & sec , len ))
static void __ovs_ct_free_action ( struct ovs_conntrack_info * ct_info ) <nl> if ( ct_info -> helper ) <nl> module_put ( ct_info -> helper -> me ); <nl> if ( ct_info -> ct ) <nl> - nf_ct_put ( ct_info -> ct ); <nl> + nf_ct_tmpl_free ( ct_info -> ct ); <nl> } <nl>  <nl> void ovs_ct_init ( struct net * net )
static int sun4i_gpadc_probe_dt ( struct platform_device * pdev , <nl> struct iio_dev * indio_dev ) <nl> { <nl> struct sun4i_gpadc_iio * info = iio_priv ( indio_dev ); <nl> - const struct of_device_id * of_dev ; <nl> struct resource * mem ; <nl> void __iomem * base ; <nl> int ret ; <nl>  <nl> - of_dev = of_match_device ( sun4i_gpadc_of_id , & pdev -> dev ); <nl> - if (! of_dev ) <nl> + info -> data = of_device_get_match_data (& pdev -> dev ); <nl> + if (! info -> data ) <nl> return - ENODEV ; <nl>  <nl> info -> no_irq = true ; <nl> - info -> data = ( struct gpadc_data *) of_dev -> data ; <nl> indio_dev -> num_channels = ARRAY_SIZE ( sun8i_a33_gpadc_channels ); <nl> indio_dev -> channels = sun8i_a33_gpadc_channels ; <nl> 
* GNU General Public License for more details . <nl> */ <nl> # include < linux / module . h > <nl> +# include < linux / of . h > <nl> # include < linux / opp . h > <nl> # include < linux / cpu . h > <nl>  <nl> int __init omap_init_opp_table ( struct omap_opp_def * opp_def , <nl> { <nl> int i , r ; <nl>  <nl> + if ( of_have_populated_dt ()) <nl> + return - EINVAL ; <nl> + <nl> if (! opp_def || ! opp_def_size ) { <nl> pr_err ("% s : invalid params !\ n ", __func__ ); <nl> return - EINVAL ;
static int xc2028_set_config ( struct dvb_frontend * fe , void * priv_cfg ) <nl> * in order to avoid troubles during device release . <nl> */ <nl> kfree ( priv -> ctrl . fname ); <nl> + priv -> ctrl . fname = NULL ; <nl> memcpy (& priv -> ctrl , p , sizeof ( priv -> ctrl )); <nl> if ( p -> fname ) { <nl> priv -> ctrl . fname = kstrdup ( p -> fname , GFP_KERNEL ); <nl> if ( priv -> ctrl . fname == NULL ) <nl> - rc = - ENOMEM ; <nl> + return - ENOMEM ; <nl> } <nl>  <nl> /*
static struct id_map_entry * <nl> id_map_alloc ( struct ib_device * ibdev , int slave_id , u32 sl_cm_id ) <nl> { <nl> int ret ; <nl> - static int next_id ; <nl> struct id_map_entry * ent ; <nl> struct mlx4_ib_sriov * sriov = & to_mdev ( ibdev )-> sriov ; <nl>  <nl> id_map_alloc ( struct ib_device * ibdev , int slave_id , u32 sl_cm_id ) <nl> idr_preload ( GFP_KERNEL ); <nl> spin_lock (& to_mdev ( ibdev )-> sriov . id_map_lock ); <nl>  <nl> - ret = idr_alloc (& sriov -> pv_id_table , ent , next_id , 0 , GFP_NOWAIT ); <nl> + ret = idr_alloc_cyclic (& sriov -> pv_id_table , ent , 0 , 0 , GFP_NOWAIT ); <nl> if ( ret >= 0 ) { <nl> - next_id = max ( ret + 1 , 0 ); <nl> ent -> pv_cm_id = ( u32 ) ret ; <nl> sl_id_map_add ( ibdev , ent ); <nl> list_add_tail (& ent -> list , & sriov -> cm_list );
int __init acpi_table_init ( void ) <nl>  <nl> static int __init acpi_parse_apic_instance ( char * str ) <nl> { <nl> + if (! str ) <nl> + return - EINVAL ; <nl>  <nl> acpi_apic_instance = simple_strtoul ( str , NULL , 0 ); <nl> 
static void arm_ccn_pmu_xp_dt_config ( struct perf_event * event , int enable ) <nl> struct arm_ccn_component * xp ; <nl> u32 val , dt_cfg ; <nl>  <nl> + /* Nothing to do for cycle counter */ <nl> + if ( hw -> idx == CCN_IDX_PMU_CYCLE_COUNTER ) <nl> + return ; <nl> + <nl> if ( CCN_CONFIG_TYPE ( event -> attr . config ) == CCN_TYPE_XP ) <nl> xp = & ccn -> xp [ CCN_CONFIG_XP ( event -> attr . config )]; <nl> else
static void ip6gre_tnl_link_config ( struct ip6_tnl * t , int set_mtu ) <nl> dev -> mtu = rt -> dst . dev -> mtu - addend ; <nl> if (!( t -> parms . flags & IP6_TNL_F_IGN_ENCAP_LIMIT )) <nl> dev -> mtu -= 8 ; <nl> + if ( dev -> type == ARPHRD_ETHER ) <nl> + dev -> mtu -= ETH_HLEN ; <nl>  <nl> if ( dev -> mtu < IPV6_MIN_MTU ) <nl> dev -> mtu = IPV6_MIN_MTU ;
int netvsc_send ( struct hv_device * device , <nl> if (! net_device ) <nl> return - ENODEV ; <nl>  <nl> + /* We may race with netvsc_connect_vsp ()/ netvsc_init_buf () and get <nl> + * here before the negotiation with the host is finished and <nl> + * send_section_map may not be allocated yet . <nl> + */ <nl> + if (! net_device -> send_section_map ) <nl> + return - EAGAIN ; <nl> + <nl> out_channel = net_device -> chn_table [ q_idx ]; <nl>  <nl> packet -> send_buf_index = NETVSC_INVALID_INDEX ;
+// SPDX - License - Identifier : GPL - 2 . 0 <nl> /* <nl> * Watchdog driver for IMX2 and later processors <nl> * <nl> * some parts adapted by similar drivers from Darius Augulis and Vladimir <nl> * Zapolskiy , additional improvements by Wim Van Sebroeck . <nl> * <nl> - * This program is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the GNU General Public License version 2 as published by <nl> - * the Free Software Foundation . <nl> - * <nl> * NOTE : MX1 has a slightly different Watchdog than MX2 and later : <nl> * <nl> * MX1 : MX2 +:
nv50_mstm = { <nl> void <nl> nv50_mstm_service ( struct nv50_mstm * mstm ) <nl> { <nl> - struct drm_dp_aux * aux = mstm -> mgr . aux ; <nl> + struct drm_dp_aux * aux = mstm ? mstm -> mgr . aux : NULL ; <nl> bool handled = true ; <nl> int ret ; <nl> u8 esi [ 8 ] = {}; <nl>  <nl> + if (! aux ) <nl> + return ; <nl> + <nl> while ( handled ) { <nl> ret = drm_dp_dpcd_read ( aux , DP_SINK_COUNT_ESI , esi , 8 ); <nl> if ( ret != 8 ) {
enum { <nl> extern void __buggy_use_of_MLX4_GET ( void ); <nl> extern void __buggy_use_of_MLX4_PUT ( void ); <nl>  <nl> - static bool enable_qos = true ; <nl> + static bool enable_qos ; <nl> module_param ( enable_qos , bool , 0444 ); <nl> - MODULE_PARM_DESC ( enable_qos , " Enable Enhanced QoS support ( default : on )"); <nl> + MODULE_PARM_DESC ( enable_qos , " Enable Enhanced QoS support ( default : off )"); <nl>  <nl> # define MLX4_GET ( dest , source , offset ) \ <nl> do { \
void i40e_dcbnl_set_all ( struct i40e_vsi * vsi ) <nl> if (!( pf -> flags & I40E_FLAG_DCB_ENABLED )) <nl> return ; <nl>  <nl> + /* MFP mode but not an iSCSI PF so return */ <nl> + if (( pf -> flags & I40E_FLAG_MFP_ENABLED ) && !( pf -> hw . func_caps . iscsi )) <nl> + return ; <nl> + <nl> dcbxcfg = & hw -> local_dcbx_config ; <nl>  <nl> /* Set up all the App TLVs if DCBx is negotiated */ <nl> void i40e_dcbnl_flush_apps ( struct i40e_pf * pf , <nl> struct i40e_dcb_app_priority_table app ; <nl> int i ; <nl>  <nl> + /* MFP mode but not an iSCSI PF so return */ <nl> + if (( pf -> flags & I40E_FLAG_MFP_ENABLED ) && !( pf -> hw . func_caps . iscsi )) <nl> + return ; <nl> + <nl> for ( i = 0 ; i < old_cfg -> numapps ; i ++) { <nl> app = old_cfg -> app [ i ]; <nl> /* The APP is not available anymore delete it */
struct sta_info * sta_info_alloc ( struct ieee80211_sub_if_data * sdata , <nl> if ( ieee80211_vif_is_mesh (& sdata -> vif ) && <nl> ! sdata -> u . mesh . user_mpm ) <nl> init_timer (& sta -> plink_timer ); <nl> + sta -> nonpeer_pm = NL80211_MESH_POWER_ACTIVE ; <nl> # endif <nl>  <nl> memcpy ( sta -> sta . addr , addr , ETH_ALEN );
enum dc_status dce110_apply_ctx_to_hw ( <nl> if ( pipe_ctx -> stream == pipe_ctx_old -> stream ) <nl> continue ; <nl>  <nl> + if ( pipe_ctx -> stream && pipe_ctx_old -> stream <nl> + && ! pipe_need_reprogram ( pipe_ctx_old , pipe_ctx )) <nl> + continue ; <nl> + <nl> if ( pipe_ctx -> top_pipe ) <nl> continue ; <nl> 
static int validate_user_key ( struct fscrypt_info * crypt_info , <nl> goto out ; <nl> } <nl> ukp = user_key_payload_locked ( keyring_key ); <nl> + if (! ukp ) { <nl> + /* key was revoked before we acquired its semaphore */ <nl> + res = - EKEYREVOKED ; <nl> + goto out ; <nl> + } <nl> if ( ukp -> datalen != sizeof ( struct fscrypt_key )) { <nl> res = - EINVAL ; <nl> goto out ;
static irqreturn_t rtl8169_interrupt ( int irq , void * dev_instance ) <nl> handled = 1 ; <nl>  <nl> rtl_irq_disable ( tp ); <nl> - napi_schedule (& tp -> napi ); <nl> + napi_schedule_irqoff (& tp -> napi ); <nl> } <nl> } <nl> return IRQ_RETVAL ( handled );
static int af9005_identify_state ( struct usb_device * udev , <nl> else if ( reply == 0x02 ) <nl> * cold = 0 ; <nl> else <nl> - return - EIO ; <nl> - deb_info (" Identify state cold = % d \ n ", * cold ); <nl> + ret = - EIO ; <nl> + if (! ret ) <nl> + deb_info (" Identify state cold = % d \ n ", * cold ); <nl>  <nl> err : <nl> kfree ( buf );
static void dump_tasks ( const struct mem_cgroup * mem ) <nl> continue ; <nl> } <nl>  <nl> - printk ( KERN_INFO "[% 5d ] % 5d % 5d % 8lu % 8lu % 3d % 3d % s \ n ", <nl> + printk ( KERN_INFO "[% 5d ] % 5d % 5d % 8lu % 8lu % 3u % 3d % s \ n ", <nl> task -> pid , __task_cred ( task )-> uid , task -> tgid , <nl> task -> mm -> total_vm , get_mm_rss ( task -> mm ), <nl> - ( int ) task_cpu ( task ), task -> signal -> oom_adj , p -> comm ); <nl> + task_cpu ( task ), task -> signal -> oom_adj , task -> comm ); <nl> task_unlock ( task ); <nl> } <nl> }
void arch_update_cpu_topology ( void ); <nl> . busy_idx = 3 , \ <nl> . idle_idx = 3 , \ <nl> . flags = SD_LOAD_BALANCE \ <nl> - | SD_SERIALIZE , \ <nl> + | SD_BALANCE_NEWIDLE \ <nl> + | SD_WAKE_AFFINE \ <nl> + | SD_SERIALIZE , \ <nl> . last_balance = jiffies , \ <nl> . balance_interval = 64 , \ <nl> }
static int hci_outgoing_auth_needed ( struct hci_dev * hdev , <nl> * is requested . <nl> */ <nl> if (! hci_conn_ssp_enabled ( conn ) && !( conn -> auth_type & 0x01 ) && <nl> + conn -> pending_sec_level != BT_SECURITY_FIPS && <nl> conn -> pending_sec_level != BT_SECURITY_HIGH && <nl> conn -> pending_sec_level != BT_SECURITY_MEDIUM ) <nl> return 0 ;
static void ath10k_hw_qca988x_set_coverage_class ( struct ath10k * ar , <nl>  <nl> /* Only modify registers if the core is started . */ <nl> if (( ar -> state != ATH10K_STATE_ON ) && <nl> - ( ar -> state != ATH10K_STATE_RESTARTED )) <nl> + ( ar -> state != ATH10K_STATE_RESTARTED )) { <nl> + spin_lock_bh (& ar -> data_lock ); <nl> + /* Store config value for when radio boots up */ <nl> + ar -> fw_coverage . coverage_class = value ; <nl> + spin_unlock_bh (& ar -> data_lock ); <nl> goto unlock ; <nl> + } <nl>  <nl> /* Retrieve the current values of the two registers that need to be <nl> * adjusted . <nl> static void ath10k_hw_qca988x_set_coverage_class ( struct ath10k * ar , <nl> ar -> fw_coverage . reg_ack_cts_timeout_orig = timeout_reg ; <nl> ar -> fw_coverage . reg_phyclk = phyclk_reg ; <nl>  <nl> - /* Calculat new value based on the ( original ) firmware calculation . */ <nl> + /* Calculate new value based on the ( original ) firmware calculation . */ <nl> slottime_reg = ar -> fw_coverage . reg_slottime_orig ; <nl> timeout_reg = ar -> fw_coverage . reg_ack_cts_timeout_orig ; <nl> 
struct netlink_compare_arg <nl> { <nl> possible_net_t pnet ; <nl> u32 portid ; <nl> - char trailer []; <nl> }; <nl>  <nl> -# define netlink_compare_arg_len offsetof ( struct netlink_compare_arg , trailer ) <nl> +/* Doing sizeof directly may yield 4 extra bytes on 64 - bit . */ <nl> +# define netlink_compare_arg_len \ <nl> + ( offsetof ( struct netlink_compare_arg , portid ) + sizeof ( u32 )) <nl>  <nl> static inline int netlink_compare ( struct rhashtable_compare_arg * arg , <nl> const void * ptr )
qla2x00_do_dpc ( void * data ) <nl> } else { <nl> fcport -> login_retry = 0 ; <nl> } <nl> - if ( fcport -> login_retry == 0 ) <nl> + if ( fcport -> login_retry == 0 && status != QLA_SUCCESS ) <nl> fcport -> loop_id = FC_NO_LOOP_ID ; <nl> } <nl> if ( test_bit ( LOOP_RESYNC_NEEDED , & ha -> dpc_flags ))
void dst_release ( struct dst_entry * dst ) <nl> { <nl> if ( dst ) { <nl> int newrefcnt ; <nl> + unsigned short nocache = dst -> flags & DST_NOCACHE ; <nl>  <nl> newrefcnt = atomic_dec_return (& dst -> __refcnt ); <nl> if ( unlikely ( newrefcnt < 0 )) <nl> net_warn_ratelimited ("% s : dst :% p refcnt :% d \ n ", <nl> __func__ , dst , newrefcnt ); <nl> - if (! newrefcnt && unlikely ( dst -> flags & DST_NOCACHE )) <nl> + if (! newrefcnt && unlikely ( nocache )) <nl> call_rcu (& dst -> rcu_head , dst_destroy_rcu ); <nl> } <nl> }
extern struct debug_obj_descr rcuhead_debug_descr ; <nl>  <nl> static inline void debug_rcu_head_queue ( struct rcu_head * head ) <nl> { <nl> + WARN_ON_ONCE (( unsigned long ) head & 0x3 ); <nl> debug_object_activate ( head , & rcuhead_debug_descr ); <nl> debug_object_active_state ( head , & rcuhead_debug_descr , <nl> STATE_RCU_HEAD_READY ,
static int acpi_battery_technology ( struct acpi_battery * battery ) <nl> return POWER_SUPPLY_TECHNOLOGY_NiMH ; <nl> if (! strcasecmp (" LION ", battery -> type )) <nl> return POWER_SUPPLY_TECHNOLOGY_LION ; <nl> + if (! strcasecmp (" LI - ION ", battery -> type )) <nl> + return POWER_SUPPLY_TECHNOLOGY_LION ; <nl> if (! strcasecmp (" LiP ", battery -> type )) <nl> return POWER_SUPPLY_TECHNOLOGY_LIPO ; <nl> return POWER_SUPPLY_TECHNOLOGY_UNKNOWN ;
static int gb_uart_flush ( struct gb_tty * gb_tty , u8 flags ) <nl> & request , sizeof ( request ), NULL , 0 ); <nl> } <nl>  <nl> - static struct gb_tty * get_gb_by_minor ( unsigned minor ) <nl> + static struct gb_tty * get_gb_by_minor ( unsigned int minor ) <nl> { <nl> struct gb_tty * gb_tty ; <nl> 
int jbd2_journal_start_reserved ( handle_t * handle , unsigned int type , <nl> */ <nl> ret = start_this_handle ( journal , handle , GFP_NOFS ); <nl> if ( ret < 0 ) { <nl> + handle -> h_journal = journal ; <nl> jbd2_journal_free_reserved ( handle ); <nl> return ret ; <nl> }
void snd_pcm_period_elapsed ( struct snd_pcm_substream * substream ) <nl> snd_timer_interrupt ( substream -> timer , 1 ); <nl> # endif <nl> _end : <nl> - snd_pcm_stream_unlock_irqrestore ( substream , flags ); <nl> kill_fasync (& runtime -> fasync , SIGIO , POLL_IN ); <nl> + snd_pcm_stream_unlock_irqrestore ( substream , flags ); <nl> } <nl>  <nl> EXPORT_SYMBOL ( snd_pcm_period_elapsed );
static void pm8001_dev_gone_notify ( struct domain_device * dev ) <nl> u32 tag ; <nl> struct pm8001_hba_info * pm8001_ha ; <nl> struct pm8001_device * pm8001_dev = dev -> lldd_dev ; <nl> - u32 device_id = pm8001_dev -> device_id ; <nl> + <nl> pm8001_ha = pm8001_find_ha_by_dev ( dev ); <nl> spin_lock_irqsave (& pm8001_ha -> lock , flags ); <nl> pm8001_tag_alloc ( pm8001_ha , & tag ); <nl> if ( pm8001_dev ) { <nl> + u32 device_id = pm8001_dev -> device_id ; <nl> + <nl> PM8001_DISC_DBG ( pm8001_ha , <nl> pm8001_printk (" found dev [% d :% x ] is gone .\ n ", <nl> pm8001_dev -> device_id , pm8001_dev -> dev_type ));
static int gic_shared_irq_domain_map ( struct irq_domain * d , unsigned int virq , <nl>  <nl> spin_lock_irqsave (& gic_lock , flags ); <nl> gic_map_to_pin ( intr , gic_cpu_pin ); <nl> - gic_map_to_vpe ( intr , vpe ); <nl> + gic_map_to_vpe ( intr , mips_cm_vp_id ( vpe )); <nl> for ( i = 0 ; i < min ( gic_vpes , NR_CPUS ); i ++) <nl> clear_bit ( intr , pcpu_masks [ i ]. pcpu_mask ); <nl> set_bit ( intr , pcpu_masks [ vpe ]. pcpu_mask );
static int nvm_get_dir_info ( struct net_device * dev , u32 * entries , u32 * length ) <nl>  <nl> static int bnxt_get_eeprom_len ( struct net_device * dev ) <nl> { <nl> + struct bnxt * bp = netdev_priv ( dev ); <nl> + <nl> + if ( BNXT_VF ( bp )) <nl> + return 0 ; <nl> + <nl> /* The - 1 return value allows the entire 32 - bit range of offsets to be <nl> * passed via the ethtool command - line utility . <nl> */
static int btrfs_dev_replace_finishing ( struct btrfs_fs_info * fs_info , <nl> WARN_ON ( ret ); <nl>  <nl> /* keep away write_all_supers () during the finishing procedure */ <nl> + mutex_lock (& root -> fs_info -> chunk_mutex ); <nl> mutex_lock (& root -> fs_info -> fs_devices -> device_list_mutex ); <nl> btrfs_dev_replace_lock ( dev_replace ); <nl> dev_replace -> replace_state = <nl> static int btrfs_dev_replace_finishing ( struct btrfs_fs_info * fs_info , <nl> rcu_str_deref ( tgt_device -> name ), scrub_ret ); <nl> btrfs_dev_replace_unlock ( dev_replace ); <nl> mutex_unlock (& root -> fs_info -> fs_devices -> device_list_mutex ); <nl> + mutex_unlock (& root -> fs_info -> chunk_mutex ); <nl> if ( tgt_device ) <nl> btrfs_destroy_dev_replace_tgtdev ( fs_info , tgt_device ); <nl> mutex_unlock (& dev_replace -> lock_finishing_cancel_unmount ); <nl> static int btrfs_dev_replace_finishing ( struct btrfs_fs_info * fs_info , <nl> */ <nl> btrfs_dev_replace_unlock ( dev_replace ); <nl> mutex_unlock (& root -> fs_info -> fs_devices -> device_list_mutex ); <nl> + mutex_unlock (& root -> fs_info -> chunk_mutex ); <nl>  <nl> /* write back the superblocks */ <nl> trans = btrfs_start_transaction ( root , 0 );
static struct phy * _of_phy_get ( struct device_node * np , int index ) <nl> if ( ret ) <nl> return ERR_PTR (- ENODEV ); <nl>  <nl> + /* This phy type handled by the usb - phy subsystem for now */ <nl> + if ( of_device_is_compatible ( args . np , " usb - nop - xceiv ")) <nl> + return ERR_PTR (- ENODEV ); <nl> + <nl> mutex_lock (& phy_provider_mutex ); <nl> phy_provider = of_phy_provider_lookup ( args . np ); <nl> if ( IS_ERR ( phy_provider ) || ! try_module_get ( phy_provider -> owner )) {
static struct nft_stats __percpu * nft_stats_alloc ( const struct nlattr * attr ) <nl> static void nft_chain_stats_replace ( struct nft_base_chain * chain , <nl> struct nft_stats __percpu * newstats ) <nl> { <nl> + if ( newstats == NULL ) <nl> + return ; <nl> + <nl> if ( chain -> stats ) { <nl> struct nft_stats __percpu * oldstats = <nl> nft_dereference ( chain -> stats );
int snd_hda_create_spdif_out_ctls ( struct hda_codec * codec , hda_nid_t nid ) <nl> } <nl> for ( dig_mix = dig_mixes ; dig_mix -> name ; dig_mix ++) { <nl> kctl = snd_ctl_new1 ( dig_mix , codec ); <nl> + if (! kctl ) <nl> + return - ENOMEM ; <nl> kctl -> id . index = idx ; <nl> kctl -> private_value = nid ; <nl> err = snd_hda_ctl_add ( codec , kctl ); <nl> snd_hda_attach_pcm ( struct hda_codec * codec , struct hda_pcm * pcm ) <nl> struct hda_pcm_stream * info ; <nl> int stream , err ; <nl>  <nl> - if (! pcm -> name ) <nl> + if ( snd_BUG_ON (! pcm -> name )) <nl> return - EINVAL ; <nl> for ( stream = 0 ; stream < 2 ; stream ++) { <nl> info = & pcm -> stream [ stream ];
static void process_checks ( struct r1bio * r1_bio ) <nl> struct page ** ppages = get_resync_pages ( pbio )-> pages ; <nl> struct page ** spages = get_resync_pages ( sbio )-> pages ; <nl> struct bio_vec * bi ; <nl> - int page_len [ RESYNC_PAGES ]; <nl> + int page_len [ RESYNC_PAGES ] = { 0 }; <nl>  <nl> if ( sbio -> bi_end_io != end_sync_read ) <nl> continue ;
drm_atomic_plane_get_property ( struct drm_plane * plane , <nl> * val = state -> src_w ; <nl> } else if ( property == config -> prop_src_h ) { <nl> * val = state -> src_h ; <nl> + } else if ( property == config -> rotation_property ) { <nl> + * val = state -> rotation ; <nl> } else if ( plane -> funcs -> atomic_get_property ) { <nl> return plane -> funcs -> atomic_get_property ( plane , state , property , val ); <nl> } else {
int fcoe_ctlr_els_send ( struct fcoe_ctlr * fip , struct fc_lport * lport , <nl> fip -> send ( fip , skb ); <nl> return - EINPROGRESS ; <nl> drop : <nl> - kfree_skb ( skb ); <nl> LIBFCOE_FIP_DBG ( fip , " drop els_send op % u d_id % x \ n ", <nl> op , ntoh24 ( fh -> fh_d_id )); <nl> + kfree_skb ( skb ); <nl> return - EINVAL ; <nl> } <nl> EXPORT_SYMBOL ( fcoe_ctlr_els_send );
static long ir_lirc_ioctl ( struct file * filep , unsigned int cmd , <nl> return 0 ; <nl>  <nl> case LIRC_GET_REC_RESOLUTION : <nl> + if (! dev -> rx_resolution ) <nl> + return - ENOTTY ; <nl> + <nl> val = dev -> rx_resolution ; <nl> break ; <nl>  <nl> static int ir_lirc_register ( struct rc_dev * dev ) <nl> if ( rc ) <nl> goto rbuf_init_failed ; <nl>  <nl> - if ( dev -> driver_type != RC_DRIVER_IR_RAW_TX ) <nl> + if ( dev -> driver_type != RC_DRIVER_IR_RAW_TX ) { <nl> features |= LIRC_CAN_REC_MODE2 ; <nl> + if ( dev -> rx_resolution ) <nl> + features |= LIRC_CAN_GET_REC_RESOLUTION ; <nl> + } <nl> if ( dev -> tx_ir ) { <nl> features |= LIRC_CAN_SEND_PULSE ; <nl> if ( dev -> s_tx_mask )
static int dvd_read_manufact ( struct cdrom_device_info * cdi , dvd_struct * s , <nl> goto out ; <nl>  <nl> s -> manufact . len = buf [ 0 ] << 8 | buf [ 1 ]; <nl> - if ( s -> manufact . len < 0 || s -> manufact . len > 2048 ) { <nl> + if ( s -> manufact . len < 0 ) { <nl> cdinfo ( CD_WARNING , " Received invalid manufacture info length " <nl> " (% d )\ n ", s -> manufact . len ); <nl> ret = - EIO ; <nl> } else { <nl> + if ( s -> manufact . len > 2048 ) { <nl> + cdinfo ( CD_WARNING , " Received invalid manufacture info " <nl> + " length (% d ): truncating to 2048 \ n ", <nl> + s -> manufact . len ); <nl> + s -> manufact . len = 2048 ; <nl> + } <nl> memcpy ( s -> manufact . value , & buf [ 4 ], s -> manufact . len ); <nl> } <nl> 
struct tpm_chip * tpmm_chip_alloc ( struct device * dev , <nl>  <nl> device_initialize (& chip -> dev ); <nl>  <nl> - chip -> cdev . owner = chip -> pdev -> driver -> owner ; <nl> cdev_init (& chip -> cdev , & tpm_fops ); <nl> + chip -> cdev . owner = chip -> pdev -> driver -> owner ; <nl> + chip -> cdev . kobj . parent = & chip -> dev . kobj ; <nl>  <nl> return chip ; <nl> }
static long tce_iommu_ioctl ( void * iommu_data , <nl> struct iommu_table * tbl = container -> tbl ; <nl> unsigned long tce ; <nl>  <nl> + if (! container -> enabled ) <nl> + return - EPERM ; <nl> + <nl> if (! tbl ) <nl> return - ENXIO ; <nl>  <nl> static long tce_iommu_ioctl ( void * iommu_data , <nl> struct vfio_iommu_type1_dma_unmap param ; <nl> struct iommu_table * tbl = container -> tbl ; <nl>  <nl> + if (! container -> enabled ) <nl> + return - EPERM ; <nl> + <nl> if ( WARN_ON (! tbl )) <nl> return - ENXIO ; <nl> 
static int octeon_usb_hub_status_data ( struct usb_hcd * hcd , char * buf ) <nl> buf [ 0 ] = 0 ; <nl> buf [ 0 ] = port_status . connect_change << 1 ; <nl>  <nl> - return ( buf [ 0 ] != 0 ); <nl> + return buf [ 0 ] != 0 ; <nl> } <nl>  <nl> static int octeon_usb_hub_control ( struct usb_hcd * hcd , u16 typeReq , u16 wValue , u16 wIndex , char * buf , u16 wLength )
static int ti_pipe3_exit ( struct phy * x ) <nl> u32 val ; <nl> unsigned long timeout ; <nl>  <nl> + /* SATA DPLL can ' t be powered down due to Errata i783 */ <nl> + if ( of_device_is_compatible ( phy -> dev -> of_node , " ti , phy - pipe3 - sata ")) <nl> + return 0 ; <nl> + <nl> /* Put DPLL in IDLE mode */ <nl> val = ti_pipe3_readl ( phy -> pll_ctrl_base , PLL_CONFIGURATION2 ); <nl> val |= PLL_IDLE ;
void hfi1_send_rc_ack ( struct hfi1_ctxtdata * rcd , struct rvt_qp * qp , <nl> struct ib_header hdr ; <nl> struct ib_other_headers * ohdr ; <nl> unsigned long flags ; <nl> + struct hfi1_qp_priv * priv = qp -> priv ; <nl> + <nl> + /* clear the defer count */ <nl> + priv -> r_adefered = 0 ; <nl>  <nl> /* Don ' t send ACK or NAK if a RDMA read or atomic is pending . */ <nl> if ( qp -> s_flags & RVT_S_RESP_PENDING )
int __udp4_lib_rcv ( struct sk_buff * skb , struct udp_table * udptable , <nl> struct udphdr * uh ; <nl> unsigned short ulen ; <nl> struct rtable * rt = ( struct rtable *) skb -> dst ; <nl> - __be32 saddr = ip_hdr ( skb )-> saddr ; <nl> - __be32 daddr = ip_hdr ( skb )-> daddr ; <nl> + __be32 saddr , daddr ; <nl> struct net * net = dev_net ( skb -> dev ); <nl>  <nl> /* <nl> int __udp4_lib_rcv ( struct sk_buff * skb , struct udp_table * udptable , <nl> if ( udp4_csum_init ( skb , uh , proto )) <nl> goto csum_error ; <nl>  <nl> + saddr = ip_hdr ( skb )-> saddr ; <nl> + daddr = ip_hdr ( skb )-> daddr ; <nl> + <nl> if ( rt -> rt_flags & ( RTCF_BROADCAST | RTCF_MULTICAST )) <nl> return __udp4_lib_mcast_deliver ( net , skb , uh , <nl> saddr , daddr , udptable );
static inline pte_t huge_ptep_get_and_clear ( struct mm_struct * mm , <nl> static inline void huge_ptep_clear_flush ( struct vm_area_struct * vma , <nl> unsigned long addr , pte_t * ptep ) <nl> { <nl> + ptep_clear_flush ( vma , addr , ptep ); <nl> } <nl>  <nl> static inline int huge_pte_none ( pte_t pte )
static void rate_control_pid_tx_status ( void * priv , struct net_device * dev , <nl> /* Ignore all frames that were sent with a different rate than the rate <nl> * we currently advise mac80211 to use . */ <nl> if ( status -> control . rate != & local -> oper_hw_mode -> rates [ sta -> txrate ]) <nl> - return ; <nl> + goto ignore ; <nl>  <nl> spinfo = sta -> rate_ctrl_priv ; <nl> spinfo -> tx_num_xmit ++; <nl> static void rate_control_pid_tx_status ( void * priv , struct net_device * dev , <nl> if ( time_after ( jiffies , spinfo -> last_sample + period )) <nl> rate_control_pid_sample ( pinfo , local , sta ); <nl>  <nl> + ignore : <nl> sta_info_put ( sta ); <nl> } <nl> 
static struct ip6_tnl * ip6_tnl_locate ( struct net * net , <nl> ( t = rtnl_dereference (* tp )) != NULL ; <nl> tp = & t -> next ) { <nl> if ( ipv6_addr_equal ( local , & t -> parms . laddr ) && <nl> - ipv6_addr_equal ( remote , & t -> parms . raddr )) <nl> + ipv6_addr_equal ( remote , & t -> parms . raddr )) { <nl> + if ( create ) <nl> + return NULL ; <nl> + <nl> return t ; <nl> + } <nl> } <nl> if (! create ) <nl> return NULL ;
xfs_attr_shortform_addname ( xfs_da_args_t * args ) <nl> if ( args -> flags & ATTR_CREATE ) <nl> return retval ; <nl> retval = xfs_attr_shortform_remove ( args ); <nl> - ASSERT ( retval == 0 ); <nl> + if ( retval ) <nl> + return retval ; <nl> + /* <nl> + * Since we have removed the old attr , clear ATTR_REPLACE so <nl> + * that the leaf format add routine won ' t trip over the attr <nl> + * not being around . <nl> + */ <nl> + args -> flags &= ~ ATTR_REPLACE ; <nl> } <nl>  <nl> if ( args -> namelen >= XFS_ATTR_SF_ENTSIZE_MAX ||
static struct ib_ucontext * hns_roce_alloc_ucontext ( struct ib_device * ib_dev , <nl> { <nl> int ret = 0 ; <nl> struct hns_roce_ucontext * context ; <nl> - struct hns_roce_ib_alloc_ucontext_resp resp ; <nl> + struct hns_roce_ib_alloc_ucontext_resp resp = {}; <nl> struct hns_roce_dev * hr_dev = to_hr_dev ( ib_dev ); <nl>  <nl> resp . qp_tab_size = hr_dev -> caps . num_qps ;
static int tegra_io_pad_prepare ( enum tegra_io_pad id , unsigned long * request , <nl> } <nl>  <nl> rate = clk_get_rate ( pmc -> clk ); <nl> + if (! rate ) <nl> + return - ENODEV ; <nl>  <nl> tegra_pmc_writel ( DPD_SAMPLE_ENABLE , DPD_SAMPLE ); <nl> 
static void save_microcode_patch ( void * data , unsigned int size ) <nl> p = memdup_patch ( data , size ); <nl> if (! p ) <nl> pr_err (" Error allocating buffer % p \ n ", data ); <nl> - else <nl> + else { <nl> list_replace (& iter -> plist , & p -> plist ); <nl> + kfree ( iter -> data ); <nl> + kfree ( iter ); <nl> + } <nl> } <nl> } <nl> 
nfsd4_exchange_id ( struct svc_rqst * rqstp , <nl> conf = find_confirmed_client_by_str ( dname , strhashval ); <nl> if ( conf ) { <nl> if (! clp_used_exchangeid ( conf )) { <nl> - status = nfserr_clid_inuse ; /* XXX : ? */ <nl> - goto out ; <nl> + if ( exid -> flags & EXCHGID4_FLAG_UPD_CONFIRMED_REC_A ) { <nl> + status = nfserr_inval ; /* buggy client */ <nl> + goto out ; <nl> + } <nl> } <nl> if (! same_creds (& conf -> cl_cred , & rqstp -> rq_cred )) { <nl> /* 18 . 35 . 4 case 9 */ <nl> nfsd4_exchange_id ( struct svc_rqst * rqstp , <nl> expire_client ( conf ); <nl> goto out_new ; <nl> } <nl> + if (! clp_used_exchangeid ( conf )) { <nl> + status = nfserr_inval ; <nl> + goto out ; <nl> + } <nl> /* <nl> * Set bit when the owner id and verifier map to an already <nl> * confirmed client id ( 18 . 35 . 3 ).
s32 igb_get_phy_id ( struct e1000_hw * hw ) <nl> u16 phy_id ; <nl>  <nl> /* ensure PHY page selection to fix misconfigured i210 */ <nl> - if ( hw -> mac . type == e1000_i210 ) <nl> + if (( hw -> mac . type == e1000_i210 ) || ( hw -> mac . type == e1000_i211 )) <nl> phy -> ops . write_reg ( hw , I347AT4_PAGE_SELECT , 0 ); <nl>  <nl> ret_val = phy -> ops . read_reg ( hw , PHY_ID1 , & phy_id );
check_sal_cache_flush ( void ) <nl> local_irq_save ( flags ); <nl>  <nl> /* <nl> - * Schedule a timer interrupt , wait until it ' s reported , and see if <nl> - * SAL_CACHE_FLUSH drops it . <nl> + * Send ourselves a timer interrupt , wait until it ' s reported , and see <nl> + * if SAL_CACHE_FLUSH drops it . <nl> */ <nl> - ia64_set_itv ( IA64_TIMER_VECTOR ); <nl> - ia64_set_itm ( ia64_get_itc () + 1000 ); <nl> + platform_send_ipi ( cpu , IA64_TIMER_VECTOR , IA64_IPI_DM_INT , 0 ); <nl>  <nl> while (! ia64_get_irr ( IA64_TIMER_VECTOR )) <nl> cpu_relax ();
static int omap_system_dma_probe ( struct platform_device * pdev ) <nl> return - ENOMEM ; <nl>  <nl> if ( dma_omap2plus ()) { <nl> - dma_linked_lch = kzalloc ( sizeof ( struct dma_link_info ) * <nl> - dma_lch_count , GFP_KERNEL ); <nl> + dma_linked_lch = kcalloc ( dma_lch_count , <nl> + sizeof (* dma_linked_lch ), <nl> + GFP_KERNEL ); <nl> if (! dma_linked_lch ) { <nl> ret = - ENOMEM ; <nl> goto exit_dma_lch_fail ;
tcpmss_mangle_packet ( struct sk_buff * skb , <nl> tcph = ( struct tcphdr *)( skb_network_header ( skb ) + tcphoff ); <nl> tcp_hdrlen = tcph -> doff * 4 ; <nl>  <nl> - if ( len < tcp_hdrlen ) <nl> + if ( len < tcp_hdrlen || tcp_hdrlen < sizeof ( struct tcphdr )) <nl> return - 1 ; <nl>  <nl> if ( info -> mss == XT_TCPMSS_CLAMP_PMTU ) { <nl> tcpmss_mangle_packet ( struct sk_buff * skb , <nl> if ( len > tcp_hdrlen ) <nl> return 0 ; <nl>  <nl> + /* tcph -> doff has 4 bits , do not wrap it to 0 */ <nl> + if ( tcp_hdrlen >= 15 * 4 ) <nl> + return 0 ; <nl> + <nl> /* <nl> * MSS Option not found ?! add it .. <nl> */
static int cciss_ioctl32_big_passthru ( struct block_device * bdev , fmode_t mode , <nl> int err ; <nl> u32 cp ; <nl>  <nl> + memset (& arg64 , 0 , sizeof ( arg64 )); <nl> err = 0 ; <nl> err |= <nl> copy_from_user (& arg64 . LUN_info , & arg32 -> LUN_info ,
static int iterate_dir_item ( struct btrfs_root * root , struct btrfs_path * path , <nl> buf = tmp ; <nl> } <nl> if (! buf ) { <nl> - buf = vmalloc ( buf_len ); <nl> + buf = kvmalloc ( buf_len , GFP_KERNEL ); <nl> if (! buf ) { <nl> ret = - ENOMEM ; <nl> goto out ;
static void om6802_sensor_init ( struct gspca_dev * gspca_dev ) <nl> reg_w_buf ( gspca_dev , sensor_reset , sizeof sensor_reset ); <nl> msleep ( 5 ); <nl> i = 4 ; <nl> - while (-- i < 0 ) { <nl> + while (-- i > 0 ) { <nl> byte = reg_r ( gspca_dev , 0x0060 ); <nl> if (!( byte & 0x01 )) <nl> break ;
int rtl8xxxu_parse_rxdesc16 ( struct rtl8xxxu_priv * priv , struct sk_buff * skb ) <nl> pkt_offset = roundup ( pkt_len + drvinfo_sz + desc_shift + <nl> sizeof ( struct rtl8xxxu_rxdesc16 ), 128 ); <nl>  <nl> - if ( pkt_cnt > 1 ) <nl> + /* <nl> + * Only clone the skb if there ' s enough data at the end to <nl> + * at least cover the rx descriptor <nl> + */ <nl> + if ( pkt_cnt > 1 && <nl> + urb_len > ( pkt_offset + sizeof ( struct rtl8xxxu_rxdesc16 ))) <nl> next_skb = skb_clone ( skb , GFP_ATOMIC ); <nl>  <nl> rx_status = IEEE80211_SKB_RXCB ( skb );
static inline int device_updated ( struct hpsa_scsi_dev_t * dev1 , <nl> return 1 ; <nl> if ( dev1 -> offload_enabled != dev2 -> offload_enabled ) <nl> return 1 ; <nl> - if ( dev1 -> queue_depth != dev2 -> queue_depth ) <nl> - return 1 ; <nl> + if (! is_logical_dev_addr_mode ( dev1 -> scsi3addr )) <nl> + if ( dev1 -> queue_depth != dev2 -> queue_depth ) <nl> + return 1 ; <nl> return 0 ; <nl> } <nl>  <nl> static void hpsa_update_scsi_devices ( struct ctlr_info * h , int hostno ) <nl> else if (!( h -> transMethod & CFGTBL_Trans_io_accel1 || <nl> h -> transMethod & CFGTBL_Trans_io_accel2 )) <nl> break ; <nl> - <nl> hpsa_get_ioaccel_drive_info ( h , this_device , <nl> lunaddrbytes , id_phys ); <nl> hpsa_get_path_info ( this_device , lunaddrbytes , id_phys );
static int __devinit max8973_probe ( struct i2c_client * client , <nl> max -> desc . uV_step = MAX8973_VOLATGE_STEP ; <nl> max -> desc . n_voltages = MAX8973_BUCK_N_VOLTAGE ; <nl>  <nl> - if ( pdata -> enable_ext_control ) { <nl> + if (! pdata -> enable_ext_control ) { <nl> max -> desc . enable_reg = MAX8973_VOUT ; <nl> max -> desc . enable_mask = MAX8973_VOUT_ENABLE ; <nl> max8973_dcdc_ops . enable = regulator_enable_regmap ;
static void ffs_user_copy_worker ( struct work_struct * work ) <nl> work ); <nl> int ret = io_data -> req -> status ? io_data -> req -> status : <nl> io_data -> req -> actual ; <nl> + bool kiocb_has_eventfd = io_data -> kiocb -> ki_flags & IOCB_EVENTFD ; <nl>  <nl> if ( io_data -> read && ret > 0 ) { <nl> use_mm ( io_data -> mm ); <nl> static void ffs_user_copy_worker ( struct work_struct * work ) <nl>  <nl> io_data -> kiocb -> ki_complete ( io_data -> kiocb , ret , ret ); <nl>  <nl> - if ( io_data -> ffs -> ffs_eventfd && <nl> - !( io_data -> kiocb -> ki_flags & IOCB_EVENTFD )) <nl> + if ( io_data -> ffs -> ffs_eventfd && ! kiocb_has_eventfd ) <nl> eventfd_signal ( io_data -> ffs -> ffs_eventfd , 1 ); <nl>  <nl> usb_ep_free_request ( io_data -> ep , io_data -> req ); <nl>  <nl> - io_data -> kiocb -> private = NULL ; <nl> if ( io_data -> read ) <nl> kfree ( io_data -> to_free ); <nl> kfree ( io_data -> buf );
struct xc4000_priv { <nl>  <nl> /* Product id */ <nl> # define XC_PRODUCT_ID_FW_NOT_LOADED 0x2000 <nl> -# define XC_PRODUCT_ID_FW_LOADED 0x0FA0 <nl> +# define XC_PRODUCT_ID_XC4000 0x0FA0 <nl> +# define XC_PRODUCT_ID_XC4100 0x1004 <nl>  <nl> /* Registers ( Write - only ) */ <nl> # define XREG_INIT 0x00 <nl> static int check_firmware ( struct dvb_frontend * fe , unsigned int type , <nl> # endif <nl>  <nl> /* Check that the tuner hardware model remains consistent over time . */ <nl> - if ( priv -> hwmodel == 0 && hwmodel == 4000 ) { <nl> + if ( priv -> hwmodel == 0 && <nl> + ( hwmodel == XC_PRODUCT_ID_XC4000 || <nl> + hwmodel == XC_PRODUCT_ID_XC4100 )) { <nl> priv -> hwmodel = hwmodel ; <nl> priv -> hwvers = version & 0xff00 ; <nl> } else if ( priv -> hwmodel == 0 || priv -> hwmodel != hwmodel || <nl> struct dvb_frontend * xc4000_attach ( struct dvb_frontend * fe , <nl> } <nl>  <nl> switch ( id ) { <nl> - case XC_PRODUCT_ID_FW_LOADED : <nl> + case XC_PRODUCT_ID_XC4000 : <nl> + case XC_PRODUCT_ID_XC4100 : <nl> printk ( KERN_INFO <nl> " xc4000 : Successfully identified at address 0x % 02x \ n ", <nl> cfg -> i2c_address );
static netdev_tx_t ip6erspan_tunnel_xmit ( struct sk_buff * skb , <nl> truncate = true ; <nl> } <nl>  <nl> + if ( skb_cow_head ( skb , dev -> needed_headroom )) <nl> + goto tx_err ; <nl> + <nl> t -> parms . o_flags &= ~ TUNNEL_KEY ; <nl> IPCB ( skb )-> flags = 0 ; <nl> 
struct sock * inet_csk_clone_lock ( const struct sock * sk , <nl> /* listeners have SOCK_RCU_FREE , not the children */ <nl> sock_reset_flag ( newsk , SOCK_RCU_FREE ); <nl>  <nl> + inet_sk ( newsk )-> mc_list = NULL ; <nl> + <nl> newsk -> sk_mark = inet_rsk ( req )-> ir_mark ; <nl> atomic64_set (& newsk -> sk_cookie , <nl> atomic64_read (& inet_rsk ( req )-> ir_cookie ));
nouveau_connector_set_encoder ( struct drm_connector * connector , <nl> return ; <nl> nv_connector -> detected_encoder = nv_encoder ; <nl>  <nl> + if ( dev_priv -> card_type >= NV_50 ) { <nl> + connector -> interlace_allowed = true ; <nl> + connector -> doublescan_allowed = true ; <nl> + } else <nl> if ( nv_encoder -> dcb -> type == OUTPUT_LVDS || <nl> nv_encoder -> dcb -> type == OUTPUT_TMDS ) { <nl> connector -> doublescan_allowed = false ;
static inline void map_vector_to_rxq ( struct ixgbe_adapter * a , int v_idx , <nl> int r_idx ) <nl> { <nl> struct ixgbe_q_vector * q_vector = a -> q_vector [ v_idx ]; <nl> + struct ixgbe_ring * rx_ring = a -> rx_ring [ r_idx ]; <nl>  <nl> set_bit ( r_idx , q_vector -> rxr_idx ); <nl> q_vector -> rxr_count ++; <nl> + rx_ring -> q_vector = q_vector ; <nl> } <nl>  <nl> static inline void map_vector_to_txq ( struct ixgbe_adapter * a , int v_idx , <nl> int t_idx ) <nl> { <nl> struct ixgbe_q_vector * q_vector = a -> q_vector [ v_idx ]; <nl> + struct ixgbe_ring * tx_ring = a -> tx_ring [ t_idx ]; <nl>  <nl> set_bit ( t_idx , q_vector -> txr_idx ); <nl> q_vector -> txr_count ++; <nl> + tx_ring -> q_vector = q_vector ; <nl> } <nl>  <nl> /**
static void rtl_runtime_suspend_enable ( struct r8152 * tp , bool enable ) <nl>  <nl> static void rtl8153_runtime_enable ( struct r8152 * tp , bool enable ) <nl> { <nl> - rtl_runtime_suspend_enable ( tp , enable ); <nl> - <nl> if ( enable ) { <nl> r8153_u1u2en ( tp , false ); <nl> r8153_u2p3en ( tp , false ); <nl> r8153_mac_clk_spd ( tp , true ); <nl> + rtl_runtime_suspend_enable ( tp , true ); <nl> } else { <nl> + rtl_runtime_suspend_enable ( tp , false ); <nl> r8153_mac_clk_spd ( tp , false ); <nl> r8153_u2p3en ( tp , true ); <nl> r8153_u1u2en ( tp , true );
static int iowarrior_probe ( struct usb_interface * interface , <nl> iface_desc = interface -> cur_altsetting ; <nl> dev -> product_id = le16_to_cpu ( udev -> descriptor . idProduct ); <nl>  <nl> + if ( iface_desc -> desc . bNumEndpoints < 1 ) { <nl> + dev_err (& interface -> dev , " Invalid number of endpoints \ n "); <nl> + retval = - EINVAL ; <nl> + goto error ; <nl> + } <nl> + <nl> /* set up the endpoint information */ <nl> for ( i = 0 ; i < iface_desc -> desc . bNumEndpoints ; ++ i ) { <nl> endpoint = & iface_desc -> endpoint [ i ]. desc ;
static int __devinit create_lt3593_led ( const struct gpio_led * template , <nl> return 0 ; <nl> } <nl>  <nl> - ret = gpio_request ( template -> gpio , template -> name ); <nl> - if ( ret < 0 ) <nl> - return ret ; <nl> - <nl> led_dat -> cdev . name = template -> name ; <nl> led_dat -> cdev . default_trigger = template -> default_trigger ; <nl> led_dat -> gpio = template -> gpio ; <nl> static int __devinit create_lt3593_led ( const struct gpio_led * template , <nl> if (! template -> retain_state_suspended ) <nl> led_dat -> cdev . flags |= LED_CORE_SUSPENDRESUME ; <nl>  <nl> - ret = gpio_direction_output ( led_dat -> gpio , state ); <nl> + ret = gpio_request_one ( template -> gpio , GPIOF_DIR_OUT | state , <nl> + template -> name ); <nl> if ( ret < 0 ) <nl> - goto err ; <nl> + return ret ; <nl>  <nl> INIT_WORK (& led_dat -> work , lt3593_led_work ); <nl> 
int cap_bprm_set_creds ( struct linux_binprm * bprm ) <nl> } <nl> skip : <nl>  <nl> + /* if we have fs caps , clear dangerous personality flags */ <nl> + if (! cap_issubset ( new -> cap_permitted , old -> cap_permitted )) <nl> + bprm -> per_clear |= PER_CLEAR_ON_SETID ; <nl> + <nl> + <nl> /* Don ' t let someone trace a set [ ug ] id / setpcap binary with the revised <nl> * credentials unless they have the appropriate permit <nl> */
static void ifx_spi_io ( unsigned long data ) <nl> ifx_dev -> spi_xfer . cs_change = 0 ; <nl> ifx_dev -> spi_xfer . speed_hz = ifx_dev -> spi_dev -> max_speed_hz ; <nl> /* ifx_dev -> spi_xfer . speed_hz = 390625 ; */ <nl> - ifx_dev -> spi_xfer . bits_per_word = spi_bpw ; <nl> + ifx_dev -> spi_xfer . bits_per_word = <nl> + ifx_dev -> spi_dev -> bits_per_word ; <nl>  <nl> ifx_dev -> spi_xfer . tx_buf = ifx_dev -> tx_buffer ; <nl> ifx_dev -> spi_xfer . rx_buf = ifx_dev -> rx_buffer ;
do { \ <nl> __get_user_asm ( val , " lw ", ptr ); \ <nl> break ; \ <nl> case 8 : \ <nl> - if (( copy_from_user (( void *)& val , ptr , 8 )) == 0 ) \ <nl> + if ( __copy_from_user (( void *)& val , ptr , 8 ) == 0 ) \ <nl> __gu_err = 0 ; \ <nl> else \ <nl> __gu_err = - EFAULT ; \ <nl> do { \ <nl> \ <nl> if ( likely ( access_ok ( VERIFY_READ , __gu_ptr , size ))) \ <nl> __get_user_common (( x ), size , __gu_ptr ); \ <nl> + else \ <nl> + ( x ) = 0 ; \ <nl> \ <nl> __gu_err ; \ <nl> }) <nl> do { \ <nl> " 2 :\ n " \ <nl> ". section . fixup ,\" ax \"\ n " \ <nl> " 3 : li % 0 , % 4 \ n " \ <nl> + " li % 1 , 0 \ n " \ <nl> " j 2b \ n " \ <nl> ". previous \ n " \ <nl> ". section __ex_table ,\" a \"\ n " \
static long aio_read_events_ring ( struct kioctx * ctx , <nl> if ( head == tail ) <nl> goto out ; <nl>  <nl> + head %= ctx -> nr_events ; <nl> + tail %= ctx -> nr_events ; <nl> + <nl> while ( ret < nr ) { <nl> long avail ; <nl> struct io_event * ev ;
static int amdgpu_cs_wait_any_fence ( struct amdgpu_device * adev , <nl> wait -> out . status = ( r > 0 ); <nl> wait -> out . first_signaled = first ; <nl>  <nl> - if ( array [ first ]) <nl> + if ( first < fence_count && array [ first ]) <nl> r = array [ first ]-> error ; <nl> else <nl> r = 0 ;
unsigned int <nl> nft_do_chain ( struct nft_pktinfo * pkt , const struct nf_hook_ops * ops ) <nl> { <nl> const struct nft_chain * chain = ops -> priv , * basechain = chain ; <nl> - const struct net * net = read_pnet (& nft_base_chain ( basechain )-> pnet ); <nl> + const struct net * chain_net = read_pnet (& nft_base_chain ( basechain )-> pnet ); <nl> + const struct net * net = dev_net ( pkt -> in ? pkt -> in : pkt -> out ); <nl> const struct nft_rule * rule ; <nl> const struct nft_expr * expr , * last ; <nl> struct nft_regs regs ; <nl> nft_do_chain ( struct nft_pktinfo * pkt , const struct nf_hook_ops * ops ) <nl> int rulenum ; <nl> unsigned int gencursor = nft_genmask_cur ( net ); <nl>  <nl> + /* Ignore chains that are not for the current network namespace */ <nl> + if (! net_eq ( net , chain_net )) <nl> + return NF_ACCEPT ; <nl> + <nl> do_chain : <nl> rulenum = 0 ; <nl> rule = list_entry (& chain -> rules , struct nft_rule , list );
static void mmu_set_spte ( struct kvm_vcpu * vcpu , u64 * sptep , <nl>  <nl> child = page_header ( pte & PT64_BASE_ADDR_MASK ); <nl> mmu_page_remove_parent_pte ( child , sptep ); <nl> + __set_spte ( sptep , shadow_trap_nonpresent_pte ); <nl> + kvm_flush_remote_tlbs ( vcpu -> kvm ); <nl> } else if ( pfn != spte_to_pfn (* sptep )) { <nl> pgprintk (" hfn old % lx new % lx \ n ", <nl> spte_to_pfn (* sptep ), pfn );
static int tvaudio_probe ( struct i2c_client * client , const struct i2c_device_id * <nl> } <nl>  <nl> chip -> thread = NULL ; <nl> + init_timer (& chip -> wt ); <nl> if ( desc -> flags & CHIP_NEED_CHECKMODE ) { <nl> if (! desc -> getmode || ! desc -> setmode ) { <nl> /* This shouldn ' t be happen . Warn user , but keep working <nl> static int tvaudio_probe ( struct i2c_client * client , const struct i2c_device_id * <nl> return 0 ; <nl> } <nl> /* start async thread */ <nl> - init_timer (& chip -> wt ); <nl> chip -> wt . function = chip_thread_wake ; <nl> chip -> wt . data = ( unsigned long ) chip ; <nl> chip -> thread = kthread_run ( chip_thread , chip , client -> name );
static const struct regmap_config rt5677_regmap = { <nl> static const struct i2c_device_id rt5677_i2c_id [] = { <nl> { " rt5677 ", RT5677 }, <nl> { " rt5676 ", RT5676 }, <nl> + { " RT5677CE : 00 ", RT5677 }, <nl> { } <nl> }; <nl> MODULE_DEVICE_TABLE ( i2c , rt5677_i2c_id );
static void sw_perf_event_destroy ( struct perf_event * event ) <nl>  <nl> static int perf_swevent_init ( struct perf_event * event ) <nl> { <nl> - int event_id = event -> attr . config ; <nl> + u64 event_id = event -> attr . config ; <nl>  <nl> if ( event -> attr . type != PERF_TYPE_SOFTWARE ) <nl> return - ENOENT ;
static int __init ptp_kvm_init ( void ) <nl> { <nl> long ret ; <nl>  <nl> + if (! kvm_para_available ()) <nl> + return - ENODEV ; <nl> + <nl> clock_pair_gpa = slow_virt_to_phys (& clock_pair ); <nl> hv_clock = pvclock_pvti_cpu0_va (); <nl> 
void gfs2_set_iop ( struct inode * inode ) <nl> inode -> i_op = & gfs2_symlink_iops ; <nl> } else { <nl> inode -> i_op = & gfs2_file_iops ; <nl> + init_special_inode ( inode , inode -> i_mode , inode -> i_rdev ); <nl> } <nl>  <nl> unlock_new_inode ( inode );
static int exynos_drm_bind ( struct device * dev ) <nl> /* Probe non kms sub drivers and virtual display driver . */ <nl> ret = exynos_drm_device_subdrv_probe ( drm ); <nl> if ( ret ) <nl> - goto err_cleanup_vblank ; <nl> + goto err_unbind_all ; <nl>  <nl> drm_mode_config_reset ( drm ); <nl>  <nl> static int exynos_drm_bind ( struct device * dev ) <nl> exynos_drm_fbdev_fini ( drm ); <nl> drm_kms_helper_poll_fini ( drm ); <nl> exynos_drm_device_subdrv_remove ( drm ); <nl> - err_cleanup_vblank : <nl> - drm_vblank_cleanup ( drm ); <nl> err_unbind_all : <nl> component_unbind_all ( drm -> dev , drm ); <nl> err_mode_config_cleanup :
bool seg6_validate_srh ( struct ipv6_sr_hdr * srh , int len ) <nl> struct sr6_tlv * tlv ; <nl> unsigned int tlv_len ; <nl>  <nl> + if ( trailing < sizeof (* tlv )) <nl> + return false ; <nl> + <nl> tlv = ( struct sr6_tlv *)(( unsigned char *) srh + tlv_offset ); <nl> tlv_len = sizeof (* tlv ) + tlv -> len ; <nl> 
ecryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , <nl> char * cipher_name , size_t * key_size ) <nl> { <nl> char dummy_key [ ECRYPTFS_MAX_KEY_BYTES ]; <nl> - char * full_alg_name ; <nl> + char * full_alg_name = NULL ; <nl> int rc ; <nl>  <nl> * key_tfm = NULL ; <nl> ecryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , <nl> if ( rc ) <nl> goto out ; <nl> * key_tfm = crypto_alloc_blkcipher ( full_alg_name , 0 , CRYPTO_ALG_ASYNC ); <nl> - kfree ( full_alg_name ); <nl> if ( IS_ERR (* key_tfm )) { <nl> rc = PTR_ERR (* key_tfm ); <nl> printk ( KERN_ERR " Unable to allocate crypto cipher with name " <nl> ecryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , <nl> goto out ; <nl> } <nl> out : <nl> + kfree ( full_alg_name ); <nl> return rc ; <nl> } <nl> 
static struct config_group * make_cma_dev ( struct config_group * group , <nl> goto fail ; <nl> } <nl>  <nl> - strncpy ( cma_dev_group -> name , name , sizeof ( cma_dev_group -> name )); <nl> + strlcpy ( cma_dev_group -> name , name , sizeof ( cma_dev_group -> name )); <nl>  <nl> config_group_init_type_name (& cma_dev_group -> ports_group , " ports ", <nl> & cma_ports_group_type );
void tsl2x7x_prox_calculate ( int * data , int length , <nl> tmp = data [ i ] - statP -> mean ; <nl> sample_sum += tmp * tmp ; <nl> } <nl> - statP -> stddev = int_sqrt (( long ) sample_sum )/ length ; <nl> + statP -> stddev = int_sqrt (( long ) sample_sum ) / length ; <nl> } <nl>  <nl> /** <nl> static ssize_t tsl2x7x_luxtable_store ( struct device * dev , <nl> { <nl> struct iio_dev * indio_dev = dev_to_iio_dev ( dev ); <nl> struct tsl2X7X_chip * chip = iio_priv ( indio_dev ); <nl> - int value [ ARRAY_SIZE ( chip -> tsl2x7x_device_lux )* 3 + 1 ]; <nl> + int value [ ARRAY_SIZE ( chip -> tsl2x7x_device_lux ) * 3 + 1 ]; <nl> int n ; <nl>  <nl> get_options ( buf , ARRAY_SIZE ( value ), value );
static void __init zone_sizes_init ( void ) <nl> * though , there ' ll be no lowmem , so we just alloc_bootmem <nl> * the memmap . There will be no percpu memory either . <nl> */ <nl> - if ( i != 0 && cpumask_test_cpu ( i , & isolnodes )) { <nl> + if ( i != 0 && node_isset ( i , isolnodes )) { <nl> node_memmap_pfn [ i ] = <nl> alloc_bootmem_pfn ( 0 , memmap_size , 0 ); <nl> BUG_ON ( node_percpu [ i ] != 0 );
SYSCALL_DEFINE6 ( sendto , int , fd , void __user *, buff , size_t , len , <nl>  <nl> if ( len > INT_MAX ) <nl> len = INT_MAX ; <nl> + if ( unlikely (! access_ok ( VERIFY_READ , buff , len ))) <nl> + return - EFAULT ; <nl> sock = sockfd_lookup_light ( fd , & err , & fput_needed ); <nl> if (! sock ) <nl> goto out ; <nl> SYSCALL_DEFINE6 ( recvfrom , int , fd , void __user *, ubuf , size_t , size , <nl>  <nl> if ( size > INT_MAX ) <nl> size = INT_MAX ; <nl> + if ( unlikely (! access_ok ( VERIFY_WRITE , ubuf , size ))) <nl> + return - EFAULT ; <nl> sock = sockfd_lookup_light ( fd , & err , & fput_needed ); <nl> if (! sock ) <nl> goto out ;
static void azx_pcm_free ( struct snd_pcm * pcm ) <nl>  <nl> # define MAX_PREALLOC_SIZE ( 32 * 1024 * 1024 ) <nl>  <nl> - int azx_attach_pcm_stream ( struct hda_bus * bus , struct hda_codec * codec , <nl> - struct hda_pcm * cpcm ) <nl> + static int azx_attach_pcm_stream ( struct hda_bus * bus , struct hda_codec * codec , <nl> + struct hda_pcm * cpcm ) <nl> { <nl> struct azx * chip = bus -> private_data ; <nl> struct snd_pcm * pcm ;
int fix_alignment ( struct pt_regs * regs ) <nl>  <nl> type = op . type & INSTR_TYPE_MASK ; <nl> if (! OP_IS_LOAD_STORE ( type )) { <nl> - if ( type != CACHEOP + DCBZ ) <nl> + if ( op . type != CACHEOP + DCBZ ) <nl> return - EINVAL ; <nl> PPC_WARN_ALIGNMENT ( dcbz , regs ); <nl> r = emulate_dcbz ( op . ea , regs );
static void qlcnic_get_ethtool_stats ( struct net_device * dev , <nl> memset ( data , 0 , stats -> n_stats * sizeof ( u64 )); <nl>  <nl> for ( ring = 0 , index = 0 ; ring < adapter -> drv_tx_rings ; ring ++) { <nl> - if ( test_bit ( __QLCNIC_DEV_UP , & adapter -> state )) { <nl> + if ( adapter -> is_up == QLCNIC_ADAPTER_UP_MAGIC ) { <nl> tx_ring = & adapter -> tx_ring [ ring ]; <nl> data = qlcnic_fill_tx_queue_stats ( data , tx_ring ); <nl> qlcnic_update_stats ( adapter );
nfsd4_layout_verify ( struct svc_export * exp , unsigned int layout_type ) <nl> return NULL ; <nl> } <nl>  <nl> - if (!( exp -> ex_layout_types & ( 1 << layout_type ))) { <nl> + if ( layout_type >= LAYOUT_TYPE_MAX || <nl> + !( exp -> ex_layout_types & ( 1 << layout_type ))) { <nl> dprintk ("% s : layout type % d not supported \ n ", <nl> __func__ , layout_type ); <nl> return NULL ;
static int vlan_device_event ( struct notifier_block * unused , unsigned long event , <nl> dev -> name ); <nl> vlan_vid_add ( dev , htons ( ETH_P_8021Q ), 0 ); <nl> } <nl> + if ( event == NETDEV_DOWN && <nl> + ( dev -> features & NETIF_F_HW_VLAN_CTAG_FILTER )) <nl> + vlan_vid_del ( dev , htons ( ETH_P_8021Q ), 0 ); <nl>  <nl> vlan_info = rtnl_dereference ( dev -> vlan_info ); <nl> if (! vlan_info ) <nl> static int vlan_device_event ( struct notifier_block * unused , unsigned long event , <nl> struct net_device * tmp ; <nl> LIST_HEAD ( close_list ); <nl>  <nl> - if ( dev -> features & NETIF_F_HW_VLAN_CTAG_FILTER ) <nl> - vlan_vid_del ( dev , htons ( ETH_P_8021Q ), 0 ); <nl> - <nl> /* Put all VLANs for this dev in the down state too . */ <nl> vlan_group_for_each_dev ( grp , i , vlandev ) { <nl> flgs = vlandev -> flags ;
static int storvsc_device_configure ( struct scsi_device * sdevice ) <nl>  <nl> /* <nl> * If the host is WIN8 or WIN8 R2 , claim conformance to SPC - 3 <nl> - * if the device is a MSFT virtual device . <nl> + * if the device is a MSFT virtual device . If the host is <nl> + * WIN10 or newer , allow write_same . <nl> */ <nl> if (! strncmp ( sdevice -> vendor , " Msft ", 4 )) { <nl> switch ( vmstor_proto_version ) { <nl> static int storvsc_device_configure ( struct scsi_device * sdevice ) <nl> sdevice -> scsi_level = SCSI_SPC_3 ; <nl> break ; <nl> } <nl> + <nl> + if ( vmstor_proto_version >= VMSTOR_PROTO_VERSION_WIN10 ) <nl> + sdevice -> no_write_same = 0 ; <nl> } <nl>  <nl> return 0 ;
int devm_request_irq ( struct device * dev , unsigned int irq , <nl>  <nl> rc = request_irq ( irq , handler , irqflags , devname , dev_id ); <nl> if ( rc ) { <nl> - kfree ( dr ); <nl> + devres_free ( dr ); <nl> return rc ; <nl> } <nl> 
static int twl4030_kp_probe ( struct platform_device * pdev ) <nl> err3 : <nl> /* mask all events - we don ' t care about the result */ <nl> ( void ) twl4030_kpwrite_u8 ( kp , 0xff , KEYP_IMR1 ); <nl> - free_irq ( kp -> irq , NULL ); <nl> + free_irq ( kp -> irq , kp ); <nl> err2 : <nl> input_unregister_device ( input ); <nl> input = NULL ;
static int ath3k_load_firmware ( struct usb_device * udev , <nl> return - ENOMEM ; <nl> } <nl>  <nl> - memcpy ( send_buf , firmware -> data , 20 ); <nl> + memcpy ( send_buf , firmware -> data , FW_HDR_SIZE ); <nl> err = usb_control_msg ( udev , pipe , USB_REQ_DFU_DNLOAD , USB_TYPE_VENDOR , <nl> - 0 , 0 , send_buf , 20 , USB_CTRL_SET_TIMEOUT ); <nl> + 0 , 0 , send_buf , FW_HDR_SIZE , <nl> + USB_CTRL_SET_TIMEOUT ); <nl> if ( err < 0 ) { <nl> BT_ERR (" Can ' t change to loading configuration err "); <nl> goto error ; <nl> } <nl> - sent += 20 ; <nl> - count -= 20 ; <nl> + sent += FW_HDR_SIZE ; <nl> + count -= FW_HDR_SIZE ; <nl>  <nl> pipe = usb_sndbulkpipe ( udev , 0x02 ); <nl> 
static int br_mdb_fill_info ( struct sk_buff * skb , struct netlink_callback * cb , <nl> port = p -> port ; <nl> if ( port ) { <nl> struct br_mdb_entry e ; <nl> + memset (& e , 0 , sizeof ( e )); <nl> e . ifindex = port -> dev -> ifindex ; <nl> e . state = p -> state ; <nl> if ( p -> addr . proto == htons ( ETH_P_IP )) <nl> static int br_mdb_dump ( struct sk_buff * skb , struct netlink_callback * cb ) <nl> break ; <nl>  <nl> bpm = nlmsg_data ( nlh ); <nl> + memset ( bpm , 0 , sizeof (* bpm )); <nl> bpm -> ifindex = dev -> ifindex ; <nl> if ( br_mdb_fill_info ( skb , cb , dev ) < 0 ) <nl> goto out ; <nl> static int nlmsg_populate_mdb_fill ( struct sk_buff * skb , <nl> return - EMSGSIZE ; <nl>  <nl> bpm = nlmsg_data ( nlh ); <nl> + memset ( bpm , 0 , sizeof (* bpm )); <nl> bpm -> family = AF_BRIDGE ; <nl> bpm -> ifindex = dev -> ifindex ; <nl> nest = nla_nest_start ( skb , MDBA_MDB ); <nl> void br_mdb_notify ( struct net_device * dev , struct net_bridge_port * port , <nl> { <nl> struct br_mdb_entry entry ; <nl>  <nl> + memset (& entry , 0 , sizeof ( entry )); <nl> entry . ifindex = port -> dev -> ifindex ; <nl> entry . addr . proto = group -> proto ; <nl> entry . addr . u . ip4 = group -> u . ip4 ;
static inline void ata_tf_init ( struct ata_device * dev , struct ata_taskfile * tf ) <nl>  <nl> static inline void ata_qc_reinit ( struct ata_queued_cmd * qc ) <nl> { <nl> + qc -> dma_dir = DMA_NONE ; <nl> qc -> __sg = NULL ; <nl> qc -> flags = 0 ; <nl> qc -> cursect = qc -> cursg = qc -> cursg_ofs = 0 ;
static void arp_send_dst ( int type , int ptype , __be32 dest_ip , <nl> if (! skb ) <nl> return ; <nl>  <nl> - skb_dst_set ( skb , dst ); <nl> + skb_dst_set ( skb , dst_clone ( dst )); <nl> arp_xmit ( skb ); <nl> } <nl>  <nl> static void arp_solicit ( struct neighbour * neigh , struct sk_buff * skb ) <nl> } <nl>  <nl> if ( skb && !( dev -> priv_flags & IFF_XMIT_DST_RELEASE )) <nl> - dst = dst_clone ( skb_dst ( skb )); <nl> + dst = skb_dst ( skb ); <nl> arp_send_dst ( ARPOP_REQUEST , ETH_P_ARP , target , dev , saddr , <nl> dst_hw , dev -> dev_addr , NULL , dst ); <nl> } <nl> static int arp_process ( struct sock * sk , struct sk_buff * skb ) <nl> } else { <nl> pneigh_enqueue (& arp_tbl , <nl> in_dev -> arp_parms , skb ); <nl> - return 0 ; <nl> + goto out_free_dst ; <nl> } <nl> goto out ; <nl> } <nl> static int arp_process ( struct sock * sk , struct sk_buff * skb ) <nl>  <nl> out : <nl> consume_skb ( skb ); <nl> + out_free_dst : <nl> + dst_release ( reply_dst ); <nl> return 0 ; <nl> } <nl> 
EXPORT_SYMBOL ( snprintf ); <nl> * @...: Arguments for the format string <nl> * <nl> * The return value is the number of characters written into @ buf not including <nl> - * the trailing '\ 0 '. If @ size is <= 0 the function returns 0 . <nl> + * the trailing '\ 0 '. If @ size is == 0 the function returns 0 . <nl> */ <nl>  <nl> int scnprintf ( char * buf , size_t size , const char * fmt , ...) <nl> int scnprintf ( char * buf , size_t size , const char * fmt , ...) <nl> i = vsnprintf ( buf , size , fmt , args ); <nl> va_end ( args ); <nl>  <nl> - return ( i >= size ) ? ( size - 1 ) : i ; <nl> + if ( likely ( i < size )) <nl> + return i ; <nl> + if ( size != 0 ) <nl> + return size - 1 ; <nl> + return 0 ; <nl> } <nl> EXPORT_SYMBOL ( scnprintf ); <nl> 
int dsa_port_vlan_add ( struct dsa_port * dp , <nl> . vlan = vlan , <nl> }; <nl>  <nl> + if ( netif_is_bridge_master ( vlan -> obj . orig_dev )) <nl> + return - EOPNOTSUPP ; <nl> + <nl> if ( br_vlan_enabled ( dp -> bridge_dev )) <nl> return dsa_port_notify ( dp , DSA_NOTIFIER_VLAN_ADD , & info ); <nl>  <nl> int dsa_port_vlan_del ( struct dsa_port * dp , <nl> . vlan = vlan , <nl> }; <nl>  <nl> + if ( netif_is_bridge_master ( vlan -> obj . orig_dev )) <nl> + return - EOPNOTSUPP ; <nl> + <nl> if ( br_vlan_enabled ( dp -> bridge_dev )) <nl> return dsa_port_notify ( dp , DSA_NOTIFIER_VLAN_DEL , & info ); <nl> 
int radeon_atombios_init ( struct radeon_device * rdev ) <nl>  <nl> void radeon_atombios_fini ( struct radeon_device * rdev ) <nl> { <nl> - kfree ( rdev -> mode_info . atom_context -> scratch ); <nl> - kfree ( rdev -> mode_info . atom_context ); <nl> + if ( rdev -> mode_info . atom_context ) { <nl> + kfree ( rdev -> mode_info . atom_context -> scratch ); <nl> + kfree ( rdev -> mode_info . atom_context ); <nl> + } <nl> kfree ( rdev -> mode_info . atom_card_info ); <nl> } <nl> 
static int __devinit saa7134_initdev ( struct pci_dev * pci_dev , <nl> saa7134_dmasound_init ( dev ); <nl> } <nl>  <nl> + if ( TUNER_ABSENT != dev -> tuner_type ) <nl> + saa7134_i2c_call_clients ( dev , TUNER_SET_STANDBY , NULL ); <nl> + <nl> return 0 ; <nl>  <nl> fail4 :
/* to align the pointer to the ( next ) page boundary */ <nl> # define PAGE_ALIGN ( addr ) ((( addr )+ PAGE_SIZE - 1 )& PAGE_MASK ) <nl>  <nl> -# define __PHYSICAL_MASK (((( phys_addr_t ) 1 ) << __PHYSICAL_MASK_SHIFT ) - 1 ) <nl> +# define __PHYSICAL_MASK (( phys_addr_t )( 1ULL << __PHYSICAL_MASK_SHIFT ) - 1 ) <nl> # define __VIRTUAL_MASK (( 1UL << __VIRTUAL_MASK_SHIFT ) - 1 ) <nl>  <nl> # ifndef __ASSEMBLY__
static struct page * get_partial ( struct kmem_cache * s , gfp_t flags , int node ) <nl> int searchnode = ( node == NUMA_NO_NODE ) ? numa_node_id () : node ; <nl>  <nl> page = get_partial_node ( get_node ( s , searchnode )); <nl> - if ( page || node != - 1 ) <nl> + if ( page || node != NUMA_NO_NODE ) <nl> return page ; <nl>  <nl> return get_any_partial ( s , flags );
static int truncate_data_node ( const struct ubifs_info * c , const struct inode * in <nl> int err , dlen , compr_type , out_len , old_dlen ; <nl>  <nl> out_len = le32_to_cpu ( dn -> size ); <nl> - buf = kmalloc ( out_len * WORST_COMPR_FACTOR , GFP_NOFS ); <nl> + buf = kmalloc_array ( out_len , WORST_COMPR_FACTOR , GFP_NOFS ); <nl> if (! buf ) <nl> return - ENOMEM ; <nl> 
nouveau_framebuffer_init ( struct drm_device * dev , <nl> return - EINVAL ; <nl> } <nl>  <nl> + if ( nvbo -> tile_flags & NOUVEAU_GEM_TILE_NONCONTIG ) { <nl> + NV_ERROR ( drm , " framebuffer requires contiguous bo \ n "); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> if ( nv_device ( drm -> device )-> chipset == 0x50 ) <nl> nv_fb -> r_format |= ( tile_flags << 8 ); <nl> 
static void _tcpm_cc_change ( struct tcpm_port * port , enum typec_cc_status cc1 , <nl> break ; <nl>  <nl> case SRC_TRY : <nl> - tcpm_set_state ( port , SRC_TRY_DEBOUNCE , 0 ); <nl> + if ( tcpm_port_is_source ( port )) <nl> + tcpm_set_state ( port , SRC_TRY_DEBOUNCE , 0 ); <nl> break ; <nl> case SRC_TRY_DEBOUNCE : <nl> tcpm_set_state ( port , SRC_TRY , 0 );
static void set_bredr_scan ( struct hci_request * req ) <nl> */ <nl> write_fast_connectable ( req , false ); <nl>  <nl> - if ( test_bit ( HCI_CONNECTABLE , & hdev -> dev_flags )) <nl> + if ( test_bit ( HCI_CONNECTABLE , & hdev -> dev_flags ) || <nl> + ! list_empty (& hdev -> whitelist )) <nl> scan |= SCAN_PAGE ; <nl> if ( test_bit ( HCI_DISCOVERABLE , & hdev -> dev_flags )) <nl> scan |= SCAN_INQUIRY ; <nl> static int set_bredr ( struct sock * sk , struct hci_dev * hdev , void * data , u16 len ) <nl>  <nl> hci_req_init (& req , hdev ); <nl>  <nl> - if ( test_bit ( HCI_CONNECTABLE , & hdev -> dev_flags )) <nl> + if ( test_bit ( HCI_CONNECTABLE , & hdev -> dev_flags ) || <nl> + ! list_empty (& hdev -> whitelist )) <nl> set_bredr_scan (& req ); <nl>  <nl> /* Since only the advertising data flags will change , there
static int __devinit ad7879_probe ( struct spi_device * spi ) <nl> kfree ( ts ); <nl> } <nl>  <nl> - return 0 ; <nl> + return error ; <nl> } <nl>  <nl> static int __devexit ad7879_remove ( struct spi_device * spi ) <nl> static int __devinit ad7879_probe ( struct i2c_client * client , <nl> kfree ( ts ); <nl> } <nl>  <nl> - return 0 ; <nl> + return error ; <nl> } <nl>  <nl> static int __devexit ad7879_remove ( struct i2c_client * client )
static inline int cipso_v4_validate ( const struct sk_buff * skb , <nl> unsigned char err_offset = 0 ; <nl> u8 opt_len = opt [ 1 ]; <nl> u8 opt_iter ; <nl> + u8 tag_len ; <nl>  <nl> if ( opt_len < 8 ) { <nl> err_offset = 1 ; <nl> static inline int cipso_v4_validate ( const struct sk_buff * skb , <nl> } <nl>  <nl> for ( opt_iter = 6 ; opt_iter < opt_len ;) { <nl> - if ( opt [ opt_iter + 1 ] > ( opt_len - opt_iter )) { <nl> + tag_len = opt [ opt_iter + 1 ]; <nl> + if (( tag_len == 0 ) || ( opt [ opt_iter + 1 ] > ( opt_len - opt_iter ))) { <nl> err_offset = opt_iter + 1 ; <nl> goto out ; <nl> } <nl> - opt_iter += opt [ opt_iter + 1 ]; <nl> + opt_iter += tag_len ; <nl> } <nl>  <nl> out :
static int igb_probe ( struct pci_dev * pdev , const struct pci_device_id * ent ) <nl> if ( hw -> flash_address ) <nl> iounmap ( hw -> flash_address ); <nl> err_sw_init : <nl> + kfree ( adapter -> shadow_vfta ); <nl> igb_clear_interrupt_scheme ( adapter ); <nl> pci_iounmap ( pdev , hw -> hw_addr ); <nl> err_ioremap :
static int ssd1307fb_probe ( struct i2c_client * client , <nl> snprintf ( bl_name , sizeof ( bl_name ), " ssd1307fb % d ", info -> node ); <nl> bl = backlight_device_register ( bl_name , & client -> dev , par , <nl> & ssd1307fb_bl_ops , NULL ); <nl> - bl -> props . brightness = par -> contrast ; <nl> - bl -> props . max_brightness = MAX_CONTRAST ; <nl> - info -> bl_dev = bl ; <nl> - <nl> if ( IS_ERR ( bl )) { <nl> dev_err (& client -> dev , " unable to register backlight device : % ld \ n ", <nl> PTR_ERR ( bl )); <nl> goto bl_init_error ; <nl> } <nl> + <nl> + bl -> props . brightness = par -> contrast ; <nl> + bl -> props . max_brightness = MAX_CONTRAST ; <nl> + info -> bl_dev = bl ; <nl> + <nl> dev_info (& client -> dev , " fb % d : % s framebuffer device registered , using % d bytes of video memory \ n ", info -> node , info -> fix . id , vmem_size ); <nl>  <nl> return 0 ;
int vcc_recvmsg ( struct kiocb * iocb , struct socket * sock , struct msghdr * msg , <nl> struct sk_buff * skb ; <nl> int copied , error = - EINVAL ; <nl>  <nl> + msg -> msg_namelen = 0 ; <nl> + <nl> if ( sock -> state != SS_CONNECTED ) <nl> return - ENOTCONN ; <nl> 
struct reset_control * of_reset_control_get ( struct device_node * node , <nl> { <nl> int index = 0 ; <nl>  <nl> - if ( id ) <nl> + if ( id ) { <nl> index = of_property_match_string ( node , <nl> " reset - names ", id ); <nl> + if ( index < 0 ) <nl> + return ERR_PTR (- ENOENT ); <nl> + } <nl> return of_reset_control_get_by_index ( node , index ); <nl> } <nl> EXPORT_SYMBOL_GPL ( of_reset_control_get );
i2c_dw_xfer ( struct i2c_adapter * adap , struct i2c_msg msgs [], int num ) <nl> i2c_dw_xfer_init ( dev ); <nl>  <nl> /* wait for tx to complete */ <nl> - if (! wait_for_completion_timeout (& dev -> cmd_complete , HZ )) { <nl> + if (! wait_for_completion_timeout (& dev -> cmd_complete , adap -> timeout )) { <nl> dev_err ( dev -> dev , " controller timed out \ n "); <nl> /* i2c_dw_init implicitly disables the adapter */ <nl> i2c_dw_init ( dev );
static int snd_imx_open ( struct snd_pcm_substream * substream ) <nl> dma_params = snd_soc_dai_get_dma_data ( rtd -> cpu_dai , substream ); <nl>  <nl> dma_data = kzalloc ( sizeof (* dma_data ), GFP_KERNEL ); <nl> + if (! dma_data ) <nl> + return - ENOMEM ; <nl> + <nl> dma_data -> peripheral_type = dma_params -> shared_peripheral ? <nl> IMX_DMATYPE_SSI_SP : IMX_DMATYPE_SSI ; <nl> dma_data -> priority = DMA_PRIO_HIGH ;
static int mcp3422_probe ( struct i2c_client * client , <nl> | MCP3422_CHANNEL_VALUE ( 0 ) <nl> | MCP3422_PGA_VALUE ( MCP3422_PGA_1 ) <nl> | MCP3422_SAMPLE_RATE_VALUE ( MCP3422_SRATE_240 )); <nl> - mcp3422_update_config ( adc , config ); <nl> + err = mcp3422_update_config ( adc , config ); <nl> + if ( err < 0 ) <nl> + return err ; <nl>  <nl> err = devm_iio_device_register (& client -> dev , indio_dev ); <nl> if ( err < 0 )
static int mwifiex_pcie_alloc_cmdrsp_buf ( struct mwifiex_adapter * adapter ) <nl> } <nl> skb_put ( skb , MWIFIEX_UPLD_SIZE ); <nl> if ( mwifiex_map_pci_memory ( adapter , skb , MWIFIEX_UPLD_SIZE , <nl> - PCI_DMA_FROMDEVICE )) <nl> + PCI_DMA_FROMDEVICE )) { <nl> + kfree_skb ( skb ); <nl> return - 1 ; <nl> + } <nl>  <nl> card -> cmdrsp_buf = skb ; <nl> 
static int do_loopback ( struct path * path , const char * old_name , <nl>  <nl> if ( IS_ERR ( mnt )) { <nl> err = PTR_ERR ( mnt ); <nl> - goto out ; <nl> + goto out2 ; <nl> } <nl>  <nl> err = graft_tree ( mnt , path );
irqreturn_t uic_cascade ( int virq , void * data ) <nl> int subvirq ; <nl>  <nl> msr = mfdcr ( uic -> dcrbase + UIC_MSR ); <nl> + if (! msr ) /* spurious interrupt */ <nl> + return IRQ_HANDLED ; <nl> + <nl> src = 32 - ffs ( msr ); <nl>  <nl> subvirq = irq_linear_revmap ( uic -> irqhost , src );
static void ixgbe_configure_dcb ( struct ixgbe_adapter * adapter ) <nl> if ( hw -> mac . type == ixgbe_mac_82598EB ) <nl> netif_set_gso_max_size ( adapter -> netdev , 32768 ); <nl>  <nl> - ixgbe_dcb_check_config (& adapter -> dcb_cfg ); <nl> ixgbe_dcb_calculate_tc_credits (& adapter -> dcb_cfg , DCB_TX_CONFIG ); <nl> ixgbe_dcb_calculate_tc_credits (& adapter -> dcb_cfg , DCB_RX_CONFIG ); <nl> 
xfsbufd ( <nl>  <nl> current -> flags |= PF_MEMALLOC ; <nl>  <nl> + set_freezable (); <nl> + <nl> do { <nl> if ( unlikely ( freezing ( current ))) { <nl> set_bit ( XBT_FORCE_SLEEP , & target -> bt_flags );
static void usb_alphatrack_disconnect ( struct usb_interface * intf ) <nl> mutex_unlock (& dev -> mtx ); <nl> usb_alphatrack_delete ( dev ); <nl> } else { <nl> + atomic_set (& dev -> writes_pending , 0 ); <nl> dev -> intf = NULL ; <nl> mutex_unlock (& dev -> mtx ); <nl> } <nl>  <nl> - atomic_set (& dev -> writes_pending , 0 ); <nl> mutex_unlock (& disconnect_mutex ); <nl>  <nl> dev_info (& intf -> dev , " Alphatrack Surface #% d now disconnected \ n ",
int trace_vbprintk ( unsigned long ip , const char * fmt , va_list args ) <nl> entry -> fmt = fmt ; <nl>  <nl> memcpy ( entry -> buf , trace_buf , sizeof ( u32 ) * len ); <nl> - if (! filter_check_discard ( call , entry , buffer , event )) <nl> + if (! filter_check_discard ( call , entry , buffer , event )) { <nl> ring_buffer_unlock_commit ( buffer , event ); <nl> + ftrace_trace_stack ( buffer , flags , 6 , pc ); <nl> + } <nl>  <nl> out_unlock : <nl> arch_spin_unlock (& trace_buf_lock ); <nl> int trace_array_vprintk ( struct trace_array * tr , <nl>  <nl> memcpy (& entry -> buf , trace_buf , len ); <nl> entry -> buf [ len ] = '\ 0 '; <nl> - if (! filter_check_discard ( call , entry , buffer , event )) <nl> + if (! filter_check_discard ( call , entry , buffer , event )) { <nl> ring_buffer_unlock_commit ( buffer , event ); <nl> + ftrace_trace_stack ( buffer , irq_flags , 6 , pc ); <nl> + } <nl>  <nl> out_unlock : <nl> arch_spin_unlock (& trace_buf_lock );
static noinline int cow_file_range ( struct inode * inode , <nl> if ( IS_ERR ( trans )) { <nl> extent_clear_unlock_delalloc ( inode , <nl> & BTRFS_I ( inode )-> io_tree , <nl> - start , end , NULL , <nl> + start , end , locked_page , <nl> EXTENT_CLEAR_UNLOCK_PAGE | <nl> EXTENT_CLEAR_UNLOCK | <nl> EXTENT_CLEAR_DELALLOC | <nl> static noinline int cow_file_range ( struct inode * inode , <nl> out_unlock : <nl> extent_clear_unlock_delalloc ( inode , <nl> & BTRFS_I ( inode )-> io_tree , <nl> - start , end , NULL , <nl> + start , end , locked_page , <nl> EXTENT_CLEAR_UNLOCK_PAGE | <nl> EXTENT_CLEAR_UNLOCK | <nl> EXTENT_CLEAR_DELALLOC |
static int fl_dump ( struct net * net , struct tcf_proto * tp , void * fh , <nl> if ( fl_dump_key_vlan ( skb , & key -> vlan , & mask -> vlan )) <nl> goto nla_put_failure ; <nl>  <nl> + if ( mask -> vlan . vlan_tpid && <nl> + nla_put_be16 ( skb , TCA_FLOWER_KEY_VLAN_ETH_TYPE , key -> basic . n_proto )) <nl> + goto nla_put_failure ; <nl> + <nl> if (( key -> basic . n_proto == htons ( ETH_P_IP ) || <nl> key -> basic . n_proto == htons ( ETH_P_IPV6 )) && <nl> ( fl_dump_key_val ( skb , & key -> basic . ip_proto , TCA_FLOWER_KEY_IP_PROTO ,
static int i915_ppgtt_info ( struct seq_file * m , void * data ) <nl> task = get_pid_task ( file -> pid , PIDTYPE_PID ); <nl> if (! task ) { <nl> ret = - ESRCH ; <nl> - goto out_put ; <nl> + goto out_unlock ; <nl> } <nl> seq_printf ( m , "\ nproc : % s \ n ", task -> comm ); <nl> put_task_struct ( task ); <nl> idr_for_each (& file_priv -> context_idr , per_file_ctx , <nl> ( void *)( unsigned long ) m ); <nl> } <nl> + out_unlock : <nl> mutex_unlock (& dev -> filelist_mutex ); <nl>  <nl> - out_put : <nl> intel_runtime_pm_put ( dev_priv ); <nl> mutex_unlock (& dev -> struct_mutex ); <nl> 
static int cpufreq_governor_dbs ( struct cpufreq_policy * policy , <nl> if ( latency == 0 ) <nl> latency = 1 ; <nl>  <nl> - def_sampling_rate = latency * <nl> + def_sampling_rate = 10 * latency * <nl> DEF_SAMPLING_RATE_LATENCY_MULTIPLIER ; <nl>  <nl> if ( def_sampling_rate < MIN_STAT_SAMPLING_RATE )
static u8 get_umr_flags ( int acc ) <nl> ( acc & IB_ACCESS_REMOTE_WRITE ? MLX5_PERM_REMOTE_WRITE : 0 ) | <nl> ( acc & IB_ACCESS_REMOTE_READ ? MLX5_PERM_REMOTE_READ : 0 ) | <nl> ( acc & IB_ACCESS_LOCAL_WRITE ? MLX5_PERM_LOCAL_WRITE : 0 ) | <nl> - MLX5_PERM_LOCAL_READ | MLX5_PERM_UMR_EN | MLX5_ACCESS_MODE_MTT ; <nl> + MLX5_PERM_LOCAL_READ | MLX5_PERM_UMR_EN ; <nl> } <nl>  <nl> static void set_mkey_segment ( struct mlx5_mkey_seg * seg , struct ib_send_wr * wr , <nl> static void set_mkey_segment ( struct mlx5_mkey_seg * seg , struct ib_send_wr * wr , <nl> return ; <nl> } <nl>  <nl> - seg -> flags = get_umr_flags ( wr -> wr . fast_reg . access_flags ); <nl> + seg -> flags = get_umr_flags ( wr -> wr . fast_reg . access_flags ) | <nl> + MLX5_ACCESS_MODE_MTT ; <nl> * writ = seg -> flags & ( MLX5_PERM_LOCAL_WRITE | IB_ACCESS_REMOTE_WRITE ); <nl> seg -> qpn_mkey7_0 = cpu_to_be32 (( wr -> wr . fast_reg . rkey & 0xff ) | 0xffffff00 ); <nl> seg -> flags_pd = cpu_to_be32 ( MLX5_MKEY_REMOTE_INVAL );
void rtsx_add_cmd ( struct rtsx_chip * chip , <nl> void rtsx_send_cmd_no_wait ( struct rtsx_chip * chip ); <nl> int rtsx_send_cmd ( struct rtsx_chip * chip , u8 card , int timeout ); <nl>  <nl> - extern inline u8 * rtsx_get_cmd_data ( struct rtsx_chip * chip ) <nl> + static inline u8 * rtsx_get_cmd_data ( struct rtsx_chip * chip ) <nl> { <nl> # ifdef CMD_USING_SG <nl> return ( u8 *)( chip -> host_sg_tbl_ptr );
struct greybus_device * greybus_new_module ( struct device * parent , <nl> size -= sizeof ( manifest -> header ); <nl> data += sizeof ( manifest -> header ); <nl> while ( size > 0 ) { <nl> + if ( size < sizeof ( desc -> header )) { <nl> + dev_err ( parent , " remaining size % d too small \ n ", size ); <nl> + goto error ; <nl> + } <nl> desc = ( struct greybus_descriptor *) data ; <nl> desc_size = le16_to_cpu ( desc -> header . size ); <nl> + if ( size < desc_size ) { <nl> + dev_err ( parent , " descriptor size % d too big \ n ", <nl> + desc_size ); <nl> + goto error ; <nl> + } <nl>  <nl> switch ( le16_to_cpu ( desc -> header . type )) { <nl> case GREYBUS_TYPE_FUNCTION :
void rcu_check_callbacks ( int cpu , int user ) <nl> static void rcu_init_percpu_data ( int cpu , struct rcu_ctrlblk * rcp , <nl> struct rcu_data * rdp ) <nl> { <nl> - long flags ; <nl> + unsigned long flags ; <nl>  <nl> spin_lock_irqsave (& rcp -> lock , flags ); <nl> memset ( rdp , 0 , sizeof (* rdp ));
static long madvise_willneed ( struct vm_area_struct * vma , <nl> { <nl> struct file * file = vma -> vm_file ; <nl>  <nl> + * prev = vma ; <nl> # ifdef CONFIG_SWAP <nl> if (! file ) { <nl> - * prev = vma ; <nl> force_swapin_readahead ( vma , start , end ); <nl> return 0 ; <nl> } <nl>  <nl> if ( shmem_mapping ( file -> f_mapping )) { <nl> - * prev = vma ; <nl> force_shm_swapin_readahead ( vma , start , end , <nl> file -> f_mapping ); <nl> return 0 ; <nl> static long madvise_willneed ( struct vm_area_struct * vma , <nl> return 0 ; <nl> } <nl>  <nl> - * prev = vma ; <nl> start = (( start - vma -> vm_start ) >> PAGE_SHIFT ) + vma -> vm_pgoff ; <nl> if ( end > vma -> vm_end ) <nl> end = vma -> vm_end ;
int etnaviv_gpu_submit ( struct etnaviv_gpu * gpu , <nl> goto out_pm_put ; <nl> } <nl>  <nl> + mutex_lock (& gpu -> lock ); <nl> + <nl> fence = etnaviv_gpu_fence_alloc ( gpu ); <nl> if (! fence ) { <nl> event_free ( gpu , event ); <nl> int etnaviv_gpu_submit ( struct etnaviv_gpu * gpu , <nl> goto out_pm_put ; <nl> } <nl>  <nl> - mutex_lock (& gpu -> lock ); <nl> - <nl> gpu -> event [ event ]. fence = fence ; <nl> submit -> fence = fence -> seqno ; <nl> gpu -> active_fence = submit -> fence ;
static void qoriq_cpufreq_ready ( struct cpufreq_policy * policy ) <nl> cpud -> cdev = of_cpufreq_cooling_register ( np , <nl> policy -> related_cpus ); <nl>  <nl> - if ( IS_ERR ( cpud -> cdev )) { <nl> - pr_err (" Failed to register cooling device cpu % d : % ld \ n ", <nl> + if ( IS_ERR ( cpud -> cdev ) && PTR_ERR ( cpud -> cdev ) != - ENOSYS ) { <nl> + pr_err (" cpu % d is not running as cooling device : % ld \ n ", <nl> policy -> cpu , PTR_ERR ( cpud -> cdev )); <nl>  <nl> cpud -> cdev = NULL ;
void Dot11d_Init ( struct ieee80211_device * ieee ) <nl>  <nl> pDot11dInfo -> State = DOT11D_STATE_NONE ; <nl> pDot11dInfo -> CountryIeLen = 0 ; <nl> - memset ( pDot11dInfo -> channel_map , 0 , MAX_CHANNEL_NUMBER + 1 ); <nl> + memset ( pDot11dInfo -> channel_map , 0 , MAX_CHANNEL_NUMBER + 1 ); <nl> memset ( pDot11dInfo -> MaxTxPwrDbmList , 0xFF , MAX_CHANNEL_NUMBER + 1 ); <nl> RESET_CIE_WATCHDOG ( ieee ); <nl> 
void spuctx_switch_state ( struct spu_context * ctx , <nl> node = spu -> node ; <nl> if ( old_state == SPU_UTIL_USER ) <nl> atomic_dec (& cbe_spu_info [ node ]. busy_spus ); <nl> - if ( new_state == SPU_UTIL_USER ); <nl> + if ( new_state == SPU_UTIL_USER ) <nl> atomic_inc (& cbe_spu_info [ node ]. busy_spus ); <nl> } <nl> }
fill_write_buffer ( struct sysfs_buffer * buffer , const char __user * buf , size_t <nl> return - ENOMEM ; <nl>  <nl> if ( count >= PAGE_SIZE ) <nl> - count = PAGE_SIZE ; <nl> + count = PAGE_SIZE - 1 ; <nl> error = copy_from_user ( buffer -> page , buf , count ); <nl> buffer -> needs_read_fill = 1 ; <nl> return error ? - EFAULT : count ;
static int ipw2100_get_firmware ( struct ipw2100_priv * priv , <nl> return 0 ; <nl> } <nl>  <nl> + MODULE_FIRMWARE ( IPW2100_FW_NAME ("- i ")); <nl> +# ifdef CONFIG_IPW2100_MONITOR <nl> + MODULE_FIRMWARE ( IPW2100_FW_NAME ("- p ")); <nl> +# endif <nl> + MODULE_FIRMWARE ( IPW2100_FW_NAME ("")); <nl> + <nl> static void ipw2100_release_firmware ( struct ipw2100_priv * priv , <nl> struct ipw2100_fw * fw ) <nl> {
set_pte_phys ( unsigned long vaddr , unsigned long phys , pgprot_t prot ) <nl> new_pte = pfn_pte ( phys >> PAGE_SHIFT , prot ); <nl>  <nl> pte = pte_offset_kernel ( pmd , vaddr ); <nl> - if (! pte_none (* pte ) && <nl> + if (! pte_none (* pte ) && pte_val ( new_pte ) && <nl> pte_val (* pte ) != ( pte_val ( new_pte ) & __supported_pte_mask )) <nl> pte_ERROR (* pte ); <nl> set_pte ( pte , new_pte );
static int netlink_dump ( struct sock * sk ) <nl> struct netlink_callback * cb ; <nl> struct sk_buff * skb = NULL ; <nl> struct nlmsghdr * nlh ; <nl> + struct module * module ; <nl> int len , err = - ENOBUFS ; <nl> int alloc_min_size ; <nl> int alloc_size ; <nl> static int netlink_dump ( struct sock * sk ) <nl> cb -> done ( cb ); <nl>  <nl> nlk -> cb_running = false ; <nl> + module = cb -> module ; <nl> + skb = cb -> skb ; <nl> mutex_unlock ( nlk -> cb_mutex ); <nl> - module_put ( cb -> module ); <nl> - consume_skb ( cb -> skb ); <nl> + module_put ( module ); <nl> + consume_skb ( skb ); <nl> return 0 ; <nl>  <nl> errout_skb :
void save_stack_trace ( struct stack_trace * trace ) <nl>  <nl> /* Bogus frame pointer ? */ <nl> if ( fp < ( thread_base + sizeof ( struct thread_info )) || <nl> - fp >= ( thread_base + THREAD_SIZE )) <nl> + fp > ( thread_base + THREAD_SIZE - sizeof ( struct sparc_stackf ))) <nl> break ; <nl>  <nl> sf = ( struct sparc_stackf *) fp ; <nl> regs = ( struct pt_regs *) ( sf + 1 ); <nl>  <nl> - if (( regs -> magic & ~ 0x1ff ) == PT_REGS_MAGIC ) { <nl> + if ((( unsigned long ) regs <= <nl> + ( thread_base + THREAD_SIZE - sizeof (* regs ))) && <nl> + ( regs -> magic & ~ 0x1ff ) == PT_REGS_MAGIC ) { <nl> if (!( regs -> tstate & TSTATE_PRIV )) <nl> break ; <nl> pc = regs -> tpc ;
mwifiex_drv_get_driver_version ( struct mwifiex_adapter * adapter , char * version , <nl> int max_len ) <nl> { <nl> union { <nl> - u32 l ; <nl> + __le32 l ; <nl> u8 c [ 4 ]; <nl> } ver ; <nl> char fw_ver [ 32 ]; <nl>  <nl> - ver . l = adapter -> fw_release_number ; <nl> + ver . l = cpu_to_le32 ( adapter -> fw_release_number ); <nl> sprintf ( fw_ver , "% u .% u .% u . p % u ", ver . c [ 2 ], ver . c [ 1 ], ver . c [ 0 ], ver . c [ 3 ]); <nl>  <nl> snprintf ( version , max_len , driver_version , fw_ver );
int crypto_dh_decode_key ( const char * buf , unsigned int len , struct dh * params ) <nl> params -> p = ( void *)( ptr + params -> key_size ); <nl> params -> g = ( void *)( ptr + params -> key_size + params -> p_size ); <nl>  <nl> + /* <nl> + * Don ' t permit ' p ' to be 0 . It ' s not a prime number , and it ' s subject <nl> + * to corner cases such as ' mod 0 ' being undefined or <nl> + * crypto_kpp_maxsize () returning 0 . <nl> + */ <nl> + if ( memchr_inv ( params -> p , 0 , params -> p_size ) == NULL ) <nl> + return - EINVAL ; <nl> + <nl> return 0 ; <nl> } <nl> EXPORT_SYMBOL_GPL ( crypto_dh_decode_key );
static int copy_msghdr_from_user ( struct msghdr * kmsg , <nl> { <nl> if ( copy_from_user ( kmsg , umsg , sizeof ( struct msghdr ))) <nl> return - EFAULT ; <nl> + <nl> + if ( kmsg -> msg_namelen < 0 ) <nl> + return - EINVAL ; <nl> + <nl> if ( kmsg -> msg_namelen > sizeof ( struct sockaddr_storage )) <nl> kmsg -> msg_namelen = sizeof ( struct sockaddr_storage ); <nl> return 0 ;
void calculate_steal_time ( void ) <nl>  <nl> if (! cpu_has_feature ( CPU_FTR_PURR )) <nl> return ; <nl> - pme = & per_cpu ( cpu_purr_data , smp_processor_id ()); <nl> + pme = & __get_cpu_var ( cpu_purr_data ); <nl> if (! pme -> initialized ) <nl> return ; /* this can happen in early boot */ <nl> tb = mftb (); <nl> static void snapshot_purr ( void ) <nl> if (! cpu_has_feature ( CPU_FTR_PURR )) <nl> return ; <nl> local_irq_save ( flags ); <nl> - pme = & per_cpu ( cpu_purr_data , smp_processor_id ()); <nl> + pme = & __get_cpu_var ( cpu_purr_data ); <nl> pme -> tb = mftb (); <nl> pme -> purr = mfspr ( SPRN_PURR ); <nl> pme -> initialized = 1 ;
xfs_rmap_convert_shared ( <nl> */ <nl> error = xfs_rmap_lookup_le_range ( cur , bno , owner , offset , flags , <nl> & PREV , & i ); <nl> + if ( error ) <nl> + goto done ; <nl> XFS_WANT_CORRUPTED_GOTO ( mp , i == 1 , done ); <nl>  <nl> ASSERT ( PREV . rm_offset <= offset );
static void kvm_write_wall_clock ( struct kvm * kvm , gpa_t wall_clock ) <nl> */ <nl> getboottime (& boot ); <nl>  <nl> + if ( kvm -> arch . kvmclock_offset ) { <nl> + struct timespec ts = ns_to_timespec ( kvm -> arch . kvmclock_offset ); <nl> + boot = timespec_sub ( boot , ts ); <nl> + } <nl> wc . sec = boot . tv_sec ; <nl> wc . nsec = boot . tv_nsec ; <nl> wc . version = version ;
static void nhmex_uncore_msr_enable_event ( struct intel_uncore_box * box , struct p <nl> { <nl> struct hw_perf_event * hwc = & event -> hw ; <nl>  <nl> - if ( hwc -> idx >= UNCORE_PMC_IDX_FIXED ) <nl> + if ( hwc -> idx == UNCORE_PMC_IDX_FIXED ) <nl> wrmsrl ( hwc -> config_base , NHMEX_PMON_CTL_EN_BIT0 ); <nl> else if ( box -> pmu -> type -> event_mask & NHMEX_PMON_CTL_EN_BIT0 ) <nl> wrmsrl ( hwc -> config_base , hwc -> config | NHMEX_PMON_CTL_EN_BIT22 );
int ip6_mroute_setsockopt ( struct sock * sk , int optname , char __user * optval , uns <nl> case MRT6_ASSERT : <nl> { <nl> int v ; <nl> + <nl> + if ( optlen != sizeof ( v )) <nl> + return - EINVAL ; <nl> if ( get_user ( v , ( int __user *) optval )) <nl> return - EFAULT ; <nl> mrt -> mroute_do_assert = v ; <nl> int ip6_mroute_setsockopt ( struct sock * sk , int optname , char __user * optval , uns <nl> case MRT6_PIM : <nl> { <nl> int v ; <nl> + <nl> + if ( optlen != sizeof ( v )) <nl> + return - EINVAL ; <nl> if ( get_user ( v , ( int __user *) optval )) <nl> return - EFAULT ; <nl> v = !! v ;
static int ni_660x_request_mite_channel ( struct comedi_device * dev , <nl> BUG_ON ( counter -> mite_chan ); <nl> mite_chan = mite_request_channel ( devpriv -> mite , <nl> mite_ring ( devpriv , counter )); <nl> - if ( mite_chan == NULL ) { <nl> + if (! mite_chan ) { <nl> spin_unlock_irqrestore (& devpriv -> mite_channel_lock , flags ); <nl> dev_err ( dev -> class_dev , <nl> " failed to reserve mite dma channel for counter \ n "); <nl> static int ni_660x_alloc_mite_rings ( struct comedi_device * dev ) <nl> for ( j = 0 ; j < counters_per_chip ; ++ j ) { <nl> devpriv -> mite_rings [ i ][ j ] = <nl> mite_alloc_ring ( devpriv -> mite ); <nl> - if ( devpriv -> mite_rings [ i ][ j ] == NULL ) <nl> + if (! devpriv -> mite_rings [ i ][ j ]) <nl> return - ENOMEM ; <nl> } <nl> } <nl> static int ni_660x_auto_attach ( struct comedi_device * dev , <nl> ni_gpct_variant_660x , <nl> ni_660x_num_counters <nl> ( dev )); <nl> - if ( devpriv -> counter_dev == NULL ) <nl> + if (! devpriv -> counter_dev ) <nl> return - ENOMEM ; <nl> for ( i = 0 ; i < NI_660X_MAX_NUM_COUNTERS ; ++ i ) { <nl> s = & dev -> subdevices [ NI_660X_GPCT_SUBDEV ( i )];
ahc_send_async ( struct ahc_softc * ahc , char channel , <nl> spi_period ( starget ) = tinfo -> curr . period ; <nl> spi_width ( starget ) = tinfo -> curr . width ; <nl> spi_offset ( starget ) = tinfo -> curr . offset ; <nl> - spi_dt ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_DT_REQ ; <nl> - spi_qas ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_QAS_REQ ; <nl> - spi_iu ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_IU_REQ ; <nl> + spi_dt ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_DT_REQ ? 1 : 0 ; <nl> + spi_qas ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_QAS_REQ ? 1 : 0 ; <nl> + spi_iu ( starget ) = tinfo -> curr . ppr_options & MSG_EXT_PPR_IU_REQ ? 1 : 0 ; <nl> spi_display_xfer_agreement ( starget ); <nl> break ; <nl> } <nl> static void ahc_linux_set_dt ( struct scsi_target * starget , int dt ) <nl> if ( dt ) { <nl> period = 9 ; /* 12 . 5ns is the only period valid for DT */ <nl> ppr_options |= MSG_EXT_PPR_DT_REQ ; <nl> - } else if ( period == 9 ) <nl> + } else if ( period == 9 ) { <nl> period = 10 ; /* if resetting DT , period must be >= 25ns */ <nl> + ppr_options &= ~ MSG_EXT_PPR_DT_REQ ; <nl> + } <nl>  <nl> ahc_compile_devinfo (& devinfo , shost -> this_id , starget -> id , 0 , <nl> starget -> channel + ' A ', ROLE_INITIATOR );
xfs_rtfree_range ( <nl> */ <nl> error = xfs_rtfind_forw ( mp , tp , end , mp -> m_sb . sb_rextents - 1 , <nl> & postblock ); <nl> + if ( error ) <nl> + return error ; <nl> /* <nl> * If there are blocks not being freed at the front of the <nl> * old extent , add summary data for them to be allocated .
static int spc_emulate_inquiry ( struct se_cmd * cmd ) <nl> unsigned char buf [ SE_INQUIRY_BUF ]; <nl> int p , ret ; <nl>  <nl> + memset ( buf , 0 , SE_INQUIRY_BUF ); <nl> + <nl> if ( dev == tpg -> tpg_virt_lun0 . lun_se_dev ) <nl> buf [ 0 ] = 0x3f ; /* Not connected */ <nl> else
static int fs_enet_rx_napi ( struct napi_struct * napi , int budget ) <nl> u16 pkt_len , sc ; <nl> int curidx ; <nl>  <nl> + if ( budget <= 0 ) <nl> + return received ; <nl> + <nl> /* <nl> * First , grab all of the stats for the incoming packet . <nl> * These get messed up if we get called due to a busy condition .
asmlinkage void math_emulate ( long arg ) <nl> entry_sel_off . offset = FPU_ORIG_EIP ; <nl> entry_sel_off . selector = FPU_CS ; <nl> entry_sel_off . opcode = ( byte1 << 8 ) | FPU_modrm ; <nl> + entry_sel_off . empty = 0 ; <nl>  <nl> FPU_rm = FPU_modrm & 7 ; <nl> 
static inline void get_page ( struct page * page ) <nl> page_ref_inc ( page ); <nl> } <nl>  <nl> + static inline __must_check bool try_get_page ( struct page * page ) <nl> +{ <nl> + page = compound_head ( page ); <nl> + if ( WARN_ON_ONCE ( page_ref_count ( page ) <= 0 )) <nl> + return false ; <nl> + page_ref_inc ( page ); <nl> + return true ; <nl> +} <nl> + <nl> static inline void put_page ( struct page * page ) <nl> { <nl> page = compound_head ( page );
nfp_flower_spawn_vnic_reprs ( struct nfp_app * app , <nl> repr_priv = kzalloc ( sizeof (* repr_priv ), GFP_KERNEL ); <nl> if (! repr_priv ) { <nl> err = - ENOMEM ; <nl> + nfp_repr_free ( repr ); <nl> goto err_reprs_clean ; <nl> } <nl>  <nl> nfp_flower_spawn_vnic_reprs ( struct nfp_app * app , <nl> port = nfp_port_alloc ( app , port_type , repr ); <nl> if ( IS_ERR ( port )) { <nl> err = PTR_ERR ( port ); <nl> + kfree ( repr_priv ); <nl> nfp_repr_free ( repr ); <nl> goto err_reprs_clean ; <nl> } <nl> nfp_flower_spawn_vnic_reprs ( struct nfp_app * app , <nl> err = nfp_repr_init ( app , repr , <nl> port_id , port , priv -> nn -> dp . netdev ); <nl> if ( err ) { <nl> + kfree ( repr_priv ); <nl> nfp_port_free ( port ); <nl> nfp_repr_free ( repr ); <nl> goto err_reprs_clean ;
int mpi_powm ( MPI res , MPI base , MPI exp , MPI mod ) <nl> if (! esize ) { <nl> /* Exponent is zero , result is 1 mod MOD , i . e ., 1 or 0 <nl> * depending on if MOD equals 1 . */ <nl> - rp [ 0 ] = 1 ; <nl> res -> nlimbs = ( msize == 1 && mod -> d [ 0 ] == 1 ) ? 0 : 1 ; <nl> + if ( res -> nlimbs ) { <nl> + if ( mpi_resize ( res , 1 ) < 0 ) <nl> + goto enomem ; <nl> + rp = res -> d ; <nl> + rp [ 0 ] = 1 ; <nl> + } <nl> res -> sign = 0 ; <nl> goto leave ; <nl> }
enum xgbe_conn_type { <nl> XGBE_CONN_TYPE_NONE = 0 , <nl> XGBE_CONN_TYPE_SFP , <nl> XGBE_CONN_TYPE_MDIO , <nl> + XGBE_CONN_TYPE_RSVD1 , <nl> XGBE_CONN_TYPE_BACKPLANE , <nl> XGBE_CONN_TYPE_MAX , <nl> }; <nl> static int xgbe_phy_init ( struct xgbe_prv_data * pdata ) <nl> if ( xgbe_phy_conn_type_mismatch ( pdata )) { <nl> dev_err ( pdata -> dev , " phy mode / connection mismatch (%# x /%# x )\ n ", <nl> phy_data -> port_mode , phy_data -> conn_type ); <nl> + return - EINVAL ; <nl> } <nl>  <nl> /* Validate the mode requested */
static void binder_send_failed_reply ( struct binder_transaction * t , <nl> if ( target_thread -> return_error == BR_OK ) { <nl> binder_debug ( BINDER_DEBUG_FAILED_TRANSACTION , <nl> " send failed reply for transaction % d to % d :% d \ n ", <nl> - t -> debug_id , target_thread -> proc -> pid , <nl> + t -> debug_id , <nl> + target_thread -> proc -> pid , <nl> target_thread -> pid ); <nl>  <nl> binder_pop_transaction ( target_thread , t );
static int safexcel_probe ( struct platform_device * pdev ) <nl> snprintf ( irq_name , 6 , " ring % d ", i ); <nl> irq = safexcel_request_ring_irq ( pdev , irq_name , safexcel_irq_ring , <nl> ring_irq ); <nl> - <nl> - if ( irq < 0 ) <nl> + if ( irq < 0 ) { <nl> + ret = irq ; <nl> goto err_clk ; <nl> + } <nl>  <nl> priv -> ring [ i ]. work_data . priv = priv ; <nl> priv -> ring [ i ]. work_data . ring = i ;
static int soc_compr_copy ( struct snd_compr_stream * cstream , <nl> struct snd_soc_platform * platform = rtd -> platform ; <nl> struct snd_soc_component * component ; <nl> struct snd_soc_rtdcom_list * rtdcom ; <nl> - int ret = 0 , __ret ; <nl> + int ret = 0 ; <nl>  <nl> mutex_lock_nested (& rtd -> pcm_mutex , rtd -> pcm_subclass ); <nl>  <nl> static int soc_compr_copy ( struct snd_compr_stream * cstream , <nl> ! component -> driver -> compr_ops -> copy ) <nl> continue ; <nl>  <nl> - __ret = component -> driver -> compr_ops -> copy ( cstream , buf , count ); <nl> - if ( __ret < 0 ) <nl> - ret = __ret ; <nl> + ret = component -> driver -> compr_ops -> copy ( cstream , buf , count ); <nl> + break ; <nl> } <nl> + <nl> err : <nl> mutex_unlock (& rtd -> pcm_mutex ); <nl> return ret ;
int ieee80211_tx_frame ( struct ieee80211_device * ieee , <nl> /* When we allocate the TXB we allocate enough space for the reserve <nl> * and full fragment bytes ( bytes_per_frag doesn ' t include prefix , <nl> * postfix , header , FCS , etc .) */ <nl> - txb = ieee80211_alloc_txb ( 1 , len , GFP_ATOMIC ); <nl> + txb = ieee80211_alloc_txb ( 1 , len , ieee -> tx_headroom , GFP_ATOMIC ); <nl> if ( unlikely (! txb )) { <nl> printk ( KERN_WARNING "% s : Could not allocate TXB \ n ", <nl> ieee -> dev -> name );
bool hci_inquiry_cache_update ( struct hci_dev * hdev , struct inquiry_data * data , <nl>  <nl> BT_DBG (" cache % p , % pMR ", cache , & data -> bdaddr ); <nl>  <nl> + hci_remove_remote_oob_data ( hdev , & data -> bdaddr ); <nl> + <nl> if ( ssp ) <nl> * ssp = data -> ssp_mode ; <nl> 
int blk_mq_alloc_tag_set ( struct blk_mq_tag_set * set ) <nl> return - EINVAL ; <nl>  <nl>  <nl> - set -> tags = kmalloc_node ( set -> nr_hw_queues * sizeof ( struct blk_mq_tags ), <nl> + set -> tags = kmalloc_node ( set -> nr_hw_queues * <nl> + sizeof ( struct blk_mq_tags *), <nl> GFP_KERNEL , set -> numa_node ); <nl> if (! set -> tags ) <nl> goto out ;
static long ppc_set_hwdebug ( struct task_struct * child , <nl>  <nl> brk . address = bp_info -> addr & ~ 7UL ; <nl> brk . type = HW_BRK_TYPE_TRANSLATE ; <nl> + brk . len = 8 ; <nl> if ( bp_info -> trigger_type & PPC_BREAKPOINT_TRIGGER_READ ) <nl> brk . type |= HW_BRK_TYPE_READ ; <nl> if ( bp_info -> trigger_type & PPC_BREAKPOINT_TRIGGER_WRITE )
static int coda_try_fmt ( struct coda_ctx * ctx , struct coda_codec * codec , <nl> BUG (); <nl> } <nl>  <nl> + f -> fmt . pix . priv = 0 ; <nl> + <nl> return 0 ; <nl> } <nl> 
EXPORT_SYMBOL ( sock_kmalloc ); <nl> */ <nl> void sock_kfree_s ( struct sock * sk , void * mem , int size ) <nl> { <nl> + if ( WARN_ON_ONCE (! mem )) <nl> + return ; <nl> kfree ( mem ); <nl> atomic_sub ( size , & sk -> sk_omem_alloc ); <nl> }
static void etb_update_buffer ( struct coresight_device * csdev , <nl>  <nl> capacity = drvdata -> buffer_depth * ETB_FRAME_SIZE_WORDS ; <nl>  <nl> - CS_UNLOCK ( drvdata -> base ); <nl> etb_disable_hw ( drvdata ); <nl> + CS_UNLOCK ( drvdata -> base ); <nl>  <nl> /* unit is in words , not bytes */ <nl> read_ptr = readl_relaxed ( drvdata -> base + ETB_RAM_READ_POINTER );
static int wtp_raw_event ( struct hid_device * hdev , u8 * data , int size ) <nl>  <nl> switch ( data [ 0 ]) { <nl> case 0x02 : <nl> + if ( size < 2 ) { <nl> + hid_err ( hdev , " Received HID report of bad size (% d )", <nl> + size ); <nl> + return 1 ; <nl> + } <nl> if ( hidpp -> quirks & HIDPP_QUIRK_WTP_PHYSICAL_BUTTONS ) { <nl> input_event ( wd -> input , EV_KEY , BTN_LEFT , <nl> !!( data [ 1 ] & 0x01 )); <nl> static int wtp_raw_event ( struct hid_device * hdev , u8 * data , int size ) <nl> return wtp_mouse_raw_xy_event ( hidpp , & data [ 7 ]); <nl> } <nl> case REPORT_ID_HIDPP_LONG : <nl> + /* size is already checked in hidpp_raw_event . */ <nl> if (( report -> fap . feature_index != wd -> mt_feature_index ) || <nl> ( report -> fap . funcindex_clientid != EVENT_TOUCHPAD_RAW_XY )) <nl> return 1 ;
static int create_in_format_blob ( struct drm_device * dev , struct drm_plane * plane <nl> plane -> format_types [ j ], <nl> plane -> modifiers [ i ])) { <nl>  <nl> - mod -> formats |= 1 << j ; <nl> + mod -> formats |= 1ULL << j ; <nl> } <nl> } <nl> 
static int gbcodec_trigger ( struct snd_pcm_substream * substream , int cmd , <nl> dev_err ( dai -> dev , "% d : Error during % s stream \ n ", ret , <nl> start ? " Start " : " Stop "); <nl>  <nl> + /* in case device removed , return 0 for stop trigger */ <nl> + if ( stop && ( ret == - ENODEV )) <nl> + ret = 0 ; <nl> + <nl> func_exit : <nl> mutex_unlock (& gb -> lock ); <nl> return ret ;
static int picolcd_raw_event ( struct hid_device * hdev , <nl> if (! data ) <nl> return 1 ; <nl>  <nl> + if ( size > 64 ) { <nl> + hid_warn ( hdev , " invalid size value (% d ) for picolcd raw event \ n ", <nl> + size ); <nl> + return 0 ; <nl> + } <nl> + <nl> if ( report -> id == REPORT_KEY_STATE ) { <nl> if ( data -> input_keys ) <nl> ret = picolcd_raw_keypad ( data , report , raw_data + 1 , size - 1 );
static void tm6000_config_tuner ( struct tm6000_core * dev ) <nl>  <nl> ctl . mts = 1 ; <nl> ctl . read_not_reliable = 1 ; <nl> + ctl . msleep = 10 ; <nl>  <nl> xc2028_cfg . tuner = TUNER_XC2028 ; <nl> xc2028_cfg . priv = & ctl ;
static struct tty_ldisc * tty_ldisc_try_get ( int disc ) <nl> } <nl> } <nl> spin_unlock_irqrestore (& tty_ldisc_lock , flags ); <nl> - if ( err ) <nl> + if ( err ) { <nl> + kfree ( ld ); <nl> return ERR_PTR ( err ); <nl> + } <nl> return ld ; <nl> } <nl>  <nl> const struct file_operations tty_ldiscs_proc_fops = { <nl> * @ ld : line discipline <nl> * <nl> * Install an instance of a line discipline into a tty structure . The <nl> - * ldisc must have a reference count above zero to ensure it remains / <nl> + * ldisc must have a reference count above zero to ensure it remains . <nl> * The tty instance refcount starts at zero . <nl> * <nl> * Locking :
int drm_atomic_helper_setup_commit ( struct drm_atomic_state * state , <nl> ! try_wait_for_completion (& old_plane_state -> commit -> flip_done )) <nl> return - EBUSY ; <nl>  <nl> - commit = crtc_or_fake_commit ( state , old_plane_state -> crtc ); <nl> + commit = crtc_or_fake_commit ( state , new_plane_state -> crtc ?: old_plane_state -> crtc ); <nl> if (! commit ) <nl> return - ENOMEM ; <nl> 
static int parse_features ( struct dm_arg_set * as , struct flakey_c * fc , <nl> arg_name = dm_shift_arg ( as ); <nl> argc --; <nl>  <nl> + if (! arg_name ) { <nl> + ti -> error = " Insufficient feature arguments "; <nl> + return - EINVAL ; <nl> + } <nl> + <nl> /* <nl> * drop_writes <nl> */
static int dlm_purge_lockres ( struct dlm_ctxt * dlm , <nl> res -> lockname . name , master ); <nl>  <nl> if (! master ) { <nl> + /* drop spinlock ... retake below */ <nl> + spin_unlock (& dlm -> spinlock ); <nl> + <nl> spin_lock (& res -> spinlock ); <nl> /* This ensures that clear refmap is sent after the set */ <nl> __dlm_wait_on_lockres_flags ( res , DLM_LOCK_RES_SETREF_INPROG ); <nl> spin_unlock (& res -> spinlock ); <nl> - /* drop spinlock to do messaging , retake below */ <nl> - spin_unlock (& dlm -> spinlock ); <nl> + <nl> /* clear our bit from the master ' s refmap , ignore errors */ <nl> ret = dlm_drop_lockres_ref ( dlm , res ); <nl> if ( ret < 0 ) {
struct oz_pd * oz_pd_alloc ( const u8 * mac_addr ) <nl> /* <nl> * Context : softirq or process <nl> */ <nl> - void oz_pd_free ( struct work_struct * work ) <nl> + static void oz_pd_free ( struct work_struct * work ) <nl> { <nl> struct list_head * e ; <nl> struct oz_tx_frame * f ;
static void ene_remove ( struct pnp_dev * pnp_dev ) <nl> struct ene_device * dev = pnp_get_drvdata ( pnp_dev ); <nl> unsigned long flags ; <nl>  <nl> + rc_unregister_device ( dev -> rdev ); <nl> + del_timer_sync (& dev -> tx_sim_timer ); <nl> spin_lock_irqsave (& dev -> hw_lock , flags ); <nl> ene_rx_disable ( dev ); <nl> ene_rx_restore_hw_buffer ( dev ); <nl> static void ene_remove ( struct pnp_dev * pnp_dev ) <nl>  <nl> free_irq ( dev -> irq , dev ); <nl> release_region ( dev -> hw_io , ENE_IO_SIZE ); <nl> - rc_unregister_device ( dev -> rdev ); <nl> kfree ( dev ); <nl> } <nl> 
static void test_acipher_speed ( const char * algo , int enc , unsigned int secs , <nl> goto out_free_req ; <nl> } <nl>  <nl> - sg_init_table ( sg , TVMEMSIZE ); <nl> - <nl> k = * keysize + * b_size ; <nl> + sg_init_table ( sg , DIV_ROUND_UP ( k , PAGE_SIZE )); <nl> + <nl> if ( k > PAGE_SIZE ) { <nl> sg_set_buf ( sg , tvmem [ 0 ] + * keysize , <nl> PAGE_SIZE - * keysize );
static long do_get_mempolicy ( int * policy , nodemask_t * nmask , <nl> * policy |= ( pol -> flags & MPOL_MODE_FLAGS ); <nl> } <nl>  <nl> - if ( vma ) { <nl> - up_read (& current -> mm -> mmap_sem ); <nl> - vma = NULL ; <nl> - } <nl> - <nl> err = 0 ; <nl> if ( nmask ) { <nl> if ( mpol_store_user_nodemask ( pol )) {
static void zfcp_fc_adisc_handler ( unsigned long data ) <nl> struct zfcp_port * port = adisc -> els . port ; <nl> struct zfcp_ls_adisc_acc * ls_adisc = & adisc -> ls_adisc_acc ; <nl>  <nl> - if (! adisc -> els . status ) { <nl> + if ( adisc -> els . status ) { <nl> /* request rejected or timed out */ <nl> zfcp_erp_port_forced_reopen ( port , 0 , 63 , NULL ); <nl> goto out ;
int create_flush_cmd_control ( struct f2fs_sb_info * sbi ) <nl> init_waitqueue_head (& fcc -> flush_wait_queue ); <nl> init_llist_head (& fcc -> issue_list ); <nl> SM_I ( sbi )-> fcc_info = fcc ; <nl> + if (! test_opt ( sbi , FLUSH_MERGE )) <nl> + return err ; <nl> + <nl> init_thread : <nl> fcc -> f2fs_issue_flush = kthread_run ( issue_flush_thread , sbi , <nl> " f2fs_flush -% u :% u ", MAJOR ( dev ), MINOR ( dev )); <nl> int build_segment_manager ( struct f2fs_sb_info * sbi ) <nl>  <nl> INIT_LIST_HEAD (& sm_info -> sit_entry_set ); <nl>  <nl> - if ( test_opt ( sbi , FLUSH_MERGE ) && ! f2fs_readonly ( sbi -> sb )) { <nl> + if (! f2fs_readonly ( sbi -> sb )) { <nl> err = create_flush_cmd_control ( sbi ); <nl> if ( err ) <nl> return err ;
# define AT91_TWI_ACR_DATAL ( len ) (( len ) & 0xff ) <nl> # define AT91_TWI_ACR_DIR BIT ( 8 ) <nl>  <nl> +# define AT91_TWI_VER 0x00fc /* Version Register */ <nl> + <nl> struct at91_twi_pdata { <nl> unsigned clk_max_div ; <nl> unsigned clk_offset ; <nl> static int at91_twi_probe ( struct platform_device * pdev ) <nl> return rc ; <nl> } <nl>  <nl> - dev_info ( dev -> dev , " AT91 i2c bus driver .\ n "); <nl> + dev_info ( dev -> dev , " AT91 i2c bus driver ( hw version : %# x ).\ n ", <nl> + at91_twi_read ( dev , AT91_TWI_VER )); <nl> return 0 ; <nl> } <nl> 
static int macronix_quad_enable ( struct spi_nor * nor ) <nl> val = read_sr ( nor ); <nl> if ( val < 0 ) <nl> return val ; <nl> + if ( val & SR_QUAD_EN_MX ) <nl> + return 0 ; <nl> + <nl> write_enable ( nor ); <nl>  <nl> write_sr ( nor , val | SR_QUAD_EN_MX );
int kdbnearsym ( unsigned long addr , kdb_symtab_t * symtab ) <nl> } <nl> if ( i >= ARRAY_SIZE ( kdb_name_table )) { <nl> debug_kfree ( kdb_name_table [ 0 ]); <nl> - memcpy ( kdb_name_table , kdb_name_table + 1 , <nl> + memmove ( kdb_name_table , kdb_name_table + 1 , <nl> sizeof ( kdb_name_table [ 0 ]) * <nl> ( ARRAY_SIZE ( kdb_name_table )- 1 )); <nl> } else { <nl> debug_kfree ( knt1 ); <nl> knt1 = kdb_name_table [ i ]; <nl> - memcpy ( kdb_name_table + i , kdb_name_table + i + 1 , <nl> + memmove ( kdb_name_table + i , kdb_name_table + i + 1 , <nl> sizeof ( kdb_name_table [ 0 ]) * <nl> ( ARRAY_SIZE ( kdb_name_table )- i - 1 )); <nl> }
_pnfs_return_layout ( struct inode * ino ) <nl> lrp = kzalloc ( sizeof (* lrp ), GFP_KERNEL ); <nl> if ( unlikely ( lrp == NULL )) { <nl> status = - ENOMEM ; <nl> - pnfs_layout_io_set_failed ( lo , IOMODE_RW ); <nl> - pnfs_layout_io_set_failed ( lo , IOMODE_READ ); <nl> + spin_lock (& ino -> i_lock ); <nl> + lo -> plh_block_lgets --; <nl> + spin_unlock (& ino -> i_lock ); <nl> pnfs_put_layout_hdr ( lo ); <nl> goto out ; <nl> }
static ssize_t iwl_dbgfs_fw_rx_stats_read ( struct file * file , <nl>  <nl> mutex_lock (& mvm -> mutex ); <nl>  <nl> + if ( iwl_mvm_firmware_running ( mvm )) <nl> + iwl_mvm_request_statistics ( mvm , false ); <nl> + <nl> pos += scnprintf ( buf + pos , bufsz - pos , fmt_header , <nl> " Statistics_Rx - OFDM "); <nl> if (! iwl_mvm_has_new_rx_stats_api ( mvm )) {
static int load_link_keys ( struct sock * sk , struct hci_dev * hdev , void * data , <nl> MGMT_STATUS_INVALID_PARAMS ); <nl> } <nl>  <nl> + if ( cp -> debug_keys != 0x00 && cp -> debug_keys != 0x01 ) <nl> + return cmd_status ( sk , hdev -> id , MGMT_OP_LOAD_LINK_KEYS , <nl> + MGMT_STATUS_INVALID_PARAMS ); <nl> + <nl> BT_DBG ("% s debug_keys % u key_count % u ", hdev -> name , cp -> debug_keys , <nl> key_count ); <nl> 
enum { none , prepare , done , } __init_state ; <nl> static void init_preload ( void ); <nl> static void try_init_preload ( void ) <nl> { <nl> - if (! __init_state != done ) <nl> + if ( __init_state != done ) <nl> init_preload (); <nl> } <nl> 
int jbd2__journal_restart ( handle_t * handle , int nblocks , gfp_t gfp_mask ) <nl>  <nl> rwsem_release (& journal -> j_trans_commit_map , 1 , _THIS_IP_ ); <nl> handle -> h_buffer_credits = nblocks ; <nl> + /* <nl> + * Restore the original nofs context because the journal restart <nl> + * is basically the same thing as journal stop and start . <nl> + * start_this_handle will start a new nofs context . <nl> + */ <nl> + memalloc_nofs_restore ( handle -> saved_alloc_context ); <nl> ret = start_this_handle ( journal , handle , gfp_mask ); <nl> return ret ; <nl> }
static void can_pernet_exit ( struct net * net ) <nl> } <nl> } <nl> rcu_read_unlock (); <nl> + <nl> + kfree ( net -> can . can_rx_alldev_list ); <nl> } <nl>  <nl> /*
static void clear_huge_page ( struct page * page , <nl> { <nl> int i ; <nl>  <nl> - if ( unlikely ( sz > MAX_ORDER_NR_PAGES )) { <nl> + if ( unlikely ( sz / PAGE_SIZE > MAX_ORDER_NR_PAGES )) { <nl> clear_gigantic_page ( page , addr , sz ); <nl> return ; <nl> }
static int dwc3_gadget_init_hw_endpoints ( struct dwc3 * dwc , <nl>  <nl> dep -> endpoint . name = dep -> name ; <nl>  <nl> + dev_vdbg ( dwc -> dev , " initializing % s \ n ", dep -> name ); <nl> + <nl> if ( epnum == 0 || epnum == 1 ) { <nl> dep -> endpoint . maxpacket = 512 ; <nl> dep -> endpoint . maxburst = 1 ;
void tipc_disc_rcv ( struct net * net , struct sk_buff * skb , <nl> u16 caps = msg_node_capabilities ( hdr ); <nl> bool respond = false ; <nl> bool dupl_addr = false ; <nl> + int err ; <nl>  <nl> - bearer -> media -> msg2addr ( bearer , & maddr , msg_media_addr ( hdr )); <nl> + err = bearer -> media -> msg2addr ( bearer , & maddr , msg_media_addr ( hdr )); <nl> kfree_skb ( skb ); <nl> + if ( err ) <nl> + return ; <nl>  <nl> /* Ensure message from node is valid and communication is permitted */ <nl> if ( net_id != tn -> net_id )
typedef struct xfs_attr_list_context { <nl> struct attrlist_cursor_kern * cursor ; /* position in list */ <nl> char * alist ; /* output buffer */ <nl> int seen_enough ; /* T / F : seen enough of list ? */ <nl> - int count ; /* num used entries */ <nl> + ssize_t count ; /* num used entries */ <nl> int dupcnt ; /* count dup hashvals seen */ <nl> int bufsize ; /* total buffer size */ <nl> int firstu ; /* first used byte in buffer */
void ieee80211_beacon_connection_loss_work ( struct work_struct * work ) <nl> struct sta_info * sta ; <nl>  <nl> if ( ifmgd -> associated ) { <nl> + rcu_read_lock (); <nl> sta = sta_info_get ( sdata , ifmgd -> bssid ); <nl> if ( sta ) <nl> sta -> beacon_loss_count ++; <nl> + rcu_read_unlock (); <nl> } <nl>  <nl> if ( sdata -> local -> hw . flags & IEEE80211_HW_CONNECTION_MONITOR )
bitmap_ipmac_tlist ( const struct ip_set * set , <nl> nla_put_failure : <nl> nla_nest_cancel ( skb , nested ); <nl> ipset_nest_end ( skb , atd ); <nl> - return - EMSGSIZE ; <nl> + if ( unlikely ( id == first )) { <nl> + cb -> args [ 2 ] = 0 ; <nl> + return - EMSGSIZE ; <nl> + } <nl> + return 0 ; <nl> } <nl>  <nl> static int
int mwifiex_ret_802_11_scan ( struct mwifiex_private * priv , <nl>  <nl> pmatch = adapter -> nd_info -> matches [ idx ]; <nl>  <nl> - if (! pmatch ) { <nl> + if ( pmatch ) { <nl> memset ( pmatch , 0 , sizeof (* pmatch )); <nl> if ( chan_band_tlv ) { <nl> pmatch -> n_channels = 1 ;
static int of_platform_serial_probe ( struct platform_device * ofdev ) <nl> if ( of_find_property ( ofdev -> dev . of_node , " used - by - rtas ", NULL )) <nl> return - EBUSY ; <nl>  <nl> - info = kmalloc ( sizeof (* info ), GFP_KERNEL ); <nl> + info = kzalloc ( sizeof (* info ), GFP_KERNEL ); <nl> if ( info == NULL ) <nl> return - ENOMEM ; <nl> 
struct vfsmount * collect_mounts ( struct path * path ) <nl> { <nl> struct mount * tree ; <nl> namespace_lock (); <nl> - tree = copy_tree ( real_mount ( path -> mnt ), path -> dentry , <nl> - CL_COPY_ALL | CL_PRIVATE ); <nl> + if (! check_mnt ( real_mount ( path -> mnt ))) <nl> + tree = ERR_PTR (- EINVAL ); <nl> + else <nl> + tree = copy_tree ( real_mount ( path -> mnt ), path -> dentry , <nl> + CL_COPY_ALL | CL_PRIVATE ); <nl> namespace_unlock (); <nl> if ( IS_ERR ( tree )) <nl> return ERR_CAST ( tree );
static void sm501_free_init_fb ( struct sm501fb_info * info , <nl> { <nl> struct fb_info * fbi = info -> fb [ head ]; <nl>  <nl> + if (! fbi ) <nl> + return ; <nl> + <nl> fb_dealloc_cmap (& fbi -> cmap ); <nl> } <nl> 
int cfg80211_get_station ( struct net_device * dev , const u8 * mac_addr , <nl> if (! rdev -> ops -> get_station ) <nl> return - EOPNOTSUPP ; <nl>  <nl> + memset ( sinfo , 0 , sizeof (* sinfo )); <nl> + <nl> return rdev_get_station ( rdev , dev , mac_addr , sinfo ); <nl> } <nl> EXPORT_SYMBOL ( cfg80211_get_station );
int kvm_arch_vcpu_ioctl_set_sregs ( struct kvm_vcpu * vcpu , <nl> kvm_set_segment ( vcpu , & sregs -> tr , VCPU_SREG_TR ); <nl> kvm_set_segment ( vcpu , & sregs -> ldt , VCPU_SREG_LDTR ); <nl>  <nl> + update_cr8_intercept ( vcpu ); <nl> + <nl> /* Older userspace won ' t unhalt the vcpu on reset . */ <nl> if ( kvm_vcpu_is_bsp ( vcpu ) && kvm_rip_read ( vcpu ) == 0xfff0 && <nl> sregs -> cs . selector == 0xf000 && sregs -> cs . base == 0xffff0000 &&
static int get_alternative_line_range ( struct debuginfo * dinfo , <nl> struct line_range * lr , <nl> const char * target , bool user ) <nl> { <nl> - struct perf_probe_point pp = { 0 }, result = { 0 }; <nl> + struct perf_probe_point pp = { . function = lr -> function , <nl> + . file = lr -> file , <nl> + . line = lr -> start }; <nl> + struct perf_probe_point result ; <nl> int ret , len = 0 ; <nl>  <nl> - pp . function = lr -> function ; <nl> - pp . file = lr -> file ; <nl> - pp . line = lr -> start ; <nl> + memset (& result , 0 , sizeof ( result )); <nl> + <nl> if ( lr -> end != INT_MAX ) <nl> len = lr -> end - lr -> start ; <nl> ret = find_alternative_probe_point ( dinfo , & pp , & result ,
static void parse_lfp_panel_data ( struct drm_psb_private * dev_priv , <nl> if (! lvds_lfp_data ) <nl> return ; <nl>  <nl> - dev_priv -> lvds_vbt = 1 ; <nl>  <nl> entry = & lvds_lfp_data -> data [ lvds_options -> panel_type ]; <nl> dvo_timing = & entry -> dvo_timing ; <nl>  <nl> panel_fixed_mode = kzalloc ( sizeof (* panel_fixed_mode ), <nl> GFP_KERNEL ); <nl> + if ( panel_fixed_mode == NULL ) { <nl> + dev_err ( dev_priv -> dev -> dev , " out of memory for fixed panel mode \ n "); <nl> + return ; <nl> + } <nl>  <nl> + dev_priv -> lvds_vbt = 1 ; <nl> fill_detail_timing_data ( panel_fixed_mode , dvo_timing ); <nl>  <nl> if ( panel_fixed_mode -> htotal > 0 && panel_fixed_mode -> vtotal > 0 ) {
static void dec_pending ( struct dm_io * io , int error ) <nl> if (! md -> barrier_error && io_error != - EOPNOTSUPP ) <nl> md -> barrier_error = io_error ; <nl> end_io_acct ( io ); <nl> + free_io ( md , io ); <nl> } else { <nl> end_io_acct ( io ); <nl> + free_io ( md , io ); <nl>  <nl> if ( io_error != DM_ENDIO_REQUEUE ) { <nl> trace_block_bio_complete ( md -> queue , bio ); <nl> static void dec_pending ( struct dm_io * io , int error ) <nl> bio_endio ( bio , io_error ); <nl> } <nl> } <nl> - <nl> - free_io ( md , io ); <nl> } <nl> } <nl> 
static struct pci_resource * get_max_resource ( struct pci_resource ** head , u32 siz <nl> temp = temp -> next ; <nl> } <nl>  <nl> - temp -> next = max -> next ; <nl> + if ( temp ) <nl> + temp -> next = max -> next ; <nl> } <nl>  <nl> max -> next = NULL ;
static int do_pages_move ( struct mm_struct * mm , struct task_struct * task , <nl> goto out_pm ; <nl>  <nl> err = - ENODEV ; <nl> + if ( node < 0 || node >= MAX_NUMNODES ) <nl> + goto out_pm ; <nl> + <nl> if (! node_state ( node , N_HIGH_MEMORY )) <nl> goto out_pm ; <nl> 
static void __init relocate_initrd ( void ) <nl> if ( clen > MAX_MAP_CHUNK - slop ) <nl> clen = MAX_MAP_CHUNK - slop ; <nl> mapaddr = ramdisk_image & PAGE_MASK ; <nl> - p = early_ioremap ( mapaddr , clen + slop ); <nl> + p = early_memremap ( mapaddr , clen + slop ); <nl> memcpy ( q , p + slop , clen ); <nl> early_iounmap ( p , clen + slop ); <nl> q += clen ; <nl> static void __init parse_setup_data ( void ) <nl> return ; <nl> pa_data = boot_params . hdr . setup_data ; <nl> while ( pa_data ) { <nl> - data = early_ioremap ( pa_data , PAGE_SIZE ); <nl> + data = early_memremap ( pa_data , PAGE_SIZE ); <nl> switch ( data -> type ) { <nl> case SETUP_E820_EXT : <nl> parse_e820_ext ( data , pa_data ); <nl> static void __init e820_reserve_setup_data ( void ) <nl> return ; <nl> pa_data = boot_params . hdr . setup_data ; <nl> while ( pa_data ) { <nl> - data = early_ioremap ( pa_data , sizeof (* data )); <nl> + data = early_memremap ( pa_data , sizeof (* data )); <nl> e820_update_range ( pa_data , sizeof (* data )+ data -> len , <nl> E820_RAM , E820_RESERVED_KERN ); <nl> found = 1 ; <nl> static void __init reserve_early_setup_data ( void ) <nl> return ; <nl> pa_data = boot_params . hdr . setup_data ; <nl> while ( pa_data ) { <nl> - data = early_ioremap ( pa_data , sizeof (* data )); <nl> + data = early_memremap ( pa_data , sizeof (* data )); <nl> sprintf ( buf , " setup data % x ", data -> type ); <nl> reserve_early ( pa_data , pa_data + sizeof (* data )+ data -> len , buf ); <nl> pa_data = data -> next ;
static void xudc_getstatus ( struct xusb_udc * udc ) <nl> break ; <nl> case USB_RECIP_ENDPOINT : <nl> epnum = udc -> setup . wIndex & USB_ENDPOINT_NUMBER_MASK ; <nl> + if ( epnum >= XUSB_MAX_ENDPOINTS ) <nl> + goto stall ; <nl> target_ep = & udc -> ep [ epnum ]; <nl> epcfgreg = udc -> read_fn ( udc -> addr + target_ep -> offset ); <nl> halt = epcfgreg & XUSB_EP_CFG_STALL_MASK ; <nl> static void xudc_set_clear_feature ( struct xusb_udc * udc ) <nl> case USB_RECIP_ENDPOINT : <nl> if (! udc -> setup . wValue ) { <nl> endpoint = udc -> setup . wIndex & USB_ENDPOINT_NUMBER_MASK ; <nl> + if ( endpoint >= XUSB_MAX_ENDPOINTS ) { <nl> + xudc_ep0_stall ( udc ); <nl> + return ; <nl> + } <nl> target_ep = & udc -> ep [ endpoint ]; <nl> outinbit = udc -> setup . wIndex & USB_ENDPOINT_DIR_MASK ; <nl> outinbit = outinbit >> 7 ;
# include " expr - bison . h " <nl> # include " expr - flex . h " <nl> # include " smt . h " <nl> +# include < linux / err . h > <nl> # include < linux / kernel . h > <nl> # include < linux / zalloc . h > <nl> # include < ctype . h > <nl> struct expr_parse_ctx * expr__ctx_new ( void ) <nl> return NULL ; <nl>  <nl> ctx -> ids = hashmap__new ( key_hash , key_equal , NULL ); <nl> + if ( IS_ERR ( ctx -> ids )) { <nl> + free ( ctx ); <nl> + return NULL ; <nl> + } <nl> ctx -> runtime = 0 ; <nl>  <nl> return ctx ;
int inet6_csk_bind_conflict ( const struct sock * sk , <nl> if ( ipv6_rcv_saddr_equal ( sk , sk2 )) <nl> break ; <nl> } <nl> + if (! relax && reuse && sk2 -> sk_reuse && <nl> + sk2 -> sk_state != TCP_LISTEN && <nl> + ipv6_rcv_saddr_equal ( sk , sk2 )) <nl> + break ; <nl> } <nl> } <nl> 
static int dsmark_graft ( struct Qdisc * sch , unsigned long arg , <nl>  <nl> DPRINTK (" dsmark_graft ( sch % p ,[ qdisc % p ], new % p , old % p )\ n ", sch , p , new , <nl> old ); <nl> - if (! new ) <nl> - new = & noop_qdisc ; <nl> + <nl> + if ( new == NULL ) { <nl> + new = qdisc_create_dflt ( sch -> dev , & pfifo_qdisc_ops ); <nl> + if ( new == NULL ) <nl> + new = & noop_qdisc ; <nl> + } <nl> + <nl> sch_tree_lock ( sch ); <nl> * old = xchg (& p -> q , new ); <nl> if (* old )
void __init exynos5_init_irq ( void ) <nl> * Theses parameters should be NULL and 0 because EXYNOS4 <nl> * uses GIC instead of VIC . <nl> */ <nl> - s5p_init_irq ( NULL , 0 ); <nl> + if (! of_machine_is_compatible (" samsung , exynos5440 ")) <nl> + s5p_init_irq ( NULL , 0 ); <nl>  <nl> gic_arch_extn . irq_set_wake = s3c_irq_wake ; <nl> }
static void aead_release ( void * private ) <nl> struct aead_tfm * tfm = private ; <nl>  <nl> crypto_free_aead ( tfm -> aead ); <nl> + crypto_put_default_null_skcipher2 (); <nl> kfree ( tfm ); <nl> } <nl>  <nl> static void aead_sock_destruct ( struct sock * sk ) <nl> unsigned int ivlen = crypto_aead_ivsize ( tfm ); <nl>  <nl> af_alg_pull_tsgl ( sk , ctx -> used , NULL , 0 ); <nl> - crypto_put_default_null_skcipher2 (); <nl> sock_kzfree_s ( sk , ctx -> iv , ivlen ); <nl> sock_kfree_s ( sk , ctx , ctx -> len ); <nl> af_alg_release_parent ( sk );
static struct fileIdentDesc * udf_find_entry ( struct inode * dir , <nl> } <nl>  <nl> if (( cfi -> fileCharacteristics & FID_FILE_CHAR_PARENT ) && <nl> - isdotdot ) { <nl> - brelse ( epos . bh ); <nl> - return fi ; <nl> - } <nl> + isdotdot ) <nl> + goto out_ok ; <nl>  <nl> if (! lfi ) <nl> continue ;
int p9_client_remove ( struct p9_fid * fid ) <nl> P9_DPRINTK ( P9_DEBUG_9P , "<<< RREMOVE fid % d \ n ", fid -> fid ); <nl>  <nl> p9_free_req ( clnt , req ); <nl> - p9_fid_destroy ( fid ); <nl> - <nl> error : <nl> + p9_fid_destroy ( fid ); <nl> return err ; <nl> } <nl> EXPORT_SYMBOL ( p9_client_remove );
int olpc_ec_cmd ( unsigned char cmd , unsigned char * inbuf , size_t inlen , <nl> unsigned long flags ; <nl> int ret = - EIO ; <nl> int i ; <nl> + int restarts = 0 ; <nl>  <nl> spin_lock_irqsave (& ec_lock , flags ); <nl>  <nl> int olpc_ec_cmd ( unsigned char cmd , unsigned char * inbuf , size_t inlen , <nl> if ( wait_on_obf ( 0x6c , 1 )) { <nl> printk ( KERN_ERR " olpc - ec : timeout waiting for " <nl> " EC to provide data !\ n "); <nl> - goto restart ; <nl> + if ( restarts ++ < 10 ) <nl> + goto restart ; <nl> + goto err ; <nl> } <nl> outbuf [ i ] = inb ( 0x68 ); <nl> pr_devel (" olpc - ec : received 0x % x \ n ", outbuf [ i ]);
static int intel_crtc_mode_set ( struct drm_crtc * crtc , <nl> } <nl> dpll |= DPLL_DVO_HIGH_SPEED ; <nl> } <nl> - if ( is_dp ) <nl> + if ( is_dp || intel_encoder_is_pch_edp (& has_edp_encoder -> base )) <nl> dpll |= DPLL_DVO_HIGH_SPEED ; <nl>  <nl> /* compute bitmask from p1 value */
__ieee80211_tx_prepare ( struct ieee80211_tx_data * tx , <nl> tx -> local = local ; <nl> tx -> sdata = IEEE80211_DEV_TO_SUB_IF ( dev ); <nl> tx -> channel = local -> hw . conf . channel ; <nl> + tx -> rate_idx = - 1 ; <nl> + tx -> last_frag_rate_idx = - 1 ; <nl> /* <nl> * Set this flag ( used below to indicate " automatic fragmentation "), <nl> * it will be cleared / left by radiotap as desired .
static int dso__load_sym ( struct dso * self , struct map * map , const char * name , <nl>  <nl> section_name = elf_sec__name (& shdr , secstrs ); <nl>  <nl> + /* On ARM , symbols for thumb functions have 1 added to <nl> + * the symbol address as a flag - remove it */ <nl> + if (( ehdr . e_machine == EM_ARM ) && <nl> + ( map -> type == MAP__FUNCTION ) && <nl> + ( sym . st_value & 1 )) <nl> + -- sym . st_value ; <nl> + <nl> if ( self -> kernel != DSO_TYPE_USER || kmodule ) { <nl> char dso_name [ PATH_MAX ]; <nl> 
int sock_setsockopt ( struct socket * sock , int level , int optname , <nl> val = min_t ( u32 , val , sysctl_wmem_max ); <nl> set_sndbuf : <nl> sk -> sk_userlocks |= SOCK_SNDBUF_LOCK ; <nl> - sk -> sk_sndbuf = max_t ( u32 , val * 2 , SOCK_MIN_SNDBUF ); <nl> + sk -> sk_sndbuf = max_t ( int , val * 2 , SOCK_MIN_SNDBUF ); <nl> /* Wake up sending tasks if we upped the value . */ <nl> sk -> sk_write_space ( sk ); <nl> break ; <nl> int sock_setsockopt ( struct socket * sock , int level , int optname , <nl> * returning the value we actually used in getsockopt <nl> * is the most desirable behavior . <nl> */ <nl> - sk -> sk_rcvbuf = max_t ( u32 , val * 2 , SOCK_MIN_RCVBUF ); <nl> + sk -> sk_rcvbuf = max_t ( int , val * 2 , SOCK_MIN_RCVBUF ); <nl> break ; <nl>  <nl> case SO_RCVBUFFORCE :
static int intel_atomic_check ( struct drm_device * dev , <nl> struct intel_crtc_state * pipe_config = <nl> to_intel_crtc_state ( crtc_state ); <nl>  <nl> + memset (& to_intel_crtc ( crtc )-> atomic , 0 , <nl> + sizeof ( struct intel_crtc_atomic_commit )); <nl> + <nl> /* Catch I915_MODE_FLAG_INHERITED */ <nl> if ( crtc_state -> mode . private_flags != crtc -> state -> mode . private_flags ) <nl> crtc_state -> mode_changed = true ;
static int sd_start ( struct gspca_dev * gspca_dev ) <nl>  <nl> /* create the JPEG header */ <nl> dev -> jpeg_hdr = kmalloc ( JPEG_HDR_SZ , GFP_KERNEL ); <nl> + if ( dev -> jpeg_hdr == NULL ) <nl> + return - ENOMEM ; <nl> jpeg_define ( dev -> jpeg_hdr , gspca_dev -> height , gspca_dev -> width , <nl> 0x21 ); /* JPEG 422 */ <nl> jpeg_set_qual ( dev -> jpeg_hdr , dev -> quality );
int __vma_adjust ( struct vm_area_struct * vma , unsigned long start , <nl> * If next doesn ' t have anon_vma , import from vma after <nl> * next , if the vma overlaps with it . <nl> */ <nl> - if ( remove_next == 2 && next && ! next -> anon_vma ) <nl> + if ( remove_next == 2 && ! next -> anon_vma ) <nl> exporter = next -> vm_next ; <nl>  <nl> } else if ( end > next -> vm_start ) {
ia_css_pipe_dequeue_buffer ( struct ia_css_pipe * pipe , <nl> ia_css_rmgr_rel_vbuf ( hmm_buffer_pool , & hmm_buffer_record -> h_vbuf ); <nl> sh_css_hmm_buffer_record_reset ( hmm_buffer_record ); <nl> } else { <nl> - IA_CSS_ERROR (" hmm_buffer_record not found ( 0x % u ) buf_type (% d )", <nl> + IA_CSS_ERROR (" hmm_buffer_record not found ( 0x % x ) buf_type (% d )", <nl> ddr_buffer_addr , buf_type ); <nl> IA_CSS_LEAVE_ERR ( IA_CSS_ERR_INTERNAL_ERROR ); <nl> return IA_CSS_ERR_INTERNAL_ERROR ;
static netdev_tx_t rtl8139_start_xmit ( struct sk_buff * skb , <nl> if ( len < ETH_ZLEN ) <nl> memset ( tp -> tx_buf [ entry ], 0 , ETH_ZLEN ); <nl> skb_copy_and_csum_dev ( skb , tp -> tx_buf [ entry ]); <nl> - dev_kfree_skb ( skb ); <nl> + dev_kfree_skb_any ( skb ); <nl> } else { <nl> - dev_kfree_skb ( skb ); <nl> + dev_kfree_skb_any ( skb ); <nl> dev -> stats . tx_dropped ++; <nl> return NETDEV_TX_OK ; <nl> }
acornfb_pan_display ( struct fb_var_screeninfo * var , struct fb_info * info ) <nl> if (!( var -> vmode & FB_VMODE_YWRAP )) <nl> y_bottom += var -> yres ; <nl>  <nl> - BUG_ON ( y_bottom > var -> yres_virtual ); <nl> + if ( y_bottom > var -> yres_virtual ) <nl> + return - EINVAL ; <nl>  <nl> acornfb_update_dma ( info , var ); <nl> 
static int addrconf_notify ( struct notifier_block * this , unsigned long event , <nl> dev -> name ); <nl> break ; <nl> } <nl> + <nl> + if ( idev ) <nl> + idev -> if_flags |= IF_READY ; <nl> } else { <nl> if (! netif_carrier_ok ( dev )) { <nl> /* device is still not ready . */
static inline bool is_pci_p2pdma_page ( const struct page * page ) <nl> } <nl> # endif /* CONFIG_DEV_PAGEMAP_OPS */ <nl>  <nl> +/* 127 : arbitrary random number , small enough to assemble well */ <nl> +# define page_ref_zero_or_close_to_overflow ( page ) \ <nl> + (( unsigned int ) page_ref_count ( page ) + 127u <= 127u ) <nl> + <nl> static inline void get_page ( struct page * page ) <nl> { <nl> page = compound_head ( page ); <nl> static inline void get_page ( struct page * page ) <nl> * Getting a normal page or the head of a compound page <nl> * requires to already have an elevated page -> _refcount . <nl> */ <nl> - VM_BUG_ON_PAGE ( page_ref_count ( page ) <= 0 , page ); <nl> + VM_BUG_ON_PAGE ( page_ref_zero_or_close_to_overflow ( page ), page ); <nl> page_ref_inc ( page ); <nl> } <nl> 
static void mtk_drm_unbind ( struct device * dev ) <nl> { <nl> struct mtk_drm_private * private = dev_get_drvdata ( dev ); <nl>  <nl> - drm_put_dev ( private -> drm ); <nl> + drm_dev_unregister ( private -> drm ); <nl> + drm_dev_unref ( private -> drm ); <nl> private -> drm = NULL ; <nl> } <nl> 
megasas_sysfs_set_dbg_lvl ( struct device_driver * dd , const char * buf , size_t coun <nl> return retval ; <nl> } <nl>  <nl> - static DRIVER_ATTR ( dbg_lvl , S_IRUGO | S_IWUGO , megasas_sysfs_show_dbg_lvl , <nl> + static DRIVER_ATTR ( dbg_lvl , S_IRUGO | S_IWUSR , megasas_sysfs_show_dbg_lvl , <nl> megasas_sysfs_set_dbg_lvl ); <nl>  <nl> static ssize_t
ccp_run_sha_cmd ( struct ccp_cmd_queue * cmd_q , struct ccp_cmd * cmd ) <nl> LSB_ITEM_SIZE ); <nl> break ; <nl> default : <nl> + kfree ( hmac_buf ); <nl> ret = - EINVAL ; <nl> - goto e_ctx ; <nl> + goto e_data ; <nl> } <nl>  <nl> memset (& hmac_cmd , 0 , sizeof ( hmac_cmd ));
bool skb_flow_dissect ( const struct sk_buff * skb , struct flow_keys * flow ) <nl> if ( poff >= 0 ) { <nl> __be32 * ports , _ports ; <nl>  <nl> - nhoff += poff ; <nl> - ports = skb_header_pointer ( skb , nhoff , sizeof ( _ports ), & _ports ); <nl> + ports = skb_header_pointer ( skb , nhoff + poff , <nl> + sizeof ( _ports ), & _ports ); <nl> if ( ports ) <nl> flow -> ports = * ports ; <nl> }
int ping_hash ( struct sock * sk ) <nl> void ping_unhash ( struct sock * sk ) <nl> { <nl> struct inet_sock * isk = inet_sk ( sk ); <nl> + <nl> pr_debug (" ping_unhash ( isk =% p , isk -> num =% u )\ n ", isk , isk -> inet_num ); <nl> + write_lock_bh (& ping_table . lock ); <nl> if ( sk_hashed ( sk )) { <nl> - write_lock_bh (& ping_table . lock ); <nl> hlist_nulls_del (& sk -> sk_nulls_node ); <nl> sk_nulls_node_init (& sk -> sk_nulls_node ); <nl> sock_put ( sk ); <nl> isk -> inet_num = 0 ; <nl> isk -> inet_sport = 0 ; <nl> sock_prot_inuse_add ( sock_net ( sk ), sk -> sk_prot , - 1 ); <nl> - write_unlock_bh (& ping_table . lock ); <nl> } <nl> + write_unlock_bh (& ping_table . lock ); <nl> } <nl> EXPORT_SYMBOL_GPL ( ping_unhash ); <nl> 
static int skl_manifest_load ( struct snd_soc_component * cmpnt , <nl> struct skl * skl = ebus_to_skl ( ebus ); <nl> int ret = 0 ; <nl>  <nl> + /* proceed only if we have private data defined */ <nl> + if ( manifest -> priv . size == 0 ) <nl> + return 0 ; <nl> + <nl> minfo = & skl -> skl_sst -> manifest ; <nl>  <nl> skl_tplg_get_manifest_data ( manifest , bus -> dev , minfo );
void rt2x00lib_txdone ( struct queue_entry * entry , <nl> * Update TX statistics . <nl> */ <nl> rt2x00dev -> link . qual . tx_success += success ; <nl> - rt2x00dev -> link . qual . tx_failed += txdesc -> retry + fail ; <nl> + rt2x00dev -> link . qual . tx_failed += fail ; <nl>  <nl> /* <nl> * Initialize TX status
i915_gem_execbuffer_relocate_entry ( struct drm_i915_gem_object * obj , <nl> else <nl> ret = relocate_entry_gtt ( obj , reloc ); <nl>  <nl> + if ( ret ) <nl> + return ret ; <nl> + <nl> /* and update the user ' s relocation entry */ <nl> reloc -> presumed_offset = target_offset ; <nl> 
__cpuinit int unsynchronized_tsc ( void ) <nl> if ( boot_cpu_data . x86_vendor == X86_VENDOR_INTEL ) { <nl> # ifdef CONFIG_ACPI <nl> /* But TSC doesn ' t tick in C3 so don ' t use it there */ <nl> - if ( acpi_fadt . length > 0 && acpi_fadt . plvl3_lat < 100 ) <nl> + if ( acpi_fadt . length > 0 && acpi_fadt . plvl3_lat < 1000 ) <nl> return 1 ; <nl> # endif <nl> return 0 ;
static int pm860x_led_dt_init ( struct platform_device * pdev , <nl> struct device_node * nproot , * np ; <nl> int iset = 0 ; <nl>  <nl> - nproot = of_node_get ( pdev -> dev . parent -> of_node ); <nl> - if (! nproot ) <nl> + if (! pdev -> dev . parent -> of_node ) <nl> return - ENODEV ; <nl> - nproot = of_get_child_by_name ( nproot , " leds "); <nl> + nproot = of_get_child_by_name ( pdev -> dev . parent -> of_node , " leds "); <nl> if (! nproot ) { <nl> dev_err (& pdev -> dev , " failed to find leds node \ n "); <nl> return - ENODEV ;
static int pvc_getname ( struct socket * sock , struct sockaddr * sockaddr , <nl> return - ENOTCONN ; <nl> * sockaddr_len = sizeof ( struct sockaddr_atmpvc ); <nl> addr = ( struct sockaddr_atmpvc *) sockaddr ; <nl> + memset ( addr , 0 , sizeof (* addr )); <nl> addr -> sap_family = AF_ATMPVC ; <nl> addr -> sap_addr . itf = vcc -> dev -> number ; <nl> addr -> sap_addr . vpi = vcc -> vpi ;
static void tfilter_notify_chain ( struct net * net , struct sk_buff * oskb , <nl>  <nl> for ( it_chain = chain ; ( tp = rtnl_dereference (* it_chain )) != NULL ; <nl> it_chain = & tp -> next ) <nl> - tfilter_notify ( net , oskb , n , tp , n -> nlmsg_flags , event , false ); <nl> + tfilter_notify ( net , oskb , n , tp , 0 , event , false ); <nl> } <nl>  <nl> /* Select new prio value from the range , managed by kernel . */
static noinline int hiddev_ioctl_usage ( struct hiddev * hiddev , unsigned int cmd , <nl> goto inval ; <nl> } else if ( uref -> usage_index >= field -> report_count ) <nl> goto inval ; <nl> - <nl> - else if (( cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES ) && <nl> - ( uref_multi -> num_values > HID_MAX_MULTI_USAGES || <nl> - uref -> usage_index + uref_multi -> num_values > field -> report_count )) <nl> - goto inval ; <nl> } <nl>  <nl> + if (( cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES ) && <nl> + ( uref_multi -> num_values > HID_MAX_MULTI_USAGES || <nl> + uref -> usage_index + uref_multi -> num_values > field -> report_count )) <nl> + goto inval ; <nl> + <nl> switch ( cmd ) { <nl> case HIDIOCGUSAGE : <nl> uref -> value = field -> value [ uref -> usage_index ];
static int hp_wmi_perform_query ( int query , int write , u32 * buffer , <nl> bios_return = *(( struct bios_return *) obj -> buffer . pointer ); <nl>  <nl> memcpy ( buffer , & bios_return . value , sizeof ( bios_return . value )); <nl> + <nl> + kfree ( obj ); <nl> return 0 ; <nl> } <nl> 
static inline uint64_t howmany_64 ( uint64_t x , uint32_t y ) <nl> # endif /* DEBUG */ <nl>  <nl> # ifdef CONFIG_XFS_RT <nl> -# define XFS_IS_REALTIME_INODE ( ip ) (( ip )-> i_d . di_flags & XFS_DIFLAG_REALTIME ) <nl> + <nl> +/* <nl> + * make sure we ignore the inode flag if the filesystem doesn ' t have a <nl> + * configured realtime device . <nl> + */ <nl> +# define XFS_IS_REALTIME_INODE ( ip ) \ <nl> + ((( ip )-> i_d . di_flags & XFS_DIFLAG_REALTIME ) && \ <nl> + ( ip )-> i_mount -> m_rtdev_targp ) <nl> # else <nl> # define XFS_IS_REALTIME_INODE ( ip ) ( 0 ) <nl> # endif
static __inline__ void atomic64_set_mask ( unsigned long mask , atomic64_t * v ) <nl> __CSG_LOOP ( v , mask , " ogr "); <nl> } <nl>  <nl> +# define atomic64_xchg ( v , new ) ( xchg (&(( v )-> counter ), new )) <nl> + <nl> static __inline__ long long atomic64_cmpxchg ( atomic64_t * v , <nl> long long old , long long new ) <nl> {
static void ntb_netdev_remove ( struct pci_dev * pdev ) <nl> if ( dev == NULL ) <nl> return ; <nl>  <nl> + list_del (& dev -> list ); <nl> + <nl> ndev = dev -> ndev ; <nl>  <nl> unregister_netdev ( ndev );
static int __devinit sta2x11_mfd_probe ( struct pci_dev * pdev , <nl> sta2x11_mfd_setup ( pdev , setup_data ); <nl>  <nl> /* Record this pdev before mfd_add_devices : their probe looks for it */ <nl> - sta2x11_mfd_add ( pdev , GFP_ATOMIC ); <nl> + if (! sta2x11_mfd_find ( pdev )) <nl> + sta2x11_mfd_add ( pdev , GFP_ATOMIC ); <nl>  <nl> /* Just 2 bars for all mfd ' s at present */ <nl> for ( i = 0 ; i < 2 ; i ++) {
static void __init early_identify_cpu ( struct cpuinfo_x86 * c ) <nl>  <nl> setup_force_cpu_cap ( X86_FEATURE_ALWAYS ); <nl>  <nl> - /* Assume for now that ALL x86 CPUs are insecure */ <nl> - setup_force_cpu_bug ( X86_BUG_CPU_INSECURE ); <nl> + if ( c -> x86_vendor != X86_VENDOR_AMD ) <nl> + setup_force_cpu_bug ( X86_BUG_CPU_INSECURE ); <nl>  <nl> fpu__init_system ( c ); <nl> 
static void slc_bump ( struct slcan * sl ) <nl> u32 tmpid ; <nl> char * cmd = sl -> rbuff ; <nl>  <nl> - cf . can_id = 0 ; <nl> + memset (& cf , 0 , sizeof ( cf )); <nl>  <nl> switch (* cmd ) { <nl> case ' r ': <nl> static void slc_bump ( struct slcan * sl ) <nl> else <nl> return ; <nl>  <nl> - *( u64 *) (& cf . data ) = 0 ; /* clear payload */ <nl> - <nl> /* RTR frames may have a dlc > 0 but they never have any data bytes */ <nl> if (!( cf . can_id & CAN_RTR_FLAG )) { <nl> for ( i = 0 ; i < cf . can_dlc ; i ++) {
xfs_bmse_merge ( <nl> xfs_iext_update_extent ( ifp , current_ext - 1 , & new ); <nl> xfs_iext_remove ( ip , current_ext , 1 , 0 ); <nl>  <nl> - /* update reverse mapping */ <nl> + /* update reverse mapping . rmap functions merge the rmaps for us */ <nl> error = xfs_rmap_unmap_extent ( mp , dfops , ip , whichfork , got ); <nl> if ( error ) <nl> return error ; <nl> - error = xfs_rmap_unmap_extent ( mp , dfops , ip , whichfork , left ); <nl> - if ( error ) <nl> - return error ; <nl> + memcpy (& new , got , sizeof ( new )); <nl> + new . br_startoff = left -> br_startoff + left -> br_blockcount ; <nl> return xfs_rmap_map_extent ( mp , dfops , ip , whichfork , & new ); <nl> } <nl> 
void ip_tunnel_xmit ( struct sk_buff * skb , struct net_device * dev , <nl> tunnel -> err_time + IPTUNNEL_ERR_TIMEO )) { <nl> tunnel -> err_count --; <nl>  <nl> + memset ( IPCB ( skb ), 0 , sizeof (* IPCB ( skb ))); <nl> dst_link_failure ( skb ); <nl> } else <nl> tunnel -> err_count = 0 ;
static int udf_load_logicalvol ( struct super_block * sb , sector_t block , <nl> struct genericPartitionMap * gpm ; <nl> uint16_t ident ; <nl> struct buffer_head * bh ; <nl> + unsigned int table_len ; <nl> int ret = 0 ; <nl>  <nl> bh = udf_read_tagged ( sb , block , block , & ident ); <nl> static int udf_load_logicalvol ( struct super_block * sb , sector_t block , <nl> return 1 ; <nl> BUG_ON ( ident != TAG_IDENT_LVD ); <nl> lvd = ( struct logicalVolDesc *) bh -> b_data ; <nl> + table_len = le32_to_cpu ( lvd -> mapTableLength ); <nl> + if ( sizeof (* lvd ) + table_len > sb -> s_blocksize ) { <nl> + udf_err ( sb , " error loading logical volume descriptor : " <nl> + " Partition table too long (% u > % lu )\ n ", table_len , <nl> + sb -> s_blocksize - sizeof (* lvd )); <nl> + goto out_bh ; <nl> + } <nl>  <nl> ret = udf_sb_alloc_partition_maps ( sb , le32_to_cpu ( lvd -> numPartitionMaps )); <nl> if ( ret ) <nl> goto out_bh ; <nl>  <nl> for ( i = 0 , offset = 0 ; <nl> - i < sbi -> s_partitions && offset < le32_to_cpu ( lvd -> mapTableLength ); <nl> + i < sbi -> s_partitions && offset < table_len ; <nl> i ++, offset += gpm -> partitionMapLength ) { <nl> struct udf_part_map * map = & sbi -> s_partmaps [ i ]; <nl> gpm = ( struct genericPartitionMap *)
int sst_hsw_stream_get_volume ( struct sst_hsw * hsw , struct sst_hsw_stream * stream <nl> return - EINVAL ; <nl>  <nl> sst_dsp_read ( hsw -> dsp , volume , <nl> - stream -> reply . volume_register_address [ channel ], sizeof ( volume )); <nl> + stream -> reply . volume_register_address [ channel ], <nl> + sizeof (* volume )); <nl>  <nl> return 0 ; <nl> }
SOC_SINGLE_TLV (" LINEOUT2 Volume ", WM8993_LINE_OUTPUTS_VOLUME , 0 , 1 , 1 , <nl> static int hp_supply_event ( struct snd_soc_dapm_widget * w , <nl> struct snd_kcontrol * kcontrol , int event ) <nl> { <nl> - struct snd_soc_codec * codec = w -> codec ; <nl> + struct snd_soc_codec * codec = snd_soc_dapm_to_codec ( w -> dapm ); <nl> struct wm_hubs_data * hubs = snd_soc_codec_get_drvdata ( codec ); <nl>  <nl> switch ( event ) { <nl> static int hp_supply_event ( struct snd_soc_dapm_widget * w , <nl> static int hp_event ( struct snd_soc_dapm_widget * w , <nl> struct snd_kcontrol * kcontrol , int event ) <nl> { <nl> - struct snd_soc_codec * codec = w -> codec ; <nl> + struct snd_soc_codec * codec = snd_soc_dapm_to_codec ( w -> dapm ); <nl> unsigned int reg = snd_soc_read ( codec , WM8993_ANALOGUE_HP_0 ); <nl>  <nl> switch ( event ) { <nl> static int hp_event ( struct snd_soc_dapm_widget * w , <nl> static int earpiece_event ( struct snd_soc_dapm_widget * w , <nl> struct snd_kcontrol * control , int event ) <nl> { <nl> - struct snd_soc_codec * codec = w -> codec ; <nl> + struct snd_soc_codec * codec = snd_soc_dapm_to_codec ( w -> dapm ); <nl> u16 reg = snd_soc_read ( codec , WM8993_ANTIPOP1 ) & ~ WM8993_HPOUT2_IN_ENA ; <nl>  <nl> switch ( event ) { <nl> static int earpiece_event ( struct snd_soc_dapm_widget * w , <nl> static int lineout_event ( struct snd_soc_dapm_widget * w , <nl> struct snd_kcontrol * control , int event ) <nl> { <nl> - struct snd_soc_codec * codec = w -> codec ; <nl> + struct snd_soc_codec * codec = snd_soc_dapm_to_codec ( w -> dapm ); <nl> struct wm_hubs_data * hubs = snd_soc_codec_get_drvdata ( codec ); <nl> bool * flag ; <nl>  <nl> static int lineout_event ( struct snd_soc_dapm_widget * w , <nl> static int micbias_event ( struct snd_soc_dapm_widget * w , <nl> struct snd_kcontrol * kcontrol , int event ) <nl> { <nl> - struct snd_soc_codec * codec = w -> codec ; <nl> + struct snd_soc_codec * codec = snd_soc_dapm_to_codec ( w -> dapm ); <nl> struct wm_hubs_data * hubs = snd_soc_codec_get_drvdata ( codec ); <nl>  <nl> switch ( w -> shift ) {
static int __devinit mwl8k_probe ( struct pci_dev * pdev , <nl> if ( rc ) { <nl> printk ( KERN_ERR "% s : Cannot register device \ n ", <nl> wiphy_name ( hw -> wiphy )); <nl> - goto err_free_irq ; <nl> + goto err_free_queues ; <nl> } <nl>  <nl> printk ( KERN_INFO "% s : % s v % d , % pM , % s firmware % u .% u .% u .% u \ n ",
int xfrm_policy_flush ( u8 type , struct xfrm_audit * audit_info ) <nl> continue ; <nl> hlist_del (& pol -> bydst ); <nl> hlist_del (& pol -> byidx ); <nl> + list_del (& pol -> walk . all ); <nl> write_unlock_bh (& xfrm_policy_lock ); <nl>  <nl> xfrm_audit_policy_delete ( pol , 1 , audit_info -> loginuid ,
xfs_acl_from_disk ( struct xfs_acl * aclp ) <nl> int count , i ; <nl>  <nl> count = be32_to_cpu ( aclp -> acl_cnt ); <nl> + if ( count > XFS_ACL_MAX_ENTRIES ) <nl> + return ERR_PTR (- EFSCORRUPTED ); <nl>  <nl> acl = posix_acl_alloc ( count , GFP_KERNEL ); <nl> if (! acl )
static int psbfb_create ( struct psb_fbdev * fbdev , <nl> mode_cmd . width = sizes -> surface_width ; <nl> mode_cmd . height = sizes -> surface_height ; <nl> bpp = sizes -> surface_bpp ; <nl> + depth = sizes -> surface_depth ; <nl>  <nl> /* No 24bit packed */ <nl> if ( bpp == 24 ) <nl> static int psbfb_create ( struct psb_fbdev * fbdev , <nl> * is ok with some fonts <nl> */ <nl> mode_cmd . pitches [ 0 ] = ALIGN ( mode_cmd . width * (( bpp + 7 ) / 8 ), 4096 >> pitch_lines ); <nl> - depth = sizes -> surface_depth ; <nl>  <nl> size = mode_cmd . pitches [ 0 ] * mode_cmd . height ; <nl> size = ALIGN ( size , PAGE_SIZE );
static int snd_soc_8_16_write ( struct snd_soc_codec * codec , unsigned int reg , <nl> data [ 1 ] = ( value >> 8 ) & 0xff ; <nl> data [ 2 ] = value & 0xff ; <nl>  <nl> - if (! snd_soc_codec_volatile_register ( codec , reg )) <nl> - reg_cache [ reg ] = value ; <nl> + if (! snd_soc_codec_volatile_register ( codec , reg ) <nl> + && reg < codec -> driver -> reg_cache_size ) <nl> + reg_cache [ reg ] = value ; <nl>  <nl> if ( codec -> cache_only ) { <nl> codec -> cache_sync = 1 ;
static int xdp_umem_reg ( struct xdp_umem * umem , struct xdp_umem_reg * mr ) <nl> u32 chunk_size = mr -> chunk_size , headroom = mr -> headroom ; <nl> unsigned int chunks , chunks_per_page ; <nl> u64 addr = mr -> addr , size = mr -> len ; <nl> - int size_chk , err ; <nl> + int err ; <nl>  <nl> if ( chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE ) { <nl> /* Strictly speaking we could support this , if : <nl> static int xdp_umem_reg ( struct xdp_umem * umem , struct xdp_umem_reg * mr ) <nl> return - EINVAL ; <nl> } <nl>  <nl> - size_chk = chunk_size - headroom - XDP_PACKET_HEADROOM ; <nl> - if ( size_chk < 0 ) <nl> + if ( headroom >= chunk_size - XDP_PACKET_HEADROOM ) <nl> return - EINVAL ; <nl>  <nl> umem -> address = ( unsigned long ) addr ;
int asn1_ber_decoder ( const struct asn1_decoder * decoder , <nl> if ( unlikely ( len > datalen - dp )) <nl> goto data_overrun_error ; <nl> } <nl> + } else { <nl> + if ( unlikely ( len > datalen - dp )) <nl> + goto data_overrun_error ; <nl> } <nl>  <nl> if ( flags & FLAG_CONS ) {
static inline void local_flush_tlb_page ( struct vm_area_struct * vma , unsigned lon <nl> static inline void local_flush_tlb_kernel_page ( unsigned long kaddr ) { } <nl> static inline void local_flush_tlb_range ( struct vm_area_struct * vma , unsigned long start , unsigned long end ) { } <nl> static inline void local_flush_tlb_kernel_range ( unsigned long start , unsigned long end ) { } <nl> + static inline void local_flush_bp_all ( void ) { } <nl>  <nl> extern void flush_tlb_all ( void ); <nl> extern void flush_tlb_mm ( struct mm_struct * mm ); <nl> extern void flush_tlb_page ( struct vm_area_struct * vma , unsigned long uaddr ); <nl> extern void flush_tlb_kernel_page ( unsigned long kaddr ); <nl> extern void flush_tlb_range ( struct vm_area_struct * vma , unsigned long start , unsigned long end ); <nl> extern void flush_tlb_kernel_range ( unsigned long start , unsigned long end ); <nl> + extern void flush_bp_all ( void ); <nl> # endif /* __ASSEMBLY__ */ <nl>  <nl> # endif
cifs_setlk ( struct file * file , struct file_lock * flock , __u32 type , <nl> rc = server -> ops -> mand_unlock_range ( cfile , flock , xid ); <nl>  <nl> out : <nl> - if ( flock -> fl_flags & FL_POSIX ) <nl> - posix_lock_file_wait ( file , flock ); <nl> + if ( flock -> fl_flags & FL_POSIX && ! rc ) <nl> + rc = posix_lock_file_wait ( file , flock ); <nl> return rc ; <nl> } <nl> 
static struct rpmsg_device * rpmsg_virtio_add_ctrl_dev ( struct virtio_device * vdev <nl>  <nl> err = rpmsg_ctrldev_register_device ( rpdev_ctrl ); <nl> if ( err ) { <nl> - kfree ( vch ); <nl> + /* vch will be free in virtio_rpmsg_release_device () */ <nl> return ERR_PTR ( err ); <nl> } <nl> 
static int nodemgr_host_thread ( void * data ) <nl> g = get_hpsb_generation ( host ); <nl> for ( i = 0 ; i < 4 ; i ++) { <nl> msleep_interruptible ( 63 ); <nl> + try_to_freeze (); <nl> if ( kthread_should_stop ()) <nl> goto exit ; <nl>  <nl> static int nodemgr_host_thread ( void * data ) <nl> /* Sleep 3 seconds */ <nl> for ( i = 3000 / 200 ; i ; i --) { <nl> msleep_interruptible ( 200 ); <nl> + try_to_freeze (); <nl> if ( kthread_should_stop ()) <nl> goto exit ; <nl> 
static void ixgbe_clean_rx_irq ( struct ixgbe_q_vector * q_vector , <nl> if ( ixgbe_rx_is_fcoe ( adapter , rx_desc )) { <nl> ddp_bytes = ixgbe_fcoe_ddp ( adapter , rx_desc , skb , <nl> staterr ); <nl> - if (! ddp_bytes ) <nl> + if (! ddp_bytes ) { <nl> + dev_kfree_skb_any ( skb ); <nl> goto next_desc ; <nl> + } <nl> } <nl> # endif /* IXGBE_FCOE */ <nl> ixgbe_receive_skb ( q_vector , skb , staterr , rx_ring , rx_desc );
static struct regulator_ops arizona_ldo1_ops = { <nl> . map_voltage = regulator_map_voltage_linear , <nl> . get_voltage_sel = regulator_get_voltage_sel_regmap , <nl> . set_voltage_sel = regulator_set_voltage_sel_regmap , <nl> - . get_bypass = regulator_get_bypass_regmap , <nl> - . set_bypass = regulator_set_bypass_regmap , <nl> }; <nl>  <nl> static const struct regulator_desc arizona_ldo1 = {
static loff_t fuse_file_llseek ( struct file * file , loff_t offset , int origin ) <nl> mutex_lock (& inode -> i_mutex ); <nl> switch ( origin ) { <nl> case SEEK_END : <nl> + retval = fuse_update_attributes ( inode , NULL , file , NULL ); <nl> + if ( retval ) <nl> + return retval ; <nl> offset += i_size_read ( inode ); <nl> break ; <nl> case SEEK_CUR :
int do_huge_pmd_numa_page ( struct mm_struct * mm , struct vm_area_struct * vma , <nl>  <nl> check_same : <nl> spin_lock (& mm -> page_table_lock ); <nl> - if ( unlikely (! pmd_same ( pmd , * pmdp ))) <nl> + if ( unlikely (! pmd_same ( pmd , * pmdp ))) { <nl> + /* Someone else took our fault */ <nl> + current_nid = - 1 ; <nl> goto out_unlock ; <nl> + } <nl> clear_pmdnuma : <nl> pmd = pmd_mknonnuma ( pmd ); <nl> set_pmd_at ( mm , haddr , pmdp , pmd );
static int f2fs_write_data_pages ( struct address_space * mapping , <nl> if (! mapping -> a_ops -> writepage ) <nl> return 0 ; <nl>  <nl> + /* skip writing if there is no dirty page in this inode */ <nl> + if (! get_dirty_pages ( inode ) && wbc -> sync_mode == WB_SYNC_NONE ) <nl> + return 0 ; <nl> + <nl> if ( S_ISDIR ( inode -> i_mode ) && wbc -> sync_mode == WB_SYNC_NONE && <nl> get_dirty_pages ( inode ) < nr_pages_to_skip ( sbi , DATA ) && <nl> available_free_memory ( sbi , DIRTY_DENTS ))
static int he_init_group ( struct he_dev * he_dev , int group ) <nl> G0_RBPS_BS + ( group * 32 )); <nl>  <nl> /* bitmap table */ <nl> - he_dev -> rbpl_table = kmalloc ( BITS_TO_LONGS ( RBPL_TABLE_SIZE ) <nl> - * sizeof ( unsigned long ), GFP_KERNEL ); <nl> + he_dev -> rbpl_table = kmalloc_array ( BITS_TO_LONGS ( RBPL_TABLE_SIZE ), <nl> + sizeof (* he_dev -> rbpl_table ), <nl> + GFP_KERNEL ); <nl> if (! he_dev -> rbpl_table ) { <nl> hprintk (" unable to allocate rbpl bitmap table \ n "); <nl> return - ENOMEM ; <nl> static int he_init_group ( struct he_dev * he_dev , int group ) <nl> bitmap_zero ( he_dev -> rbpl_table , RBPL_TABLE_SIZE ); <nl>  <nl> /* rbpl_virt 64 - bit pointers */ <nl> - he_dev -> rbpl_virt = kmalloc ( RBPL_TABLE_SIZE <nl> - * sizeof ( struct he_buff *), GFP_KERNEL ); <nl> + he_dev -> rbpl_virt = kmalloc_array ( RBPL_TABLE_SIZE , <nl> + sizeof (* he_dev -> rbpl_virt ), <nl> + GFP_KERNEL ); <nl> if (! he_dev -> rbpl_virt ) { <nl> hprintk (" unable to allocate rbpl virt table \ n "); <nl> goto out_free_rbpl_table ;
int tc_classify ( struct sk_buff * skb , struct tcf_proto * tp , <nl> tp = otp ; <nl>  <nl> if ( verd ++ >= MAX_REC_LOOP ) { <nl> - printk (" rule prio % u protocol % 02x reclassify loop , " <nl> - " packet dropped \ n ", <nl> - tp -> prio & 0xffff , ntohs ( tp -> protocol )); <nl> + if ( net_ratelimit ()) <nl> + printk ( KERN_NOTICE <nl> + "% s : packet reclassify loop " <nl> + " rule prio % u protocol % 02x \ n ", <nl> + tp -> q -> ops -> id , <nl> + tp -> prio & 0xffff , ntohs ( tp -> protocol )); <nl> return TC_ACT_SHOT ; <nl> } <nl> skb -> tc_verd = SET_TC_VERD ( skb -> tc_verd , verd );
static void __init cgroup_init_subsys ( struct cgroup_subsys * ss ) <nl>  <nl> printk ( KERN_INFO " Initializing cgroup subsys % s \ n ", ss -> name ); <nl>  <nl> + mutex_lock (& cgroup_mutex ); <nl> + <nl> /* init base cftset */ <nl> cgroup_init_cftsets ( ss ); <nl>  <nl> static void __init cgroup_init_subsys ( struct cgroup_subsys * ss ) <nl> if ( ss -> post_create ) <nl> ss -> post_create ( dummytop ); <nl>  <nl> + mutex_unlock (& cgroup_mutex ); <nl> + <nl> /* this function shouldn ' t be used with modular subsystems , since they <nl> * need to register a subsys_id , among other things */ <nl> BUG_ON ( ss -> module );
static const struct snd_soc_dapm_widget rt5659_dapm_widgets [] = { <nl> RT5659_PWR_ADC_L1_BIT , 0 , NULL , 0 ), <nl> SND_SOC_DAPM_SUPPLY (" ADC1 R Power ", RT5659_PWR_DIG_1 , <nl> RT5659_PWR_ADC_R1_BIT , 0 , NULL , 0 ), <nl> - SND_SOC_DAPM_SUPPLY (" ADC2 L Power ", RT5659_PWR_DIG_2 , <nl> + SND_SOC_DAPM_SUPPLY (" ADC2 L Power ", RT5659_PWR_DIG_1 , <nl> RT5659_PWR_ADC_L2_BIT , 0 , NULL , 0 ), <nl> - SND_SOC_DAPM_SUPPLY (" ADC2 R Power ", RT5659_PWR_DIG_2 , <nl> + SND_SOC_DAPM_SUPPLY (" ADC2 R Power ", RT5659_PWR_DIG_1 , <nl> RT5659_PWR_ADC_R2_BIT , 0 , NULL , 0 ), <nl> SND_SOC_DAPM_SUPPLY (" ADC1 clock ", SND_SOC_NOPM , 0 , 0 , set_adc_clk , <nl> SND_SOC_DAPM_POST_PMU | SND_SOC_DAPM_PRE_PMD ),
static int sdhci_st_probe ( struct platform_device * pdev ) <nl> if ( IS_ERR ( icnclk )) <nl> icnclk = NULL ; <nl>  <nl> - rstc = devm_reset_control_get (& pdev -> dev , NULL ); <nl> + rstc = devm_reset_control_get_exclusive (& pdev -> dev , NULL ); <nl> if ( IS_ERR ( rstc )) <nl> rstc = NULL ; <nl> else
static int sc16is7xx_probe ( struct device * dev , <nl> else <nl> return PTR_ERR ( s -> clk ); <nl> } else { <nl> + clk_prepare_enable ( s -> clk ); <nl> freq = clk_get_rate ( s -> clk ); <nl> } <nl> 
int kvm_timer_enable ( struct kvm_vcpu * vcpu ) <nl> return ret ; <nl>  <nl> no_vgic : <nl> + preempt_disable (); <nl> timer -> enabled = 1 ; <nl> + kvm_timer_vcpu_load_vgic ( vcpu ); <nl> + preempt_enable (); <nl> + <nl> return 0 ; <nl> } <nl> 
static void raise_dtr ( struct isi_port * port ) <nl> } <nl>  <nl> /* card -> lock HAS to be held */ <nl> - static inline void drop_dtr ( struct isi_port * port ) <nl> + static void drop_dtr ( struct isi_port * port ) <nl> { <nl> struct isi_board * card = port -> card ; <nl> unsigned long base = card -> base ;
static void pvr2_hdw_state_log_state ( struct pvr2_hdw * hdw ) <nl> printk ( KERN_INFO "% s %.* s \ n ", hdw -> name , ccnt , buf ); <nl> } <nl> ccnt = pvr2_hdw_report_clients ( hdw , buf , sizeof ( buf )); <nl> + if ( ccnt >= sizeof ( buf )) <nl> + ccnt = sizeof ( buf ); <nl> + <nl> ucnt = 0 ; <nl> while ( ucnt < ccnt ) { <nl> lcnt = 0 ;
static int tegra_pcie_probe ( struct platform_device * pdev ) <nl> struct pci_bus * child ; <nl> int err ; <nl>  <nl> - host = pci_alloc_host_bridge ( sizeof (* pcie )); <nl> + host = devm_pci_alloc_host_bridge ( dev , sizeof (* pcie )); <nl> if (! host ) <nl> return - ENOMEM ; <nl> 
static void memcpy16_toio ( void __iomem * trg , const void * src , int size ) <nl> * holds a page in natural order , i . e . writesize bytes data + oobsize bytes <nl> * spare ) and the NFC buffer . <nl> */ <nl> - static void copy_spare ( struct mtd_info * mtd , bool bfrom ) <nl> + static void copy_spare ( struct mtd_info * mtd , bool bfrom , void * buf ) <nl> { <nl> struct nand_chip * this = mtd_to_nand ( mtd ); <nl> struct mxc_nand_host * host = nand_get_controller_data ( this ); <nl> u16 i , oob_chunk_size ; <nl> u16 num_chunks = mtd -> writesize / 512 ; <nl>  <nl> - u8 * d = host -> data_buf + mtd -> writesize ; <nl> + u8 * d = buf ; <nl> u8 __iomem * s = host -> spare0 ; <nl> u16 sparebuf_size = host -> devtype_data -> spare_len ; <nl>  <nl> static void mxc_nand_command ( struct mtd_info * mtd , unsigned command , <nl>  <nl> memcpy32_fromio ( host -> data_buf , host -> main_area0 , <nl> mtd -> writesize ); <nl> - copy_spare ( mtd , true ); <nl> + copy_spare ( mtd , true , host -> data_buf + mtd -> writesize ); <nl> break ; <nl>  <nl> case NAND_CMD_SEQIN : <nl> static void mxc_nand_command ( struct mtd_info * mtd , unsigned command , <nl>  <nl> case NAND_CMD_PAGEPROG : <nl> memcpy32_toio ( host -> main_area0 , host -> data_buf , mtd -> writesize ); <nl> - copy_spare ( mtd , false ); <nl> + copy_spare ( mtd , false , host -> data_buf + mtd -> writesize ); <nl> host -> devtype_data -> send_page ( mtd , NFC_INPUT ); <nl> host -> devtype_data -> send_cmd ( host , command , true ); <nl> WARN_ONCE ( column != - 1 || page_addr != - 1 ,
static struct file_system_type proc_fs_type = { <nl>  <nl> void __init proc_root_init ( void ) <nl> { <nl> - struct vfsmount * mnt ; <nl> int err ; <nl>  <nl> proc_init_inodecache (); <nl> err = register_filesystem (& proc_fs_type ); <nl> if ( err ) <nl> return ; <nl> - mnt = kern_mount_data (& proc_fs_type , & init_pid_ns ); <nl> - if ( IS_ERR ( mnt )) { <nl> + err = pid_ns_prepare_proc (& init_pid_ns ); <nl> + if ( err ) { <nl> unregister_filesystem (& proc_fs_type ); <nl> return ; <nl> } <nl>  <nl> - init_pid_ns . proc_mnt = mnt ; <nl> proc_symlink (" mounts ", NULL , " self / mounts "); <nl>  <nl> proc_net_init (); <nl> int pid_ns_prepare_proc ( struct pid_namespace * ns ) <nl>  <nl> void pid_ns_release_proc ( struct pid_namespace * ns ) <nl> { <nl> - mntput ( ns -> proc_mnt ); <nl> + kern_unmount ( ns -> proc_mnt ); <nl> }
MODULE_DEVICE_TABLE ( pci , epca_pci_tbl ); <nl> int __init init_PCI ( void ) <nl> { /* Begin init_PCI */ <nl> memset (& epca_driver , 0 , sizeof ( epca_driver )); <nl> + epca_driver . owner = THIS_MODULE ; <nl> epca_driver . name = " epca "; <nl> epca_driver . id_table = epca_pci_tbl ; <nl> epca_driver . probe = epca_init_one ;
 <nl> # define DAS08JR_DI_REG 0x03 /* ( R ) digital inputs (" JR " boards ) */ <nl> # define DAS08JR_DO_REG 0x03 /* ( W ) digital outputs (" JR " boards ) */ <nl> -# define DAS08JR_AO_LSB ( x ) (( x ) ? 6 : 4 ) <nl> -# define DAS08JR_AO_MSB ( x ) (( x ) ? 7 : 5 ) <nl> +/* ( W ) analog output l . s . b . registers for 2 channels (" JR " boards ) */ <nl> +# define DAS08JR_AO_LSB_REG ( x ) (( x ) ? 0x06 : 0x04 ) <nl> +/* ( W ) analog output m . s . b . registers for 2 channels (" JR " boards ) */ <nl> +# define DAS08JR_AO_MSB_REG ( x ) (( x ) ? 0x07 : 0x05 ) <nl>  <nl> /* <nl> cio - das08_aox . pdf <nl> static void das08_ao_set_data ( struct comedi_device * dev , <nl> lsb = data & 0xff ; <nl> msb = ( data >> 8 ) & 0xff ; <nl> if ( thisboard -> is_jr ) { <nl> - outb ( lsb , dev -> iobase + DAS08JR_AO_LSB ( chan )); <nl> - outb ( msb , dev -> iobase + DAS08JR_AO_MSB ( chan )); <nl> + outb ( lsb , dev -> iobase + DAS08JR_AO_LSB_REG ( chan )); <nl> + outb ( msb , dev -> iobase + DAS08JR_AO_MSB_REG ( chan )); <nl> /* load DACs */ <nl> inb ( dev -> iobase + DAS08JR_DI_REG ); <nl> } else {
static int __init nbd_init ( void ) <nl> if ( max_part > 0 ) <nl> part_shift = fls ( max_part ); <nl>  <nl> + if (( 1UL << part_shift ) > DISK_MAX_PARTS ) <nl> + return - EINVAL ; <nl> + <nl> + if ( nbds_max > 1UL << ( MINORBITS - part_shift )) <nl> + return - EINVAL ; <nl> + <nl> for ( i = 0 ; i < nbds_max ; i ++) { <nl> struct gendisk * disk = alloc_disk ( 1 << part_shift ); <nl> if (! disk )
int host_int_set_wep_default_key ( struct host_if_drv * hif_drv , u8 index ); <nl> * @ date 8 March 2012 <nl> * @ version 1 . 0 <nl> */ <nl> - int host_int_add_wep_key_bss_sta ( struct host_if_drv * hWFIDrv , const u8 * pu8WepKey , u8 u8WepKeylen , u8 u8Keyidx ); <nl> + int host_int_add_wep_key_bss_sta ( struct host_if_drv * hif_drv , const u8 * pu8WepKey , u8 u8WepKeylen , u8 u8Keyidx ); <nl> /** <nl> * @ brief host_int_add_wep_key_bss_ap <nl> * @ details valid only in AP mode if External Supplicant support is enabled .
void wake_up_new_task ( struct task_struct * p ) <nl> struct rq * rq ; <nl>  <nl> raw_spin_lock_irqsave (& p -> pi_lock , flags ); <nl> + /* Initialize new task ' s runnable average */ <nl> + init_entity_runnable_average (& p -> se ); <nl> # ifdef CONFIG_SMP <nl> /* <nl> * Fork balancing , do it here and not earlier because : <nl> void wake_up_new_task ( struct task_struct * p ) <nl> set_task_cpu ( p , select_task_rq ( p , task_cpu ( p ), SD_BALANCE_FORK , 0 )); <nl> # endif <nl>  <nl> - /* Initialize new task ' s runnable average */ <nl> - init_entity_runnable_average (& p -> se ); <nl> rq = __task_rq_lock ( p ); <nl> activate_task ( rq , p , 0 ); <nl> p -> on_rq = TASK_ON_RQ_QUEUED ;
static int find_data_references ( struct reloc_control * rc , <nl> } <nl>  <nl> key . objectid = ref_objectid ; <nl> - key . offset = ref_offset ; <nl> key . type = BTRFS_EXTENT_DATA_KEY ; <nl> + if ( ref_offset > (( u64 )- 1 << 32 )) <nl> + key . offset = 0 ; <nl> + else <nl> + key . offset = ref_offset ; <nl>  <nl> path -> search_commit_root = 1 ; <nl> path -> skip_locking = 1 ;
int iptunnel_xmit ( struct sock * sk , struct rtable * rt , struct sk_buff * skb , <nl> __be32 src , __be32 dst , __u8 proto , <nl> __u8 tos , __u8 ttl , __be16 df , bool xnet ) <nl> { <nl> - int pkt_len = skb -> len ; <nl> + int pkt_len = skb -> len - skb_inner_network_offset ( skb ); <nl> struct iphdr * iph ; <nl> int err ; <nl> 
int mmc_send_if_cond ( struct mmc_host * host , u32 ocr ) <nl> static const u8 test_pattern = 0xAA ; <nl> u8 result_pattern ; <nl>  <nl> + memset (& cmd , 0 , sizeof ( struct mmc_command )); <nl> + <nl> /* <nl> * To support SD 2 . 0 cards , we must always invoke SD_SEND_IF_COND <nl> * before SD_APP_OP_COND . This command will harmlessly fail for
static void picolcd_debug_out_report ( struct picolcd_data * data , <nl> report -> id , raw_size ); <nl> hid_debug_event ( hdev , buff ); <nl> if ( raw_size + 5 > sizeof ( raw_data )) { <nl> + kfree ( buff ); <nl> hid_debug_event ( hdev , " TOO BIG \ n "); <nl> return ; <nl> } else {
static int create_trace_uprobe ( int argc , char ** argv ) <nl> goto fail_address_parse ; <nl>  <nl> inode = igrab ( path . dentry -> d_inode ); <nl> + if (! S_ISREG ( inode -> i_mode )) { <nl> + ret = - EINVAL ; <nl> + goto fail_address_parse ; <nl> + } <nl>  <nl> argc -= 2 ; <nl> argv += 2 ; <nl> static int create_trace_uprobe ( int argc , char ** argv ) <nl> if ( inode ) <nl> iput ( inode ); <nl>  <nl> - pr_info (" Failed to parse address .\ n "); <nl> + pr_info (" Failed to parse address or file .\ n "); <nl>  <nl> return ret ; <nl> }
ips_link_to_i915_driver ( void ) <nl> EXPORT_SYMBOL_GPL ( ips_link_to_i915_driver ); <nl>  <nl> static const struct pci_device_id ips_id_table [] = { <nl> - { PCI_DEVICE ( PCI_VENDOR_ID_INTEL , <nl> - PCI_DEVICE_ID_INTEL_THERMAL_SENSOR ), }, <nl> + { PCI_VDEVICE ( INTEL , PCI_DEVICE_ID_INTEL_THERMAL_SENSOR ), }, <nl> { 0 , } <nl> }; <nl> 
void dlm_add_cb ( struct dlm_lkb * lkb , uint32_t flags , int mode , int status , <nl>  <nl> spin_lock (& dlm_cb_seq_spin ); <nl> new_seq = ++ dlm_cb_seq ; <nl> + if (! dlm_cb_seq ) <nl> + new_seq = ++ dlm_cb_seq ; <nl> spin_unlock (& dlm_cb_seq_spin ); <nl>  <nl> if ( lkb -> lkb_flags & DLM_IFL_USER ) {
int usbatm_usb_probe ( struct usb_interface * intf , const struct usb_device_id * id , <nl> struct usb_device * usb_dev = interface_to_usbdev ( intf ); <nl> struct usbatm_data * instance ; <nl> char * buf ; <nl> + size_t instance_size = sizeof (* instance ) + sizeof ( struct urb *) * ( num_rcv_urbs + num_snd_urbs ); <nl> int error = - ENOMEM ; <nl> int i , length ; <nl> int need_heavy ; <nl> int usbatm_usb_probe ( struct usb_interface * intf , const struct usb_device_id * id , <nl> intf -> altsetting -> desc . bInterfaceNumber ); <nl>  <nl> /* instance init */ <nl> - instance = kmalloc ( sizeof (* instance ) + sizeof ( struct urb *) * ( num_rcv_urbs + num_snd_urbs ), <nl> - GFP_KERNEL ); <nl> + instance = kmalloc ( instance_size , GFP_KERNEL ); <nl> if (! instance ) { <nl> dev_dbg ( dev , "% s : no memory for instance data !\ n ", __func__ ); <nl> return - ENOMEM ; <nl> } <nl>  <nl> - memset ( instance , 0 , sizeof (* instance )); <nl> + memset ( instance , 0 , instance_size ); <nl>  <nl> /* public fields */ <nl>  <nl> int usbatm_usb_probe ( struct usb_interface * intf , const struct usb_device_id * id , <nl> goto fail_unbind ; <nl> } <nl>  <nl> + instance -> urbs [ i ] = urb ; <nl> + <nl> buffer = kmalloc ( channel -> buf_size , GFP_KERNEL ); <nl> if (! buffer ) { <nl> dev_dbg ( dev , "% s : no memory for buffer % d !\ n ", __func__ , i ); <nl> int usbatm_usb_probe ( struct usb_interface * intf , const struct usb_device_id * id , <nl>  <nl> vdbg ("% s : alloced buffer 0x % p buf size % u urb 0x % p ", <nl> __func__ , urb -> transfer_buffer , urb -> transfer_buffer_length , urb ); <nl> - instance -> urbs [ i ] = urb ; <nl> } <nl>  <nl> if ( need_heavy && driver -> heavy_init ) {
static int prealloc_file_range ( struct inode * inode , u64 start , u64 end , <nl> inode -> i_ctime = CURRENT_TIME ; <nl> BTRFS_I ( inode )-> flags |= BTRFS_INODE_PREALLOC ; <nl> if (!( mode & FALLOC_FL_KEEP_SIZE ) && <nl> - cur_offset > inode -> i_size ) { <nl> + ( actual_len > inode -> i_size ) && <nl> + ( cur_offset > inode -> i_size )) { <nl> + <nl> if ( cur_offset > actual_len ) <nl> i_size = actual_len ; <nl> else
# ifndef __SUN3_MMU_H__ <nl> # define __SUN3_MMU_H__ <nl>  <nl> +# include < linux / types . h > <nl> # include < asm / movs . h > <nl> # include < asm / sun3 - head . h > <nl>  <nl> static inline void sun3_put_context ( unsigned char c ) <nl> return ; <nl> } <nl>  <nl> - extern void * sun3_ioremap ( unsigned long phys , unsigned long size , <nl> + extern void __iomem * sun3_ioremap ( unsigned long phys , unsigned long size , <nl> unsigned long type ); <nl>  <nl> extern int sun3_map_test ( unsigned long addr , char * val );
struct reg_beacon { <nl> struct ieee80211_channel chan ; <nl> }; <nl>  <nl> + static void reg_todo ( struct work_struct * work ); <nl> + static DECLARE_WORK ( reg_work , reg_todo ); <nl> + <nl> /* We keep a static world regulatory domain in case of the absence of CRDA */ <nl> static const struct ieee80211_regdomain world_regdom = { <nl> . n_reg_rules = 5 , <nl> static void reg_todo ( struct work_struct * work ) <nl> reg_process_pending_beacon_hints (); <nl> } <nl>  <nl> - static DECLARE_WORK ( reg_work , reg_todo ); <nl> - <nl> static void queue_regulatory_request ( struct regulatory_request * request ) <nl> { <nl> if ( isalpha ( request -> alpha2 [ 0 ]))
void __key_link_end ( struct key * keyring , <nl> if ( index_key -> type == & key_type_keyring ) <nl> up_write (& keyring_serialise_link_sem ); <nl>  <nl> - if ( edit && ! edit -> dead_leaf ) { <nl> - key_payload_reserve ( keyring , <nl> - keyring -> datalen - KEYQUOTA_LINK_BYTES ); <nl> + if ( edit ) { <nl> + if (! edit -> dead_leaf ) { <nl> + key_payload_reserve ( keyring , <nl> + keyring -> datalen - KEYQUOTA_LINK_BYTES ); <nl> + } <nl> assoc_array_cancel_edit ( edit ); <nl> } <nl> up_write (& keyring -> sem );
unsigned long perf_instruction_pointer ( struct pt_regs * regs ) <nl> bool use_siar = regs_use_siar ( regs ); <nl> unsigned long siar = mfspr ( SPRN_SIAR ); <nl>  <nl> - if ( ppmu -> flags & PPMU_P10_DD1 ) { <nl> + if ( ppmu && ( ppmu -> flags & PPMU_P10_DD1 )) { <nl> if ( siar ) <nl> return siar ; <nl> else
int venus_readlink ( struct super_block * sb , struct CodaFid * fid , <nl> char * result ; <nl>  <nl> insize = max_t ( unsigned int , <nl> - INSIZE ( readlink ), OUTSIZE ( readlink )+ * length + 1 ); <nl> + INSIZE ( readlink ), OUTSIZE ( readlink )+ * length ); <nl> UPARG ( CODA_READLINK ); <nl>  <nl> inp -> coda_readlink . VFid = * fid ; <nl> int venus_readlink ( struct super_block * sb , struct CodaFid * fid , <nl> error = coda_upcall ( coda_vcp ( sb ), insize , & outsize , inp ); <nl> if (! error ) { <nl> retlen = outp -> coda_readlink . count ; <nl> - if ( retlen > * length ) <nl> - retlen = * length ; <nl> + if ( retlen >= * length ) <nl> + retlen = * length - 1 ; <nl> * length = retlen ; <nl> result = ( char *) outp + ( long ) outp -> coda_readlink . data ; <nl> memcpy ( buffer , result , retlen );
ip_vs_new_dest ( struct ip_vs_service * svc , struct ip_vs_dest_user_kern * udest , <nl> # ifdef CONFIG_IP_VS_IPV6 <nl> if ( svc -> af == AF_INET6 ) { <nl> atype = ipv6_addr_type (& udest -> addr . in6 ); <nl> - if (!( atype & IPV6_ADDR_UNICAST ) && <nl> + if ((!( atype & IPV6_ADDR_UNICAST ) || <nl> + atype & IPV6_ADDR_LINKLOCAL ) && <nl> ! __ip_vs_addr_is_local_v6 (& udest -> addr . in6 )) <nl> return - EINVAL ; <nl> } else
void qla4xxx_free_ddb_index ( struct scsi_qla_host * ha ) <nl> ret = qla4xxx_get_fwddb_entry ( ha , idx , NULL , 0 , NULL , <nl> & next_idx , & state , & conn_err , <nl> NULL , NULL ); <nl> - if ( ret == QLA_ERROR ) <nl> + if ( ret == QLA_ERROR ) { <nl> + next_idx ++; <nl> continue ; <nl> + } <nl> if ( state == DDB_DS_NO_CONNECTION_ACTIVE || <nl> state == DDB_DS_SESSION_FAILED ) { <nl> DEBUG2 ( ql4_printk ( KERN_INFO , ha ,
static int ftrace_convert_nops ( struct module * mod , <nl> p = start ; <nl> while ( p < end ) { <nl> addr = ftrace_call_adjust (* p ++); <nl> + /* <nl> + * Some architecture linkers will pad between <nl> + * the different mcount_loc sections of different <nl> + * object files to satisfy alignments . <nl> + * Skip any NULL pointers . <nl> + */ <nl> + if (! addr ) <nl> + continue ; <nl> ftrace_record_ip ( addr ); <nl> } <nl> 
# include < linux / llc . h > <nl> # include < net / llc . h > <nl> # include < net / llc_pdu . h > <nl> +# include < asm / unaligned . h > <nl>  <nl> # include " br_private . h " <nl> # include " br_private_stp . h " <nl> static inline void br_set_ticks ( unsigned char * dest , int j ) <nl> { <nl> unsigned long ticks = ( STP_HZ * j )/ HZ ; <nl>  <nl> - *(( __be16 *) dest ) = htons ( ticks ); <nl> + put_unaligned ( htons ( ticks ), ( __be16 *) dest ); <nl> } <nl>  <nl> static inline int br_get_ticks ( const unsigned char * src ) <nl> { <nl> - unsigned long ticks = ntohs (*( __be16 *) src ); <nl> + unsigned long ticks = ntohs ( get_unaligned (( __be16 *) src )); <nl>  <nl> return ( ticks * HZ + STP_HZ - 1 ) / STP_HZ ; <nl> }
static int imx_ssi_probe ( struct platform_device * pdev ) <nl> } <nl>  <nl> ssi -> irq = platform_get_irq ( pdev , 0 ); <nl> + if ( ssi -> irq < 0 ) { <nl> + dev_err (& pdev -> dev , " Failed to get IRQ : % d \ n ", ssi -> irq ); <nl> + return ssi -> irq ; <nl> + } <nl>  <nl> ssi -> clk = devm_clk_get (& pdev -> dev , NULL ); <nl> if ( IS_ERR ( ssi -> clk )) {
static inline void nested_release_vmcs12 ( struct vcpu_vmx * vmx ) <nl> */ <nl> static void free_nested ( struct vcpu_vmx * vmx ) <nl> { <nl> - if (! vmx -> nested . vmxon ) <nl> + if (! vmx -> nested . vmxon && ! vmx -> nested . smm . vmxon ) <nl> return ; <nl>  <nl> vmx -> nested . vmxon = false ; <nl> + vmx -> nested . smm . vmxon = false ; <nl> free_vpid ( vmx -> nested . vpid02 ); <nl> vmx -> nested . posted_intr_nv = - 1 ; <nl> vmx -> nested . current_vmptr = - 1ull ;
static int wl1271_dev_notify ( struct notifier_block * me , unsigned long what , <nl>  <nl> wdev = dev -> ieee80211_ptr ; <nl> if ( wdev == NULL ) <nl> - return - ENODEV ; <nl> + return NOTIFY_DONE ; <nl>  <nl> wiphy = wdev -> wiphy ; <nl> if ( wiphy == NULL ) <nl> - return - ENODEV ; <nl> + return NOTIFY_DONE ; <nl>  <nl> hw = wiphy_priv ( wiphy ); <nl> if ( hw == NULL ) <nl> - return - ENODEV ; <nl> + return NOTIFY_DONE ; <nl>  <nl> /* Check that the interface is one supported by this driver . */ <nl> wl_temp = hw -> priv ; <nl> static int wl1271_dev_notify ( struct notifier_block * me , unsigned long what , <nl> break ; <nl> } <nl> if ( wl == NULL ) <nl> - return - ENODEV ; <nl> + return NOTIFY_DONE ; <nl>  <nl> /* Get the interface IP address for the device . " ifa " will become <nl> NULL if : <nl> static int wl1271_dev_notify ( struct notifier_block * me , unsigned long what , <nl> out : <nl> mutex_unlock (& wl -> mutex ); <nl>  <nl> - return ret ; <nl> + return NOTIFY_OK ; <nl> } <nl>  <nl> static struct notifier_block wl1271_dev_notifier = {
static int nested_vmx_check_guest_state ( struct kvm_vcpu * vcpu , <nl> struct vmcs12 * vmcs12 , <nl> enum vm_entry_failure_code * entry_failure_code ) <nl> { <nl> - bool ia32e ; <nl> + bool ia32e = !!( vmcs12 -> vm_entry_controls & VM_ENTRY_IA32E_MODE ); <nl>  <nl> * entry_failure_code = ENTRY_FAIL_DEFAULT ; <nl>  <nl> static int nested_vmx_check_guest_state ( struct kvm_vcpu * vcpu , <nl> vmcs12 -> guest_ia32_perf_global_ctrl ))) <nl> return - EINVAL ; <nl>  <nl> + if ( CC (( vmcs12 -> guest_cr0 & ( X86_CR0_PG | X86_CR0_PE )) == X86_CR0_PG )) <nl> + return - EINVAL ; <nl> + <nl> + if ( CC ( ia32e && !( vmcs12 -> guest_cr4 & X86_CR4_PAE )) || <nl> + CC ( ia32e && !( vmcs12 -> guest_cr0 & X86_CR0_PG ))) <nl> + return - EINVAL ; <nl> + <nl> /* <nl> * If the load IA32_EFER VM - entry control is 1 , the following checks <nl> * are performed on the field for the IA32_EFER MSR : <nl> static int nested_vmx_check_guest_state ( struct kvm_vcpu * vcpu , <nl> */ <nl> if ( to_vmx ( vcpu )-> nested . nested_run_pending && <nl> ( vmcs12 -> vm_entry_controls & VM_ENTRY_LOAD_IA32_EFER )) { <nl> - ia32e = ( vmcs12 -> vm_entry_controls & VM_ENTRY_IA32E_MODE ) != 0 ; <nl> if ( CC (! kvm_valid_efer ( vcpu , vmcs12 -> guest_ia32_efer )) || <nl> CC ( ia32e != !!( vmcs12 -> guest_ia32_efer & EFER_LMA )) || <nl> CC ((( vmcs12 -> guest_cr0 & X86_CR0_PG ) &&
static int mqueue_create ( struct inode * dir , struct dentry * dentry , <nl> error = - EACCES ; <nl> goto out_unlock ; <nl> } <nl> - if ( ipc_ns -> mq_queues_count >= ipc_ns -> mq_queues_max && <nl> - ! capable ( CAP_SYS_RESOURCE )) { <nl> + if ( ipc_ns -> mq_queues_count >= HARD_QUEUESMAX || <nl> + ( ipc_ns -> mq_queues_count >= ipc_ns -> mq_queues_max && <nl> + ! capable ( CAP_SYS_RESOURCE ))) { <nl> error = - ENOSPC ; <nl> goto out_unlock ; <nl> } <nl> static int mq_attr_ok ( struct ipc_namespace * ipc_ns , struct mq_attr * attr ) <nl> if ( attr -> mq_maxmsg <= 0 || attr -> mq_msgsize <= 0 ) <nl> return 0 ; <nl> if ( capable ( CAP_SYS_RESOURCE )) { <nl> - if ( attr -> mq_maxmsg > HARD_MSGMAX ) <nl> + if ( attr -> mq_maxmsg > HARD_MSGMAX || <nl> + attr -> mq_msgsize > HARD_MSGSIZEMAX ) <nl> return 0 ; <nl> } else { <nl> if ( attr -> mq_maxmsg > ipc_ns -> mq_msg_max ||
struct kmem_cache * btrfs_delayed_extent_op_cachep ; <nl> * compare two delayed tree backrefs with same bytenr and type <nl> */ <nl> static int comp_tree_refs ( struct btrfs_delayed_tree_ref * ref2 , <nl> - struct btrfs_delayed_tree_ref * ref1 , int type ) <nl> + struct btrfs_delayed_tree_ref * ref1 ) <nl> { <nl> - if ( type == BTRFS_TREE_BLOCK_REF_KEY ) { <nl> + if ( ref1 -> node . type == BTRFS_TREE_BLOCK_REF_KEY ) { <nl> if ( ref1 -> root < ref2 -> root ) <nl> return - 1 ; <nl> if ( ref1 -> root > ref2 -> root ) <nl> static bool merge_ref ( struct btrfs_trans_handle * trans , <nl> if (( ref -> type == BTRFS_TREE_BLOCK_REF_KEY || <nl> ref -> type == BTRFS_SHARED_BLOCK_REF_KEY ) && <nl> comp_tree_refs ( btrfs_delayed_node_to_tree_ref ( ref ), <nl> - btrfs_delayed_node_to_tree_ref ( next ), <nl> - ref -> type )) <nl> + btrfs_delayed_node_to_tree_ref ( next ))) <nl> goto next ; <nl> if (( ref -> type == BTRFS_EXTENT_DATA_REF_KEY || <nl> ref -> type == BTRFS_SHARED_DATA_REF_KEY ) && <nl> add_delayed_ref_tail_merge ( struct btrfs_trans_handle * trans , <nl> if (( exist -> type == BTRFS_TREE_BLOCK_REF_KEY || <nl> exist -> type == BTRFS_SHARED_BLOCK_REF_KEY ) && <nl> comp_tree_refs ( btrfs_delayed_node_to_tree_ref ( exist ), <nl> - btrfs_delayed_node_to_tree_ref ( ref ), <nl> - ref -> type )) <nl> + btrfs_delayed_node_to_tree_ref ( ref ))) <nl> goto add_tail ; <nl> if (( exist -> type == BTRFS_EXTENT_DATA_REF_KEY || <nl> exist -> type == BTRFS_SHARED_DATA_REF_KEY ) &&
struct usb_function * ecm_alloc ( struct usb_function_instance * fi ) <nl> sizeof ( ecm -> ethaddr )); <nl> if ( status < 12 ) { <nl> kfree ( ecm ); <nl> + mutex_unlock (& opts -> lock ); <nl> return ERR_PTR (- EINVAL ); <nl> } <nl> ecm_string_defs [ 1 ]. s = ecm -> ethaddr ;
int mei_cl_disconnect ( struct mei_cl * cl ) <nl> cl_err ( dev , cl , " failed to disconnect .\ n "); <nl> goto free ; <nl> } <nl> + cl -> timer_count = MEI_CONNECT_TIMEOUT ; <nl> mdelay ( 10 ); /* Wait for hardware disconnection ready */ <nl> list_add_tail (& cb -> list , & dev -> ctrl_rd_list . list ); <nl> } else {
static int ttm_page_pool_free ( struct ttm_page_pool * pool , unsigned nr_free ) <nl> static unsigned long <nl> ttm_pool_shrink_scan ( struct shrinker * shrink , struct shrink_control * sc ) <nl> { <nl> - static atomic_t start_pool = ATOMIC_INIT ( 0 ); <nl> + static DEFINE_MUTEX ( lock ); <nl> + static unsigned start_pool ; <nl> unsigned i ; <nl> - unsigned pool_offset = atomic_add_return ( 1 , & start_pool ); <nl> + unsigned pool_offset ; <nl> struct ttm_page_pool * pool ; <nl> int shrink_pages = sc -> nr_to_scan ; <nl> unsigned long freed = 0 ; <nl>  <nl> - pool_offset = pool_offset % NUM_POOLS ; <nl> + if (! mutex_trylock (& lock )) <nl> + return SHRINK_STOP ; <nl> + pool_offset = ++ start_pool % NUM_POOLS ; <nl> /* select start pool in round robin fashion */ <nl> for ( i = 0 ; i < NUM_POOLS ; ++ i ) { <nl> unsigned nr_free = shrink_pages ; <nl> ttm_pool_shrink_scan ( struct shrinker * shrink , struct shrink_control * sc ) <nl> shrink_pages = ttm_page_pool_free ( pool , nr_free ); <nl> freed += nr_free - shrink_pages ; <nl> } <nl> + mutex_unlock (& lock ); <nl> return freed ; <nl> } <nl> 
build_unc_path_to_root ( const struct smb_vol * vol , <nl> pos = full_path + unc_len ; <nl>  <nl> if ( pplen ) { <nl> - * pos ++ = CIFS_DIR_SEP ( cifs_sb ); <nl> - strncpy ( pos , vol -> prepath , pplen ); <nl> + * pos = CIFS_DIR_SEP ( cifs_sb ); <nl> + strncpy ( pos + 1 , vol -> prepath , pplen ); <nl> pos += pplen ; <nl> } <nl> 
cfg80211_inform_bss_frame ( struct wiphy * wiphy , <nl> return NULL ; <nl>  <nl> if ( WARN_ON ( wiphy -> signal_type == CFG80211_SIGNAL_TYPE_UNSPEC && <nl> - ( signal < 0 || signal > 100 ))) <nl> + ( signal < 0 || signal > 100 ))) <nl> return NULL ; <nl>  <nl> if ( WARN_ON ( len < offsetof ( struct ieee80211_mgmt , u . probe_resp . variable )))
static int goldfish_audio_probe ( struct platform_device * pdev ) <nl> platform_set_drvdata ( pdev , data ); <nl>  <nl> r = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> - if ( r == NULL ) { <nl> + if (! r ) { <nl> dev_err (& pdev -> dev , " platform_get_resource failed \ n "); <nl> return - ENODEV ; <nl> } <nl> data -> reg_base = devm_ioremap (& pdev -> dev , r -> start , PAGE_SIZE ); <nl> - if ( data -> reg_base == NULL ) <nl> + if (! data -> reg_base ) <nl> return - ENOMEM ; <nl>  <nl> data -> irq = platform_get_irq ( pdev , 0 ); <nl> static int goldfish_audio_probe ( struct platform_device * pdev ) <nl> } <nl> data -> buffer_virt = dmam_alloc_coherent (& pdev -> dev , <nl> COMBINED_BUFFER_SIZE , & buf_addr , GFP_KERNEL ); <nl> - if ( data -> buffer_virt == NULL ) { <nl> + if (! data -> buffer_virt ) { <nl> dev_err (& pdev -> dev , " allocate buffer failed \ n "); <nl> return - ENOMEM ; <nl> }
int batadv_bla_tx ( struct batadv_priv * bat_priv , struct sk_buff * skb , <nl> if (! atomic_read (& bat_priv -> bridge_loop_avoidance )) <nl> goto allow ; <nl>  <nl> - /* in VLAN case , the mac header might not be set . */ <nl> - skb_reset_mac_header ( skb ); <nl> - <nl> if ( batadv_bla_process_claim ( bat_priv , primary_if , skb )) <nl> goto handled ; <nl> 
static inline void nfs4_stateid_downgrade ( struct nfs4_ol_stateid * stp , u32 to_ac <nl> } <nl>  <nl> static void <nl> - reset_union_bmap_deny ( unsigned long deny , struct nfs4_ol_stateid * stp ) <nl> + reset_union_bmap_deny ( u32 deny , struct nfs4_ol_stateid * stp ) <nl> { <nl> int i ; <nl> - for ( i = 0 ; i < 4 ; i ++) { <nl> + <nl> + for ( i = 1 ; i < 4 ; i ++) { <nl> if (( i & deny ) != i ) <nl> clear_deny ( i , stp ); <nl> }
static int enc_post_frame_start ( struct s5p_mfc_ctx * ctx ) <nl> { <nl> struct s5p_mfc_dev * dev = ctx -> dev ; <nl> struct s5p_mfc_buf * mb_entry ; <nl> - unsigned long enc_y_addr , enc_c_addr ; <nl> + unsigned long enc_y_addr = 0 , enc_c_addr = 0 ; <nl> unsigned long mb_y_addr , mb_c_addr ; <nl> int slice_type ; <nl> unsigned int strm_size ;
static void isd200_ata_command ( struct scsi_cmnd * srb , struct us_data * us ) <nl>  <nl> /* Make sure driver was initialized */ <nl>  <nl> - if ( us -> extra == NULL ) <nl> + if ( us -> extra == NULL ) { <nl> usb_stor_dbg ( us , " ERROR Driver not initialized \ n "); <nl> + srb -> result = DID_ERROR << 16 ; <nl> + return ; <nl> + } <nl>  <nl> scsi_set_resid ( srb , 0 ); <nl> /* scsi_bufflen might change in protocol translation to ata */
static struct rds_connection * __rds_conn_create ( struct net * net , <nl> } <nl> } <nl>  <nl> + if ( trans == NULL ) { <nl> + kmem_cache_free ( rds_conn_slab , conn ); <nl> + conn = ERR_PTR (- ENODEV ); <nl> + goto out ; <nl> + } <nl> + <nl> conn -> c_trans = trans ; <nl>  <nl> ret = trans -> conn_alloc ( conn , gfp );
static int bcm_delete_rx_op ( struct list_head * ops , struct bcm_msg_head * mh , <nl> bcm_rx_handler , op ); <nl>  <nl> list_del (& op -> list ); <nl> + synchronize_rcu (); <nl> bcm_remove_op ( op ); <nl> return 1 ; /* done */ <nl> } <nl> static int bcm_release ( struct socket * sock ) <nl> REGMASK ( op -> can_id ), <nl> bcm_rx_handler , op ); <nl>  <nl> - bcm_remove_op ( op ); <nl> } <nl>  <nl> + synchronize_rcu (); <nl> + <nl> + list_for_each_entry_safe ( op , next , & bo -> rx_ops , list ) <nl> + bcm_remove_op ( op ); <nl> + <nl> # if IS_ENABLED ( CONFIG_PROC_FS ) <nl> /* remove procfs entry */ <nl> if ( net -> can . bcmproc_dir && bo -> bcm_proc_read )
isdn_net_setcfg ( isdn_net_ioctl_cfg * cfg ) <nl> char * c , <nl> * e ; <nl>  <nl> + if ( strnlen ( cfg -> drvid , sizeof ( cfg -> drvid )) == <nl> + sizeof ( cfg -> drvid )) <nl> + return - EINVAL ; <nl> drvidx = - 1 ; <nl> chidx = - 1 ; <nl> strcpy ( drvid , cfg -> drvid );
static int yurex_probe ( struct usb_interface * interface , const struct usb_device_ <nl> usb_rcvintpipe ( dev -> udev , dev -> int_in_endpointAddr ), <nl> dev -> int_buffer , YUREX_BUF_SIZE , yurex_interrupt , <nl> dev , 1 ); <nl> - dev -> cntl_urb -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; <nl> + dev -> urb -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; <nl> if ( usb_submit_urb ( dev -> urb , GFP_KERNEL )) { <nl> retval = - EIO ; <nl> err (" Could not submitting URB ");
__init int intel_pmu_init ( void ) <nl> if ( version > 1 ) <nl> x86_pmu . num_counters_fixed = max (( int ) edx . split . num_counters_fixed , 3 ); <nl>  <nl> - /* <nl> - * v2 and above have a perf capabilities MSR <nl> - */ <nl> - if ( version > 1 ) { <nl> + if ( boot_cpu_has ( X86_FEATURE_PDCM )) { <nl> u64 capabilities ; <nl>  <nl> rdmsrl ( MSR_IA32_PERF_CAPABILITIES , capabilities );
static void ath9k_wiphy_unpause_channel ( struct ath_softc * sc ) <nl> void ath9k_wiphy_chan_work ( struct work_struct * work ) <nl> { <nl> struct ath_softc * sc = container_of ( work , struct ath_softc , chan_work ); <nl> + struct ath_common * common = ath9k_hw_common ( sc -> sc_ah ); <nl> struct ath_wiphy * aphy = sc -> next_wiphy ; <nl>  <nl> if ( aphy == NULL ) <nl> void ath9k_wiphy_chan_work ( struct work_struct * work ) <nl> /* XXX : remove me eventually */ <nl> ath9k_update_ichannel ( sc , aphy -> hw , <nl> & sc -> sc_ah -> channels [ sc -> chan_idx ]); <nl> + <nl> + /* sync hw configuration for hw code */ <nl> + common -> hw = aphy -> hw ; <nl> + <nl> ath_update_chainmask ( sc , sc -> chan_is_ht ); <nl> if ( ath_set_channel ( sc , aphy -> hw , <nl> & sc -> sc_ah -> channels [ sc -> chan_idx ]) < 0 ) {
static void tk_setup_internals ( struct timekeeper * tk , struct clocksource * clock ) <nl> tk -> cycle_interval = interval ; <nl>  <nl> /* Go back from cycles -> shifted ns */ <nl> - tk -> xtime_interval = ( u64 ) interval * clock -> mult ; <nl> + tk -> xtime_interval = interval * clock -> mult ; <nl> tk -> xtime_remainder = ntpinterval - tk -> xtime_interval ; <nl> - tk -> raw_interval = <nl> - (( u64 ) interval * clock -> mult ) >> clock -> shift ; <nl> + tk -> raw_interval = ( interval * clock -> mult ) >> clock -> shift ; <nl>  <nl> /* if changing clocks , convert xtime_nsec shift units */ <nl> if ( old_clock ) {
int btrfs_add_inode_defrag ( struct btrfs_trans_handle * trans , <nl> spin_lock (& root -> fs_info -> defrag_inodes_lock ); <nl> if (! BTRFS_I ( inode )-> in_defrag ) <nl> __btrfs_add_inode_defrag ( inode , defrag ); <nl> + else <nl> + kfree ( defrag ); <nl> spin_unlock (& root -> fs_info -> defrag_inodes_lock ); <nl> return 0 ; <nl> }
int __init pci_legacy_init ( void ) <nl>  <nl> return 0 ; <nl> } <nl> - EXPORT_SYMBOL_GPL ( pci_legacy_init ); <nl>  <nl> void pcibios_scan_specific_bus ( int busn ) <nl> {
static int zd1201_resume ( struct usb_interface * interface ) <nl> { <nl> struct zd1201 * zd = usb_get_intfdata ( interface ); <nl>  <nl> + if (! zd || ! zd -> dev ) <nl> + return - ENODEV ; <nl> + <nl> netif_device_attach ( zd -> dev ); <nl>  <nl> if ( zd -> was_enabled )
static int cqspi_setup_flash ( struct cqspi_st * cqspi , struct device_node * np ) <nl> goto err ; <nl> } <nl>  <nl> - if ( cs > CQSPI_MAX_CHIPSELECT ) { <nl> + if ( cs >= CQSPI_MAX_CHIPSELECT ) { <nl> dev_err ( dev , " Chip select % d out of range .\ n ", cs ); <nl> goto err ; <nl> }
static ssize_t write_ports ( struct file * file , char * buf , size_t size ) <nl> /* Decrease the count , but don ' t shutdown the <nl> * the service <nl> */ <nl> + lock_kernel (); <nl> nfsd_serv -> sv_nrthreads --; <nl> + unlock_kernel (); <nl> } <nl> return err ; <nl> }
int i2400m_op_rfkill_sw_toggle ( struct wimax_dev * wimax_dev , <nl> "% d \ n ", result ); <nl> result = 0 ; <nl> error_cmd : <nl> - kfree ( cmd ); <nl> kfree_skb ( ack_skb ); <nl> error_msg_to_dev : <nl> error_alloc : <nl> d_fnend ( 4 , dev , "( wimax_dev % p state % d ) = % d \ n ", <nl> wimax_dev , state , result ); <nl> + kfree ( cmd ); <nl> return result ; <nl> } <nl> 
struct sk_buff * sock_alloc_send_pskb ( struct sock * sk , unsigned long header_len , <nl> gfp_t gfp_mask ; <nl> long timeo ; <nl> int err ; <nl> + int npages = ( data_len + ( PAGE_SIZE - 1 )) >> PAGE_SHIFT ; <nl> + <nl> + err = - EMSGSIZE ; <nl> + if ( npages > MAX_SKB_FRAGS ) <nl> + goto failure ; <nl>  <nl> gfp_mask = sk -> sk_allocation ; <nl> if ( gfp_mask & __GFP_WAIT ) <nl> struct sk_buff * sock_alloc_send_pskb ( struct sock * sk , unsigned long header_len , <nl> if ( atomic_read (& sk -> sk_wmem_alloc ) < sk -> sk_sndbuf ) { <nl> skb = alloc_skb ( header_len , gfp_mask ); <nl> if ( skb ) { <nl> - int npages ; <nl> int i ; <nl>  <nl> /* No pages , we ' re done ... */ <nl> if (! data_len ) <nl> break ; <nl>  <nl> - npages = ( data_len + ( PAGE_SIZE - 1 )) >> PAGE_SHIFT ; <nl> skb -> truesize += data_len ; <nl> skb_shinfo ( skb )-> nr_frags = npages ; <nl> for ( i = 0 ; i < npages ; i ++) {
struct inode { <nl> uid_t i_uid ; <nl> gid_t i_gid ; <nl> dev_t i_rdev ; <nl> + unsigned long i_version ; <nl> loff_t i_size ; <nl> +# ifdef __NEED_I_SIZE_ORDERED <nl> + seqcount_t i_size_seqcount ; <nl> +# endif <nl> struct timespec i_atime ; <nl> struct timespec i_mtime ; <nl> struct timespec i_ctime ; <nl> unsigned int i_blkbits ; <nl> - unsigned long i_version ; <nl> blkcnt_t i_blocks ; <nl> unsigned short i_bytes ; <nl> spinlock_t i_lock ; /* i_blocks , i_bytes , maybe i_size */ <nl> struct inode { <nl> void * i_security ; <nl> # endif <nl> void * i_private ; /* fs or device private pointer */ <nl> -# ifdef __NEED_I_SIZE_ORDERED <nl> - seqcount_t i_size_seqcount ; <nl> -# endif <nl> }; <nl>  <nl> /*
static inline void pack_descriptor ( __u32 * a , __u32 * b , <nl> { <nl> * a = (( base & 0xffff ) << 16 ) | ( limit & 0xffff ); <nl> * b = ( base & 0xff000000 ) | (( base & 0xff0000 ) >> 16 ) | <nl> - (( type & 0xff ) << 8 ) | (( flags & 0xf ) << 12 ); <nl> + ( limit & 0x000f0000 ) | (( type & 0xff ) << 8 ) | (( flags & 0xf ) << 20 ); <nl> } <nl>  <nl> static inline void pack_gate ( __u32 * a , __u32 * b ,
int __ieee80211_suspend ( struct ieee80211_hw * hw , struct cfg80211_wowlan * wowlan ) <nl> int err = drv_suspend ( local , wowlan ); <nl> if ( err < 0 ) { <nl> local -> quiescing = false ; <nl> + local -> wowlan = false ; <nl> return err ; <nl> } else if ( err > 0 ) { <nl> WARN_ON ( err != 1 );
static LIST_HEAD ( dev_map_list ); <nl>  <nl> static u64 dev_map_bitmap_size ( const union bpf_attr * attr ) <nl> { <nl> - return BITS_TO_LONGS ( attr -> max_entries ) * sizeof ( unsigned long ); <nl> + return BITS_TO_LONGS (( u64 ) attr -> max_entries ) * sizeof ( unsigned long ); <nl> } <nl>  <nl> static struct bpf_map * dev_map_alloc ( union bpf_attr * attr )
struct simple_xattr * simple_xattr_alloc ( const void * value , size_t size ) <nl>  <nl> /* wrap around ? */ <nl> len = sizeof (* new_xattr ) + size ; <nl> - if ( len <= sizeof (* new_xattr )) <nl> + if ( len < sizeof (* new_xattr )) <nl> return NULL ; <nl>  <nl> new_xattr = kmalloc ( len , GFP_KERNEL );
static ssize_t btrfs_label_store ( struct kobject * kobj , <nl> struct btrfs_fs_info * fs_info = to_fs_info ( kobj ); <nl> size_t p_len ; <nl>  <nl> + if (! fs_info ) <nl> + return - EPERM ; <nl> + <nl> if ( fs_info -> sb -> s_flags & MS_RDONLY ) <nl> return - EROFS ; <nl> 
void cfg80211_scan_done ( struct cfg80211_scan_request * request , bool aborted ) <nl> else <nl> nl80211_send_scan_done ( wiphy_to_dev ( request -> wiphy ), dev ); <nl>  <nl> - wiphy_to_dev ( request -> wiphy )-> scan_req = NULL ; <nl> - <nl> # ifdef CONFIG_WIRELESS_EXT <nl> if (! aborted ) { <nl> memset (& wrqu , 0 , sizeof ( wrqu )); <nl> void cfg80211_scan_done ( struct cfg80211_scan_request * request , bool aborted ) <nl> dev_put ( dev ); <nl>  <nl> out : <nl> + wiphy_to_dev ( request -> wiphy )-> scan_req = NULL ; <nl> kfree ( request ); <nl> } <nl> EXPORT_SYMBOL ( cfg80211_scan_done );
static bool intel_choose_pipe_bpp_dither ( struct drm_crtc * crtc , <nl> bpc = 6 ; /* min is 18bpp */ <nl> break ; <nl> case 24 : <nl> - bpc = min (( unsigned int ) 8 , display_bpc ); <nl> + bpc = 8 ; <nl> break ; <nl> case 30 : <nl> - bpc = min (( unsigned int ) 10 , display_bpc ); <nl> + bpc = 10 ; <nl> break ; <nl> case 48 : <nl> - bpc = min (( unsigned int ) 12 , display_bpc ); <nl> + bpc = 12 ; <nl> break ; <nl> default : <nl> DRM_DEBUG (" unsupported depth , assuming 24 bits \ n "); <nl> static bool intel_choose_pipe_bpp_dither ( struct drm_crtc * crtc , <nl> break ; <nl> } <nl>  <nl> + display_bpc = min ( display_bpc , bpc ); <nl> + <nl> DRM_DEBUG_DRIVER (" setting pipe bpc to % d ( max display bpc % d )\ n ", <nl> bpc , display_bpc ); <nl>  <nl> - * pipe_bpp = bpc * 3 ; <nl> + * pipe_bpp = display_bpc * 3 ; <nl>  <nl> return display_bpc != bpc ; <nl> }
static bool g4x_compute_wm0 ( struct drm_device * dev , <nl> int entries , tlb_miss ; <nl>  <nl> crtc = intel_get_crtc_for_plane ( dev , plane ); <nl> - if ( crtc -> fb == NULL || ! crtc -> enabled ) <nl> + if ( crtc -> fb == NULL || ! crtc -> enabled ) { <nl> + * cursor_wm = cursor -> guard_size ; <nl> + * plane_wm = display -> guard_size ; <nl> return false ; <nl> + } <nl>  <nl> htotal = crtc -> mode . htotal ; <nl> hdisplay = crtc -> mode . hdisplay ;
parse_tag_11_packet ( unsigned char * data , unsigned char * contents , <nl> rc = - EINVAL ; <nl> goto out ; <nl> } <nl> + if ( unlikely ((* tag_11_contents_size ) > max_contents_bytes )) { <nl> + printk ( KERN_ERR " Literal data section in tag 11 packet exceeds " <nl> + " expected size \ n "); <nl> + rc = - EINVAL ; <nl> + goto out ; <nl> + } <nl> if ( data [(* packet_size )++] != 0x62 ) { <nl> printk ( KERN_WARNING " Unrecognizable packet \ n "); <nl> rc = - EINVAL ;
static ssize_t cxlflash_show_port_status ( struct device * dev , <nl> u64 * fc_regs ; <nl>  <nl> rc = kstrtouint (( attr -> attr . name + 4 ), 10 , & port ); <nl> - if ( rc || ( port > NUM_FC_PORTS )) <nl> + if ( rc || ( port >= NUM_FC_PORTS )) <nl> return 0 ; <nl>  <nl> fc_regs = & afu -> afu_map -> global . fc_regs [ port ][ 0 ];
static int uvesafb_setcmap ( struct fb_cmap * cmap , struct fb_info * info ) <nl> info -> cmap . len || cmap -> start < info -> cmap . start ) <nl> return - EINVAL ; <nl>  <nl> - entries = kmalloc ( sizeof (* entries ) * cmap -> len , GFP_KERNEL ); <nl> + entries = kmalloc_array ( cmap -> len , sizeof (* entries ), <nl> + GFP_KERNEL ); <nl> if (! entries ) <nl> return - ENOMEM ; <nl> 
static void s5k5baf_synchronize ( struct s5k5baf * state , int timeout , u16 addr ) <nl> static u16 * s5k5baf_fw_get_seq ( struct s5k5baf * state , u16 seq_id ) <nl> { <nl> struct s5k5baf_fw * fw = state -> fw ; <nl> - u16 * data = fw -> data + 2 * fw -> count ; <nl> + u16 * data ; <nl> int i ; <nl>  <nl> if ( fw == NULL ) <nl> return NULL ; <nl>  <nl> + data = fw -> data + 2 * fw -> count ; <nl> + <nl> for ( i = 0 ; i < fw -> count ; ++ i ) { <nl> if ( fw -> seq [ i ]. id == seq_id ) <nl> return data + fw -> seq [ i ]. offset ;
static void set_avi_info_frame ( <nl> info_packet -> hb2 = <nl> info_frame . avi_info_packet . info_packet_hdmi . packet_raw_data . hb2 ; <nl>  <nl> - for ( byte_index = 0 ; byte_index < sizeof ( info_packet -> sb ); byte_index ++) <nl> + for ( byte_index = 0 ; byte_index < sizeof ( info_frame . avi_info_packet . <nl> + info_packet_hdmi . packet_raw_data . sb ); byte_index ++) <nl> info_packet -> sb [ byte_index ] = info_frame . avi_info_packet . <nl> - info_packet_hdmi . packet_raw_data . sb [ byte_index ]; <nl> + info_packet_hdmi . packet_raw_data . sb [ byte_index ]; <nl>  <nl> info_packet -> valid = true ; <nl> }
static int amd_gpio_remove ( struct platform_device * pdev ) <nl> gpio_dev = platform_get_drvdata ( pdev ); <nl>  <nl> gpiochip_remove (& gpio_dev -> gc ); <nl> - pinctrl_unregister ( gpio_dev -> pctrl ); <nl>  <nl> return 0 ; <nl> }
static ssize_t comp_algorithm_store ( struct device * dev , <nl> struct zram * zram = dev_to_zram ( dev ); <nl> size_t sz ; <nl>  <nl> + if (! zcomp_available_algorithm ( buf )) <nl> + return - EINVAL ; <nl> + <nl> down_write (& zram -> init_lock ); <nl> if ( init_done ( zram )) { <nl> up_write (& zram -> init_lock ); <nl> static ssize_t comp_algorithm_store ( struct device * dev , <nl> if ( sz > 0 && zram -> compressor [ sz - 1 ] == '\ n ') <nl> zram -> compressor [ sz - 1 ] = 0x00 ; <nl>  <nl> - if (! zcomp_available_algorithm ( zram -> compressor )) <nl> - len = - EINVAL ; <nl> - <nl> up_write (& zram -> init_lock ); <nl> return len ; <nl> }
void l2_cache_init ( void ) <nl> enum { <nl> UNUSED = 0 , <nl> ENABLED , <nl> + DISABLED , <nl>  <nl> /* interrupt sources */ <nl> IRQ0 , IRQ1 , IRQ2 , IRQ3 , IRQ4 , IRQ5 , IRQ6 , IRQ7 , <nl> static struct intc_group groups [] __initdata = { <nl> static struct intc_mask_reg mask_registers [] __initdata = { <nl> { 0xa4080080 , 0xa40800c0 , 8 , /* IMR0 / IMCR0 */ <nl> { 0 , TMU1_TUNI2 , TMU1_TUNI1 , TMU1_TUNI0 , <nl> - 0 , 0 , ENABLED , ENABLED } }, <nl> + 0 , DISABLED , ENABLED , ENABLED } }, <nl> { 0xa4080084 , 0xa40800c4 , 8 , /* IMR1 / IMCR1 */ <nl> { VIO_VOUI , VIO_VEU2HI , VIO_BEUI , VIO_CEUI , DMAC0A_DEI3 , DMAC0A_DEI2 , DMAC0A_DEI1 , DMAC0A_DEI0 } }, <nl> { 0xa4080088 , 0xa40800c8 , 8 , /* IMR2 / IMCR2 */ <nl> static struct intc_mask_reg mask_registers [] __initdata = { <nl> { I2C_DTEI , I2C_WAITI , I2C_TACKI , I2C_ALI , <nl> FLCTL_FLTREQ1I , FLCTL_FLTREQ0I , FLCTL_FLTENDI , FLCTL_FLSTEI } }, <nl> { 0xa40800a0 , 0xa40800e0 , 8 , /* IMR8 / IMCR8 */ <nl> - { 0 , 0 , ENABLED , ENABLED , <nl> + { 0 , DISABLED , ENABLED , ENABLED , <nl> 0 , 0 , SCIFA_SCIFA2 , SIU_SIUI } }, <nl> { 0xa40800a4 , 0xa40800e4 , 8 , /* IMR9 / IMCR9 */ <nl> { 0 , 0 , 0 , CMT_CMTI , 0 , 0 , USB_USI0 , 0 } }, <nl> static struct intc_mask_reg ack_registers [] __initdata = { <nl> static struct intc_desc intc_desc __initdata = { <nl> . name = " sh7723 ", <nl> . force_enable = ENABLED , <nl> + . force_disable = DISABLED , <nl> . hw = INTC_HW_DESC ( vectors , groups , mask_registers , <nl> prio_registers , sense_registers , ack_registers ), <nl> };
static void release_one_tty ( struct work_struct * work ) <nl> list_del_init (& tty -> tty_files ); <nl> file_list_unlock (); <nl>  <nl> + put_pid ( tty -> pgrp ); <nl> + put_pid ( tty -> session ); <nl> free_tty_struct ( tty ); <nl> } <nl> 
static long vop_ioctl ( struct file * f , unsigned int cmd , unsigned long arg ) <nl> ret = - EFAULT ; <nl> goto free_ret ; <nl> } <nl> + /* Ensure desc has not changed between the two reads */ <nl> + if ( memcmp (& dd , dd_config , sizeof ( dd ))) { <nl> + ret = - EINVAL ; <nl> + goto free_ret ; <nl> + } <nl> mutex_lock (& vdev -> vdev_mutex ); <nl> mutex_lock (& vi -> vop_mutex ); <nl> ret = vop_virtio_add_device ( vdev , dd_config );
static int tty_open ( struct inode * inode , struct file * filp ) <nl> if ( IS_ERR ( tty )) { <nl> tty_unlock (); <nl> mutex_unlock (& tty_mutex ); <nl> + tty_driver_kref_put ( driver ); <nl> return PTR_ERR ( tty ); <nl> } <nl> }
EXPORT_SYMBOL ( vio_unregister_driver ); <nl> /* vio_dev refcount hit 0 */ <nl> static void __devinit vio_dev_release ( struct device * dev ) <nl> { <nl> - if ( dev -> archdata . of_node ) { <nl> - /* XXX should free TCE table */ <nl> - of_node_put ( dev -> archdata . of_node ); <nl> - } <nl> + /* XXX should free TCE table */ <nl> + of_node_put ( dev -> archdata . of_node ); <nl> kfree ( to_vio_dev ( dev )); <nl> } <nl> 
int go7007_snd_init ( struct go7007 * go ) <nl> kfree ( gosnd ); <nl> return ret ; <nl> } <nl> - strncpy ( gosnd -> card -> driver , " go7007 ", sizeof ( gosnd -> card -> driver )); <nl> - strncpy ( gosnd -> card -> shortname , go -> name , sizeof ( gosnd -> card -> driver )); <nl> - strncpy ( gosnd -> card -> longname , gosnd -> card -> shortname , <nl> + strlcpy ( gosnd -> card -> driver , " go7007 ", sizeof ( gosnd -> card -> driver )); <nl> + strlcpy ( gosnd -> card -> shortname , go -> name , sizeof ( gosnd -> card -> driver )); <nl> + strlcpy ( gosnd -> card -> longname , gosnd -> card -> shortname , <nl> sizeof ( gosnd -> card -> longname )); <nl>  <nl> gosnd -> pcm -> private_data = go ;
static int wil_cfg80211_stop_ap ( struct wiphy * wiphy , <nl> wil6210_bus_request ( wil , WIL_DEFAULT_BUS_REQUEST_KBPS ); <nl> wil_set_recovery_state ( wil , fw_recovery_idle ); <nl>  <nl> + set_bit ( wil_status_resetting , wil -> status ); <nl> + <nl> mutex_lock (& wil -> mutex ); <nl>  <nl> wmi_pcp_stop ( wil );
struct pci_dn * handle_eeh_events ( struct eeh_event * event ) <nl> } <nl>  <nl> /* All devices should claim they have recovered by now . */ <nl> - if ( result != PCI_ERS_RESULT_RECOVERED ) { <nl> + if (( result != PCI_ERS_RESULT_RECOVERED ) && <nl> + ( result != PCI_ERS_RESULT_NONE )) { <nl> printk ( KERN_WARNING " EEH : Not recovered \ n "); <nl> goto hard_fail ; <nl> }
static int nfs_open_revalidate ( struct dentry * dentry , struct nameidata * nd ) <nl> lock_kernel (); <nl> verifier = nfs_save_change_attribute ( dir ); <nl> ret = nfs4_open_revalidate ( dir , dentry , openflags , nd ); <nl> - if (! ret ) <nl> + if ( ret == 1 ) <nl> nfs_set_verifier ( dentry , verifier ); <nl> unlock_kernel (); <nl> out :
static int ironlake_do_reset ( struct drm_device * dev ) <nl>  <nl> I915_WRITE ( MCHBAR_MIRROR_BASE + ILK_GDSR , <nl> ILK_GRDOM_MEDIA | ILK_GRDOM_RESET_ENABLE ); <nl> - return wait_for (( I915_READ ( MCHBAR_MIRROR_BASE + ILK_GDSR ) & <nl> - ILK_GRDOM_RESET_ENABLE ) == 0 , 500 ); <nl> + ret = wait_for (( I915_READ ( MCHBAR_MIRROR_BASE + ILK_GDSR ) & <nl> + ILK_GRDOM_RESET_ENABLE ) == 0 , 500 ); <nl> + if ( ret ) <nl> + return ret ; <nl> + <nl> + I915_WRITE ( MCHBAR_MIRROR_BASE + ILK_GDSR , 0 ); <nl> + <nl> + return 0 ; <nl> } <nl>  <nl> static int gen6_do_reset ( struct drm_device * dev )
static int pcie_find_smpss ( struct pci_dev * dev , void * data ) <nl> * will occur as normal . <nl> */ <nl> if ( dev -> is_hotplug_bridge && (! list_is_singular (& dev -> bus -> devices ) || <nl> - dev -> bus -> self -> pcie_type != PCI_EXP_TYPE_ROOT_PORT )) <nl> + ( dev -> bus -> self && <nl> + dev -> bus -> self -> pcie_type != PCI_EXP_TYPE_ROOT_PORT ))) <nl> * smpss = 0 ; <nl>  <nl> if (* smpss > dev -> pcie_mpss )
int tcp_conn_request ( struct request_sock_ops * rsk_ops , <nl> if ( tmp_opt . tstamp_ok ) <nl> tcp_rsk ( req )-> ts_off = af_ops -> init_ts_off ( net , skb ); <nl>  <nl> + dst = af_ops -> route_req ( sk , & fl , req ); <nl> + if (! dst ) <nl> + goto drop_and_free ; <nl> + <nl> if (! want_cookie && ! isn ) { <nl> /* Kill the following clause , if you dislike this way . */ <nl> if (! net -> ipv4 . sysctl_tcp_syncookies && <nl> int tcp_conn_request ( struct request_sock_ops * rsk_ops , <nl>  <nl> isn = af_ops -> init_seq ( skb ); <nl> } <nl> - if (! dst ) { <nl> - dst = af_ops -> route_req ( sk , & fl , req ); <nl> - if (! dst ) <nl> - goto drop_and_free ; <nl> - } <nl>  <nl> tcp_ecn_create_request ( req , skb , sk , dst ); <nl> 
static int __build_sched_domains ( const cpumask_t * cpu_map , <nl> error : <nl> free_sched_groups ( cpu_map , tmpmask ); <nl> SCHED_CPUMASK_FREE (( void *) allmasks ); <nl> + kfree ( rd ); <nl> return - ENOMEM ; <nl> # endif <nl> }
static ssize_t __ffs_ep0_read_events ( struct ffs_data * ffs , char __user * buf , <nl> spin_unlock_irq (& ffs -> ev . waitq . lock ); <nl> mutex_unlock (& ffs -> mutex ); <nl>  <nl> - return unlikely ( __copy_to_user ( buf , events , size )) ? - EFAULT : size ; <nl> + return unlikely ( copy_to_user ( buf , events , size )) ? - EFAULT : size ; <nl> } <nl>  <nl> static ssize_t ffs_ep0_read ( struct file * file , char __user * buf , <nl> static ssize_t ffs_ep0_read ( struct file * file , char __user * buf , <nl>  <nl> /* unlocks spinlock */ <nl> ret = __ffs_ep0_queue_wait ( ffs , data , len ); <nl> - if ( likely ( ret > 0 ) && unlikely ( __copy_to_user ( buf , data , len ))) <nl> + if ( likely ( ret > 0 ) && unlikely ( copy_to_user ( buf , data , len ))) <nl> ret = - EFAULT ; <nl> goto done_mutex ; <nl>  <nl> static char * ffs_prepare_buffer ( const char __user * buf , size_t len ) <nl> if ( unlikely (! data )) <nl> return ERR_PTR (- ENOMEM ); <nl>  <nl> - if ( unlikely ( __copy_from_user ( data , buf , len ))) { <nl> + if ( unlikely ( copy_from_user ( data , buf , len ))) { <nl> kfree ( data ); <nl> return ERR_PTR (- EFAULT ); <nl> }
mlxreg_hotplug_health_work_helper ( struct mlxreg_hotplug_priv_data * priv , <nl> { <nl> struct mlxreg_core_data * data = item -> data ; <nl> u32 regval ; <nl> - int i , ret ; <nl> + int i , ret = 0 ; <nl>  <nl> for ( i = 0 ; i < item -> count ; i ++, data ++) { <nl> /* Mask event . */
static void nbd_config_put ( struct nbd_device * nbd ) <nl> } <nl> kfree ( config -> socks ); <nl> } <nl> + kfree ( nbd -> config ); <nl> nbd -> config = NULL ; <nl>  <nl> nbd -> tag_set . timeout = 0 ;
static void compat_input ( struct dlm_write_request * kb , <nl> static void compat_output ( struct dlm_lock_result * res , <nl> struct dlm_lock_result32 * res32 ) <nl> { <nl> + memset ( res32 , 0 , sizeof (* res32 )); <nl> + <nl> res32 -> version [ 0 ] = res -> version [ 0 ]; <nl> res32 -> version [ 1 ] = res -> version [ 1 ]; <nl> res32 -> version [ 2 ] = res -> version [ 2 ];
int main ( void ) <nl> len = recvfrom ( fd , kvp_recv_buffer , sizeof ( kvp_recv_buffer ), 0 , <nl> addr_p , & addr_l ); <nl>  <nl> - if ( len < 0 || addr . nl_pid ) { <nl> + if ( len < 0 ) { <nl> syslog ( LOG_ERR , " recvfrom failed ; pid :% u error :% d % s ", <nl> addr . nl_pid , errno , strerror ( errno )); <nl> close ( fd ); <nl> return - 1 ; <nl> } <nl>  <nl> + if ( addr . nl_pid ) { <nl> + syslog ( LOG_WARNING , " Received packet from untrusted pid :% u ", <nl> + addr . nl_pid ); <nl> + continue ; <nl> + } <nl> + <nl> incoming_msg = ( struct nlmsghdr *) kvp_recv_buffer ; <nl> incoming_cn_msg = ( struct cn_msg *) NLMSG_DATA ( incoming_msg ); <nl> hv_msg = ( struct hv_kvp_msg *) incoming_cn_msg -> data ;
struct edac_pci_ctl_info * edac_pci_create_generic_ctl ( struct device * dev , <nl>  <nl> pci -> mod_name = mod_name ; <nl> pci -> ctl_name = EDAC_PCI_GENCTL_NAME ; <nl> - pci -> edac_check = edac_pci_generic_check ; <nl> + if ( edac_op_state == EDAC_OPSTATE_POLL ) <nl> + pci -> edac_check = edac_pci_generic_check ; <nl>  <nl> pdata -> edac_idx = edac_pci_idx ++; <nl> 
rpcrdma_register_internal ( struct rpcrdma_ia * ia , void * va , int len , <nl> */ <nl> iov -> addr = ib_dma_map_single ( ia -> ri_id -> device , <nl> va , len , DMA_BIDIRECTIONAL ); <nl> + if ( ib_dma_mapping_error ( ia -> ri_id -> device , iov -> addr )) <nl> + return - ENOMEM ; <nl> + <nl> iov -> length = len ; <nl>  <nl> if ( ia -> ri_have_dma_lkey ) {
static int rtnl_fill_statsinfo ( struct sk_buff * skb , struct net_device * dev , <nl> return - EMSGSIZE ; <nl>  <nl> ifsm = nlmsg_data ( nlh ); <nl> + ifsm -> family = PF_UNSPEC ; <nl> + ifsm -> pad1 = 0 ; <nl> + ifsm -> pad2 = 0 ; <nl> ifsm -> ifindex = dev -> ifindex ; <nl> ifsm -> filter_mask = filter_mask ; <nl> 
static struct dma_async_tx_descriptor * sdma_prep_slave_sg ( <nl>  <nl> param = BD_DONE | BD_EXTD | BD_CONT ; <nl>  <nl> - if ( i + 1 == sg_len ) <nl> + if ( i + 1 == sg_len ) { <nl> param |= BD_INTR ; <nl> + param |= BD_LAST ; <nl> + param &= ~ BD_CONT ; <nl> + } <nl>  <nl> dev_dbg ( sdma -> dev , " entry % d : count : % d dma : 0x % 08x % s % s \ n ", <nl> i , count , sg -> dma_address ,
static void kick_tx ( int fd ) <nl> int ret ; <nl>  <nl> ret = sendto ( fd , NULL , 0 , MSG_DONTWAIT , NULL , 0 ); <nl> - if ( ret >= 0 || errno == ENOBUFS || errno == EAGAIN ) <nl> + if ( ret >= 0 || errno == ENOBUFS || errno == EAGAIN || errno == EBUSY ) <nl> return ; <nl> lassert ( 0 ); <nl> }
static int may_commit_transaction ( struct btrfs_fs_info * fs_info , <nl>  <nl> spin_lock (& delayed_rsv -> lock ); <nl> if ( percpu_counter_compare (& space_info -> total_bytes_pinned , <nl> - bytes - delayed_rsv -> size ) >= 0 ) { <nl> + bytes - delayed_rsv -> size ) < 0 ) { <nl> spin_unlock (& delayed_rsv -> lock ); <nl> return - ENOSPC ; <nl> }
static void ip_cmsg_recv_checksum ( struct msghdr * msg , struct sk_buff * skb , <nl> if ( skb -> ip_summed != CHECKSUM_COMPLETE ) <nl> return ; <nl>  <nl> - if ( offset != 0 ) <nl> - csum = csum_sub ( csum , <nl> - csum_partial ( skb_transport_header ( skb ) + tlen , <nl> - offset , 0 )); <nl> + if ( offset != 0 ) { <nl> + int tend_off = skb_transport_offset ( skb ) + tlen ; <nl> + csum = csum_sub ( csum , skb_checksum ( skb , tend_off , offset , 0 )); <nl> + } <nl>  <nl> put_cmsg ( msg , SOL_IP , IP_CHECKSUM , sizeof ( __wsum ), & csum ); <nl> }
static int pm_genpd_summary_one ( struct seq_file * s , <nl>  <nl> if ( WARN_ON ( genpd -> status >= ARRAY_SIZE ( status_lookup ))) <nl> goto exit ; <nl> - seq_printf ( s , "%- 30s %- 15s ", genpd -> name , status_lookup [ genpd -> status ]); <nl> + seq_printf ( s , "%- 30s %- 15s ", genpd -> name , status_lookup [ genpd -> status ]); <nl>  <nl> /* <nl> * Modifications on the list require holding locks on both <nl> static int pm_genpd_summary_show ( struct seq_file * s , void * data ) <nl> struct generic_pm_domain * genpd ; <nl> int ret = 0 ; <nl>  <nl> - seq_puts ( s , " domain status slaves \ n "); <nl> - seq_puts ( s , " / device runtime status \ n "); <nl> + seq_puts ( s , " domain status slaves \ n "); <nl> + seq_puts ( s , " / device runtime status \ n "); <nl> seq_puts ( s , "----------------------------------------------------------------------\ n "); <nl>  <nl> ret = mutex_lock_interruptible (& gpd_list_lock );
static int __net_init __ip_vs_ftp_init ( struct net * net ) <nl> struct ip_vs_app * app ; <nl> struct netns_ipvs * ipvs = net_ipvs ( net ); <nl>  <nl> + if (! ipvs ) <nl> + return - ENOENT ; <nl> app = kmemdup (& ip_vs_ftp , sizeof ( struct ip_vs_app ), GFP_KERNEL ); <nl> if (! app ) <nl> return - ENOMEM ;
static struct fdtable * alloc_fdtable ( int nr ) <nl> if (! fdt ) <nl> goto out ; <nl>  <nl> - nfds = 8 * L1_CACHE_BYTES ; <nl> - /* Expand to the max in easy steps */ <nl> - while ( nfds <= nr ) { <nl> - nfds = nfds * 2 ; <nl> - if ( nfds > NR_OPEN ) <nl> - nfds = NR_OPEN ; <nl> - } <nl> + nfds = max_t ( int , 8 * L1_CACHE_BYTES , roundup_pow_of_two ( nfds )); <nl> + if ( nfds > NR_OPEN ) <nl> + nfds = NR_OPEN ; <nl>  <nl> new_openset = alloc_fdset ( nfds ); <nl> new_execset = alloc_fdset ( nfds );
void iio_disable_all_buffers ( struct iio_dev * indio_dev ) <nl> indio_dev -> currentmode = INDIO_DIRECT_MODE ; <nl> if ( indio_dev -> setup_ops -> postdisable ) <nl> indio_dev -> setup_ops -> postdisable ( indio_dev ); <nl> + <nl> + if ( indio_dev -> available_scan_masks == NULL ) <nl> + kfree ( indio_dev -> active_scan_mask ); <nl> } <nl>  <nl> int iio_update_buffers ( struct iio_dev * indio_dev ,
static void __init __e820_add_region ( struct e820map * e820x , u64 start , u64 size , <nl> { <nl> int x = e820x -> nr_map ; <nl>  <nl> - if ( x == ARRAY_SIZE ( e820x -> map )) { <nl> + if ( x >= ARRAY_SIZE ( e820x -> map )) { <nl> printk ( KERN_ERR " Ooops ! Too many entries in the memory map !\ n "); <nl> return ; <nl> }
lpfc_nvme_io_cmd_wqe_cmpl ( struct lpfc_hba * phba , struct lpfc_iocbq * pwqeIn , <nl> phba -> cpucheck_cmpl_io [ lpfc_ncmd -> cpu ]++; <nl> } <nl> # endif <nl> - freqpriv = nCmd -> private ; <nl> - freqpriv -> nvme_buf = NULL ; <nl>  <nl> /* NVME targets need completion held off until the abort exchange <nl> * completes unless the NVME Rport is getting unregistered . <nl> */ <nl>  <nl> if (!( lpfc_ncmd -> flags & LPFC_SBUF_XBUSY )) { <nl> + freqpriv = nCmd -> private ; <nl> + freqpriv -> nvme_buf = NULL ; <nl> nCmd -> done ( nCmd ); <nl> lpfc_ncmd -> nvmeCmd = NULL ; <nl> }
SYSCALL_DEFINE5 ( add_key , const char __user *, _type , <nl> /* pull the payload in if one was supplied */ <nl> payload = NULL ; <nl>  <nl> - if ( _payload ) { <nl> + if ( plen ) { <nl> ret = - ENOMEM ; <nl> payload = kvmalloc ( plen , GFP_KERNEL ); <nl> if (! payload ) <nl> long keyctl_update_key ( key_serial_t id , <nl>  <nl> /* pull the payload in if one was supplied */ <nl> payload = NULL ; <nl> - if ( _payload ) { <nl> + if ( plen ) { <nl> ret = - ENOMEM ; <nl> payload = kmalloc ( plen , GFP_KERNEL ); <nl> if (! payload )
static ssize_t rp5c01_nvram_read ( struct file * filp , struct kobject * kobj , <nl>  <nl> spin_lock_irq (& priv -> lock ); <nl>  <nl> - for ( count = 0 ; size > 0 && pos < RP5C01_MODE ; count ++, size --) { <nl> + for ( count = 0 ; count < size ; count ++) { <nl> u8 data ; <nl>  <nl> rp5c01_write ( priv , <nl> static ssize_t rp5c01_nvram_write ( struct file * filp , struct kobject * kobj , <nl>  <nl> spin_lock_irq (& priv -> lock ); <nl>  <nl> - for ( count = 0 ; size > 0 && pos < RP5C01_MODE ; count ++, size --) { <nl> + for ( count = 0 ; count < size ; count ++) { <nl> u8 data = * buf ++; <nl>  <nl> rp5c01_write ( priv ,
static int did_overwrite_first_ref ( struct send_ctx * sctx , u64 ino , u64 gen ) <nl> * Insert a name cache entry . On 32bit kernels the radix tree index is 32bit , <nl> * so we need to do some special handling in case we have clashes . This function <nl> * takes care of this with the help of name_cache_entry :: radix_list . <nl> + * In case of error , nce is kfreed . <nl> */ <nl> static int name_cache_insert ( struct send_ctx * sctx , <nl> struct name_cache_entry * nce ) <nl> static int name_cache_insert ( struct send_ctx * sctx , <nl> INIT_LIST_HEAD ( nce_head ); <nl>  <nl> ret = radix_tree_insert (& sctx -> name_cache , nce -> ino , nce_head ); <nl> - if ( ret < 0 ) <nl> + if ( ret < 0 ) { <nl> + kfree ( nce_head ); <nl> + kfree ( nce ); <nl> return ret ; <nl> + } <nl> } <nl> list_add_tail (& nce -> radix_list , nce_head ); <nl> list_add_tail (& nce -> list , & sctx -> name_cache_list );
static int __init cy_detect_isa ( void ) <nl> continue ; <nl> } <nl> # ifdef MODULE <nl> - if ( isparam && irq [ i ]) <nl> + if ( isparam && i < NR_CARDS && irq [ i ]) <nl> cy_isa_irq = irq [ i ]; <nl> else <nl> # endif
static int dlm_add_member ( struct dlm_ls * ls , int nodeid ) <nl> return - ENOMEM ; <nl>  <nl> w = dlm_node_weight ( ls -> ls_name , nodeid ); <nl> - if ( w < 0 ) <nl> + if ( w < 0 ) { <nl> + kfree ( memb ); <nl> return w ; <nl> + } <nl>  <nl> memb -> nodeid = nodeid ; <nl> memb -> weight = w ;
static int acm_tty_open ( struct tty_struct * tty , struct file * filp ) <nl> else <nl> rv = 0 ; <nl>  <nl> + set_bit ( TTY_NO_WRITE_SPLIT , & tty -> flags ); <nl> tty -> driver_data = acm ; <nl> acm -> tty = tty ; <nl> 
static struct pcmcia_device_id orinoco_cs_ids [] = { <nl> PCMCIA_DEVICE_PROD_ID12 (" Cabletron ", " RoamAbout 802 . 11 DS ", 0x32d445f5 , 0xedeffd90 ), <nl> PCMCIA_DEVICE_PROD_ID12 (" corega K . K .", " Wireless LAN PCC - 11 ", 0x5261440f , 0xa6405584 ), <nl> PCMCIA_DEVICE_PROD_ID12 (" corega K . K .", " Wireless LAN PCCA - 11 ", 0x5261440f , 0xdf6115f9 ), <nl> + PCMCIA_DEVICE_PROD_ID12 (" corega_K . K .", " Wireless_LAN_PCCB - 11 ", 0x29e33311 , 0xee7a27ae ), <nl> PCMCIA_DEVICE_PROD_ID12 (" D ", " Link DRC - 650 11Mbps WLAN Card ", 0x71b18589 , 0xf144e3ac ), <nl> PCMCIA_DEVICE_PROD_ID12 (" D ", " Link DWL - 650 11Mbps WLAN Card ", 0x71b18589 , 0xb6f1b0ab ), <nl> PCMCIA_DEVICE_PROD_ID12 (" ELSA ", " AirLancer MC - 11 ", 0x4507a33a , 0xef54f0e3 ),
static int amd_gpio_probe ( struct platform_device * pdev ) <nl> gpio_dev -> ngroups = ARRAY_SIZE ( kerncz_groups ); <nl>  <nl> amd_pinctrl_desc . name = dev_name (& pdev -> dev ); <nl> - gpio_dev -> pctrl = pinctrl_register (& amd_pinctrl_desc , <nl> - & pdev -> dev , gpio_dev ); <nl> + gpio_dev -> pctrl = devm_pinctrl_register (& pdev -> dev , & amd_pinctrl_desc , <nl> + gpio_dev ); <nl> if ( IS_ERR ( gpio_dev -> pctrl )) { <nl> dev_err (& pdev -> dev , " Couldn ' t register pinctrl driver \ n "); <nl> return PTR_ERR ( gpio_dev -> pctrl ); <nl> static int amd_gpio_probe ( struct platform_device * pdev ) <nl>  <nl> ret = gpiochip_add_data (& gpio_dev -> gc , gpio_dev ); <nl> if ( ret ) <nl> - goto out1 ; <nl> + return ret ; <nl>  <nl> ret = gpiochip_add_pin_range (& gpio_dev -> gc , dev_name (& pdev -> dev ), <nl> 0 , 0 , TOTAL_NUMBER_OF_PINS ); <nl> static int amd_gpio_probe ( struct platform_device * pdev ) <nl> out2 : <nl> gpiochip_remove (& gpio_dev -> gc ); <nl>  <nl> - out1 : <nl> - pinctrl_unregister ( gpio_dev -> pctrl ); <nl> return ret ; <nl> } <nl>  <nl> static int amd_gpio_remove ( struct platform_device * pdev ) <nl> gpio_dev = platform_get_drvdata ( pdev ); <nl>  <nl> gpiochip_remove (& gpio_dev -> gc ); <nl> - pinctrl_unregister ( gpio_dev -> pctrl ); <nl>  <nl> return 0 ; <nl> }
static int __cpu_find_by ( int (* compare )( int , int , void *), void * compare_arg , <nl> int err = check_cpu_node ( dp -> node , & cur_inst , <nl> compare , compare_arg , <nl> prom_node , mid ); <nl> - if (! err ) <nl> + if (! err ) { <nl> + of_node_put ( dp ); <nl> return 0 ; <nl> + } <nl> } <nl>  <nl> return - ENODEV ;
static int bpf_tcp_sendmsg ( struct sock * sk , struct msghdr * msg , size_t size ) <nl> timeo = sock_sndtimeo ( sk , msg -> msg_flags & MSG_DONTWAIT ); <nl>  <nl> while ( msg_data_left ( msg )) { <nl> - struct sk_msg_buff * m ; <nl> + struct sk_msg_buff * m = NULL ; <nl> bool enospc = false ; <nl> int copy ; <nl>  <nl> static int bpf_tcp_sendmsg ( struct sock * sk , struct msghdr * msg , size_t size ) <nl> set_bit ( SOCK_NOSPACE , & sk -> sk_socket -> flags ); <nl> wait_for_memory : <nl> err = sk_stream_wait_memory ( sk , & timeo ); <nl> - if ( err ) <nl> + if ( err ) { <nl> + if ( m && m != psock -> cork ) <nl> + free_start_sg ( sk , m ); <nl> goto out_err ; <nl> + } <nl> } <nl> out_err : <nl> if ( err < 0 )
static int spear_smi_probe_config_dt ( struct platform_device * pdev , <nl> pdata -> board_flash_info = devm_kzalloc (& pdev -> dev , <nl> sizeof (* pdata -> board_flash_info ), <nl> GFP_KERNEL ); <nl> + if (! pdata -> board_flash_info ) <nl> + return - ENOMEM ; <nl>  <nl> /* Fill structs for each subnode ( flash device ) */ <nl> while (( pp = of_get_next_child ( np , pp ))) {
struct cx25821_fmt * cx25821_format_by_fourcc ( unsigned int fourcc ) <nl> { <nl> unsigned int i ; <nl>  <nl> - if ( fourcc == V4L2_PIX_FMT_Y41P || fourcc == V4L2_PIX_FMT_YUV411P ) { <nl> + if ( fourcc == V4L2_PIX_FMT_Y41P || fourcc == V4L2_PIX_FMT_YUV411P ) <nl> return formats + 1 ; <nl> - } <nl>  <nl> for ( i = 0 ; i < ARRAY_SIZE ( formats ); i ++) <nl> if ( formats [ i ]. fourcc == fourcc ) <nl> void cx25821_video_wakeup ( struct cx25821_dev * dev , struct cx25821_dmaqueue * q , <nl> /* count comes from the hw and it is 16bit wide -- <nl> * this trick handles wrap - arounds correctly for <nl> * up to 32767 buffers in flight ... */ <nl> - if (( s16 ) ( count - buf -> count ) < 0 ) { <nl> + if (( s16 ) ( count - buf -> count ) < 0 ) <nl> break ; <nl> - } <nl>  <nl> do_gettimeofday (& buf -> vb . ts ); <nl> buf -> vb . state = VIDEOBUF_DONE ;
struct bio * bio_map_user_iov ( struct request_queue * q , <nl> offset = offset_in_page ( uaddr ); <nl> for ( j = cur_page ; j < page_limit ; j ++) { <nl> unsigned int bytes = PAGE_SIZE - offset ; <nl> + unsigned short prev_bi_vcnt = bio -> bi_vcnt ; <nl>  <nl> if ( len <= 0 ) <nl> break ; <nl> struct bio * bio_map_user_iov ( struct request_queue * q , <nl> bytes ) <nl> break ; <nl>  <nl> + /* <nl> + * check if vector was merged with previous <nl> + * drop page reference if needed <nl> + */ <nl> + if ( bio -> bi_vcnt == prev_bi_vcnt ) <nl> + put_page ( pages [ j ]); <nl> + <nl> len -= bytes ; <nl> offset = 0 ; <nl> }
static void execlists_submission_tasklet ( unsigned long data ) <nl> trace_i915_request_out ( rq ); <nl> i915_request_put ( rq ); <nl>  <nl> + GEM_TRACE ("% s completed ctx =% d \ n ", <nl> + engine -> name , port -> context_id ); <nl> + <nl> execlists_port_complete ( execlists , port ); <nl> } else { <nl> port_set ( port , port_pack ( rq , count ));
static int rsc_parse ( struct cache_detail * cd , <nl> /* number of additional gid ' s */ <nl> if ( get_int (& mesg , & N )) <nl> goto out ; <nl> + if ( N < 0 || N > NGROUPS_MAX ) <nl> + goto out ; <nl> status = - ENOMEM ; <nl> rsci . cred . cr_group_info = groups_alloc ( N ); <nl> if ( rsci . cred . cr_group_info == NULL )
static int nf_tables_delflowtable ( struct net * net , struct sock * nlsk , <nl> struct nft_table * table ; <nl> struct nft_ctx ctx ; <nl>  <nl> + if (! nla [ NFTA_FLOWTABLE_TABLE ] || <nl> + (! nla [ NFTA_FLOWTABLE_NAME ] && <nl> + ! nla [ NFTA_FLOWTABLE_HANDLE ])) <nl> + return - EINVAL ; <nl> + <nl> table = nf_tables_table_lookup ( net , nla [ NFTA_FLOWTABLE_TABLE ], <nl> family , genmask ); <nl> if ( IS_ERR ( table ))
static void setup_format_params ( int track ) <nl> raw_cmd -> kernel_data = floppy_track_buffer ; <nl> raw_cmd -> length = 4 * F_SECT_PER_TRACK ; <nl>  <nl> + if (! F_SECT_PER_TRACK ) <nl> + return ; <nl> + <nl> /* allow for about 30ms for data transport per track */ <nl> head_shift = ( F_SECT_PER_TRACK + 5 ) / 6 ; <nl>  <nl> static int set_geometry ( unsigned int cmd , struct floppy_struct * g , <nl> /* sanity checking for parameters . */ <nl> if ( g -> sect <= 0 || <nl> g -> head <= 0 || <nl> + /* check for zero in F_SECT_PER_TRACK */ <nl> + ( unsigned char )(( g -> sect << 2 ) >> FD_SIZECODE ( g )) == 0 || <nl> g -> track <= 0 || g -> track > UDP -> tracks >> STRETCH ( g ) || <nl> /* check if reserved bits are set */ <nl> ( g -> stretch & ~( FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK )) != 0 )
static int pinconf_dbg_config_write ( struct file * file , <nl> int i ; <nl>  <nl> /* Get userspace string and assure termination */ <nl> - buf_size = min ( count , ( sizeof ( buf )- 1 )); <nl> + buf_size = min ( count , ( size_t )( sizeof ( buf )- 1 )); <nl> if ( copy_from_user ( buf , user_buf , buf_size )) <nl> return - EFAULT ; <nl> buf [ buf_size ] = 0 ;
intel_ioapic_set_affinity ( struct irq_data * data , const struct cpumask * mask , <nl>  <nl> err = apic -> cpu_mask_to_apicid_and ( cfg -> domain , mask , & dest ); <nl> if ( err ) { <nl> - if ( assign_irq_vector ( irq , cfg , data -> affinity )); <nl> + if ( assign_irq_vector ( irq , cfg , data -> affinity )) <nl> pr_err (" Failed to recover vector for irq % d \ n ", irq ); <nl> return err ; <nl> }
int iwl_mvm_mac_setup_register ( struct iwl_mvm * mvm ) <nl> else <nl> hw -> wiphy -> flags &= ~ WIPHY_FLAG_PS_ON_BY_DEFAULT ; <nl>  <nl> - if ( mvm -> fw -> ucode_capa . flags & IWL_UCODE_TLV_FLAGS_SCHED_SCAN ) { <nl> + if ( 0 && mvm -> fw -> ucode_capa . flags & IWL_UCODE_TLV_FLAGS_SCHED_SCAN ) { <nl> hw -> wiphy -> flags |= WIPHY_FLAG_SUPPORTS_SCHED_SCAN ; <nl> hw -> wiphy -> max_sched_scan_ssids = PROBE_OPTION_MAX ; <nl> hw -> wiphy -> max_match_sets = IWL_SCAN_MAX_PROFILES ;
static int thunderx_lmc_probe ( struct pci_dev * pdev , <nl>  <nl> lmc -> xor_bank = lmc_control & LMC_CONTROL_XOR_BANK ; <nl>  <nl> - l2c_ioaddr = ioremap ( L2C_CTL | FIELD_PREP ( THUNDERX_NODE , lmc -> node ), <nl> - PAGE_SIZE ); <nl> - <nl> + l2c_ioaddr = ioremap ( L2C_CTL | FIELD_PREP ( THUNDERX_NODE , lmc -> node ), PAGE_SIZE ); <nl> if (! l2c_ioaddr ) { <nl> dev_err (& pdev -> dev , " Cannot map L2C_CTL \ n "); <nl> + ret = - ENOMEM ; <nl> goto err_free ; <nl> } <nl> 
static int kcm_sendmsg ( struct socket * sock , struct msghdr * msg , size_t len ) <nl> } else { <nl> /* Message not complete , save state */ <nl> partial_message : <nl> - kcm -> seq_skb = head ; <nl> - kcm_tx_msg ( head )-> last_skb = skb ; <nl> + if ( head ) { <nl> + kcm -> seq_skb = head ; <nl> + kcm_tx_msg ( head )-> last_skb = skb ; <nl> + } <nl> } <nl>  <nl> KCM_STATS_ADD ( kcm -> stats . tx_bytes , copied );
rio_dma_transfer ( struct file * filp , u32 transfer_mode , <nl> goto err_req ; <nl> } <nl>  <nl> - pinned = get_user_pages_unlocked ( <nl> + pinned = get_user_pages_fast ( <nl> ( unsigned long ) xfer -> loc_addr & PAGE_MASK , <nl> - nr_pages , <nl> - page_list , <nl> - dir == DMA_FROM_DEVICE ? FOLL_WRITE : 0 ); <nl> + nr_pages , dir == DMA_FROM_DEVICE , page_list ); <nl>  <nl> if ( pinned != nr_pages ) { <nl> if ( pinned < 0 ) {
EXPORT_SYMBOL ( ipmi_get_smi_info ); <nl> static void free_user ( struct kref * ref ) <nl> { <nl> struct ipmi_user * user = container_of ( ref , struct ipmi_user , refcount ); <nl> + cleanup_srcu_struct (& user -> release_barrier ); <nl> kfree ( user ); <nl> } <nl>  <nl> int ipmi_destroy_user ( struct ipmi_user * user ) <nl> { <nl> _ipmi_destroy_user ( user ); <nl>  <nl> - cleanup_srcu_struct (& user -> release_barrier ); <nl> kref_put (& user -> refcount , free_user ); <nl>  <nl> return 0 ;
int iwlagn_mac_setup_register ( struct iwl_priv * priv , <nl> ARRAY_SIZE ( iwlagn_iface_combinations_dualmode ); <nl> } <nl>  <nl> - hw -> wiphy -> max_remain_on_channel_duration = 1000 ; <nl> + hw -> wiphy -> max_remain_on_channel_duration = 500 ; <nl>  <nl> hw -> wiphy -> flags |= WIPHY_FLAG_CUSTOM_REGULATORY | <nl> WIPHY_FLAG_DISABLE_BEACON_HINTS |
static void atmci_set_ios ( struct mmc_host * mmc , struct mmc_ios * ios ) <nl>  <nl> if ( ios -> clock ) { <nl> unsigned int clock_min = ~ 0U ; <nl> - u32 clkdiv ; <nl> + int clkdiv ; <nl>  <nl> spin_lock_bh (& host -> lock ); <nl> if (! host -> mode_reg ) { <nl> static void atmci_set_ios ( struct mmc_host * mmc , struct mmc_ios * ios ) <nl> /* Calculate clock divider */ <nl> if ( host -> caps . has_odd_clk_div ) { <nl> clkdiv = DIV_ROUND_UP ( host -> bus_hz , clock_min ) - 2 ; <nl> - if ( clkdiv > 511 ) { <nl> + if ( clkdiv < 0 ) { <nl> + dev_warn (& mmc -> class_dev , <nl> + " clock % u too fast ; using % lu \ n ", <nl> + clock_min , host -> bus_hz / 2 ); <nl> + clkdiv = 0 ; <nl> + } else if ( clkdiv > 511 ) { <nl> dev_warn (& mmc -> class_dev , <nl> " clock % u too slow ; using % lu \ n ", <nl> clock_min , host -> bus_hz / ( 511 + 2 ));
static int rk_hw_params ( struct snd_pcm_substream * substream , <nl> case 96000 : <nl> mclk = 12288000 ; <nl> break ; <nl> + case 192000 : <nl> + mclk = 24576000 ; <nl> + break ; <nl> case 11025 : <nl> case 22050 : <nl> case 44100 :
direct_io_worker ( int rw , struct kiocb * iocb , struct inode * inode , <nl> dio -> get_block = get_block ; <nl> dio -> end_io = end_io ; <nl> dio -> map_bh . b_private = NULL ; <nl> + dio -> map_bh . b_state = 0 ; <nl> dio -> final_block_in_bio = - 1 ; <nl> dio -> next_block_for_io = - 1 ; <nl> 
static void do_fault ( struct work_struct * work ) <nl> goto out ; <nl> } <nl>  <nl> + if (!( vma -> vm_flags & ( VM_READ | VM_EXEC | VM_WRITE ))) { <nl> + /* handle_mm_fault would BUG_ON () */ <nl> + up_read (& mm -> mmap_sem ); <nl> + handle_fault_error ( fault ); <nl> + goto out ; <nl> + } <nl> + <nl> ret = handle_mm_fault ( mm , vma , address , write ); <nl> if ( ret & VM_FAULT_ERROR ) { <nl> /* failed to service fault */
static int snd_usb_copy_string_desc ( struct mixer_build * state , <nl> int index , char * buf , int maxlen ) <nl> { <nl> int len = usb_string ( state -> chip -> dev , index , buf , maxlen - 1 ); <nl> + <nl> + if ( len < 0 ) <nl> + return 0 ; <nl> + <nl> buf [ len ] = 0 ; <nl> return len ; <nl> }
static inline clock_t jiffies_delta_to_clock_t ( long delta ) <nl> return jiffies_to_clock_t ( max ( 0L , delta )); <nl> } <nl>  <nl> + static inline unsigned int jiffies_delta_to_msecs ( long delta ) <nl> +{ <nl> + return jiffies_to_msecs ( max ( 0L , delta )); <nl> +} <nl> + <nl> extern unsigned long clock_t_to_jiffies ( unsigned long x ); <nl> extern u64 jiffies_64_to_clock_t ( u64 x ); <nl> extern u64 nsec_to_clock_t ( u64 x );
static void v4l_fill_fmtdesc ( struct v4l2_fmtdesc * fmt ) <nl> case V4L2_PIX_FMT_VC1_ANNEX_L : descr = " VC - 1 ( SMPTE 412M Annex L )"; break ; <nl> case V4L2_PIX_FMT_VP8 : descr = " VP8 "; break ; <nl> case V4L2_PIX_FMT_VP9 : descr = " VP9 "; break ; <nl> + case V4L2_PIX_FMT_HEVC : descr = " HEVC "; break ; /* aka H . 265 */ <nl> case V4L2_PIX_FMT_CPIA1 : descr = " GSPCA CPiA YUV "; break ; <nl> case V4L2_PIX_FMT_WNVA : descr = " WNVA "; break ; <nl> case V4L2_PIX_FMT_SN9C10X : descr = " GSPCA SN9C10X "; break ;
static SIMPLE_DEV_PM_OPS ( ds1374_pm , ds1374_suspend , ds1374_resume ); <nl> static struct i2c_driver ds1374_driver = { <nl> . driver = { <nl> . name = " rtc - ds1374 ", <nl> + . of_match_table = of_match_ptr ( ds1374_of_match ), <nl> . pm = & ds1374_pm , <nl> }, <nl> . probe = ds1374_probe ,
xfs_growfs_rt ( <nl> /* <nl> * Initial error checking . <nl> */ <nl> - if ( mp -> m_rtdev_targp || mp -> m_rbmip == NULL || <nl> + if ( mp -> m_rtdev_targp == NULL || mp -> m_rbmip == NULL || <nl> ( nrblocks = in -> newblocks ) <= sbp -> sb_rblocks || <nl> ( sbp -> sb_rblocks && ( in -> extsize != sbp -> sb_rextsize ))) <nl> return XFS_ERROR ( EINVAL );
static unsigned long get_ctl_id_hash ( const struct snd_ctl_elem_id * id ) <nl> h = id -> iface ; <nl> h = MULTIPLIER * h + id -> device ; <nl> h = MULTIPLIER * h + id -> subdevice ; <nl> - for ( i = 0 ; id -> name [ i ] && i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN ; i ++) <nl> + for ( i = 0 ; i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN && id -> name [ i ]; i ++) <nl> h = MULTIPLIER * h + id -> name [ i ]; <nl> h = MULTIPLIER * h + id -> index ; <nl> h &= LONG_MAX ;
static struct kset * ipl_kset ; <nl>  <nl> static void __ipl_run ( void * unused ) <nl> { <nl> + if ( MACHINE_IS_LPAR && ipl_info . type == IPL_TYPE_CCW ) <nl> + diag308 ( DIAG308_LOAD_NORMAL_DUMP , NULL ); <nl> diag308 ( DIAG308_LOAD_CLEAR , NULL ); <nl> if ( MACHINE_IS_VM ) <nl> __cpcmd (" IPL ", NULL , 0 , NULL );
bool ath9k_hw_eeprom_set_board_values ( struct ath_hal * ah , <nl>  <nl> txRxAttenLocal = IS_CHAN_2GHZ ( chan ) ? 23 : 44 ; <nl>  <nl> - ath9k_hw_get_eeprom_antenna_cfg ( ah , chan , 1 , & ant_config ); <nl> + ath9k_hw_get_eeprom_antenna_cfg ( ah , chan , 0 , & ant_config ); <nl> REG_WRITE ( ah , AR_PHY_SWITCH_COM , ant_config ); <nl>  <nl> for ( i = 0 ; i < AR5416_MAX_CHAINS ; i ++) {
int ipv6_find_hdr ( const struct sk_buff * skb , unsigned int * offset , <nl> found = ( nexthdr == target ); <nl>  <nl> if ((! ipv6_ext_hdr ( nexthdr )) || nexthdr == NEXTHDR_NONE ) { <nl> - if ( target < 0 ) <nl> + if ( target < 0 || found ) <nl> break ; <nl> return - ENOENT ; <nl> }
static void ftrace_syscall_enter ( void * data , struct pt_regs * regs , long id ) <nl> int size ; <nl>  <nl> syscall_nr = trace_get_syscall_nr ( current , regs ); <nl> - if ( syscall_nr < 0 ) <nl> + if ( syscall_nr < 0 || syscall_nr >= NR_syscalls ) <nl> return ; <nl>  <nl> /* Here we ' re inside tp handler ' s rcu_read_lock_sched ( __DO_TRACE ) */ <nl> static void ftrace_syscall_exit ( void * data , struct pt_regs * regs , long ret ) <nl> int syscall_nr ; <nl>  <nl> syscall_nr = trace_get_syscall_nr ( current , regs ); <nl> - if ( syscall_nr < 0 ) <nl> + if ( syscall_nr < 0 || syscall_nr >= NR_syscalls ) <nl> return ; <nl>  <nl> /* Here we ' re inside tp handler ' s rcu_read_lock_sched ( __DO_TRACE ()) */ <nl> static void perf_syscall_enter ( void * ignore , struct pt_regs * regs , long id ) <nl> int size ; <nl>  <nl> syscall_nr = trace_get_syscall_nr ( current , regs ); <nl> - if ( syscall_nr < 0 ) <nl> + if ( syscall_nr < 0 || syscall_nr >= NR_syscalls ) <nl> return ; <nl> if (! test_bit ( syscall_nr , enabled_perf_enter_syscalls )) <nl> return ; <nl> static void perf_syscall_exit ( void * ignore , struct pt_regs * regs , long ret ) <nl> int size ; <nl>  <nl> syscall_nr = trace_get_syscall_nr ( current , regs ); <nl> - if ( syscall_nr < 0 ) <nl> + if ( syscall_nr < 0 || syscall_nr >= NR_syscalls ) <nl> return ; <nl> if (! test_bit ( syscall_nr , enabled_perf_exit_syscalls )) <nl> return ;
static void alc889_fixup_dac_route ( struct hda_codec * codec , <nl> const struct alc_fixup * fix , int action ) <nl> { <nl> if ( action == ALC_FIXUP_ACT_PRE_PROBE ) { <nl> + /* fake the connections during parsing the tree */ <nl> hda_nid_t conn1 [ 2 ] = { 0x0c , 0x0d }; <nl> hda_nid_t conn2 [ 2 ] = { 0x0e , 0x0f }; <nl> snd_hda_override_conn_list ( codec , 0x14 , 2 , conn1 ); <nl> snd_hda_override_conn_list ( codec , 0x15 , 2 , conn1 ); <nl> snd_hda_override_conn_list ( codec , 0x18 , 2 , conn2 ); <nl> snd_hda_override_conn_list ( codec , 0x1a , 2 , conn2 ); <nl> + } else if ( action == ALC_FIXUP_ACT_PROBE ) { <nl> + /* restore the connections */ <nl> + hda_nid_t conn [ 5 ] = { 0x0c , 0x0d , 0x0e , 0x0f , 0x26 }; <nl> + snd_hda_override_conn_list ( codec , 0x14 , 5 , conn ); <nl> + snd_hda_override_conn_list ( codec , 0x15 , 5 , conn ); <nl> + snd_hda_override_conn_list ( codec , 0x18 , 5 , conn ); <nl> + snd_hda_override_conn_list ( codec , 0x1a , 5 , conn ); <nl> } <nl> } <nl> 
long kvm_vm_ioctl_create_spapr_tce ( struct kvm * kvm , <nl> int ret = - ENOMEM ; <nl> int i ; <nl>  <nl> - if (! args -> size ) <nl> + if (! args -> size || args -> page_shift < 12 || args -> page_shift > 34 || <nl> + ( args -> offset + args -> size > ( ULLONG_MAX >> args -> page_shift ))) <nl> return - EINVAL ; <nl>  <nl> size = _ALIGN_UP ( args -> size , PAGE_SIZE >> 3 );
static int __devinit twl6040_probe ( struct platform_device * pdev ) <nl> if ( pdata -> codec ) { <nl> cell = & twl6040 -> cells [ children ]; <nl> cell -> name = " twl6040 - codec "; <nl> - /* The codec expects the twl4030_audio_data as platform data */ <nl> - cell -> platform_data = pdata ; <nl> - cell -> pdata_size = sizeof (* pdata ); <nl> + cell -> platform_data = pdata -> codec ; <nl> + cell -> pdata_size = sizeof (* pdata -> codec ); <nl> children ++; <nl> } <nl> 
static void ieee80211_iface_work ( struct work_struct * work ) <nl> if ( sta ) { <nl> u16 last_seq ; <nl>  <nl> - last_seq = le16_to_cpu ( <nl> - sta -> last_seq_ctrl [ rx_agg -> tid ]); <nl> + last_seq = IEEE80211_SEQ_TO_SN ( le16_to_cpu ( <nl> + sta -> last_seq_ctrl [ rx_agg -> tid ])); <nl>  <nl> __ieee80211_start_rx_ba_session ( sta , <nl> 0 , 0 ,
isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> if ( copy_from_user (& iocts , argp , <nl> sizeof ( isdn_ioctl_struct ))) <nl> return - EFAULT ; <nl> + iocts . drvid [ sizeof ( iocts . drvid )- 1 ] = 0 ; <nl> if ( strlen ( iocts . drvid )) { <nl> if (( p = strchr ( iocts . drvid , ','))) <nl> * p = 0 ; <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> if ( copy_from_user (& iocts , argp , <nl> sizeof ( isdn_ioctl_struct ))) <nl> return - EFAULT ; <nl> + iocts . drvid [ sizeof ( iocts . drvid )- 1 ] = 0 ; <nl> if ( strlen ( iocts . drvid )) { <nl> drvidx = - 1 ; <nl> for ( i = 0 ; i < ISDN_MAX_DRIVERS ; i ++) <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> } else { <nl> p = ( char __user *) iocts . arg ; <nl> for ( i = 0 ; i < 10 ; i ++) { <nl> - sprintf ( bname , "% s % s ", <nl> + snprintf ( bname , sizeof ( bname ), "% s % s ", <nl> strlen ( dev -> drv [ drvidx ]-> msn2eaz [ i ]) ? <nl> dev -> drv [ drvidx ]-> msn2eaz [ i ] : " _ ", <nl> ( i < 9 ) ? "," : "\ 0 "); <nl> isdn_ioctl ( struct inode * inode , struct file * file , uint cmd , ulong arg ) <nl> char * p ; <nl> if ( copy_from_user (& iocts , argp , sizeof ( isdn_ioctl_struct ))) <nl> return - EFAULT ; <nl> + iocts . drvid [ sizeof ( iocts . drvid )- 1 ] = 0 ; <nl> if ( strlen ( iocts . drvid )) { <nl> if (( p = strchr ( iocts . drvid , ','))) <nl> * p = 0 ;
static int send_pin_code_neg_reply ( struct sock * sk , struct hci_dev * hdev , <nl> if (! cmd ) <nl> return - ENOMEM ; <nl>  <nl> + cmd -> cmd_complete = addr_cmd_complete ; <nl> + <nl> err = hci_send_cmd ( hdev , HCI_OP_PIN_CODE_NEG_REPLY , <nl> sizeof ( cp -> addr . bdaddr ), & cp -> addr . bdaddr ); <nl> if ( err < 0 )
static int mxcmci_probe ( struct platform_device * pdev ) <nl>  <nl> res = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); <nl> irq = platform_get_irq ( pdev , 0 ); <nl> - if ( irq < 0 ) <nl> - return - EINVAL ; <nl> + if ( irq < 0 ) { <nl> + dev_err (& pdev -> dev , " failed to get IRQ : % d \ n ", irq ); <nl> + return irq ; <nl> + } <nl>  <nl> mmc = mmc_alloc_host ( sizeof (* host ), & pdev -> dev ); <nl> if (! mmc )
static void cx_auto_check_auto_mic ( struct hda_codec * codec ) <nl> int pset [ INPUT_PIN_ATTR_NORMAL + 1 ]; <nl> int i ; <nl>  <nl> - for ( i = 0 ; i < INPUT_PIN_ATTR_NORMAL ; i ++) <nl> + for ( i = 0 ; i < ARRAY_SIZE ( pset ); i ++) <nl> pset [ i ] = - 1 ; <nl> for ( i = 0 ; i < spec -> private_imux . num_items ; i ++) { <nl> hda_nid_t pin = spec -> imux_info [ i ]. pin ;
static int __wlcore_cmd_send ( struct wl1271 * wl , u16 id , void * buf , <nl> id != CMD_STOP_FWLOGGER )) <nl> return - EIO ; <nl>  <nl> + if ( WARN_ON_ONCE ( len < sizeof (* cmd ))) <nl> + return - EIO ; <nl> + <nl> cmd = buf ; <nl> cmd -> id = cpu_to_le16 ( id ); <nl> cmd -> status = 0 ; <nl> int wlcore_cmd_configure_failsafe ( struct wl1271 * wl , u16 id , void * buf , <nl>  <nl> wl1271_debug ( DEBUG_CMD , " cmd configure (% d )", id ); <nl>  <nl> + if ( WARN_ON_ONCE ( len < sizeof (* acx ))) <nl> + return - EIO ; <nl> + <nl> acx -> id = cpu_to_le16 ( id ); <nl>  <nl> /* payload length , does not include any headers */
static struct sk_buff * udp6_ufo_fragment ( struct sk_buff * skb , u32 features ) <nl> skb -> ip_summed = CHECKSUM_NONE ; <nl>  <nl> /* Check if there is enough headroom to insert fragment header . */ <nl> - if (( skb_headroom ( skb ) < frag_hdr_sz ) && <nl> + if (( skb_mac_header ( skb ) < skb -> head + frag_hdr_sz ) && <nl> pskb_expand_head ( skb , frag_hdr_sz , 0 , GFP_ATOMIC )) <nl> goto out ; <nl> 
static int alloc_and_submit_int_urb ( struct gspca_dev * gspca_dev , <nl> void * buffer = NULL ; <nl> int ret = - EINVAL ; <nl>  <nl> - buffer_len = ep -> wMaxPacketSize ; <nl> + buffer_len = le16_to_cpu ( ep -> wMaxPacketSize ); <nl> interval = ep -> bInterval ; <nl> PDEBUG ( D_PROBE , " found int in endpoint : 0x % x , " <nl> " buffer_len =% u , interval =% u ", <nl> static int alloc_and_submit_int_urb ( struct gspca_dev * gspca_dev , <nl> goto error ; <nl> } <nl>  <nl> - buffer = usb_buffer_alloc ( dev , ep -> wMaxPacketSize , <nl> + buffer = usb_buffer_alloc ( dev , buffer_len , <nl> GFP_KERNEL , & urb -> transfer_dma ); <nl> if (! buffer ) { <nl> ret = - ENOMEM ;
bool wb_over_bg_thresh ( struct bdi_writeback * wb ) <nl> if ( gdtc -> dirty > gdtc -> bg_thresh ) <nl> return true ; <nl>  <nl> - if ( wb_stat ( wb , WB_RECLAIMABLE ) > __wb_calc_thresh ( gdtc )) <nl> + if ( wb_stat ( wb , WB_RECLAIMABLE ) > <nl> + wb_calc_thresh ( gdtc -> wb , gdtc -> bg_thresh )) <nl> return true ; <nl>  <nl> if ( mdtc ) { <nl> bool wb_over_bg_thresh ( struct bdi_writeback * wb ) <nl> if ( mdtc -> dirty > mdtc -> bg_thresh ) <nl> return true ; <nl>  <nl> - if ( wb_stat ( wb , WB_RECLAIMABLE ) > __wb_calc_thresh ( mdtc )) <nl> + if ( wb_stat ( wb , WB_RECLAIMABLE ) > <nl> + wb_calc_thresh ( mdtc -> wb , mdtc -> bg_thresh )) <nl> return true ; <nl> } <nl> 
static int modify_prefix_route ( struct inet6_ifaddr * ifp , <nl> unsigned long expires , u32 flags ) <nl> { <nl> struct fib6_info * f6i ; <nl> + u32 prio ; <nl>  <nl> f6i = addrconf_get_prefix_route (& ifp -> addr , <nl> ifp -> prefix_len , <nl> static int modify_prefix_route ( struct inet6_ifaddr * ifp , <nl> if (! f6i ) <nl> return - ENOENT ; <nl>  <nl> - if ( f6i -> fib6_metric != ifp -> rt_priority ) { <nl> + prio = ifp -> rt_priority ? : IP6_RT_PRIO_ADDRCONF ; <nl> + if ( f6i -> fib6_metric != prio ) { <nl> + /* delete old one */ <nl> + ip6_del_rt ( dev_net ( ifp -> idev -> dev ), f6i ); <nl> + <nl> /* add new one */ <nl> addrconf_prefix_route (& ifp -> addr , ifp -> prefix_len , <nl> ifp -> rt_priority , ifp -> idev -> dev , <nl> expires , flags , GFP_KERNEL ); <nl> - /* delete old one */ <nl> - ip6_del_rt ( dev_net ( ifp -> idev -> dev ), f6i ); <nl> } else { <nl> if (! expires ) <nl> fib6_clean_expires ( f6i );
nfsd4_decode_create_session ( struct nfsd4_compoundargs * argp , <nl>  <nl> u32 dummy ; <nl> char * machine_name ; <nl> - int i ; <nl> + int i , j ; <nl> int nr_secflavs ; <nl>  <nl> READ_BUF ( 16 ); <nl> nfsd4_decode_create_session ( struct nfsd4_compoundargs * argp , <nl> READ_BUF ( 4 ); <nl> READ32 ( dummy ); <nl> READ_BUF ( dummy * 4 ); <nl> - for ( i = 0 ; i < dummy ; ++ i ) <nl> + for ( j = 0 ; j < dummy ; ++ j ) <nl> READ32 ( dummy ); <nl> break ; <nl> case RPC_AUTH_GSS :
static void zynqmp_dma_chan_remove ( struct zynqmp_dma_chan * chan ) <nl> if (! chan ) <nl> return ; <nl>  <nl> - devm_free_irq ( chan -> zdev -> dev , chan -> irq , chan ); <nl> + if ( chan -> irq ) <nl> + devm_free_irq ( chan -> zdev -> dev , chan -> irq , chan ); <nl> tasklet_kill (& chan -> tasklet ); <nl> list_del (& chan -> common . device_node ); <nl> }
videobuf_vm_open ( struct vm_area_struct * vma ) <nl> { <nl> struct videobuf_mapping * map = vma -> vm_private_data ; <nl>  <nl> - dprintk ( 2 ," vm_open % p [ count =% d , vma =% 08lx -% 08lx ]\ n ", map , <nl> + dprintk ( 2 ," vm_open % p [ count =% u , vma =% 08lx -% 08lx ]\ n ", map , <nl> map -> count , vma -> vm_start , vma -> vm_end ); <nl>  <nl> map -> count ++; <nl> videobuf_vm_close ( struct vm_area_struct * vma ) <nl> struct videobuf_queue * q = map -> q ; <nl> int i ; <nl>  <nl> - dprintk ( 2 ," vm_close % p [ count =% d , vma =% 08lx -% 08lx ]\ n ", map , <nl> + dprintk ( 2 ," vm_close % p [ count =% u , vma =% 08lx -% 08lx ]\ n ", map , <nl> map -> count , vma -> vm_start , vma -> vm_end ); <nl>  <nl> map -> count --; <nl> static int __videobuf_mmap_mapper ( struct videobuf_queue * q , <nl> } <nl>  <nl> /* create mapping + update buffer list */ <nl> - map = q -> bufs [ first ]-> map = kmalloc ( sizeof ( struct videobuf_mapping ), GFP_KERNEL ); <nl> + map = q -> bufs [ first ]-> map = kzalloc ( sizeof ( struct videobuf_mapping ), GFP_KERNEL ); <nl> if ( NULL == map ) <nl> return - ENOMEM ; <nl> 
void DisableVGA ( volatile STG4000REG __iomem * pSTGReg ) <nl> { <nl> u32 tmp ; <nl> - volatile u32 count , i ; <nl> + volatile u32 count = 0 , i ; <nl>  <nl> /* Reset the VGA registers */ <nl> tmp = STG_READ_REG ( SoftwareReset );
static bool __oom_reap_task_mm ( struct task_struct * tsk , struct mm_struct * mm ) <nl> */ <nl> set_bit ( MMF_UNSTABLE , & mm -> flags ); <nl>  <nl> - tlb_gather_mmu (& tlb , mm , 0 , - 1 ); <nl> for ( vma = mm -> mmap ; vma ; vma = vma -> vm_next ) { <nl> if (! can_madv_dontneed_vma ( vma )) <nl> continue ; <nl> static bool __oom_reap_task_mm ( struct task_struct * tsk , struct mm_struct * mm ) <nl> * we do not want to block exit_mmap by keeping mm ref <nl> * count elevated without a good reason . <nl> */ <nl> - if ( vma_is_anonymous ( vma ) || !( vma -> vm_flags & VM_SHARED )) <nl> + if ( vma_is_anonymous ( vma ) || !( vma -> vm_flags & VM_SHARED )) { <nl> + tlb_gather_mmu (& tlb , mm , vma -> vm_start , vma -> vm_end ); <nl> unmap_page_range (& tlb , vma , vma -> vm_start , vma -> vm_end , <nl> NULL ); <nl> + tlb_finish_mmu (& tlb , vma -> vm_start , vma -> vm_end ); <nl> + } <nl> } <nl> - tlb_finish_mmu (& tlb , 0 , - 1 ); <nl> pr_info (" oom_reaper : reaped process % d (% s ), now anon - rss :% lukB , file - rss :% lukB , shmem - rss :% lukB \ n ", <nl> task_pid_nr ( tsk ), tsk -> comm , <nl> K ( get_mm_counter ( mm , MM_ANONPAGES )),
static void pllx_get_dyn_steps ( struct clk_hw * hw , u32 * step_a , u32 * step_b ) <nl> { <nl> unsigned long input_rate ; <nl>  <nl> - if (! IS_ERR_OR_NULL ( hw -> clk )) { <nl> + /* cf rate */ <nl> + if (! IS_ERR_OR_NULL ( hw -> clk )) <nl> input_rate = clk_hw_get_rate ( clk_hw_get_parent ( hw )); <nl> - /* cf rate */ <nl> - input_rate /= tegra_pll_get_fixed_mdiv ( hw , input_rate ); <nl> - } else { <nl> + else <nl> input_rate = 38400000 ; <nl> - } <nl> + <nl> + input_rate /= tegra_pll_get_fixed_mdiv ( hw , input_rate ); <nl>  <nl> switch ( input_rate ) { <nl> case 12000000 :
# define LAST_VM86_IRQ 15 <nl> # define invalid_vm86_irq ( irq ) (( irq ) < 3 || ( irq ) > 15 ) <nl>  <nl> -# if defined ( CONFIG_X86_IO_APIC ) && ! defined ( CONFIG_PARAVIRT ) && ! defined ( CONFIG_X86_VISWS ) && ! defined ( CONFIG_X86_VOYAGER ) <nl> +# if defined ( CONFIG_X86_IO_APIC ) && ! defined ( CONFIG_X86_VOYAGER ) <nl> # if NR_CPUS < MAX_IO_APICS <nl> # define NR_IRQS ( NR_VECTORS + ( 32 * NR_CPUS )) <nl> # else <nl> # define NR_IRQS ( NR_VECTORS + ( 32 * MAX_IO_APICS )) <nl> # endif <nl>  <nl> -# elif defined ( CONFIG_PARAVIRT ) || defined ( CONFIG_X86_VISWS ) || defined ( CONFIG_X86_VOYAGER ) <nl> +# elif defined ( CONFIG_X86_VOYAGER ) <nl>  <nl> # define NR_IRQS 224 <nl>  <nl> -# else /* IO_APIC || PARAVIRT */ <nl> +# else /* IO_APIC || VOYAGER */ <nl>  <nl> # define NR_IRQS 16 <nl> 
struct ieee80211_hw * ieee80211_alloc_hw ( size_t priv_data_len , <nl> if ( WARN_ON ( ops -> sta_state && ( ops -> sta_add || ops -> sta_remove ))) <nl> return NULL ; <nl>  <nl> + /* check all or no channel context operations exist */ <nl> + i = !! ops -> add_chanctx + !! ops -> remove_chanctx + <nl> + !! ops -> change_chanctx + !! ops -> assign_vif_chanctx + <nl> + !! ops -> unassign_vif_chanctx ; <nl> + if ( WARN_ON ( i != 0 && i != 5 )) <nl> + return NULL ; <nl> + <nl> /* Ensure 32 - byte alignment of our private data and hw private data . <nl> * We use the wiphy priv data for both our ieee80211_local and for <nl> * the driver ' s private data
static int __devinit w90p910_keypad_probe ( struct platform_device * pdev ) <nl> { <nl> const struct w90p910_keypad_platform_data * pdata = <nl> pdev -> dev . platform_data ; <nl> - const struct matrix_keymap_data * keymap_data = pdata -> keymap_data ; <nl> + const struct matrix_keymap_data * keymap_data ; <nl> struct w90p910_keypad * keypad ; <nl> struct input_dev * input_dev ; <nl> struct resource * res ; <nl> static int __devinit w90p910_keypad_probe ( struct platform_device * pdev ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + keymap_data = pdata -> keymap_data ; <nl> + <nl> irq = platform_get_irq ( pdev , 0 ); <nl> if ( irq < 0 ) { <nl> dev_err (& pdev -> dev , " failed to get keypad irq \ n ");
static bool lm3533_readable_register ( struct device * dev , unsigned int reg ) <nl> static bool lm3533_volatile_register ( struct device * dev , unsigned int reg ) <nl> { <nl> switch ( reg ) { <nl> - case 0x34 : /* zone */ <nl> + case 0x34 ... 0x36 : /* zone */ <nl> case 0x37 ... 0x38 : /* adc */ <nl> case 0xb0 ... 0xb1 : /* fault */ <nl> return true ;
static int tun_set_iff ( struct net * net , struct file * file , struct ifreq * ifr ) <nl>  <nl> err_detach : <nl> tun_detach_all ( dev ); <nl> + /* register_netdevice () already called tun_free_netdev () */ <nl> + goto err_free_dev ; <nl> + <nl> err_free_flow : <nl> tun_flow_uninit ( tun ); <nl> security_tun_dev_free_security ( tun -> security );
static int mb86s70_gpio_request ( struct gpio_chip * gc , unsigned gpio ) <nl> spin_lock_irqsave (& gchip -> lock , flags ); <nl>  <nl> val = readl ( gchip -> base + PFR ( gpio )); <nl> + if (!( val & OFFSET ( gpio ))) { <nl> + spin_unlock_irqrestore (& gchip -> lock , flags ); <nl> + return - EINVAL ; <nl> + } <nl> + <nl> val &= ~ OFFSET ( gpio ); <nl> writel ( val , gchip -> base + PFR ( gpio )); <nl> 
static byte connect_res ( dword Id , word Number , DIVA_CAPI_ADAPTER * a , <nl> add_ai ( plci , & parms [ 5 ]); <nl> sig_req ( plci , REJECT , 0 ); <nl> } <nl> - else if ( Reject == 1 || Reject > 9 ) <nl> + else if ( Reject == 1 || Reject >= 9 ) <nl> { <nl> add_ai ( plci , & parms [ 5 ]); <nl> sig_req ( plci , HANGUP , 0 );
ssize_t tomoyo_write_control ( struct tomoyo_io_buffer * head , <nl> return - EFAULT ; <nl> if ( mutex_lock_interruptible (& head -> io_sem )) <nl> return - EINTR ; <nl> + head -> read_user_buf_avail = 0 ; <nl> idx = tomoyo_read_lock (); <nl> /* Read a line and dispatch it to the policy handler . */ <nl> while ( avail_len > 0 ) {
static void f2fs_submit_discard_endio ( struct bio * bio ) <nl>  <nl> dc -> error = bio -> bi_error ; <nl> dc -> state = D_DONE ; <nl> - complete (& dc -> wait ); <nl> + complete_all (& dc -> wait ); <nl> bio_put ( bio ); <nl> } <nl> 
static void * __iommu_alloc_attrs ( struct device * dev , size_t size , <nl> size >> PAGE_SHIFT ); <nl> return NULL ; <nl> } <nl> - if (! coherent ) <nl> - __dma_flush_area ( page_to_virt ( page ), iosize ); <nl> - <nl> addr = dma_common_contiguous_remap ( page , size , VM_USERMAP , <nl> prot , <nl> __builtin_return_address ( 0 )); <nl> - if (! addr ) { <nl> + if ( addr ) { <nl> + memset ( addr , 0 , size ); <nl> + if (! coherent ) <nl> + __dma_flush_area ( page_to_virt ( page ), iosize ); <nl> + } else { <nl> iommu_dma_unmap_page ( dev , * handle , iosize , 0 , attrs ); <nl> dma_release_from_contiguous ( dev , page , <nl> size >> PAGE_SHIFT );
static int nvme_trans_log_info_exceptions ( struct nvme_ns * ns , <nl> c . common . opcode = nvme_admin_get_log_page ; <nl> c . common . nsid = cpu_to_le32 ( 0xFFFFFFFF ); <nl> c . common . prp1 = cpu_to_le64 ( dma_addr ); <nl> - c . common . cdw10 [ 0 ] = cpu_to_le32 ((( sizeof ( struct nvme_smart_log ) / <nl> - BYTES_TO_DWORDS ) << 16 ) | NVME_GET_SMART_LOG_PAGE ); <nl> + c . common . cdw10 [ 0 ] = cpu_to_le32 (((( sizeof ( struct nvme_smart_log ) / <nl> + BYTES_TO_DWORDS ) - 1 ) << 16 ) | NVME_GET_SMART_LOG_PAGE ); <nl> res = nvme_submit_admin_cmd ( dev , & c , NULL ); <nl> if ( res != NVME_SC_SUCCESS ) { <nl> temp_c = LOG_TEMP_UNKNOWN ; <nl> static int nvme_trans_log_temperature ( struct nvme_ns * ns , struct sg_io_hdr * hdr , <nl> c . common . opcode = nvme_admin_get_log_page ; <nl> c . common . nsid = cpu_to_le32 ( 0xFFFFFFFF ); <nl> c . common . prp1 = cpu_to_le64 ( dma_addr ); <nl> - c . common . cdw10 [ 0 ] = cpu_to_le32 ((( sizeof ( struct nvme_smart_log ) / <nl> - BYTES_TO_DWORDS ) << 16 ) | NVME_GET_SMART_LOG_PAGE ); <nl> + c . common . cdw10 [ 0 ] = cpu_to_le32 (((( sizeof ( struct nvme_smart_log ) / <nl> + BYTES_TO_DWORDS ) - 1 ) << 16 ) | NVME_GET_SMART_LOG_PAGE ); <nl> res = nvme_submit_admin_cmd ( dev , & c , NULL ); <nl> if ( res != NVME_SC_SUCCESS ) { <nl> temp_c_cur = LOG_TEMP_UNKNOWN ;
static int wait_for_connected ( struct usb_device * udev , <nl> while ( delay_ms < 2000 ) { <nl> if ( status || * portstatus & USB_PORT_STAT_CONNECTION ) <nl> break ; <nl> + if (! port_is_power_on ( hub , * portstatus )) { <nl> + status = - ENODEV ; <nl> + break ; <nl> + } <nl> msleep ( 20 ); <nl> delay_ms += 20 ; <nl> status = hub_port_status ( hub , * port1 , portstatus , portchange );
static void kvm_iommu_put_pages ( struct kvm * kvm , <nl> gfn_t base_gfn , unsigned long npages ); <nl>  <nl> static pfn_t kvm_pin_pages ( struct kvm_memory_slot * slot , gfn_t gfn , <nl> - unsigned long size ) <nl> + unsigned long npages ) <nl> { <nl> gfn_t end_gfn ; <nl> pfn_t pfn ; <nl>  <nl> pfn = gfn_to_pfn_memslot ( slot , gfn ); <nl> - end_gfn = gfn + ( size >> PAGE_SHIFT ); <nl> + end_gfn = gfn + npages ; <nl> gfn += 1 ; <nl>  <nl> if ( is_error_noslot_pfn ( pfn )) <nl> int kvm_iommu_map_pages ( struct kvm * kvm , struct kvm_memory_slot * slot ) <nl> * Pin all pages we are about to map in memory . This is <nl> * important because we unmap and unpin in 4kb steps later . <nl> */ <nl> - pfn = kvm_pin_pages ( slot , gfn , page_size ); <nl> + pfn = kvm_pin_pages ( slot , gfn , page_size >> PAGE_SHIFT ); <nl> if ( is_error_noslot_pfn ( pfn )) { <nl> gfn += 1 ; <nl> continue ; <nl> int kvm_iommu_map_pages ( struct kvm * kvm , struct kvm_memory_slot * slot ) <nl> if ( r ) { <nl> printk ( KERN_ERR " kvm_iommu_map_address :" <nl> " iommu failed to map pfn =% llx \ n ", pfn ); <nl> - kvm_unpin_pages ( kvm , pfn , page_size ); <nl> + kvm_unpin_pages ( kvm , pfn , page_size >> PAGE_SHIFT ); <nl> goto unmap_pages ; <nl> } <nl> 
static void btusb_disconnect ( struct usb_interface * intf ) <nl> return ; <nl>  <nl> hdev = data -> hdev ; <nl> - <nl> - hci_dev_hold ( hdev ); <nl> - <nl> usb_set_intfdata ( data -> intf , NULL ); <nl>  <nl> if ( data -> isoc ) <nl> static void btusb_disconnect ( struct usb_interface * intf ) <nl> else if ( data -> isoc ) <nl> usb_driver_release_interface (& btusb_driver , data -> isoc ); <nl>  <nl> - hci_dev_put ( hdev ); <nl> - <nl> hci_free_dev ( hdev ); <nl> kfree ( data ); <nl> }
early_initcall ( tegra_init_fuse ); <nl> # ifdef CONFIG_ARM64 <nl> static int __init tegra_init_soc ( void ) <nl> { <nl> + struct device_node * np ; <nl> struct device * soc ; <nl>  <nl> + /* make sure we ' re running on Tegra */ <nl> + np = of_find_matching_node ( NULL , tegra_fuse_match ); <nl> + if (! np ) <nl> + return 0 ; <nl> + <nl> + of_node_put ( np ); <nl> + <nl> soc = tegra_soc_device_register (); <nl> if ( IS_ERR ( soc )) { <nl> pr_err (" failed to register SoC device : % ld \ n ", PTR_ERR ( soc ));
static void ipt_ulog_packet ( struct net * net , <nl> ub -> qlen ++; <nl>  <nl> pm = nlmsg_data ( nlh ); <nl> + memset ( pm , 0 , sizeof (* pm )); <nl>  <nl> /* We might not have a timestamp , get one */ <nl> if ( skb -> tstamp . tv64 == 0 ) <nl> static void ipt_ulog_packet ( struct net * net , <nl> } <nl> else if ( loginfo -> prefix [ 0 ] != '\ 0 ') <nl> strncpy ( pm -> prefix , loginfo -> prefix , sizeof ( pm -> prefix )); <nl> - else <nl> - *( pm -> prefix ) = '\ 0 '; <nl>  <nl> if ( in && in -> hard_header_len > 0 && <nl> skb -> mac_header != skb -> network_header && <nl> static void ipt_ulog_packet ( struct net * net , <nl>  <nl> if ( in ) <nl> strncpy ( pm -> indev_name , in -> name , sizeof ( pm -> indev_name )); <nl> - else <nl> - pm -> indev_name [ 0 ] = '\ 0 '; <nl>  <nl> if ( out ) <nl> strncpy ( pm -> outdev_name , out -> name , sizeof ( pm -> outdev_name )); <nl> - else <nl> - pm -> outdev_name [ 0 ] = '\ 0 '; <nl>  <nl> /* copy_len <= skb -> len , so can ' t fail . */ <nl> if ( skb_copy_bits ( skb , 0 , pm -> payload , copy_len ) < 0 )
static void isp_video_buffer_query ( struct isp_video_buffer * buf , <nl> switch ( buf -> state ) { <nl> case ISP_BUF_STATE_ERROR : <nl> vbuf -> flags |= V4L2_BUF_FLAG_ERROR ; <nl> + /* Fallthrough */ <nl> case ISP_BUF_STATE_DONE : <nl> vbuf -> flags |= V4L2_BUF_FLAG_DONE ; <nl> + break ; <nl> case ISP_BUF_STATE_QUEUED : <nl> case ISP_BUF_STATE_ACTIVE : <nl> vbuf -> flags |= V4L2_BUF_FLAG_QUEUED ;
static int __init parse_options ( struct early_uart_device * device , char * options ) <nl>  <nl> if (( options = strchr ( options , ','))) { <nl> options ++; <nl> - device -> baud = simple_strtoul ( options , 0 , 0 ); <nl> + device -> baud = simple_strtoul ( options , NULL , 0 ); <nl> length = min ( strcspn ( options , " "), sizeof ( device -> options )); <nl> strncpy ( device -> options , options , length ); <nl> } else {
int __annotation__scnprintf_samples_period ( struct annotation * notes , <nl> bool show_freq ) <nl> { <nl> const char * ev_name = perf_evsel__name ( evsel ); <nl> - char ref [ 30 ] = " show reference callgraph , "; <nl> + char buf [ 1024 ], ref [ 30 ] = " show reference callgraph , "; <nl> char sample_freq_str [ 64 ] = ""; <nl> unsigned long nr_samples = 0 ; <nl> int nr_members = 1 ; <nl> int __annotation__scnprintf_samples_period ( struct annotation * notes , <nl> char unit ; <nl> int i ; <nl>  <nl> - if ( perf_evsel__is_group_event ( evsel )) <nl> + if ( perf_evsel__is_group_event ( evsel )) { <nl> + perf_evsel__group_desc ( evsel , buf , sizeof ( buf )); <nl> + ev_name = buf ; <nl> nr_members = evsel -> nr_members ; <nl> + } <nl>  <nl> for ( i = 0 ; i < nr_members ; i ++) { <nl> struct sym_hist * ah = annotation__histogram ( notes , evsel -> idx + i );
int cx231xx_set_mode ( struct cx231xx * dev , enum cx231xx_mode set_mode ) <nl> } <nl> } <nl>  <nl> - return errCode ? - EINVAL : 0 ; <nl> + if ( errCode < 0 ) { <nl> + dev_err ( dev -> dev , " Failed to set devmode to % s : error : % i ", <nl> + dev -> mode == CX231XX_DIGITAL_MODE ? " digital " : " analog ", <nl> + errCode ); <nl> + return errCode ; <nl> + } <nl> + <nl> + return 0 ; <nl> } <nl> EXPORT_SYMBOL_GPL ( cx231xx_set_mode ); <nl> 
void __ptrace_link ( struct task_struct * child , struct task_struct * new_parent , <nl> */ <nl> static void ptrace_link ( struct task_struct * child , struct task_struct * new_parent ) <nl> { <nl> - rcu_read_lock (); <nl> - __ptrace_link ( child , new_parent , __task_cred ( new_parent )); <nl> - rcu_read_unlock (); <nl> + __ptrace_link ( child , new_parent , current_cred ()); <nl> } <nl>  <nl> /**
int ext3_sync_file ( struct file * file , struct dentry * dentry , int datasync ) <nl> goto out ; <nl> } <nl>  <nl> + if ( datasync && !( inode -> i_state & I_DIRTY_DATASYNC )) <nl> + goto out ; <nl> + <nl> /* <nl> * The VFS has written the file data . If the inode is unaltered <nl> * then we need not start a commit .
cfg80211_bss_update ( struct cfg80211_registered_device * dev , <nl> kfree_rcu (( struct cfg80211_bss_ies *) old , <nl> rcu_head ); <nl> } else if ( rcu_access_pointer ( tmp -> pub . beacon_ies )) { <nl> - const struct cfg80211_bss_ies * old , * ies ; <nl> + const struct cfg80211_bss_ies * old ; <nl>  <nl> old = rcu_access_pointer ( found -> pub . beacon_ies ); <nl> - ies = rcu_access_pointer ( found -> pub . ies ); <nl>  <nl> rcu_assign_pointer ( found -> pub . beacon_ies , <nl> tmp -> pub . beacon_ies ); <nl>  <nl> /* Override IEs if they were from a beacon before */ <nl> - if ( old == ies ) <nl> + if ( old == rcu_access_pointer ( found -> pub . ies )) <nl> rcu_assign_pointer ( found -> pub . ies , <nl> tmp -> pub . beacon_ies ); <nl> 
TRACE_EVENT ( snd_soc_dapm_output_path , <nl> __assign_str ( pname , path -> name ? path -> name : DAPM_DIRECT ); <nl> __assign_str ( psname , path -> sink -> name ); <nl> __entry -> path_connect = path -> connect ; <nl> - __entry -> path_sink = ( int ) path -> sink ; <nl> + __entry -> path_sink = ( long ) path -> sink ; <nl> ), <nl>  <nl> TP_printk ("% c % s -> % s -> % s \ n ", <nl> TRACE_EVENT ( snd_soc_dapm_input_path , <nl> __assign_str ( pname , path -> name ? path -> name : DAPM_DIRECT ); <nl> __assign_str ( psname , path -> source -> name ); <nl> __entry -> path_connect = path -> connect ; <nl> - __entry -> path_source = ( int ) path -> source ; <nl> + __entry -> path_source = ( long ) path -> source ; <nl> ), <nl>  <nl> TP_printk ("% c % s <- % s <- % s \ n ",
static int xive_spapr_get_ipi ( unsigned int cpu , struct xive_cpu * xc ) <nl>  <nl> static void xive_spapr_put_ipi ( unsigned int cpu , struct xive_cpu * xc ) <nl> { <nl> + if (! xc -> hw_ipi ) <nl> + return ; <nl> + <nl> xive_irq_bitmap_free ( xc -> hw_ipi ); <nl> + xc -> hw_ipi = 0 ; <nl> } <nl> # endif /* CONFIG_SMP */ <nl> 
static ssize_t ucma_accept ( struct ucma_file * file , const char __user * inbuf , <nl> return PTR_ERR ( ctx ); <nl>  <nl> if ( cmd . conn_param . valid ) { <nl> - ctx -> uid = cmd . uid ; <nl> ucma_copy_conn_param (& conn_param , & cmd . conn_param ); <nl> + mutex_lock (& file -> mut ); <nl> ret = rdma_accept ( ctx -> cm_id , & conn_param ); <nl> + if (! ret ) <nl> + ctx -> uid = cmd . uid ; <nl> + mutex_unlock (& file -> mut ); <nl> } else <nl> ret = rdma_accept ( ctx -> cm_id , NULL ); <nl> 
static int bcma_get_next_core ( struct bcma_bus * bus , u32 __iomem ** eromptr , <nl> switch ( core -> id . id ) { <nl> case BCMA_CORE_4706_MAC_GBIT_COMMON : <nl> case BCMA_CORE_NS_CHIPCOMMON_B : <nl> + case BCMA_CORE_PMU : <nl> + case BCMA_CORE_GCI : <nl> /* Not used yet : case BCMA_CORE_OOB_ROUTER : */ <nl> break ; <nl> default :
int __kvm_set_memory_region ( struct kvm * kvm , <nl> /* destroy any largepage mappings for dirty tracking */ <nl> } <nl>  <nl> - if (! npages ) { <nl> + if (! npages || base_gfn != old . base_gfn ) { <nl> struct kvm_memory_slot * slot ; <nl>  <nl> r = - ENOMEM ; <nl> int __kvm_set_memory_region ( struct kvm * kvm , <nl> old_memslots = kvm -> memslots ; <nl> rcu_assign_pointer ( kvm -> memslots , slots ); <nl> synchronize_srcu_expedited (& kvm -> srcu ); <nl> - /* From this point no new shadow pages pointing to a deleted <nl> - * memslot will be created . <nl> + /* From this point no new shadow pages pointing to a deleted , <nl> + * or moved , memslot will be created . <nl> * <nl> * validation of sp -> gfn happens in : <nl> * - gfn_to_hva ( kvm_read_guest , gfn_to_pfn )
static int pppoe_rcv_core ( struct sock * sk , struct sk_buff * skb ) <nl> * can ' t change . <nl> */ <nl>  <nl> + if ( skb -> pkt_type == PACKET_OTHERHOST ) <nl> + goto abort_kfree ; <nl> + <nl> if ( sk -> sk_state & PPPOX_BOUND ) { <nl> ppp_input (& po -> chan , skb ); <nl> } else if ( sk -> sk_state & PPPOX_RELAY ) {
xfs_acl_from_disk ( struct xfs_acl * aclp ) <nl> struct posix_acl_entry * acl_e ; <nl> struct posix_acl * acl ; <nl> struct xfs_acl_entry * ace ; <nl> - int count , i ; <nl> + unsigned int count , i ; <nl>  <nl> count = be32_to_cpu ( aclp -> acl_cnt ); <nl> if ( count > XFS_ACL_MAX_ENTRIES )
struct request_list * __blk_queue_next_rl ( struct request_list * rl , <nl> */ <nl> if ( rl == & q -> root_rl ) { <nl> ent = & q -> blkg_list ; <nl> + /* There are no more block groups , hence no request lists */ <nl> + if ( list_empty ( ent )) <nl> + return NULL ; <nl> } else { <nl> blkg = container_of ( rl , struct blkcg_gq , rl ); <nl> ent = & blkg -> q_node ;
int regulator_map_voltage_linear_range ( struct regulator_dev * rdev , <nl> return ret ; <nl> } <nl>  <nl> + ret += range -> min_sel ; <nl> + <nl> break ; <nl> } <nl> 
static inline void x86_assign_hw_event ( struct perf_event * event , <nl> hwc -> event_base = 0 ; <nl> } else if ( hwc -> idx >= X86_PMC_IDX_FIXED ) { <nl> hwc -> config_base = MSR_ARCH_PERFMON_FIXED_CTR_CTRL ; <nl> - hwc -> event_base = MSR_ARCH_PERFMON_FIXED_CTR0 ; <nl> + hwc -> event_base = MSR_ARCH_PERFMON_FIXED_CTR0 + ( hwc -> idx - X86_PMC_IDX_FIXED ); <nl> } else { <nl> hwc -> config_base = x86_pmu_config_addr ( hwc -> idx ); <nl> hwc -> event_base = x86_pmu_event_addr ( hwc -> idx );
static void mem_cgroup_put ( struct mem_cgroup * memcg ); <nl>  <nl> /* Writing them here to avoid exposing memcg ' s inner layout */ <nl> # ifdef CONFIG_CGROUP_MEM_RES_CTLR_KMEM <nl> -# ifdef CONFIG_INET <nl> # include < net / sock . h > <nl> # include < net / ip . h > <nl>  <nl> void sock_release_memcg ( struct sock * sk ) <nl> } <nl> } <nl>  <nl> +# ifdef CONFIG_INET <nl> struct cg_proto * tcp_proto_cgroup ( struct mem_cgroup * memcg ) <nl> { <nl> if (! memcg || mem_cgroup_is_root ( memcg ))
static u32 atombios_adjust_pll ( struct drm_crtc * crtc , <nl> if ( ASIC_IS_DCE41 ( rdev ) || ASIC_IS_DCE61 ( rdev ) || ASIC_IS_DCE8 ( rdev )) <nl> radeon_crtc -> pll_flags |= RADEON_PLL_USE_FRAC_FB_DIV ; <nl> /* use frac fb div on RS780 / RS880 */ <nl> - if (( rdev -> family == CHIP_RS780 ) || ( rdev -> family == CHIP_RS880 )) <nl> + if ((( rdev -> family == CHIP_RS780 ) || ( rdev -> family == CHIP_RS880 )) <nl> + && ! radeon_crtc -> ss_enabled ) <nl> radeon_crtc -> pll_flags |= RADEON_PLL_USE_FRAC_FB_DIV ; <nl> if ( ASIC_IS_DCE32 ( rdev ) && mode -> clock > 165000 ) <nl> radeon_crtc -> pll_flags |= RADEON_PLL_USE_FRAC_FB_DIV ; <nl> static u32 atombios_adjust_pll ( struct drm_crtc * crtc , <nl> if ( radeon_crtc -> ss . refdiv ) { <nl> radeon_crtc -> pll_flags |= RADEON_PLL_USE_REF_DIV ; <nl> radeon_crtc -> pll_reference_div = radeon_crtc -> ss . refdiv ; <nl> - if ( ASIC_IS_AVIVO ( rdev )) <nl> + if ( rdev -> family >= CHIP_RV770 ) <nl> radeon_crtc -> pll_flags |= RADEON_PLL_USE_FRAC_FB_DIV ; <nl> } <nl> }
int policydb_read ( struct policydb * p , void * fp ) <nl> } else <nl> tr -> tclass = p -> process_class ; <nl>  <nl> + rc = - EINVAL ; <nl> if (! policydb_role_isvalid ( p , tr -> role ) || <nl> ! policydb_type_isvalid ( p , tr -> type ) || <nl> ! policydb_class_isvalid ( p , tr -> tclass ) ||
int rtc_irq_set_freq ( struct rtc_device * rtc , struct rtc_task * task , int freq ) <nl> int err = 0 ; <nl> unsigned long flags ; <nl>  <nl> - if ( freq <= 0 ) <nl> + if ( freq <= 0 || freq > 5000 ) <nl> return - EINVAL ; <nl>  <nl> spin_lock_irqsave (& rtc -> irq_task_lock , flags );
int uprobe_write_opcode ( struct mm_struct * mm , unsigned long vaddr , <nl>  <nl> retry : <nl> /* Read the page with vaddr into memory */ <nl> - ret = get_user_pages_remote ( NULL , mm , vaddr , 1 , FOLL_FORCE , & old_page , <nl> - & vma , NULL ); <nl> + ret = get_user_pages_remote ( NULL , mm , vaddr , 1 , <nl> + FOLL_FORCE | FOLL_SPLIT , & old_page , & vma , NULL ); <nl> if ( ret <= 0 ) <nl> return ret ; <nl> 
struct sk_buff * tcp_make_synack ( const struct sock * sk , struct dst_entry * dst , <nl> th -> source = htons ( ireq -> ir_num ); <nl> th -> dest = ireq -> ir_rmt_port ; <nl> skb -> mark = ireq -> ir_mark ; <nl> - /* Setting of flags are superfluous here for callers ( and ECE is <nl> - * not even correctly set ) <nl> - */ <nl> - tcp_init_nondata_skb ( skb , tcp_rsk ( req )-> snt_isn , <nl> - TCPHDR_SYN | TCPHDR_ACK ); <nl> - <nl> - th -> seq = htonl ( TCP_SKB_CB ( skb )-> seq ); <nl> + skb -> ip_summed = CHECKSUM_PARTIAL ; <nl> + th -> seq = htonl ( tcp_rsk ( req )-> snt_isn ); <nl> /* XXX data is queued and acked as is . No buffer / window check */ <nl> th -> ack_seq = htonl ( tcp_rsk ( req )-> rcv_nxt ); <nl> 
static int fc_lport_els_request ( struct fc_bsg_job * job , <nl> char * pp ; <nl> int len ; <nl>  <nl> - fp = fc_frame_alloc ( lport , sizeof ( struct fc_frame_header ) + <nl> - job -> request_payload . payload_len ); <nl> + fp = fc_frame_alloc ( lport , job -> request_payload . payload_len ); <nl> if (! fp ) <nl> return - ENOMEM ; <nl> 
static void copy_instruction ( struct kprobe * p ) <nl> ftrace_generate_nop_insn (( struct ftrace_insn *) p -> ainsn . insn ); <nl> p -> ainsn . is_ftrace_insn = 1 ; <nl> } else <nl> - memcpy ( p -> ainsn . insn , p -> addr , insn_length ( p -> opcode >> 8 )); <nl> + memcpy ( p -> ainsn . insn , p -> addr , insn_length (* p -> addr >> 8 )); <nl> p -> opcode = p -> ainsn . insn [ 0 ]; <nl> if (! probe_is_insn_relative_long ( p -> ainsn . insn )) <nl> return ;
static int sw_sync_open ( struct inode * inode , struct file * file ) <nl> get_task_comm ( task_comm , current ); <nl>  <nl> obj = sw_sync_timeline_create ( task_comm ); <nl> - if ( obj == NULL ) <nl> + if (! obj ) <nl> return - ENOMEM ; <nl>  <nl> file -> private_data = obj ; <nl> static long sw_sync_ioctl_create_fence ( struct sw_sync_timeline * obj , <nl> } <nl>  <nl> pt = sw_sync_pt_create ( obj , data . value ); <nl> - if ( pt == NULL ) { <nl> + if (! pt ) { <nl> err = - ENOMEM ; <nl> goto err ; <nl> } <nl>  <nl> data . name [ sizeof ( data . name ) - 1 ] = '\ 0 '; <nl> fence = sync_fence_create ( data . name , pt ); <nl> - if ( fence == NULL ) { <nl> + if (! fence ) { <nl> sync_pt_free ( pt ); <nl> err = - ENOMEM ; <nl> goto err ;
static void __soc_pcmcia_hw_shutdown ( struct soc_pcmcia_socket * skt , <nl>  <nl> if ( skt -> ops -> hw_shutdown ) <nl> skt -> ops -> hw_shutdown ( skt ); <nl> + <nl> + clk_disable_unprepare ( skt -> clk ); <nl> } <nl>  <nl> static void soc_pcmcia_hw_shutdown ( struct soc_pcmcia_socket * skt ) <nl> static int soc_pcmcia_hw_init ( struct soc_pcmcia_socket * skt ) <nl> { <nl> int ret = 0 , i ; <nl>  <nl> + clk_prepare_enable ( skt -> clk ); <nl> + <nl> if ( skt -> ops -> hw_init ) { <nl> ret = skt -> ops -> hw_init ( skt ); <nl> if ( ret )
unsigned int v4l2_m2m_poll ( struct file * file , struct v4l2_m2m_ctx * m2m_ctx , <nl> if ( m2m_ctx -> m2m_dev -> m2m_ops -> unlock ) <nl> m2m_ctx -> m2m_dev -> m2m_ops -> unlock ( m2m_ctx -> priv ); <nl>  <nl> - poll_wait ( file , & src_q -> done_wq , wait ); <nl> - poll_wait ( file , & dst_q -> done_wq , wait ); <nl> + if ( list_empty (& src_q -> done_list )) <nl> + poll_wait ( file , & src_q -> done_wq , wait ); <nl> + if ( list_empty (& dst_q -> done_list )) <nl> + poll_wait ( file , & dst_q -> done_wq , wait ); <nl>  <nl> if ( m2m_ctx -> m2m_dev -> m2m_ops -> lock ) <nl> m2m_ctx -> m2m_dev -> m2m_ops -> lock ( m2m_ctx -> priv );
static int key_notify_policy_flush ( const struct km_event * c ) <nl> hdr -> sadb_msg_pid = c -> portid ; <nl> hdr -> sadb_msg_version = PF_KEY_V2 ; <nl> hdr -> sadb_msg_errno = ( uint8_t ) 0 ; <nl> + hdr -> sadb_msg_satype = SADB_SATYPE_UNSPEC ; <nl> hdr -> sadb_msg_len = ( sizeof ( struct sadb_msg ) / sizeof ( uint64_t )); <nl> pfkey_broadcast ( skb_out , GFP_ATOMIC , BROADCAST_ALL , NULL , c -> net ); <nl> return 0 ;
static enum page_references page_check_references ( struct page * page , <nl> } <nl>  <nl> /* Reclaim if clean , defer dirty pages to writeback */ <nl> - if ( referenced_page ) <nl> + if ( referenced_page && ! PageSwapBacked ( page )) <nl> return PAGEREF_RECLAIM_CLEAN ; <nl>  <nl> return PAGEREF_RECLAIM ;
static void __init imx6sl_init_late ( void ) <nl> if ( IS_ENABLED ( CONFIG_ARM_IMX6Q_CPUFREQ )) <nl> platform_device_register_simple (" imx6q - cpufreq ", - 1 , NULL , 0 ); <nl>  <nl> - if ( cpu_is_imx6sl ()) <nl> + if ( IS_ENABLED ( CONFIG_SOC_IMX6SL ) && cpu_is_imx6sl ()) <nl> imx6sl_cpuidle_init (); <nl> - else <nl> + else if ( IS_ENABLED ( CONFIG_SOC_IMX6SLL )) <nl> imx6sx_cpuidle_init (); <nl> } <nl> 
static int airspy_probe ( struct usb_interface * intf , <nl> if ( ret ) { <nl> dev_err ( s -> dev , " Failed to register as video device (% d )\ n ", <nl> ret ); <nl> - goto err_unregister_v4l2_dev ; <nl> + goto err_free_controls ; <nl> } <nl> dev_info ( s -> dev , " Registered as % s \ n ", <nl> video_device_node_name (& s -> vdev )); <nl> static int airspy_probe ( struct usb_interface * intf , <nl>  <nl> err_free_controls : <nl> v4l2_ctrl_handler_free (& s -> hdl ); <nl> - err_unregister_v4l2_dev : <nl> v4l2_device_unregister (& s -> v4l2_dev ); <nl> err_free_mem : <nl> kfree ( s );
u32 __tcp_select_window ( struct sock * sk ) <nl> */ <nl> if ( window <= free_space - mss || window > free_space ) <nl> window = ( free_space / mss )* mss ; <nl> + else if ( mss == full_space && <nl> + free_space > window + full_space / 2 ) <nl> + window = free_space ; <nl> } <nl>  <nl> return window ;
void mesh_mgmt_ies_add ( struct sk_buff * skb , struct ieee80211_sub_if_data * sdata ) <nl> } <nl> } <nl>  <nl> + if ( sband -> band == IEEE80211_BAND_2GHZ ) { <nl> + pos = skb_put ( skb , 2 + 1 ); <nl> + * pos ++ = WLAN_EID_DS_PARAMS ; <nl> + * pos ++ = 1 ; <nl> + * pos ++ = ieee80211_frequency_to_channel ( local -> hw . conf . channel -> center_freq ); <nl> + } <nl> + <nl> pos = skb_put ( skb , 2 + sdata -> u . mesh . mesh_id_len ); <nl> * pos ++ = WLAN_EID_MESH_ID ; <nl> * pos ++ = sdata -> u . mesh . mesh_id_len ;
int rtl_pci_reset_trx_ring ( struct ieee80211_hw * hw ) <nl> dev_kfree_skb_irq ( skb ); <nl> ring -> idx = ( ring -> idx + 1 ) % ring -> entries ; <nl> } <nl> + <nl> + if ( rtlpriv -> use_new_trx_flow ) { <nl> + rtlpci -> tx_ring [ i ]. cur_tx_rp = 0 ; <nl> + rtlpci -> tx_ring [ i ]. cur_tx_wp = 0 ; <nl> + } <nl> + <nl> ring -> idx = 0 ; <nl> + ring -> entries = rtlpci -> txringcount [ i ]; <nl> } <nl> } <nl> spin_unlock_irqrestore (& rtlpriv -> locks . irq_th_lock , flags );
int amdgpu_vce_resume ( struct amdgpu_device * adev ) <nl>  <nl> hdr = ( const struct common_firmware_header *) adev -> vce . fw -> data ; <nl> offset = le32_to_cpu ( hdr -> ucode_array_offset_bytes ); <nl> - memcpy ( cpu_addr , ( adev -> vce . fw -> data ) + offset , <nl> - ( adev -> vce . fw -> size ) - offset ); <nl> + memcpy_toio ( cpu_addr , adev -> vce . fw -> data + offset , <nl> + adev -> vce . fw -> size - offset ); <nl>  <nl> amdgpu_bo_kunmap ( adev -> vce . vcpu_bo ); <nl> 
static int pn533_i2c_remove ( struct i2c_client * client ) <nl>  <nl> pn533_unregister_device ( phy -> priv ); <nl>  <nl> + free_irq ( client -> irq , phy ); <nl> + <nl> return 0 ; <nl> } <nl> 
static int load_firmware ( struct octeon_device * oct ) <nl> char fw_name [ LIO_MAX_FW_FILENAME_LEN ]; <nl> char * tmp_fw_type ; <nl>  <nl> - if ( fw_type_is_auto ()) <nl> + if ( fw_type_is_auto ()) { <nl> tmp_fw_type = LIO_FW_NAME_TYPE_NIC ; <nl> - else <nl> + strncpy ( fw_type , tmp_fw_type , sizeof ( fw_type )); <nl> + } else { <nl> tmp_fw_type = fw_type ; <nl> + } <nl>  <nl> sprintf ( fw_name , "% s % s % s_ % s % s ", LIO_FW_DIR , LIO_FW_BASE_NAME , <nl> octeon_get_conf ( oct )-> card_name , tmp_fw_type ,
int __init dmar_parse_dev_scope ( void * start , void * end , int * cnt , <nl> if ( scope -> entry_type == ACPI_DMAR_SCOPE_TYPE_ENDPOINT || <nl> scope -> entry_type == ACPI_DMAR_SCOPE_TYPE_BRIDGE ) <nl> (* cnt )++; <nl> - else if ( scope -> entry_type != ACPI_DMAR_SCOPE_TYPE_IOAPIC ) { <nl> + else if ( scope -> entry_type != ACPI_DMAR_SCOPE_TYPE_IOAPIC && <nl> + scope -> entry_type != ACPI_DMAR_SCOPE_TYPE_HPET ) { <nl> pr_warn (" Unsupported device scope \ n "); <nl> } <nl> start += scope -> length ;
static void destroy_cm_id ( struct iw_cm_id * cm_id ) <nl> { <nl> struct iwcm_id_private * cm_id_priv ; <nl> unsigned long flags ; <nl> - int ret ; <nl>  <nl> cm_id_priv = container_of ( cm_id , struct iwcm_id_private , id ); <nl> /* <nl> static void destroy_cm_id ( struct iw_cm_id * cm_id ) <nl> cm_id_priv -> state = IW_CM_STATE_DESTROYING ; <nl> spin_unlock_irqrestore (& cm_id_priv -> lock , flags ); <nl> /* destroy the listening endpoint */ <nl> - ret = cm_id -> device -> iwcm -> destroy_listen ( cm_id ); <nl> + cm_id -> device -> iwcm -> destroy_listen ( cm_id ); <nl> spin_lock_irqsave (& cm_id_priv -> lock , flags ); <nl> break ; <nl> case IW_CM_STATE_ESTABLISHED :
static int wm8903_probe ( struct snd_soc_codec * codec ) <nl> /* power down chip */ <nl> static int wm8903_remove ( struct snd_soc_codec * codec ) <nl> { <nl> + struct wm8903_priv * wm8903 = snd_soc_codec_get_drvdata ( codec ); <nl> + <nl> wm8903_free_gpio ( codec ); <nl> wm8903_set_bias_level ( codec , SND_SOC_BIAS_OFF ); <nl> + if ( wm8903 -> irq ) <nl> + free_irq ( wm8903 -> irq , codec ); <nl> + <nl> return 0 ; <nl> } <nl> 
static void i40evf_adminq_task ( struct work_struct * work ) <nl>  <nl> /* check for error indications */ <nl> val = rd32 ( hw , hw -> aq . arq . len ); <nl> + if ( val == 0xdeadbeef ) /* indicates device in reset */ <nl> + goto freedom ; <nl> oldval = val ; <nl> if ( val & I40E_VF_ARQLEN1_ARQVFE_MASK ) { <nl> dev_info (& adapter -> pdev -> dev , " ARQ VF Error detected \ n ");
static int fsl_lpspi_probe ( struct platform_device * pdev ) <nl> ret = pm_runtime_get_sync ( fsl_lpspi -> dev ); <nl> if ( ret < 0 ) { <nl> dev_err ( fsl_lpspi -> dev , " failed to enable clock \ n "); <nl> - return ret ; <nl> + goto out_controller_put ; <nl> } <nl>  <nl> temp = readl ( fsl_lpspi -> base + IMX7ULP_PARAM );
static struct snd_soc_dai * fsi_get_dai ( struct snd_pcm_substream * substream ) <nl> return rtd -> cpu_dai ; <nl> } <nl>  <nl> - static struct fsi_priv * fsi_get_priv ( struct snd_pcm_substream * substream ) <nl> + static struct fsi_priv * fsi_get_priv_frm_dai ( struct snd_soc_dai * dai ) <nl> { <nl> - struct snd_soc_dai * dai = fsi_get_dai ( substream ); <nl> struct fsi_master * master = snd_soc_dai_get_drvdata ( dai ); <nl>  <nl> if ( dai -> id == 0 ) <nl> static struct fsi_priv * fsi_get_priv ( struct snd_pcm_substream * substream ) <nl> return & master -> fsib ; <nl> } <nl>  <nl> + static struct fsi_priv * fsi_get_priv ( struct snd_pcm_substream * substream ) <nl> +{ <nl> + return fsi_get_priv_frm_dai ( fsi_get_dai ( substream )); <nl> +} <nl> + <nl> static u32 fsi_get_info_flags ( struct fsi_priv * fsi ) <nl> { <nl> int is_porta = fsi_is_port_a ( fsi );
static int dwc3_qcom_probe ( struct platform_device * pdev ) <nl>  <nl> if ( qcom -> acpi_pdata -> is_urs ) { <nl> qcom -> urs_usb = dwc3_qcom_create_urs_usb_platdev ( dev ); <nl> - if (! qcom -> urs_usb ) { <nl> + if ( IS_ERR_OR_NULL ( qcom -> urs_usb )) { <nl> dev_err ( dev , " failed to create URS USB platdev \ n "); <nl> - return - ENODEV ; <nl> + if (! qcom -> urs_usb ) <nl> + return - ENODEV ; <nl> + else <nl> + return PTR_ERR ( qcom -> urs_usb ); <nl> } <nl> } <nl> }
ip_set_sockfn_get ( struct sock * sk , int optval , void __user * user , int * len ) <nl> if (* op < IP_SET_OP_VERSION ) { <nl> /* Check the version at the beginning of operations */ <nl> struct ip_set_req_version * req_version = data ; <nl> + <nl> + if (* len < sizeof ( struct ip_set_req_version )) { <nl> + ret = - EINVAL ; <nl> + goto done ; <nl> + } <nl> + <nl> if ( req_version -> version != IPSET_PROTOCOL ) { <nl> ret = - EPROTO ; <nl> goto done ;
static inline void tpg_s_bytesperline ( struct tpg_data * tpg , unsigned plane , unsi <nl>  <nl> tpg -> bytesperline [ p ] = plane_w / tpg -> hdownsampling [ p ]; <nl> } <nl> + if ( tpg_g_interleaved ( tpg )) <nl> + tpg -> bytesperline [ 1 ] = tpg -> bytesperline [ 0 ]; <nl> } <nl>  <nl> 
static int snd_sst_fill_kernel_list ( struct stream_info * stream , <nl> static int sent_offset ; <nl> static unsigned long sent_index ; <nl>  <nl> - stream_bufs = kzalloc ( sizeof (* stream_bufs ), GFP_KERNEL ); <nl> - if (! stream_bufs ) <nl> - return - ENOMEM ; <nl> - stream_bufs -> addr = sst_drv_ctx -> mmap_mem ; <nl> # ifdef CONFIG_MRST_RAR_HANDLER <nl> if ( stream -> ops == STREAM_OPS_PLAYBACK_DRM ) { <nl> for ( index = stream -> sg_index ; index < nr_segs ; index ++) { <nl> static int snd_sst_fill_kernel_list ( struct stream_info * stream , <nl> return retval ; <nl> } <nl> # endif <nl> + stream_bufs = kzalloc ( sizeof (* stream_bufs ), GFP_KERNEL ); <nl> + if (! stream_bufs ) <nl> + return - ENOMEM ; <nl> + stream_bufs -> addr = sst_drv_ctx -> mmap_mem ; <nl> mmap_len = sst_drv_ctx -> mmap_len ; <nl> stream_bufs -> addr = sst_drv_ctx -> mmap_mem ; <nl> bufp = stream -> cur_ptr ;
static int pn533_data_exchange_complete ( struct pn533 * dev , void * _arg , <nl> */ <nl> void pn533_recv_frame ( struct pn533 * dev , struct sk_buff * skb , int status ) <nl> { <nl> + if (! dev -> cmd ) <nl> + goto sched_wq ; <nl> + <nl> dev -> cmd -> status = status ; <nl>  <nl> + if ( status != 0 ) { <nl> + dev_dbg ( dev -> dev , "% s : Error received : % d \ n ", __func__ , status ); <nl> + goto sched_wq ; <nl> + } <nl> + <nl> if ( skb == NULL ) { <nl> pr_err (" NULL Frame -> link is dead \ n "); <nl> goto sched_wq ;
# endif <nl> # include " igb . h " <nl>  <nl> -# define DRV_VERSION " 2 . 4 . 13 - k2 " <nl> +# define MAJ 3 <nl> +# define MIN 0 <nl> +# define BUILD 6 <nl> +# define KFIX 2 <nl> +# define DRV_VERSION __stringify ( MAJ ) "." __stringify ( MIN ) "." \ <nl> + __stringify ( BUILD ) "- k " __stringify ( KFIX ) <nl> char igb_driver_name [] = " igb "; <nl> char igb_driver_version [] = DRV_VERSION ; <nl> static const char igb_driver_string [] =
static int trace__event_handler ( struct trace * trace , struct perf_evsel * evsel , <nl> { <nl> trace__printf_interrupted_entry ( trace , sample ); <nl> trace__fprintf_tstamp ( trace , sample -> time , trace -> output ); <nl> - fprintf ( trace -> output , "(% 9 . 9s ): % s :", " ", evsel -> name ); <nl> + <nl> + if ( trace -> trace_syscalls ) <nl> + fprintf ( trace -> output , "( ): "); <nl> + <nl> + fprintf ( trace -> output , "% s :", evsel -> name ); <nl>  <nl> if ( evsel -> tp_format ) { <nl> event_format__fprintf ( evsel -> tp_format , sample -> cpu ,
static int ds_event ( struct pcmcia_socket * skt , event_t event , int priority ) <nl> { <nl> struct pcmcia_socket * s = pcmcia_get_socket ( skt ); <nl>  <nl> + if (! s ) { <nl> + printk ( KERN_ERR " PCMCIA obtaining reference to socket % p " \ <nl> + " failed , event 0x % x lost !\ n ", skt , event ); <nl> + return - ENODEV ; <nl> + } <nl> + <nl> ds_dbg ( 1 , " ds_event ( 0x % 06x , % d , 0x % p )\ n ", <nl> event , priority , skt ); <nl> 
int skl_init_module ( struct skl_sst * ctx , <nl> return ret ; <nl> } <nl> mconfig -> m_state = SKL_MODULE_INIT_DONE ; <nl> - <nl> + kfree ( param_data ); <nl> return ret ; <nl> } <nl> 
static int rt5514_dsp_voice_wake_up_put ( struct snd_kcontrol * kcontrol , <nl> # else <nl> dev_err ( component -> dev , " There is no SPI driver for " <nl> " loading the firmware \ n "); <nl> + memset ( buf , 0 , sizeof ( buf )); <nl> # endif <nl> rt5514 -> pll3_cal_value = buf [ 0 ] | buf [ 1 ] << 8 | <nl> buf [ 2 ] << 16 | buf [ 3 ] << 24 ;
static int alps_enter_command_mode ( struct psmouse * psmouse , <nl> return - 1 ; <nl> } <nl>  <nl> - if ( param [ 0 ] != 0x88 && param [ 1 ] != 0x07 ) { <nl> + if ( param [ 0 ] != 0x88 || ( param [ 1 ] != 0x07 && param [ 1 ] != 0x08 )) { <nl> psmouse_dbg ( psmouse , <nl> " unknown response while entering command mode \ n "); <nl> return - 1 ;
static struct snd_soc_dai_driver psc_i2s_dai [] = {{ <nl> . ops = & psc_i2s_dai_ops , <nl> } }; <nl>  <nl> + static const struct snd_soc_component_driver psc_i2s_component = { <nl> + . name = " mpc5200 - i2s ", <nl> +}; <nl> + <nl> /* --------------------------------------------------------------------- <nl> * OF platform bus binding code : <nl> * - Probe / remove operations <nl> static int psc_i2s_of_probe ( struct platform_device * op ) <nl> if ( rc != 0 ) <nl> return rc ; <nl>  <nl> - rc = snd_soc_register_dais (& op -> dev , psc_i2s_dai , ARRAY_SIZE ( psc_i2s_dai )); <nl> + rc = snd_soc_register_component (& op -> dev , & psc_i2s_component , <nl> + psc_i2s_dai , ARRAY_SIZE ( psc_i2s_dai )); <nl> if ( rc != 0 ) { <nl> pr_err (" Failed to register DAI \ n "); <nl> return rc ; <nl> static int psc_i2s_of_probe ( struct platform_device * op ) <nl> static int psc_i2s_of_remove ( struct platform_device * op ) <nl> { <nl> mpc5200_audio_dma_destroy ( op ); <nl> - snd_soc_unregister_dais (& op -> dev , ARRAY_SIZE ( psc_i2s_dai )); <nl> + snd_soc_unregister_component (& op -> dev ); <nl> return 0 ; <nl> } <nl> 
static int blktrans_open ( struct block_device * bdev , fmode_t mode ) <nl>  <nl> mutex_lock (& dev -> lock ); <nl>  <nl> - if ( dev -> open ++) <nl> + if ( dev -> open ) <nl> goto unlock ; <nl>  <nl> kref_get (& dev -> ref ); <nl> static int blktrans_open ( struct block_device * bdev , fmode_t mode ) <nl> goto error_release ; <nl>  <nl> unlock : <nl> + dev -> open ++; <nl> mutex_unlock (& dev -> lock ); <nl> blktrans_dev_put ( dev ); <nl> return ret ;
static void __init atmci_get_cap ( struct atmel_mci * host ) <nl> /* keep only major version number */ <nl> switch ( version & 0xf00 ) { <nl> case 0x100 : <nl> + host -> caps . has_pdc = 1 ; <nl> + break ; <nl> case 0x200 : <nl> host -> caps . has_pdc = 1 ; <nl> host -> caps . has_rwproof = 1 ;
int qla24xx_async_notify_ack ( scsi_qla_host_t * vha , fc_port_t * fcport , <nl> qla2x00_init_timer ( sp , qla2x00_get_async_timeout ( vha )+ 2 ); <nl>  <nl> sp -> u . iocb_cmd . u . nack . ntfy = ntfy ; <nl> - <nl> + sp -> u . iocb_cmd . timeout = qla2x00_async_iocb_timeout ; <nl> sp -> done = qla2x00_async_nack_sp_done ; <nl>  <nl> rval = qla2x00_start_sp ( sp );
static int da8xx_pan_display ( struct fb_var_screeninfo * var , <nl>  <nl> start = fix -> smem_start + <nl> new_var . yoffset * fix -> line_length + <nl> - new_var . xoffset * var -> bits_per_pixel / 8 ; <nl> - end = start + var -> yres * fix -> line_length - 1 ; <nl> + new_var . xoffset * fbi -> var . bits_per_pixel / 8 ; <nl> + end = start + fbi -> var . yres * fix -> line_length - 1 ; <nl> par -> dma_start = start ; <nl> par -> dma_end = end ; <nl> }
static int qed_iov_enable_vf_access ( struct qed_hwfn * p_hwfn , <nl> u32 igu_vf_conf = IGU_VF_CONF_FUNC_EN ; <nl> int rc ; <nl>  <nl> + /* It ' s possible VF was previously considered malicious - <nl> + * clear the indication even if we ' re only going to disable VF . <nl> + */ <nl> + vf -> b_malicious = false ; <nl> + <nl> if ( vf -> to_disable ) <nl> return 0 ; <nl>  <nl> static int qed_iov_enable_vf_access ( struct qed_hwfn * p_hwfn , <nl>  <nl> qed_iov_vf_igu_reset ( p_hwfn , p_ptt , vf ); <nl>  <nl> - /* It ' s possible VF was previously considered malicious */ <nl> - vf -> b_malicious = false ; <nl> - <nl> rc = qed_mcp_config_vf_msix ( p_hwfn , p_ptt , vf -> abs_vf_id , vf -> num_sbs ); <nl> if ( rc ) <nl> return rc ;
int ipu_dp_init ( struct ipu_soc * ipu , struct device * dev , unsigned long base ) <nl> int i ; <nl>  <nl> priv = devm_kzalloc ( dev , sizeof (* priv ), GFP_KERNEL ); <nl> + if (! priv ) <nl> + return - ENOMEM ; <nl> priv -> dev = dev ; <nl> priv -> ipu = ipu ; <nl> 
static void ext3_mark_recovery_complete ( struct super_block * sb , <nl>  <nl> journal_lock_updates ( journal ); <nl> journal_flush ( journal ); <nl> + lock_super ( sb ); <nl> if ( EXT3_HAS_INCOMPAT_FEATURE ( sb , EXT3_FEATURE_INCOMPAT_RECOVER ) && <nl> sb -> s_flags & MS_RDONLY ) { <nl> EXT3_CLEAR_INCOMPAT_FEATURE ( sb , EXT3_FEATURE_INCOMPAT_RECOVER ); <nl> sb -> s_dirt = 0 ; <nl> ext3_commit_super ( sb , es , 1 ); <nl> } <nl> + unlock_super ( sb ); <nl> journal_unlock_updates ( journal ); <nl> } <nl>  <nl> static int ext3_remount ( struct super_block * sb , int * flags , char * data ) <nl> ( sbi -> s_mount_state & EXT3_VALID_FS )) <nl> es -> s_state = cpu_to_le16 ( sbi -> s_mount_state ); <nl>  <nl> + /* <nl> + * We have to unlock super so that we can wait for <nl> + * transactions . <nl> + */ <nl> + unlock_super ( sb ); <nl> ext3_mark_recovery_complete ( sb , es ); <nl> + lock_super ( sb ); <nl> } else { <nl> __le32 ret ; <nl> if (( ret = EXT3_HAS_RO_COMPAT_FEATURE ( sb ,
static int conf_choice ( struct menu * menu ) <nl> } <nl> if (! child ) <nl> continue ; <nl> - if ( line [ strlen ( line ) - 1 ] == '?') { <nl> + if ( line [ 0 ] && line [ strlen ( line ) - 1 ] == '?') { <nl> print_help ( child ); <nl> continue ; <nl> }
struct ipt_hashlimit_htable { <nl> /* used internally */ <nl> spinlock_t lock ; /* lock for list_head */ <nl> u_int32_t rnd ; /* random seed for hash */ <nl> + int rnd_initialized ; <nl> struct timer_list timer ; /* timer for gc */ <nl> atomic_t count ; /* number entries in table */ <nl>  <nl> __dsthash_alloc_init ( struct ipt_hashlimit_htable * ht , struct dsthash_dst * dst ) <nl>  <nl> /* initialize hash with random val at the time we allocate <nl> * the first hashtable entry */ <nl> - if (! ht -> rnd ) <nl> + if (! ht -> rnd_initialized ) { <nl> get_random_bytes (& ht -> rnd , 4 ); <nl> + ht -> rnd_initialized = 1 ; <nl> + } <nl>  <nl> if ( ht -> cfg . max && <nl> atomic_read (& ht -> count ) >= ht -> cfg . max ) { <nl> static int htable_create ( struct ipt_hashlimit_info * minfo ) <nl>  <nl> atomic_set (& hinfo -> count , 0 ); <nl> atomic_set (& hinfo -> use , 1 ); <nl> - hinfo -> rnd = 0 ; <nl> + hinfo -> rnd_initialized = 0 ; <nl> spin_lock_init (& hinfo -> lock ); <nl> hinfo -> pde = create_proc_entry ( minfo -> name , 0 , hashlimit_procdir ); <nl> if (! hinfo -> pde ) {
static int destroy_queue_nocpsch ( struct device_queue_manager * dqm , <nl> } <nl> dqm -> sdma_queue_count --; <nl> deallocate_sdma_queue ( dqm , q -> sdma_id ); <nl> + } else { <nl> + pr_debug (" q -> properties . type is invalid (% d )\ n ", <nl> + q -> properties . type ); <nl> + retval = - EINVAL ; <nl> + goto out ; <nl> } <nl>  <nl> retval = mqd -> destroy_mqd ( mqd , q -> mqd ,
# include < asm / atariints . h > <nl> # include < asm / atari_stdma . h > <nl>  <nl> +# define DRV_NAME " falconide " <nl>  <nl> /* <nl> * Base of the IDE interface <nl> static int __init falconide_init ( void ) <nl>  <nl> printk ( KERN_INFO " ide : Falcon IDE controller \ n "); <nl>  <nl> + if (! request_mem_region ( ATA_HD_BASE , 0x40 , DRV_NAME )) { <nl> + printk ( KERN_ERR "% s : resources busy \ n ", DRV_NAME ); <nl> + return - EBUSY ; <nl> + } <nl> + <nl> falconide_setup_ports (& hw ); <nl>  <nl> hwif = ide_find_port (); <nl> static int __init falconide_init ( void ) <nl>  <nl> ide_init_port_data ( hwif , index ); <nl> ide_init_port_hw ( hwif , & hw ); <nl> + hwif -> mmio = 1 ; <nl>  <nl> ide_get_lock ( NULL , NULL ); <nl> ide_device_add ( idx , NULL );
int sock_diag_register ( struct sock_diag_handler * hndl ) <nl> { <nl> int err = 0 ; <nl>  <nl> - if ( hndl -> family > AF_MAX ) <nl> + if ( hndl -> family >= AF_MAX ) <nl> return - EINVAL ; <nl>  <nl> mutex_lock (& sock_diag_table_mutex ); <nl> void sock_diag_unregister ( struct sock_diag_handler * hnld ) <nl> { <nl> int family = hnld -> family ; <nl>  <nl> - if ( family > AF_MAX ) <nl> + if ( family >= AF_MAX ) <nl> return ; <nl>  <nl> mutex_lock (& sock_diag_table_mutex );
xfs_da3_fixhashpath ( <nl> node = blk -> bp -> b_addr ; <nl> dp -> d_ops -> node_hdr_from_disk (& nodehdr , node ); <nl> btree = dp -> d_ops -> node_tree_p ( node ); <nl> - if ( be32_to_cpu ( btree -> hashval ) == lasthash ) <nl> + if ( be32_to_cpu ( btree [ blk -> index ]. hashval ) == lasthash ) <nl> break ; <nl> blk -> hashval = lasthash ; <nl> btree [ blk -> index ]. hashval = cpu_to_be32 ( lasthash );
void vgic_v3_populate_lr ( struct kvm_vcpu * vcpu , struct vgic_irq * irq , int lr ) <nl> if ( irq -> hw ) { <nl> val |= ICH_LR_HW ; <nl> val |= (( u64 ) irq -> hwintid ) << ICH_LR_PHYS_ID_SHIFT ; <nl> + /* <nl> + * Never set pending + active on a HW interrupt , as the <nl> + * pending state is kept at the physical distributor <nl> + * level . <nl> + */ <nl> + if ( irq -> active && irq_is_pending ( irq )) <nl> + val &= ~ ICH_LR_PENDING_BIT ; <nl> } else { <nl> if ( irq -> config == VGIC_CONFIG_LEVEL ) <nl> val |= ICH_LR_EOI ;
static int omap_pcm_new ( struct snd_soc_pcm_runtime * rtd ) <nl> } <nl>  <nl> out : <nl> + /* free preallocated buffers in case of error */ <nl> + if ( ret ) <nl> + omap_pcm_free_dma_buffers ( pcm ); <nl> + <nl> return ret ; <nl> } <nl> 
asmlinkage int sys_rt_sigreturn ( struct pt_regs * regs ) <nl> if ( restore_sigcontext ( regs , & frame -> uc . uc_mcontext )) <nl> goto badframe ; <nl>  <nl> + if ( do_sigaltstack (& frame -> uc . uc_stack , NULL , regs -> sp ) == - EFAULT ) <nl> + goto badframe ; <nl> + <nl> pr_debug (" Context restored : pc = % 08lx , lr = % 08lx , sp = % 08lx \ n ", <nl> regs -> pc , regs -> lr , regs -> sp ); <nl> 
affs_do_readpage_ofs ( struct page * page , unsigned to ) <nl> pr_debug ("% s (% lu , % ld , 0 , % d )\ n ", __func__ , inode -> i_ino , <nl> page -> index , to ); <nl> BUG_ON ( to > PAGE_CACHE_SIZE ); <nl> - kmap ( page ); <nl> - data = page_address ( page ); <nl> bsize = AFFS_SB ( sb )-> s_data_blksize ; <nl> tmp = page -> index << PAGE_CACHE_SHIFT ; <nl> bidx = tmp / bsize ; <nl> affs_do_readpage_ofs ( struct page * page , unsigned to ) <nl> return PTR_ERR ( bh ); <nl> tmp = min ( bsize - boff , to - pos ); <nl> BUG_ON ( pos + tmp > to || tmp > bsize ); <nl> + data = kmap_atomic ( page ); <nl> memcpy ( data + pos , AFFS_DATA ( bh ) + boff , tmp ); <nl> + kunmap_atomic ( data ); <nl> affs_brelse ( bh ); <nl> bidx ++; <nl> pos += tmp ; <nl> boff = 0 ; <nl> } <nl> flush_dcache_page ( page ); <nl> - kunmap ( page ); <nl> return 0 ; <nl> } <nl> 
void drm_helper_resume_force_mode ( struct drm_device * dev ) <nl> int encoder_dpms ; <nl> bool ret ; <nl>  <nl> + drm_modeset_lock_all ( dev ); <nl> list_for_each_entry ( crtc , & dev -> mode_config . crtc_list , head ) { <nl>  <nl> if (! crtc -> enabled ) <nl> void drm_helper_resume_force_mode ( struct drm_device * dev ) <nl>  <nl> /* disable the unused connectors while restoring the modesetting */ <nl> __drm_helper_disable_unused_functions ( dev ); <nl> + drm_modeset_unlock_all ( dev ); <nl> } <nl> EXPORT_SYMBOL ( drm_helper_resume_force_mode ); <nl> 
static int asoc_simple_card_probe ( struct platform_device * pdev ) <nl> snd_soc_card_set_drvdata ( card , priv ); <nl>  <nl> ret = devm_snd_soc_register_card ( dev , card ); <nl> - if ( ret >= 0 ) <nl> - return ret ; <nl> + if ( ret < 0 ) <nl> + goto err ; <nl> + <nl> + return 0 ; <nl> err : <nl> asoc_simple_card_clean_reference ( card ); <nl> 
static void gb_svc_remove_modules ( struct gb_svc * svc ) <nl>  <nl> void gb_svc_del ( struct gb_svc * svc ) <nl> { <nl> - gb_connection_disable ( svc -> connection ); <nl> + gb_connection_disable_rx ( svc -> connection ); <nl>  <nl> /* <nl> * The SVC device and input device may have been registered <nl> void gb_svc_del ( struct gb_svc * svc ) <nl> flush_workqueue ( svc -> wq ); <nl>  <nl> gb_svc_remove_modules ( svc ); <nl> + <nl> + gb_connection_disable ( svc -> connection ); <nl> } <nl>  <nl> void gb_svc_put ( struct gb_svc * svc )
static int ci_get_platdata ( struct device * dev , <nl> return ret ; <nl> } <nl>  <nl> + if ( of_find_property ( dev -> of_node , " non - zero - ttctrl - ttha ", NULL )) <nl> + platdata -> flags |= CI_HDRC_SET_NON_ZERO_TTHA ; <nl> + <nl> ext_id = ERR_PTR (- ENODEV ); <nl> ext_vbus = ERR_PTR (- ENODEV ); <nl> if ( of_property_read_bool ( dev -> of_node , " extcon ")) {
static int alloc_reserved_tree_block ( struct btrfs_trans_handle * trans , <nl> ret = btrfs_insert_empty_item ( trans , fs_info -> extent_root , path , <nl> ins , size ); <nl> if ( ret ) { <nl> + btrfs_free_path ( path ); <nl> btrfs_free_and_pin_reserved_extent ( root , ins -> objectid , <nl> root -> nodesize ); <nl> - btrfs_free_path ( path ); <nl> return ret ; <nl> } <nl> 
batadv_frag_merge_packets ( struct hlist_head * chain , struct sk_buff * skb ) <nl> kfree ( entry ); <nl>  <nl> /* Make room for the rest of the fragments . */ <nl> - if ( pskb_expand_head ( skb_out , 0 , size - skb -> len , GFP_ATOMIC ) < 0 ) { <nl> + if ( pskb_expand_head ( skb_out , 0 , size - skb_out -> len , GFP_ATOMIC ) < 0 ) { <nl> kfree_skb ( skb_out ); <nl> skb_out = NULL ; <nl> goto free ;
static int destroy_queue_cpsch ( struct device_queue_manager * dqm , <nl>  <nl> list_del (& q -> list ); <nl> qpd -> queue_count --; <nl> - if ( q -> properties . is_active ) <nl> + if ( q -> properties . is_active ) { <nl> dqm -> queue_count --; <nl> - <nl> - retval = execute_queues_cpsch ( dqm , <nl> + retval = execute_queues_cpsch ( dqm , <nl> KFD_UNMAP_QUEUES_FILTER_DYNAMIC_QUEUES , 0 ); <nl> - if ( retval == - ETIME ) <nl> - qpd -> reset_wavefronts = true ; <nl> + if ( retval == - ETIME ) <nl> + qpd -> reset_wavefronts = true ; <nl> + } <nl>  <nl> mqd -> uninit_mqd ( mqd , q -> mqd , q -> mqd_mem_obj ); <nl> 
static int pn_recvmsg ( struct kiocb * iocb , struct sock * sk , <nl> static int pn_backlog_rcv ( struct sock * sk , struct sk_buff * skb ) <nl> { <nl> int err = sock_queue_rcv_skb ( sk , skb ); <nl> - if ( err < 0 ) <nl> + if ( err < 0 ) { <nl> kfree_skb ( skb ); <nl> + if ( err == - ENOMEM ) <nl> + atomic_inc (& sk -> sk_drops ); <nl> + } <nl> return err ? NET_RX_DROP : NET_RX_SUCCESS ; <nl> } <nl> 
int extent_fiemap ( struct inode * inode , struct fiemap_extent_info * fieinfo , <nl> last_for_get_extent = isize ; <nl> } <nl>  <nl> - lock_extent_bits (& BTRFS_I ( inode )-> io_tree , start , start + len , 0 , <nl> + lock_extent_bits (& BTRFS_I ( inode )-> io_tree , start , start + len - 1 , 0 , <nl> & cached_state ); <nl>  <nl> em = get_extent_skip_holes ( inode , start , last_for_get_extent , <nl> int extent_fiemap ( struct inode * inode , struct fiemap_extent_info * fieinfo , <nl> out_free : <nl> free_extent_map ( em ); <nl> out : <nl> - unlock_extent_cached (& BTRFS_I ( inode )-> io_tree , start , start + len , <nl> + unlock_extent_cached (& BTRFS_I ( inode )-> io_tree , start , start + len - 1 , <nl> & cached_state , GFP_NOFS ); <nl> return ret ; <nl> }
EXPORT_SYMBOL ( vprintk_emit ); <nl>  <nl> asmlinkage int vprintk ( const char * fmt , va_list args ) <nl> { <nl> - return vprintk_emit ( 0 , LOGLEVEL_DEFAULT , NULL , 0 , fmt , args ); <nl> + return vprintk_func ( fmt , args ); <nl> } <nl> EXPORT_SYMBOL ( vprintk ); <nl> 
static int dgnc_found_board ( struct pci_dev * pdev , int id ) <nl> return - ENOMEM ; <nl>  <nl> /* make a temporary message buffer for the boot messages */ <nl> - brd -> msgbuf_head = kzalloc ( sizeof ( u8 ) * 8192 , GFP_KERNEL ); <nl> + brd -> msgbuf_head = kcalloc ( 8192 , sizeof ( u8 ), GFP_KERNEL ); <nl> brd -> msgbuf = brd -> msgbuf_head ; <nl>  <nl> if (! brd -> msgbuf ) {
static struct regulator_consumer_supply __initdata ldo3_consumer [] = { <nl> REGULATOR_SUPPLY (" vddcore ", " s5p - mipi - csis . 0 "), /* MIPI */ <nl> REGULATOR_SUPPLY (" vdd ", " exynos4 - hdmi "), /* HDMI */ <nl> REGULATOR_SUPPLY (" vdd_pll ", " exynos4 - hdmi "), /* HDMI */ <nl> + REGULATOR_SUPPLY (" vusb_a ", " s3c - hsotg "), /* OTG */ <nl> }; <nl> static struct regulator_consumer_supply __initdata ldo6_consumer [] = { <nl> REGULATOR_SUPPLY (" vddio ", " s5p - mipi - csis . 0 "), /* MIPI */ <nl> static struct regulator_consumer_supply __initdata ldo7_consumer [] = { <nl> static struct regulator_consumer_supply __initdata ldo8_consumer [] = { <nl> REGULATOR_SUPPLY (" vdd ", " s5p - adc "), /* ADC */ <nl> REGULATOR_SUPPLY (" vdd_osc ", " exynos4 - hdmi "), /* HDMI */ <nl> + REGULATOR_SUPPLY (" vusb_d ", " s3c - hsotg "), /* OTG */ <nl> }; <nl> static struct regulator_consumer_supply __initdata ldo9_consumer [] = { <nl> REGULATOR_SUPPLY (" dvdd ", " swb - a31 "), /* AR6003 WLAN & CSR 8810 BT */
static inline void rt2x00lib_set_if_combinations ( struct rt2x00_dev * rt2x00dev ) <nl> */ <nl> if_limit = & rt2x00dev -> if_limits_ap ; <nl> if_limit -> max = rt2x00dev -> ops -> max_ap_intf ; <nl> - if_limit -> types = BIT ( NL80211_IFTYPE_AP ); <nl> + if_limit -> types = BIT ( NL80211_IFTYPE_AP ) | <nl> + BIT ( NL80211_IFTYPE_MESH_POINT ); <nl>  <nl> /* <nl> * Build up AP interface combinations structure .
nfp_fl_output ( struct nfp_fl_output * output , const struct tc_action * action , <nl> */ <nl> if (! switchdev_port_same_parent_id ( in_dev , out_dev )) <nl> return - EOPNOTSUPP ; <nl> + if (! nfp_netdev_is_nfp_repr ( out_dev )) <nl> + return - EOPNOTSUPP ; <nl>  <nl> output -> port = cpu_to_be32 ( nfp_repr_get_port_id ( out_dev )); <nl> if (! output -> port )
static int sd_config ( struct gspca_dev * gspca_dev , <nl> break ; <nl> } <nl> sd -> brightness = BRIGHTNESS_DEF ; <nl> - sd -> contrast = CONTRAST_DEF ; <nl> + if ( sd -> sensor == SEN_OV6630 || sd -> sensor == SEN_OV66308AF ) <nl> + sd -> contrast = 200 ; /* The default is too low for the ov6630 */ <nl> + else <nl> + sd -> contrast = CONTRAST_DEF ; <nl> sd -> colors = COLOR_DEF ; <nl> sd -> hflip = HFLIP_DEF ; <nl> sd -> vflip = VFLIP_DEF ;
static int intel_pstate_init_cpu ( unsigned int cpunum ) <nl> return 0 ; <nl> } <nl>  <nl> - static unsigned int intel_pstate_get ( unsigned int cpu_num ) <nl> -{ <nl> - struct cpudata * cpu = all_cpu_data [ cpu_num ]; <nl> - <nl> - return cpu ? get_avg_frequency ( cpu ) : 0 ; <nl> -} <nl> - <nl> static void intel_pstate_set_update_util_hook ( unsigned int cpu_num ) <nl> { <nl> struct cpudata * cpu = all_cpu_data [ cpu_num ]; <nl> static struct cpufreq_driver intel_pstate = { <nl> . setpolicy = intel_pstate_set_policy , <nl> . suspend = intel_pstate_hwp_save_state , <nl> . resume = intel_pstate_resume , <nl> - . get = intel_pstate_get , <nl> . init = intel_pstate_cpu_init , <nl> . exit = intel_pstate_cpu_exit , <nl> . stop_cpu = intel_pstate_stop_cpu ,
static size_t copy_in_kernel ( size_t count , void __user * to , <nl> * contains the ( negative ) exception code . <nl> */ <nl> # ifdef CONFIG_64BIT <nl> + <nl> static unsigned long follow_table ( struct mm_struct * mm , <nl> unsigned long address , int write ) <nl> { <nl> unsigned long * table = ( unsigned long *) __pa ( mm -> pgd ); <nl>  <nl> + if ( unlikely ( address > mm -> context . asce_limit - 1 )) <nl> + return - 0x38UL ; <nl> switch ( mm -> context . asce_bits & _ASCE_TYPE_MASK ) { <nl> case _ASCE_TYPE_REGION1 : <nl> table = table + (( address >> 53 ) & 0x7ff );
void radeon_atom_backlight_init ( struct radeon_encoder * radeon_encoder , <nl> u8 backlight_level ; <nl> char bl_name [ 16 ]; <nl>  <nl> + /* Mac laptops with multiple GPUs use the gmux driver for backlight <nl> + * so don ' t register a backlight device <nl> + */ <nl> + if (( rdev -> pdev -> subsystem_vendor == PCI_VENDOR_ID_APPLE ) && <nl> + ( rdev -> pdev -> device == 0x6741 )) <nl> + return ; <nl> + <nl> if (! radeon_encoder -> enc_priv ) <nl> return ; <nl> 
static int tps6586x_ldo_get_voltage ( struct regulator_dev * rdev ) <nl> mask = (( 1 << ri -> volt_nbits ) - 1 ) << ri -> volt_shift ; <nl> val = ( val & mask ) >> ri -> volt_shift ; <nl>  <nl> - if ( val > ri -> desc . n_voltages ) <nl> + if ( val >= ri -> desc . n_voltages ) <nl> BUG (); <nl>  <nl> return ri -> voltages [ val ] * 1000 ;
static int _regulator_do_set_voltage ( struct regulator_dev * rdev , <nl> int regulator_set_voltage ( struct regulator * regulator , int min_uV , int max_uV ) <nl> { <nl> struct regulator_dev * rdev = regulator -> rdev ; <nl> - int ret ; <nl> + int ret = 0 ; <nl>  <nl> mutex_lock (& rdev -> mutex ); <nl>  <nl> + /* If we ' re setting the same range as last time the change <nl> + * should be a noop ( some cpufreq implementations use the same <nl> + * voltage for multiple frequencies , for example ). <nl> + */ <nl> + if ( regulator -> min_uV == min_uV && regulator -> max_uV == max_uV ) <nl> + goto out ; <nl> + <nl> /* sanity check */ <nl> if (! rdev -> desc -> ops -> set_voltage && <nl> ! rdev -> desc -> ops -> set_voltage_sel ) {
int __init init_common ( struct tsens_device * tmdev ) <nl> void __iomem * base ; <nl>  <nl> base = of_iomap ( tmdev -> dev -> of_node , 0 ); <nl> - if ( IS_ERR ( base )) <nl> + if (! base ) <nl> return - EINVAL ; <nl>  <nl> tmdev -> map = devm_regmap_init_mmio ( tmdev -> dev , base , & tsens_config ); <nl> - if (! tmdev -> map ) { <nl> + if ( IS_ERR ( tmdev -> map )) { <nl> iounmap ( base ); <nl> - return - ENODEV ; <nl> + return PTR_ERR ( tmdev -> map ); <nl> } <nl>  <nl> return 0 ;
int netpoll_setup ( struct netpoll * np ) <nl> return - ENODEV ; <nl> } <nl>  <nl> + if ( ndev -> master ) { <nl> + printk ( KERN_ERR "% s : % s is a slave device , aborting .\ n ", <nl> + np -> name , np -> dev_name ); <nl> + return - EBUSY ; <nl> + } <nl> + <nl> if (! netif_running ( ndev )) { <nl> unsigned long atmost , atleast ; <nl> 
static int mn88472_set_frontend ( struct dvb_frontend * fe ) <nl> switch ( c -> delivery_system ) { <nl> case SYS_DVBT : <nl> case SYS_DVBT2 : <nl> - if ( c -> bandwidth_hz <= 6000000 ) { <nl> + if ( c -> bandwidth_hz <= 5000000 ) { <nl> + memcpy ( bw_val , "\ xe5 \ x99 \ x9a \ x1b \ xa9 \ x1b \ xa9 ", 7 ); <nl> + bw_val2 = 0x03 ; <nl> + } else if ( c -> bandwidth_hz <= 6000000 ) { <nl> /* IF 3570000 Hz , BW 6000000 Hz */ <nl> memcpy ( bw_val , "\ xbf \ x55 \ x55 \ x15 \ x6b \ x15 \ x6b ", 7 ); <nl> bw_val2 = 0x02 ;
static int brcmf_enable_bw40_2g ( struct brcmf_cfg80211_info * cfg ) <nl>  <nl> ch . band = BRCMU_CHAN_BAND_2G ; <nl> ch . bw = BRCMU_CHAN_BW_40 ; <nl> + ch . sb = BRCMU_CHAN_SB_NONE ; <nl> ch . chnum = 0 ; <nl> cfg -> d11inf . encchspec (& ch ); <nl>  <nl> static int brcmf_enable_bw40_2g ( struct brcmf_cfg80211_info * cfg ) <nl>  <nl> brcmf_update_bw40_channel_flag (& band -> channels [ j ], & ch ); <nl> } <nl> + kfree ( pbuf ); <nl> } <nl> return err ; <nl> }
asmlinkage void __sched schedule ( void ) <nl> } <nl> EXPORT_SYMBOL ( schedule ); <nl>  <nl> -# ifdef CONFIG_SMP <nl> +# ifdef CONFIG_MUTEX_SPIN_ON_OWNER <nl> /* <nl> * Look out ! " owner " is an entirely speculative pointer <nl> * access and not reliable .
static int prepare_vmcs02 ( struct kvm_vcpu * vcpu , struct vmcs12 * vmcs12 , <nl> if ( exec_control & CPU_BASED_TPR_SHADOW ) { <nl> vmcs_write64 ( VIRTUAL_APIC_PAGE_ADDR , - 1ull ); <nl> vmcs_write32 ( TPR_THRESHOLD , vmcs12 -> tpr_threshold ); <nl> + } else { <nl> +# ifdef CONFIG_X86_64 <nl> + exec_control |= CPU_BASED_CR8_LOAD_EXITING | <nl> + CPU_BASED_CR8_STORE_EXITING ; <nl> +# endif <nl> } <nl>  <nl> /*
static int r5l_recovery_log ( struct r5l_log * log ) <nl> log -> seq = ctx . seq + 11 ; <nl> log -> log_start = r5l_ring_add ( log , ctx . pos , BLOCK_SECTORS ); <nl> r5l_write_super ( log , ctx . pos ); <nl> + log -> last_checkpoint = ctx . pos ; <nl> + log -> next_checkpoint = ctx . pos ; <nl> } else { <nl> log -> log_start = ctx . pos ; <nl> log -> seq = ctx . seq ; <nl> static int r5l_load_log ( struct r5l_log * log ) <nl> if ( log -> max_free_space > RECLAIM_MAX_FREE_SPACE ) <nl> log -> max_free_space = RECLAIM_MAX_FREE_SPACE ; <nl> log -> last_checkpoint = cp ; <nl> + log -> next_checkpoint = cp ; <nl>  <nl> __free_page ( page ); <nl> 
static int __devinit cas_init_one ( struct pci_dev * pdev , <nl> INIT_WORK (& cp -> reset_task , cas_reset_task ); <nl>  <nl> /* Default link parameters */ <nl> - if ( link_mode >= 0 && link_mode <= 6 ) <nl> + if ( link_mode >= 0 && link_mode < 6 ) <nl> cp -> link_cntl = link_modes [ link_mode ]; <nl> else <nl> cp -> link_cntl = BMCR_ANENABLE ;
static int create_fixed_stream_quirk ( struct snd_usb_audio * chip , <nl> return - ENOMEM ; <nl> } <nl> if ( fp -> nr_rates > 0 ) { <nl> - rate_table = kmalloc ( sizeof ( int ) * fp -> nr_rates , GFP_KERNEL ); <nl> + rate_table = kmemdup ( fp -> rate_table , <nl> + sizeof ( int ) * fp -> nr_rates , GFP_KERNEL ); <nl> if (! rate_table ) { <nl> kfree ( fp ); <nl> return - ENOMEM ; <nl> } <nl> - memcpy ( rate_table , fp -> rate_table , sizeof ( int ) * fp -> nr_rates ); <nl> fp -> rate_table = rate_table ; <nl> } <nl>  <nl> static int create_uaxx_quirk ( struct snd_usb_audio * chip , <nl> if ( altsd -> bNumEndpoints != 1 ) <nl> return - ENXIO ; <nl>  <nl> - fp = kmalloc ( sizeof (* fp ), GFP_KERNEL ); <nl> + fp = kmemdup (& ua_format , sizeof (* fp ), GFP_KERNEL ); <nl> if (! fp ) <nl> return - ENOMEM ; <nl> - memcpy ( fp , & ua_format , sizeof (* fp )); <nl>  <nl> fp -> iface = altsd -> bInterfaceNumber ; <nl> fp -> endpoint = get_endpoint ( alts , 0 )-> bEndpointAddress ;
static void kvm_vcpu_init ( struct kvm_vcpu * vcpu , struct kvm * kvm , unsigned id ) <nl>  <nl> static void kvm_vcpu_destroy ( struct kvm_vcpu * vcpu ) <nl> { <nl> - kvm_dirty_ring_free (& vcpu -> dirty_ring ); <nl> kvm_arch_vcpu_destroy ( vcpu ); <nl> + kvm_dirty_ring_free (& vcpu -> dirty_ring ); <nl>  <nl> /* <nl> * No need for rcu_read_lock as VCPU_RUN is the only place that changes
static int vnet_walk_rx_one ( struct vnet_port * port , <nl> if ( IS_ERR ( desc )) <nl> return PTR_ERR ( desc ); <nl>  <nl> + if ( desc -> hdr . state != VIO_DESC_READY ) <nl> + return 1 ; <nl> + <nl> + rmb (); <nl> + <nl> viodbg ( DATA , " vio_walk_rx_one desc [% 02x :% 02x :% 08x :% 08x :% llx :% llx ]\ n ", <nl> desc -> hdr . state , desc -> hdr . ack , <nl> desc -> size , desc -> ncookies , <nl> desc -> cookies [ 0 ]. cookie_addr , <nl> desc -> cookies [ 0 ]. cookie_size ); <nl>  <nl> - if ( desc -> hdr . state != VIO_DESC_READY ) <nl> - return 1 ; <nl> err = vnet_rx_one ( port , desc -> size , desc -> cookies , desc -> ncookies ); <nl> if ( err == - ECONNRESET ) <nl> return err ;
static int musb_gadget_start ( struct usb_gadget * g , <nl> musb -> gadget_driver = driver ; <nl>  <nl> spin_lock_irqsave (& musb -> lock , flags ); <nl> + musb -> is_active = 1 ; <nl>  <nl> otg_set_peripheral ( otg , & musb -> g ); <nl> musb -> xceiv -> state = OTG_STATE_B_IDLE ;
MODULE_LICENSE (" GPL v2 "); <nl>  <nl> static int debug ; <nl> module_param ( debug , int , 0644 ); <nl> - MODULE_PARM_DESC ( debug , " debug level 0 = off ( default ) 1 = on \ n "); <nl> + MODULE_PARM_DESC ( debug , " debug level 0 = off ( default ) 1 = on "); <nl>  <nl> /* # define MPX_DEBUG */ <nl> 
static int smb2_get_data_area_len ( unsigned int * off , unsigned int * len , <nl> * off = 0 ; <nl> * len = 0 ; <nl>  <nl> - /* error reqeusts do not have data area */ <nl> - if ( hdr -> Status && hdr -> Status != STATUS_MORE_PROCESSING_REQUIRED && <nl> - ((( struct smb2_err_rsp *) hdr )-> StructureSize ) == SMB2_ERROR_STRUCTURE_SIZE2_LE ) <nl> - return ret ; <nl> - <nl> /* <nl> * Following commands have data areas so we have to get the location <nl> * of the data buffer offset and data buffer length for the particular
int kvmppc_mmu_init ( struct kvm_vcpu * vcpu ) <nl> return - 1 ; <nl> vcpu3s -> context_id [ 0 ] = err ; <nl>  <nl> - vcpu3s -> proto_vsid_max = (( vcpu3s -> context_id [ 0 ] + 1 ) <nl> + vcpu3s -> proto_vsid_max = (( u64 )( vcpu3s -> context_id [ 0 ] + 1 ) <nl> << ESID_BITS ) - 1 ; <nl> - vcpu3s -> proto_vsid_first = vcpu3s -> context_id [ 0 ] << ESID_BITS ; <nl> + vcpu3s -> proto_vsid_first = ( u64 ) vcpu3s -> context_id [ 0 ] << ESID_BITS ; <nl> vcpu3s -> proto_vsid_next = vcpu3s -> proto_vsid_first ; <nl>  <nl> kvmppc_mmu_hpte_init ( vcpu );
# include < linux / integrity . h > <nl> # include < linux / evm . h > <nl> # include < crypto / hash . h > <nl> +# include < crypto / algapi . h > <nl> # include " evm . h " <nl>  <nl> int evm_initialized ; <nl> static enum integrity_status evm_verify_hmac ( struct dentry * dentry , <nl> xattr_value_len , calc . digest ); <nl> if ( rc ) <nl> break ; <nl> - rc = memcmp ( xattr_data -> digest , calc . digest , <nl> + rc = crypto_memneq ( xattr_data -> digest , calc . digest , <nl> sizeof ( calc . digest )); <nl> if ( rc ) <nl> rc = - EINVAL ;
static int img_prl_out_set_fmt ( struct snd_soc_dai * dai , unsigned int fmt ) <nl> return - EINVAL ; <nl> } <nl>  <nl> + pm_runtime_get_sync ( prl -> dev ); <nl> reg = img_prl_out_readl ( prl , IMG_PRL_OUT_CTL ); <nl> reg = ( reg & ~ IMG_PRL_OUT_CTL_EDGE_MASK ) | control_set ; <nl> img_prl_out_writel ( prl , reg , IMG_PRL_OUT_CTL ); <nl> + pm_runtime_put ( prl -> dev ); <nl>  <nl> return 0 ; <nl> }
static sctp_xmit_t sctp_packet_bundle_auth ( struct sctp_packet * pkt , <nl> /* See if this is an auth chunk we are bundling or if <nl> * auth is already bundled . <nl> */ <nl> - if ( chunk -> chunk_hdr -> type == SCTP_CID_AUTH || pkt -> auth ) <nl> + if ( chunk -> chunk_hdr -> type == SCTP_CID_AUTH || pkt -> has_auth ) <nl> return retval ; <nl>  <nl> /* if the peer did not request this chunk to be authenticated ,
static int ar9002_hw_calibrate ( struct ath_hw * ah , struct ath9k_channel * chan , <nl> return 0 ; <nl>  <nl> ah -> cal_list_curr = currCal = currCal -> calNext ; <nl> - if ( currCal -> calState == CAL_WAITING ) { <nl> + if ( currCal -> calState == CAL_WAITING ) <nl> ath9k_hw_reset_calibration ( ah , currCal ); <nl> - return 0 ; <nl> - } <nl> + <nl> + return 0 ; <nl> } <nl>  <nl> /* Do NF cal only at longer intervals */
static int i2c_sendbytes ( struct i2c_adapter * i2c_adap , <nl> goto err ; <nl> if ( retval == 0 ) <nl> goto eio ; <nl> + if (! i2c_slave_did_ack ( i2c_adap )) { <nl> + retval = - ENXIO ; <nl> + goto err ; <nl> + } <nl> if ( i2c_debug ) { <nl> printk (" < W % 02x % 02x ", msg -> addr << 1 , msg -> buf [ 0 ]); <nl> if (!( ctrl & I2C_NOSTOP )) <nl> static int i2c_readbytes ( struct i2c_adapter * i2c_adap , <nl> goto err ; <nl> if ( retval == 0 ) <nl> goto eio ; <nl> + if ( cnt == 0 && ! i2c_slave_did_ack ( i2c_adap )) { <nl> + retval = - ENXIO ; <nl> + goto err ; <nl> + } <nl> msg -> buf [ cnt ] = cx_read ( bus -> reg_rdata ) & 0xff ; <nl> if ( i2c_debug ) { <nl> dprintk ( 1 , " % 02x ", msg -> buf [ cnt ]);
static int htc_config_pipe_credits ( struct htc_target * target ) <nl> time_left = wait_for_completion_timeout (& target -> cmd_wait , HZ ); <nl> if (! time_left ) { <nl> dev_err ( target -> dev , " HTC credit config timeout \ n "); <nl> + kfree_skb ( skb ); <nl> return - ETIMEDOUT ; <nl> } <nl>  <nl> static int htc_setup_complete ( struct htc_target * target ) <nl> time_left = wait_for_completion_timeout (& target -> cmd_wait , HZ ); <nl> if (! time_left ) { <nl> dev_err ( target -> dev , " HTC start timeout \ n "); <nl> + kfree_skb ( skb ); <nl> return - ETIMEDOUT ; <nl> } <nl>  <nl> int htc_connect_service ( struct htc_target * target , <nl> if (! time_left ) { <nl> dev_err ( target -> dev , " Service connection timeout for : % d \ n ", <nl> service_connreq -> service_id ); <nl> + kfree_skb ( skb ); <nl> return - ETIMEDOUT ; <nl> } <nl> 
static int check_ptr_alignment ( struct bpf_verifier_env * env , <nl> break ; <nl> case PTR_TO_STACK : <nl> pointer_desc = " stack "; <nl> + /* The stack spill tracking logic in check_stack_write () <nl> + * and check_stack_read () relies on stack accesses being <nl> + * aligned . <nl> + */ <nl> + strict = true ; <nl> break ; <nl> default : <nl> break ;
xfs_inumbers ( <nl> return error ; <nl>  <nl> bcount = MIN ( left , ( int )( PAGE_SIZE / sizeof (* buffer ))); <nl> - buffer = kmem_alloc ( bcount * sizeof (* buffer ), KM_SLEEP ); <nl> + buffer = kmem_zalloc ( bcount * sizeof (* buffer ), KM_SLEEP ); <nl> do { <nl> struct xfs_inobt_rec_incore r ; <nl> int stat ;
static ssize_t error_store ( struct device * dev , struct device_attribute * attr , <nl> const char * buf , size_t count ) <nl> { <nl> u32 error ; <nl> - int ret ; <nl> + int err ; <nl>  <nl> if ( kstrtou32 ( buf , 10 , & error )) <nl> return - EINVAL ; <nl>  <nl> - ret = visorchannel_write <nl> + err = visorchannel_write <nl> ( chipset_dev -> controlvm_channel , <nl> offsetof ( struct spar_controlvm_channel_protocol , <nl> installation_error ), <nl> & error , sizeof ( u32 )); <nl> - if ( ret ) <nl> - return ret ; <nl> + if ( err ) <nl> + return err ; <nl> return count ; <nl> } <nl> static DEVICE_ATTR_RW ( error );
static int gfx_v6_0_sw_init ( void * handle ) <nl> ring -> me = 1 ; <nl> ring -> pipe = i ; <nl> ring -> queue = i ; <nl> - sprintf ( ring -> name , " comp % d .% d .% d ", ring -> me , ring -> pipe , ring -> queue ); <nl> + sprintf ( ring -> name , " comp_ % d .% d .% d ", ring -> me , ring -> pipe , ring -> queue ); <nl> irq_type = AMDGPU_CP_IRQ_COMPUTE_MEC1_PIPE0_EOP + ring -> pipe ; <nl> r = amdgpu_ring_init ( adev , ring , 1024 , <nl> & adev -> gfx . eop_irq , irq_type );
TRACE_EVENT ( nfsd_dirent , <nl> __entry -> ino = ino ; <nl> __entry -> len = namlen ; <nl> memcpy ( __get_str ( name ), name , namlen ); <nl> - __assign_str ( name , name ); <nl> ), <nl> TP_printk (" fh_hash = 0x % 08x ino =% llu name =%.* s ", <nl> __entry -> fh_hash , __entry -> ino ,
struct iwl_trans { <nl> static inline void iwl_trans_configure ( struct iwl_trans * trans , <nl> const struct iwl_trans_config * trans_cfg ) <nl> { <nl> - /* <nl> - * only set the op_mode for the moment . Later on , this function will do <nl> - * more <nl> - */ <nl> trans -> op_mode = trans_cfg -> op_mode ; <nl>  <nl> trans -> ops -> configure ( trans , trans_cfg ); <nl> static inline void iwl_trans_stop_hw ( struct iwl_trans * trans , <nl>  <nl> trans -> ops -> stop_hw ( trans , op_mode_leaving ); <nl>  <nl> + if ( op_mode_leaving ) <nl> + trans -> op_mode = NULL ; <nl> + <nl> trans -> state = IWL_TRANS_NO_FW ; <nl> } <nl> 
# define crisv10_mask_irq ( irq_nr ) (* R_VECT_MASK_CLR = 1 << ( irq_nr )); <nl> # define crisv10_unmask_irq ( irq_nr ) (* R_VECT_MASK_SET = 1 << ( irq_nr )); <nl>  <nl> + extern void kgdb_init ( void ); <nl> + extern void breakpoint ( void ); <nl> + <nl> /* don ' t use set_int_vector , it bypasses the linux interrupt handlers . it is <nl> * global just so that the kernel gdb can use it . <nl> */
static inline void set_cmd_timeout ( struct mmc_omap_host * host , struct mmc_reques <nl>  <nl> static inline void set_data_timeout ( struct mmc_omap_host * host , struct mmc_request * req ) <nl> { <nl> - int timeout ; <nl> + unsigned int timeout , cycle_ns ; <nl> u16 reg ; <nl>  <nl> - /* Convert ns to clock cycles by assuming 20MHz frequency <nl> - * 1 cycle at 20MHz = 500 ns <nl> - */ <nl> - timeout = req -> data -> timeout_clks + req -> data -> timeout_ns / 500 ; <nl> + cycle_ns = 1000000000 / host -> current_slot -> fclk_freq ; <nl> + timeout = req -> data -> timeout_ns / cycle_ns ; <nl> + timeout += req -> data -> timeout_clks ; <nl>  <nl> /* Check if we need to use timeout multiplier register */ <nl> reg = OMAP_MMC_READ ( host , SDIO );
static int allowed_drive_mask = 0x33 ; <nl>  <nl> static int irqdma_allocated ; <nl>  <nl> -# define DEVICE_NAME " floppy " <nl> - <nl> # include < linux / blkdev . h > <nl> # include < linux / blkpg . h > <nl> # include < linux / cdrom . h > /* for the compatibility eject ioctl */ <nl> static int initialising = 1 ; <nl> # define UFDCS (& fdc_state [ FDC ( drive )]) <nl>  <nl> # define DPRINT ( format , args ...) \ <nl> - pr_info ( DEVICE_NAME "% d : " format , current_drive , ## args ) <nl> + pr_info (" floppy % d : " format , current_drive , ## args ) <nl>  <nl> # define PH_HEAD ( floppy , head ) ((((( floppy )-> stretch & 2 ) >> 1 ) ^ head ) << 2 ) <nl> # define STRETCH ( floppy ) (( floppy )-> stretch & FD_STRETCH )
void task_tick_numa ( struct rq * rq , struct task_struct * curr ) <nl> now = curr -> se . sum_exec_runtime ; <nl> period = ( u64 ) curr -> numa_scan_period * NSEC_PER_MSEC ; <nl>  <nl> - if ( now - curr -> node_stamp > period ) { <nl> + if ( now > curr -> node_stamp + period ) { <nl> if (! curr -> node_stamp ) <nl> curr -> numa_scan_period = task_scan_min ( curr ); <nl> curr -> node_stamp += period ;
static int ax25_recvmsg ( struct kiocb * iocb , struct socket * sock , <nl> ax25_address src ; <nl> const unsigned char * mac = skb_mac_header ( skb ); <nl>  <nl> + memset ( sax , 0 , sizeof ( struct full_sockaddr_ax25 )); <nl> ax25_addr_parse ( mac + 1 , skb -> data - mac - 1 , & src , NULL , <nl> & digi , NULL , NULL ); <nl> sax -> sax25_family = AF_AX25 ;
static int get_dir_index_using_offset ( struct super_block * sb , <nl> * is offset by 3 because we invent "." and ".." entries which are <nl> * not actually stored in the directory . <nl> */ <nl> - if ( f_pos < 3 ) <nl> + if ( f_pos <= 3 ) <nl> return f_pos ; <nl> f_pos -= 3 ; <nl> 
static int torture_shutdown_notify ( struct notifier_block * unused1 , <nl> unsigned long unused2 , void * unused3 ) <nl> { <nl> mutex_lock (& fullstop_mutex ); <nl> - if ( fullstop == FULLSTOP_DONTSTOP ) <nl> + if ( fullstop == FULLSTOP_DONTSTOP ) { <nl> + VERBOSE_TOROUT_STRING (" Unscheduled system shutdown detected "); <nl> fullstop = FULLSTOP_SHUTDOWN ; <nl> - else <nl> + } else { <nl> pr_warn (" Concurrent rmmod and shutdown illegal !\ n "); <nl> + } <nl> mutex_unlock (& fullstop_mutex ); <nl> return NOTIFY_DONE ; <nl> }
static int eeti_ts_probe ( struct i2c_client * client , <nl> priv = kzalloc ( sizeof (* priv ), GFP_KERNEL ); <nl> if (! priv ) { <nl> dev_err (& client -> dev , " failed to allocate driver data \ n "); <nl> - goto err0 ; <nl> + return - ENOMEM ; <nl> } <nl>  <nl> mutex_init (& priv -> mutex ); <nl> input = input_allocate_device (); <nl> - <nl> if (! input ) { <nl> dev_err (& client -> dev , " Failed to allocate input device .\ n "); <nl> goto err1 ; <nl> static int eeti_ts_probe ( struct i2c_client * client , <nl> err1 : <nl> input_free_device ( input ); <nl> kfree ( priv ); <nl> - err0 : <nl> return err ; <nl> } <nl> 
static ssize_t blk_msg_write ( struct file * filp , const char __user * buffer , <nl> char * msg ; <nl> struct blk_trace * bt ; <nl>  <nl> - if ( count > BLK_TN_MAX_MSG ) <nl> + if ( count > BLK_TN_MAX_MSG - 1 ) <nl> return - EINVAL ; <nl>  <nl> - msg = kmalloc ( count , GFP_KERNEL ); <nl> + msg = kmalloc ( count + 1 , GFP_KERNEL ); <nl> if ( msg == NULL ) <nl> return - ENOMEM ; <nl>  <nl> static ssize_t blk_msg_write ( struct file * filp , const char __user * buffer , <nl> return - EFAULT ; <nl> } <nl>  <nl> + msg [ count ] = '\ 0 '; <nl> bt = filp -> private_data ; <nl> __trace_note_message ( bt , "% s ", msg ); <nl> kfree ( msg );
int dm_kcopyd_copy ( struct dm_kcopyd_client * kc , struct dm_io_region * from , <nl> job -> fn = fn ; <nl> job -> context = context ; <nl>  <nl> - if ( job -> source . count < SUB_JOB_SIZE ) <nl> + if ( job -> source . count <= SUB_JOB_SIZE ) <nl> dispatch_job ( job ); <nl>  <nl> else {
void ath10k_htt_tx_free ( struct ath10k_htt * htt ) <nl> { <nl> int size ; <nl>  <nl> + tasklet_kill (& htt -> txrx_compl_task ); <nl> + <nl> idr_for_each (& htt -> pending_tx , ath10k_htt_tx_clean_up_pending , htt -> ar ); <nl> idr_destroy (& htt -> pending_tx ); <nl> 
int __init igafb_init ( void ) <nl> iounmap ( info -> screen_base ); <nl> kfree ( par -> mmap_map ); <nl> kfree ( info ); <nl> + return - ENODEV ; <nl> } <nl>  <nl> # ifdef CONFIG_SPARC
struct clk_plt_data { <nl> struct clk_plt_fixed ** parents ; <nl> u8 nparents ; <nl> struct clk_plt * clks [ PMC_CLK_NUM ]; <nl> + struct clk_lookup * mclk_lookup ; <nl> }; <nl>  <nl> /* Return an index in parent table */ <nl> static int plt_clk_probe ( struct platform_device * pdev ) <nl> goto err_unreg_clk_plt ; <nl> } <nl> } <nl> + data -> mclk_lookup = clkdev_hw_create (& data -> clks [ 3 ]-> hw , " mclk ", NULL ); <nl> + if ( IS_ERR ( data -> mclk_lookup )) { <nl> + err = PTR_ERR ( data -> mclk_lookup ); <nl> + goto err_unreg_clk_plt ; <nl> + } <nl>  <nl> plt_clk_free_parent_names_loop ( parent_names , data -> nparents ); <nl>  <nl> static int plt_clk_remove ( struct platform_device * pdev ) <nl>  <nl> data = platform_get_drvdata ( pdev ); <nl>  <nl> + clkdev_drop ( data -> mclk_lookup ); <nl> plt_clk_unregister_loop ( data , PMC_CLK_NUM ); <nl> plt_clk_unregister_parents ( data ); <nl> return 0 ;
static struct rpc_task * nfs4_do_unlck ( struct file_lock * fl , <nl> { <nl> struct nfs4_unlockdata * data ; <nl>  <nl> + /* Ensure this is an unlock - when canceling a lock , the <nl> + * canceled lock is passed in , and it won ' t be an unlock . <nl> + */ <nl> + fl -> fl_type = F_UNLCK ; <nl> + <nl> data = nfs4_alloc_unlockdata ( fl , ctx , lsp , seqid ); <nl> if ( data == NULL ) { <nl> nfs_free_seqid ( seqid );
struct platform_device * __init imx_add_mxc_mmc ( <nl> struct resource res [] = { <nl> { <nl> . start = data -> iobase , <nl> - . end = data -> iobase + SZ_4K - 1 , <nl> + . end = data -> iobase + data -> iosize - 1 , <nl> . flags = IORESOURCE_MEM , <nl> }, { <nl> . start = data -> irq ,
static int acl_permission_check ( struct inode * inode , int mask ) <nl> if ( current_user_ns () != inode_userns ( inode )) <nl> goto other_perms ; <nl>  <nl> - if ( current_fsuid () == inode -> i_uid ) <nl> + if ( likely ( current_fsuid () == inode -> i_uid )) <nl> mode >>= 6 ; <nl> else { <nl> if ( IS_POSIXACL ( inode ) && ( mode & S_IRWXG )) {
static int r820t_set_tv_standard ( struct r820t_priv * priv , <nl> return rc ; <nl> msleep ( 1 ); <nl> } <nl> - priv -> int_freq = if_khz ; <nl> + priv -> int_freq = if_khz * 1000 ; <nl>  <nl> /* Check if standard changed . If so , filter calibration is needed */ <nl> if ( type != priv -> type )
void btrfs_drop_and_free_fs_root ( struct btrfs_fs_info * fs_info , <nl> if ( btrfs_root_refs (& root -> root_item ) == 0 ) <nl> synchronize_srcu (& fs_info -> subvol_srcu ); <nl>  <nl> - if ( test_bit ( BTRFS_FS_STATE_ERROR , & fs_info -> fs_state )) <nl> + if ( test_bit ( BTRFS_FS_STATE_ERROR , & fs_info -> fs_state )) { <nl> btrfs_free_log ( NULL , root ); <nl> + if ( root -> reloc_root ) { <nl> + free_extent_buffer ( root -> reloc_root -> node ); <nl> + free_extent_buffer ( root -> reloc_root -> commit_root ); <nl> + btrfs_put_fs_root ( root -> reloc_root ); <nl> + root -> reloc_root = NULL ; <nl> + } <nl> + } <nl>  <nl> if ( root -> free_ino_pinned ) <nl> __btrfs_remove_free_space_cache ( root -> free_ino_pinned );
MOBI_RET mobi_parse_huffdic ( const MOBIData * m , MOBIHuffCdic * huffcdic ) { <nl> } <nl> curr = curr -> next ; <nl> } <nl> + if ( huffcdic -> index_count != huffcdic -> index_read ) { <nl> + debug_print (" CDIC : wrong read index count : % zu , total : % zu \ n ", huffcdic -> index_read , huffcdic -> index_count ); <nl> + return MOBI_DATA_CORRUPT ; <nl> + } <nl> return MOBI_SUCCESS ; <nl> } <nl> 
static int setup_config ( int type ) <nl> if ( rv < 0 ) <nl> goto out ; <nl>  <nl> - if ( is_auth_req ()) { <nl> + if ( booth_conf -> authfile [ 0 ] != '\ 0 ') { <nl> rv = read_authkey (); <nl> if ( rv < 0 ) <nl> goto out ;
vhost_user_get_inflight_fd ( struct virtio_net ** pdev , <nl> int numa_node = SOCKET_ID_ANY ; <nl> void * addr ; <nl>  <nl> + if ( validate_msg_fds ( dev , ctx , 0 ) != 0 ) <nl> + return RTE_VHOST_MSG_RESULT_ERR ; <nl> + <nl> if ( ctx -> msg . size != sizeof ( ctx -> msg . payload . inflight )) { <nl> VHOST_LOG_CONFIG ( ERR , "(% s ) invalid get_inflight_fd message size is % d \ n ", <nl> dev -> ifname , ctx -> msg . size ); <nl> vhost_user_set_inflight_fd ( struct virtio_net ** pdev , <nl> int fd , i ; <nl> int numa_node = SOCKET_ID_ANY ; <nl>  <nl> + if ( validate_msg_fds ( dev , ctx , 1 ) != 0 ) <nl> + return RTE_VHOST_MSG_RESULT_ERR ; <nl> + <nl> fd = ctx -> fds [ 0 ]; <nl> if ( ctx -> msg . size != sizeof ( ctx -> msg . payload . inflight ) || fd < 0 ) { <nl> VHOST_LOG_CONFIG ( ERR , "(% s ) invalid set_inflight_fd message size is % d , fd is % d \ n ",
int Socket :: startSslClient ( const std :: string & certificate_path , String hostname ) <nl> // fcntl ( this -> getFD () , F_SETFL , O_NONBLOCK ); // blocking mode used currently <nl> SSL_set_fd ( ssl , this -> getFD ()); <nl> SSL_set_tlsext_host_name ( ssl , hostname . c_str ()); <nl> +# if OPENSSL_VERSION_NUMBER < 0x10100000L <nl> +# else <nl> + X509_VERIFY_PARAM_set1_host ( SSL_get0_param ( ssl ), hostname . c_str (), 0 ); <nl> +# endif <nl>  <nl> // make io non blocking as select wont tell us if we can do a read without blocking <nl> // BIO_set_nbio ( SSL_get_rbio ( ssl ), 1l ); // blocking mode used currently
class McAsciiParserBase { <nl> const char * posStart , <nl> const char * posEnd ); <nl>  <nl> + // limit the value size . <nl> + static constexpr uint32_t maxValueBytes = 1 * 1024 * 1024 * 1024 ; // 1GB <nl> + <nl> std :: string currentErrorDescription_ ; <nl>  <nl> uint64_t currentUInt_ { 0 };
namespace Exiv2 { <nl> } <nl> } <nl>  <nl> - long WebPImage :: getHeaderOffset ( byte * data , long data_size , <nl> - byte * header , long header_size ) { <nl> + long WebPImage :: getHeaderOffset ( byte * data , long data_size , byte * header , long header_size ) <nl> + { <nl> + if ( data_size < header_size ) { return - 1 ; } <nl> long pos = - 1 ; <nl> for ( long i = 0 ; i < data_size - header_size ; i ++) { <nl> if ( memcmp ( header , & data [ i ], header_size ) == 0 ) {
fribidi_get_par_embedding_levels_ex ( <nl> } <nl>  <nl> RL_LEVEL ( pp ) = level ; <nl> - RL_ISOLATE_LEVEL ( pp ) = isolate_level ++; <nl> + RL_ISOLATE_LEVEL ( pp ) = isolate_level ; <nl> + if ( isolate_level < FRIBIDI_BIDI_MAX_EXPLICIT_LEVEL - 1 ) <nl> + isolate_level ++; <nl> base_level_per_iso_level [ isolate_level ] = new_level ; <nl>  <nl> if (! FRIBIDI_IS_NEUTRAL ( override ))
hermesBuiltinApply ( void *, Runtime * runtime , NativeArgs args ) { <nl>  <nl> ScopedNativeCallFrame newFrame { <nl> runtime , len , * fn , isConstructor , thisVal . getHermesValue ()}; <nl> + if ( LLVM_UNLIKELY ( newFrame . overflowed ())) <nl> + return runtime -> raiseStackOverflow ( Runtime :: StackOverflowKind :: NativeStack ); <nl> + <nl> for ( uint32_t i = 0 ; i < len ; ++ i ) { <nl> newFrame -> getArgRef ( i ) = argArray -> at ( runtime , i ); <nl> }
Literal * hermes :: evalUnaryOperator ( <nl> case ValueKind :: LiteralStringKind : <nl> return builder . getLiteralString (" string "); <nl> default : <nl> - llvm_unreachable (" Invalid literal kind ."); <nl> + break ; <nl> } <nl> break ; <nl> 
static cdk_error_t skip_packet ( cdk_stream_t inp , size_t pktlen ) <nl> return 0 ; <nl> } <nl>  <nl> +# define MAX_PACKET_LEN ( 1 << 24 ) <nl>  <nl> /** <nl> * cdk_pkt_read : <nl> cdk_error_t cdk_pkt_read ( cdk_stream_t inp , cdk_packet_t pkt ) <nl> else <nl> read_old_length ( inp , ctb , & pktlen , & pktsize ); <nl>  <nl> + /* enforce limits to ensure that the following calculations <nl> + * do not overflow */ <nl> + if ( pktlen >= MAX_PACKET_LEN || pktsize >= MAX_PACKET_LEN ) { <nl> + _cdk_log_info (" cdk_pkt_read : too long packet \ n "); <nl> + return gnutls_assert_val ( CDK_Inv_Packet ); <nl> + } <nl> + <nl> pkt -> pkttype = pkttype ; <nl> pkt -> pktlen = pktlen ; <nl> pkt -> pktsize = pktsize + pktlen ; <nl> cdk_error_t cdk_pkt_read ( cdk_stream_t inp , cdk_packet_t pkt ) <nl> break ; <nl>  <nl> case CDK_PKT_USER_ID : <nl> + <nl> pkt -> pkt . user_id = cdk_calloc ( 1 , sizeof * pkt -> pkt . user_id <nl> + pkt -> pktlen + 1 ); <nl> if (! pkt -> pkt . user_id )
static PyObject * patch ( PyObject * self , PyObject * args ) <nl> y = PyLong_AsLong ( PyTuple_GET_ITEM ( tuple , 1 )); <nl> z = PyLong_AsLong ( PyTuple_GET_ITEM ( tuple , 2 )); <nl> if ( newpos + x > newDataLength || <nl> - diffPtr + x > diffBlock + diffBlockLength || <nl> - extraPtr + y > extraBlock + extraBlockLength ) { <nl> + diffPtr + x > diffBlock + diffBlockLength ) { <nl> PyMem_Free ( newData ); <nl> PyErr_SetString ( PyExc_ValueError , " corrupt patch ( overflow )"); <nl> return NULL ; <nl> static PyObject * patch ( PyObject * self , PyObject * args ) <nl> newData [ newpos + j ] += origData [ oldpos + j ]; <nl> newpos += x ; <nl> oldpos += x ; <nl> + if ( newpos + y > newDataLength || <nl> + extraPtr + y > extraBlock + extraBlockLength ) { <nl> + PyMem_Free ( newData ); <nl> + PyErr_SetString ( PyExc_ValueError , " corrupt patch ( overflow )"); <nl> + return NULL ; <nl> + } <nl> memcpy ( newData + newpos , extraPtr , y ); <nl> extraPtr += y ; <nl> newpos += y ;
KCleanup :: expandVariables ( const KFileInfo * item , <nl> const QString & unexpanded ) const <nl> { <nl> QString expanded = unexpanded ; <nl> - <nl> - expanded . replace ( QRegExp ( "% p " ), <nl> - "'" + QString :: fromLocal8Bit ( item -> url () ) + "'" ); <nl> - expanded . replace ( QRegExp ( "% n " ), <nl> - "'" + QString :: fromLocal8Bit ( item -> name () ) + "'" ); <nl> + QString url = QString :: fromLocal8Bit ( item -> url () ). replace ("'", "'\\''"); <nl> + expanded . replace ( QRegExp ( "% p " ), "'" + url + "'" ); <nl> + QString name = QString :: fromLocal8Bit ( item -> name () ). replace ("'", "'\\''"); <nl> + expanded . replace ( QRegExp ( "% n " ), "'" + name + "'" ); <nl>  <nl> // if ( KDE :: versionMajor () >= 3 && KDE :: versionMinor () >= 4 ) <nl> expanded . replace ( QRegExp ( "% t " ), " trash :/" );
void KPasswordDlg :: keyPressed ( QKeyEvent * e ) <nl> break ; <nl>  <nl> case Key_Return : <nl> + timer . stop (); <nl> waitForAuthentication = true ; <nl> if ( tryPassword () ) <nl> emit passOk ();
PrimitiveStatus TrustedPrimitives :: UntrustedCall ( uint64_t untrusted_selector , <nl> if ( sgx_params -> input ) { <nl> untrusted_cache -> Free ( const_cast < void *>( sgx_params -> input )); <nl> } <nl> - if (! TrustedPrimitives :: IsOutsideEnclave ( sgx_params -> output , <nl> - sgx_params -> output_size )) { <nl> + const void * output_pointer = sgx_params -> output ; <nl> + uint64_t output_size = sgx_params -> output_size ; <nl> + if (! TrustedPrimitives :: IsOutsideEnclave ( output_pointer , output_size )) { <nl> TrustedPrimitives :: BestEffortAbort ( <nl> " UntrustedCall : sgx_param output should be in untrusted memory "); <nl> } <nl> if ( sgx_params -> output ) { <nl> // For the results obtained in | output_buffer |, copy them to | output | <nl> // before freeing the buffer . <nl> - output -> Deserialize ( sgx_params -> output , sgx_params -> output_size ); <nl> + output -> Deserialize ( output_pointer , output_size ); <nl> TrustedPrimitives :: UntrustedLocalFree ( sgx_params -> output ); <nl> } <nl> return PrimitiveStatus :: OkStatus ();
extern " C " int64_t enc_untrusted_syscall ( int sysno , ...) { <nl> // Copy outputs back into pointer parameters . <nl> auto response_reader = <nl> asylo :: system_call :: MessageReader ({ response_buffer , response_size }); <nl> + if ( response_reader . sysno () != sysno ) { <nl> + error_handler (" system_call . cc : Unexpected sysno in response "); <nl> + } <nl> const asylo :: primitives :: PrimitiveStatus response_status = <nl> response_reader . Validate (); <nl> if (! response_status . ok ()) {
// anti - copyright Lucy Phipps 2022 <nl> // vi : sw = 2 tw = 80 <nl> -# define VERSION " v1 . 0 . 4 " <nl> +# define VERSION " v1 . 0 . 5 " <nl> # include < errno . h > <nl> # include < inttypes . h > <nl> # include < limits . h > <nl> static bool w2p ( char * ip , char * op ) { <nl> } <nl> size_t l = (( uint32_t )( i [ 4 ] | ( i [ 5 ] << 8 ) | ( i [ 6 ] << 16 ) | ( i [ 7 ] << 24 ))) + 8 ; <nl> // ^ RIFF header size <nl> + if ( l <= 12 <nl> +# ifdef SSIZE_MAX <nl> + || l - 12 > SSIZE_MAX <nl> +# endif <nl> + ) { <nl> + PF (" ERROR reading % s : % s ", IP , k [ 2 ]); <nl> + goto w2p_close ; <nl> + } <nl> x = malloc ( l ); <nl> if (! x ) { <nl> PF (" ERROR reading % s : % s ", IP , * k );
escape_xml ( const char * text ) <nl> char * out ; <nl> size_t len ; <nl>  <nl> - if (! strlen ( text )) return " empty string "; <nl> + if (! strlen ( text )) return ""; <nl>  <nl> for ( out = escaped , len = 0 ; * text ; ++ len , ++ out , ++ text ) { <nl> /* Make sure there ' s plenty of room for a quoted character */
pspdf_prepare_outpages () <nl> chapter_outstarts [ c ] = num_outpages ; <nl>  <nl> for ( i = chapter_starts [ c ], j = 0 , nup = - 1 , page = pages + i ; <nl> - i <= chapter_ends [ c ]; <nl> + i <= chapter_ends [ c ] && num_outpages < num_pages ; <nl> i ++, page ++) <nl> { <nl> if ( nup != page -> nup )
parse_paragraph ( tree_t * t , /* I - Tree to parse */ <nl> { <nl> break ; <nl> } <nl> - else if ( prev -> markup == MARKUP_NONE ) <nl> + else if ( prev -> markup == MARKUP_NONE && *( prev -> data )) <nl> { <nl> int ch = prev -> data [ strlen (( char *) prev -> data ) - 1 ]; <nl> 
static void cmd_parse_status ( IMAP_DATA * idata , char * s ) <nl> idata -> status = IMAP_FATAL ; <nl> return ; <nl> } <nl> + <nl> + if ( strlen ( idata -> buf ) < litlen ) <nl> + { <nl> + dprint ( 1 , ( debugfile , " Error parsing STATUS mailbox \ n ")); <nl> + return ; <nl> + } <nl> + <nl> mailbox = idata -> buf ; <nl> s = mailbox + litlen ; <nl> * s = '\ 0 ';
header_cache_t * imap_hcache_open ( IMAP_DATA * idata , const char * path ) <nl> ciss_url_t url ; <nl> char cachepath [ LONG_STRING ]; <nl> char mbox [ LONG_STRING ]; <nl> + size_t len ; <nl>  <nl> if ( path ) <nl> imap_cachepath ( idata , path , mbox , sizeof ( mbox )); <nl> header_cache_t * imap_hcache_open ( IMAP_DATA * idata , const char * path ) <nl> FREE (& mx . mbox ); <nl> } <nl>  <nl> + if ( strstr ( mbox , "/../") || ( strcmp ( mbox , "..") == 0 ) || ( strncmp ( mbox , "../", 3 ) == 0 )) <nl> + return NULL ; <nl> + len = strlen ( mbox ); <nl> + if (( len > 3 ) && ( strcmp ( mbox + len - 3 , "/..") == 0 )) <nl> + return NULL ; <nl> + <nl> mutt_account_tourl (& idata -> conn -> account , & url ); <nl> url . path = mbox ; <nl> url_ciss_tostring (& url , cachepath , sizeof ( cachepath ), U_PATH );
static bool checkreturn decode_pointer_field ( pb_istream_t * stream , pb_wire_type_ <nl> if (! check_wire_type ( wire_type , field )) <nl> PB_RETURN_ERROR ( stream , " wrong wire type "); <nl>  <nl> - (* size )++; <nl> - if (! allocate_field ( stream , field -> pField , field -> data_size , * size )) <nl> + if (! allocate_field ( stream , field -> pField , field -> data_size , ( size_t )(* size + 1 ))) <nl> return false ; <nl>  <nl> - field -> pData = *( char **) field -> pField + field -> data_size * (* size - 1 ); <nl> + field -> pData = *( char **) field -> pField + field -> data_size * (* size ); <nl> + (* size )++; <nl> initialize_pointer_field ( field -> pData , field ); <nl> return decode_basic_field ( stream , field ); <nl> }
ssize_t nghttp2_session_mem_recv ( nghttp2_session * session , const uint8_t * in , <nl> break ; <nl> } <nl>  <nl> + /* Check the settings flood counter early to be safe */ <nl> + if ( session -> obq_flood_counter_ >= session -> max_outbound_ack && <nl> + !( iframe -> frame . hd . flags & NGHTTP2_FLAG_ACK )) { <nl> + return NGHTTP2_ERR_FLOODED ; <nl> + } <nl> + <nl> iframe -> state = NGHTTP2_IB_READ_SETTINGS ; <nl>  <nl> if ( iframe -> payloadleft ) {
-/* NetHack 3 . 6 files . c $ NHDT - Date : 1574116097 2019 / 11 / 18 22 : 28 : 17 $ $ NHDT - Branch : NetHack - 3 . 6 $:$ NHDT - Revision : 1 . 272 $ */ <nl> +/* NetHack 3 . 6 files . c $ NHDT - Date : 1576626110 2019 / 12 / 17 23 : 41 : 50 $ $ NHDT - Branch : NetHack - 3 . 6 $:$ NHDT - Revision : 1 . 276 $ */ <nl> /* Copyright ( c ) Stichting Mathematisch Centrum , Amsterdam , 1985 . */ <nl> /*- Copyright ( c ) Derek S . Ray , 2015 . */ <nl> /* NetHack may be freely redistributed . See license for details . */ <nl> boolean FDECL ((* proc ), ( char *)); <nl> free ( buf ); <nl> } <nl> buf = strcat ( tmpbuf , ep ); <nl> - buf [ sizeof inbuf - 1 ] = '\ 0 '; <nl> + if ( strlen ( buf ) >= sizeof inbuf ) <nl> + buf [ sizeof inbuf - 1 ] = '\ 0 '; <nl> } <nl>  <nl> if ( morelines || ( ignoreline && ! oldline ))
ngx_http_send_error_page ( ngx_http_request_t * r , ngx_http_err_page_t * err_page ) <nl> return ngx_http_named_location ( r , & uri ); <nl> } <nl>  <nl> + r -> expect_tested = 1 ; <nl> + <nl> + if ( ngx_http_discard_request_body ( r ) != NGX_OK ) { <nl> + r -> keepalive = 0 ; <nl> + } <nl> + <nl> location = ngx_list_push (& r -> headers_out . headers ); <nl>  <nl> if ( location == NULL ) {
static char * clean_path ( char * path ) <nl> char * ch ; <nl> char * ch2 ; <nl> char * str ; <nl> - str = xmalloc ( strlen ( path )); <nl> + str = xmalloc ( strlen ( path ) + 1 ); <nl> ch = path ; <nl> ch2 = str ; <nl> while ( true ) {
char * parse_content_length ( char * buffer , char * end , int * length ) <nl> size = 0 ; <nl> number = 0 ; <nl> while ( p < end && * p >=' 0 ' && * p <=' 9 ') { <nl> - number = number * 10 + (* p )-' 0 '; <nl> - if ( number < 0 ) { <nl> - LM_ERR (" number overflow at pos % d in len number [%.* s ]\ n ", <nl> + /* do not actually cause an integer overflow , as it is UB ! -- liviu */ <nl> + if ( number > 214748363 ) { <nl> + LM_ERR (" integer overflow risk at pos % d in len number [%.* s ]\ n ", <nl> ( int )( p - buffer ),( int )( end - buffer ), buffer ); <nl> return 0 ; <nl> } <nl> + <nl> + number = number * 10 + (* p )-' 0 '; <nl> size ++; <nl> p ++; <nl> }
int delete_sdp_line ( struct sip_msg * msg , char * s , struct sdp_stream_cell * str <nl>  <nl> while (* end != '\ n ' && end < ( stream -> body . s + stream -> body . len ) ) <nl> end ++; <nl> - end ++; <nl> + if ( * end == '\ n ') <nl> + end ++; <nl>  <nl> /* delete the entry */ <nl> if ( del_lump ( msg , start - msg -> buf , end - start , 0 ) == NULL )
static inline char * parse_to_param ( char * buffer , char * end , <nl> switch ( status ) <nl> { <nl> case PARA_VALUE_QUOTED : <nl> + if ( tmp + 1 == end ) <nl> + goto parse_error ; <nl> switch (*( tmp + 1 )) <nl> { <nl> case '\ r ': <nl> static inline char * parse_to_param ( char * buffer , char * end , <nl> }/* switch */ <nl> }/* for */ <nl>  <nl> + if ( status == PARA_VALUE_QUOTED ) { <nl> + LM_ERR (" unexpected end of header in state % d \ n ", status ); <nl> + goto parse_error ; <nl> + } <nl>  <nl> endofheader : <nl> + LM_DBG (" end of header reached , state =% d \ n ", status ); <nl> if ( param ) { <nl> if ( saved_status == S_EQUAL || saved_status == S_PARA_VALUE ) { <nl> saved_status = E_PARA_VALUE ;
IHEVCD_ERROR_T ihevcd_parse_sps ( codec_t * ps_codec ) <nl> UEV_PARSE (" max_dec_pic_buffering ", value , ps_bitstrm ); <nl> ps_sps -> ai1_sps_max_dec_pic_buffering [ i ] = value + 1 ; <nl>  <nl> + if ( ps_sps -> ai1_sps_max_dec_pic_buffering [ i ] > MAX_DPB_SIZE ) <nl> + { <nl> + return IHEVCD_INVALID_PARAMETER ; <nl> + } <nl> + <nl> UEV_PARSE (" num_reorder_pics ", value , ps_bitstrm ); <nl> ps_sps -> ai1_sps_max_num_reorder_pics [ i ] = value ; <nl>  <nl> + if ( ps_sps -> ai1_sps_max_num_reorder_pics [ i ] > ps_sps -> ai1_sps_max_dec_pic_buffering [ i ]) <nl> + { <nl> + return IHEVCD_INVALID_PARAMETER ; <nl> + } <nl> + <nl> UEV_PARSE (" max_latency_increase ", value , ps_bitstrm ); <nl> ps_sps -> ai1_sps_max_latency_increase [ i ] = value ; <nl> }
WORD32 ih264d_video_decode ( iv_obj_t * dec_hdl , void * pv_api_ip , void * pv_api_op ) <nl> else <nl> prev_slice_err = 2 ; <nl>  <nl> + if ( ps_dec -> u4_first_slice_in_pic && ( ps_dec -> u2_total_mbs_coded == 0 )) <nl> + prev_slice_err = 1 ; <nl> + <nl> ret1 = ih264d_mark_err_slice_skip ( ps_dec , num_mb_skipped , ps_dec -> u1_nal_unit_type == IDR_SLICE_NAL , ps_dec -> ps_cur_slice -> u2_frame_num , <nl> & temp_poc , prev_slice_err ); <nl> 
xmlParsePEReference ( xmlParserCtxtPtr ctxt ) <nl> if ( xmlPushInput ( ctxt , input ) < 0 ) <nl> return ; <nl> } else { <nl> + if (( entity -> etype == XML_EXTERNAL_PARAMETER_ENTITY ) && <nl> + (( ctxt -> options & XML_PARSE_NOENT ) == 0 ) && <nl> + (( ctxt -> options & XML_PARSE_DTDVALID ) == 0 ) && <nl> + (( ctxt -> options & XML_PARSE_DTDLOAD ) == 0 ) && <nl> + (( ctxt -> options & XML_PARSE_DTDATTR ) == 0 ) && <nl> + ( ctxt -> replaceEntities == 0 ) && <nl> + ( ctxt -> validate == 0 )) <nl> + return ; <nl> /* <nl> * TODO !!! <nl> * handle the extra spaces added before and after
static vpx_codec_err_t vp8_peek_si_internal ( const uint8_t * data , <nl> si -> h = ( clear [ 8 ] | ( clear [ 9 ] << 8 )) & 0x3fff ; <nl>  <nl> /* printf (" w =% d , h =% d \ n ", si -> w , si -> h );*/ <nl> - if (!( si -> h | si -> w )) <nl> - res = VPX_CODEC_UNSUP_BITSTREAM ; <nl> + if (!( si -> h && si -> w )) <nl> + res = VPX_CODEC_CORRUPT_FRAME ; <nl> } <nl> else <nl> { <nl> static vpx_codec_err_t vp8_decode ( vpx_codec_alg_priv_t * ctx , <nl> if ( setjmp ( pbi -> common . error . jmp )) <nl> { <nl> pbi -> common . error . setjmp = 0 ; <nl> + /* on failure clear the cached resolution to ensure a full <nl> + * reallocation is attempted on resync . */ <nl> + ctx -> si . w = 0 ; <nl> + ctx -> si . h = 0 ; <nl> vp8_clear_system_state (); <nl> /* same return value as used in vp8dx_receive_compressed_data */ <nl> return - 1 ;
namespace android { <nl>  <nl> // These could perhaps be optimized to use __builtin_bswap16 and friends . <nl> static uint32_t readU16 ( const uint8_t * data , size_t offset ) { <nl> - return data [ offset ] << 8 | data [ offset + 1 ]; <nl> + return (( uint32_t ) data [ offset ]) << 8 | (( uint32_t ) data [ offset + 1 ]); <nl> } <nl>  <nl> static uint32_t readU32 ( const uint8_t * data , size_t offset ) { <nl> - return data [ offset ] << 24 | data [ offset + 1 ] << 16 | data [ offset + 2 ] << 8 | data [ offset + 3 ]; <nl> + return (( uint32_t ) data [ offset ]) << 24 | (( uint32_t ) data [ offset + 1 ]) << 16 | <nl> + (( uint32_t ) data [ offset + 2 ]) << 8 | (( uint32_t ) data [ offset + 3 ]); <nl> } <nl>  <nl> static void addRange ( vector < uint32_t > & coverage , uint32_t start , uint32_t end ) { <nl> static bool getCoverageFormat12 ( vector < uint32_t >& coverage , const uint8_t * data , <nl> const size_t kGroupSize = 12 ; <nl> const size_t kStartCharCodeOffset = 0 ; <nl> const size_t kEndCharCodeOffset = 4 ; <nl> + const size_t kMaxNGroups = 0xfffffff0 / kGroupSize ; // protection against overflow <nl> + // For all values < kMaxNGroups , kFirstGroupOffset + nGroups * kGroupSize fits in 32 bits . <nl> if ( kFirstGroupOffset > size ) { <nl> return false ; <nl> } <nl> uint32_t nGroups = readU32 ( data , kNGroupsOffset ); <nl> - if ( kFirstGroupOffset + nGroups * kGroupSize > size ) { <nl> + if ( nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size ) { <nl> return false ; <nl> } <nl> for ( uint32_t i = 0 ; i < nGroups ; i ++) {
void wifi_cleanup ( wifi_handle handle , wifi_cleaned_up_handler handler ) <nl> pthread_mutex_unlock (& info -> cb_lock ); <nl> cmd -> cancel (); <nl> pthread_mutex_lock (& info -> cb_lock ); <nl> - /* release reference added when command is saved */ <nl> - cmd -> releaseRef (); <nl> if ( num_cmd == info -> num_cmd ) { <nl> ALOGI (" Cancelling command % p :% s did not work ", cmd , ( cmd ? cmd -> getType (): "")); <nl> bad_commands ++; <nl> } <nl> + /* release reference added when command is saved */ <nl> + cmd -> releaseRef (); <nl> } <nl> } <nl> 
native_handle * Parcel :: readNativeHandle () const <nl>  <nl> for ( int i = 0 ; err == NO_ERROR && i < numFds ; i ++) { <nl> h -> data [ i ] = dup ( readFileDescriptor ()); <nl> - if ( h -> data [ i ] < 0 ) err = BAD_VALUE ; <nl> + if ( h -> data [ i ] < 0 ) { <nl> + for ( int j = 0 ; j < i ; j ++) { <nl> + close ( h -> data [ j ]); <nl> + } <nl> + native_handle_delete ( h ); <nl> + return 0 ; <nl> + } <nl> } <nl> err = read ( h -> data + numFds , sizeof ( int )* numInts ); <nl> if ( err != NO_ERROR ) {
static bool cleanupNative ( JNIEnv * env , jobject obj ) { <nl> return JNI_TRUE ; <nl> } <nl>  <nl> - static jboolean enableNative ( JNIEnv * env , jobject obj ) { <nl> + static jboolean enableNative ( JNIEnv * env , jobject obj , jboolean isGuest ) { <nl> ALOGV ("% s :", __FUNCTION__ ); <nl>  <nl> jboolean result = JNI_FALSE ; <nl> if (! sBluetoothInterface ) return result ; <nl> - <nl> - int ret = sBluetoothInterface -> enable (); <nl> + int ret = sBluetoothInterface -> enable ( isGuest == JNI_TRUE ? 1 : 0 ); <nl> result = ( ret == BT_STATUS_SUCCESS || ret == BT_STATUS_DONE ) ? JNI_TRUE : JNI_FALSE ; <nl> return result ; <nl> } <nl> static JNINativeMethod sMethods [] = { <nl> {" classInitNative ", "() V ", ( void *) classInitNative }, <nl> {" initNative ", "() Z ", ( void *) initNative }, <nl> {" cleanupNative ", "() V ", ( void *) cleanupNative }, <nl> - {" enableNative ", "() Z ", ( void *) enableNative }, <nl> + {" enableNative ", "( Z ) Z ", ( void *) enableNative }, <nl> {" disableNative ", "() Z ", ( void *) disableNative }, <nl> {" setAdapterPropertyNative ", "( I [ B ) Z ", ( void *) setAdapterPropertyNative }, <nl> {" getAdapterPropertiesNative ", "() Z ", ( void *) getAdapterPropertiesNative },
netdutils :: Status XfrmController :: ipSecSetEncapSocketOwner ( const android :: base :: <nl> } <nl>  <nl> int optval ; <nl> - socklen_t optlen ; <nl> + socklen_t optlen = sizeof ( optval ); <nl> netdutils :: Status status = <nl> getSyscallInstance (). getsockopt ( Fd ( socket ), IPPROTO_UDP , UDP_ENCAP , & optval , & optlen ); <nl> if ( status != netdutils :: status :: ok ) {
out : <nl> static void print_maps ( struct pid_info_t * info ) <nl> { <nl> FILE * maps ; <nl> + <nl> size_t offset ; <nl> char device [ 10 ]; <nl> long int inode ; <nl> - char file [ PATH_MAX ]; <nl> + char file [ 1024 ]; <nl>  <nl> strlcat ( info -> path , " maps ", sizeof ( info -> path )); <nl>  <nl> static void print_maps ( struct pid_info_t * info ) <nl> if (! maps ) <nl> goto out ; <nl>  <nl> - while ( fscanf ( maps , "%* x -%* x %* s % zx % s % ld % s \ n ", & offset , device , & inode , <nl> - file ) == 4 ) { <nl> + while ( fscanf ( maps , "%* x -%* x %* s % zx % 5s % ld % 1023s \ n ", <nl> + & offset , device , & inode , file ) == 4 ) { <nl> // We don ' t care about non - file maps <nl> if ( inode == 0 || ! strcmp ( device , " 00 : 00 ")) <nl> continue ;
static ssize_t get_node_path_locked ( struct node * node , char * buf , size_t bufsize <nl>  <nl> ssize_t pathlen = 0 ; <nl> if ( node -> parent && node -> graft_path == NULL ) { <nl> - pathlen = get_node_path_locked ( node -> parent , buf , bufsize - namelen - 2 ); <nl> + pathlen = get_node_path_locked ( node -> parent , buf , bufsize - namelen - 1 ); <nl> if ( pathlen < 0 ) { <nl> return - 1 ; <nl> }
pci_emul_mem_handler ( struct vmctx * ctx , int vcpu , int dir , uint64_t addr , <nl> uint64_t offset ; <nl> int bidx = ( int ) arg2 ; <nl>  <nl> - assert ( bidx <= PCI_BARMAX ); <nl> - assert ( pdi -> bar [ bidx ]. type == PCIBAR_MEM32 || <nl> - pdi -> bar [ bidx ]. type == PCIBAR_MEM64 ); <nl> - assert ( addr >= pdi -> bar [ bidx ]. addr && <nl> - addr + size <= pdi -> bar [ bidx ]. addr + pdi -> bar [ bidx ]. size ); <nl> + if ( addr + size > pdi -> bar [ bidx ]. addr + pdi -> bar [ bidx ]. size ) { <nl> + printf ("% s , Out of emulated memory range .\ n ", __func__ ); <nl> + return - ESRCH ; <nl> + } <nl>  <nl> offset = addr - pdi -> bar [ bidx ]. addr ; <nl> 
void unmarshallAudioAttributes ( const Parcel & parcel , audio_attributes_t * attribu <nl> // copying array size - 1 , array for tags was calloc ' d , no need to NULL - terminate it <nl> size_t tagSize = realTagSize > AUDIO_ATTRIBUTES_TAGS_MAX_SIZE - 1 ? <nl> AUDIO_ATTRIBUTES_TAGS_MAX_SIZE - 1 : realTagSize ; <nl> - utf16_to_utf8 ( tags . string (), tagSize , attributes -> tags ); <nl> + utf16_to_utf8 ( tags . string (), tagSize , attributes -> tags , <nl> + sizeof ( attributes -> tags ) / sizeof ( attributes -> tags [ 0 ])); <nl> } <nl> } else { <nl> ALOGE (" unmarshallAudioAttributes () received unflattened tags , ignoring tag values ");
status_t SampleIterator :: seekTo ( uint32_t sampleIndex ) { <nl> + mFirstChunk ; <nl>  <nl> if (! mInitialized || chunk != mCurrentChunkIndex ) { <nl> - mCurrentChunkIndex = chunk ; <nl> - <nl> status_t err ; <nl> if (( err = getChunkOffset ( chunk , & mCurrentChunkOffset )) != OK ) { <nl> ALOGE (" getChunkOffset return error "); <nl> status_t SampleIterator :: seekTo ( uint32_t sampleIndex ) { <nl>  <nl> uint32_t firstChunkSampleIndex = <nl> mFirstChunkSampleIndex <nl> - + mSamplesPerChunk * ( mCurrentChunkIndex - mFirstChunk ); <nl> + + mSamplesPerChunk * ( chunk - mFirstChunk ); <nl>  <nl> for ( uint32_t i = 0 ; i < mSamplesPerChunk ; ++ i ) { <nl> size_t sampleSize ; <nl> if (( err = getSampleSizeDirect ( <nl> firstChunkSampleIndex + i , & sampleSize )) != OK ) { <nl> ALOGE (" getSampleSizeDirect return error "); <nl> + mCurrentChunkSampleSizes . clear (); <nl> return err ; <nl> } <nl>  <nl> mCurrentChunkSampleSizes . push ( sampleSize ); <nl> } <nl> + <nl> + mCurrentChunkIndex = chunk ; <nl> } <nl>  <nl> uint32_t chunkRelativeSampleIndex =
status_t ESDS :: parseESDescriptor ( size_t offset , size_t size ) { <nl> -- size ; <nl>  <nl> if ( streamDependenceFlag ) { <nl> + if ( size < 2 ) <nl> + return ERROR_MALFORMED ; <nl> offset += 2 ; <nl> size -= 2 ; <nl> } <nl> status_t ESDS :: parseESDescriptor ( size_t offset , size_t size ) { <nl> return ERROR_MALFORMED ; <nl> } <nl> unsigned URLlength = mData [ offset ]; <nl> + if ( URLlength >= size ) <nl> + return ERROR_MALFORMED ; <nl> offset += URLlength + 1 ; <nl> size -= URLlength + 1 ; <nl> } <nl>  <nl> if ( OCRstreamFlag ) { <nl> + if ( size < 2 ) <nl> + return ERROR_MALFORMED ; <nl> offset += 2 ; <nl> size -= 2 ; <nl> 
status_t AudioFlinger :: EffectModule :: command ( uint32_t cmdCode , <nl> if ( mStatus != NO_ERROR ) { <nl> return mStatus ; <nl> } <nl> + if ( cmdCode == EFFECT_CMD_GET_PARAM && <nl> + (* replySize < sizeof ( effect_param_t ) || <nl> + (( effect_param_t *) pCmdData )-> psize > * replySize - sizeof ( effect_param_t ))) { <nl> + android_errorWriteLog ( 0x534e4554 , " 29251553 "); <nl> + return - EINVAL ; <nl> + } <nl> status_t status = (* mEffectInterface )-> command ( mEffectInterface , <nl> cmdCode , <nl> cmdSize ,
handle_keywordonly_args ( struct compiling * c , const node * n , int start , <nl> goto error ; <nl> asdl_seq_SET ( kwonlyargs , j ++, arg ); <nl> i += 1 ; /* the name */ <nl> - if ( TYPE ( CHILD ( n , i )) == COMMA ) <nl> + if ( i < NCH ( n ) && TYPE ( CHILD ( n , i )) == COMMA ) <nl> i += 1 ; /* the comma , if present */ <nl> break ; <nl> case TYPE_COMMENT : <nl> ast_for_arguments ( struct compiling * c , const node * n ) <nl> if (! kwarg ) <nl> return NULL ; <nl> i += 2 ; /* the double star and the name */ <nl> - if ( TYPE ( CHILD ( n , i )) == COMMA ) <nl> + if ( i < NCH ( n ) && TYPE ( CHILD ( n , i )) == COMMA ) <nl> i += 1 ; /* the comma , if present */ <nl> break ; <nl> case TYPE_COMMENT :
void streamGetEdgeID ( stream * s , int first , int skip_tombstones , streamID * edge_i <nl> streamID min_id = { 0 , 0 }, max_id = { UINT64_MAX , UINT64_MAX }; <nl> * edge_id = first ? max_id : min_id ; <nl> } <nl> - <nl> + streamIteratorStop (& si ); <nl> } <nl>  <nl> /* Adds a new item into the stream ' s ' having the specified number of
static int vcf_parse_format ( kstring_t * s , const bcf_hdr_t * h , bcf1_t * v , char * p <nl> v -> errcode |= BCF_ERR_LIMITS ; <nl> return - 1 ; <nl> } <nl> - f -> offset = mem -> l ; <nl>  <nl> // Limit the total memory to ~ 2Gb per VCF row . This should mean <nl> // malformed VCF data is less likely to take excessive memory and / or <nl> // time . <nl> - if ( v -> n_sample * ( uint64_t ) f -> size > INT_MAX ) { <nl> + if (( uint64_t ) mem -> l + v -> n_sample * ( uint64_t ) f -> size > INT_MAX ) { <nl> hts_log_error (" Excessive memory required by FORMAT fields at % s :%" PRIhts_pos , bcf_seqname_safe ( h , v ), v -> pos + 1 ); <nl> v -> errcode |= BCF_ERR_LIMITS ; <nl> return - 1 ; <nl> } <nl> + <nl> + f -> offset = mem -> l ; <nl> if ( ks_resize ( mem , mem -> l + v -> n_sample * ( size_t ) f -> size ) < 0 ) { <nl> hts_log_error (" Memory allocation failure at % s :%" PRIhts_pos , bcf_seqname_safe ( h , v ), v -> pos + 1 ); <nl> v -> errcode |= BCF_ERR_LIMITS ;
# include < errno . h > <nl> # include < module . h > <nl> # include < linux / err . h > <nl> +# include < crypto . h > <nl> # include < crypto / internal . h > <nl>  <nl> static LIST_HEAD ( digests ); <nl> int digest_generic_verify ( struct digest * d , const unsigned char * md ) <nl> if ( ret ) <nl> goto end ; <nl>  <nl> - ret = memcmp ( md , tmp , len ); <nl> - ret = ret ? - EINVAL : 0 ; <nl> + if ( crypto_memneq ( md , tmp , len )) <nl> + ret = - EINVAL ; <nl> + else <nl> + ret = 0 ; <nl> end : <nl> free ( tmp ); <nl> return ret ;
bool MemoryManager :: validate_user_stack ( const Process & process , VirtualAddress v <nl>  <nl> bool MemoryManager :: validate_user_read ( const Process & process , VirtualAddress vaddr ) const <nl> { <nl> - auto * region = region_from_vaddr ( process , vaddr ); <nl> - return region && region -> is_readable (); <nl> + auto * region = user_region_from_vaddr ( const_cast < Process &>( process ), vaddr ); <nl> + return region && region -> is_user_accessible () && region -> is_readable (); <nl> } <nl>  <nl> bool MemoryManager :: validate_user_write ( const Process & process , VirtualAddress vaddr ) const <nl> { <nl> - auto * region = region_from_vaddr ( process , vaddr ); <nl> - return region && region -> is_writable (); <nl> + auto * region = user_region_from_vaddr ( const_cast < Process &>( process ), vaddr ); <nl> + return region && region -> is_user_accessible () && region -> is_writable (); <nl> } <nl>  <nl> void MemoryManager :: register_vmobject ( VMObject & vmobject )
NAN_METHOD ( DetectCharacterEncoding ) { <nl>  <nl> if ( U_FAILURE ( errorCode )) { <nl> Nan :: ThrowError (" Failed to set ICU charset detector  s text ."); <nl> + ucsdet_close ( charsetDetector ); <nl> return ; <nl> } <nl>  <nl> NAN_METHOD ( DetectCharacterEncoding ) { <nl>  <nl> if ( U_FAILURE ( errorCode )) { <nl> Nan :: ThrowError (" Failed to detect charset ."); <nl> + ucsdet_close ( charsetDetector ); <nl> return ; <nl> } <nl>  <nl> NAN_METHOD ( DetectCharacterEncoding ) { <nl>  <nl> if ( U_FAILURE ( errorCode )) { <nl> Nan :: ThrowError (" Failed to get name from charset match ."); <nl> + ucsdet_close ( charsetDetector ); <nl> return ; <nl> } <nl>  <nl> NAN_METHOD ( DetectCharacterEncoding ) { <nl>  <nl> if ( U_FAILURE ( errorCode )) { <nl> Nan :: ThrowError (" Failed to get confidence from charset match ."); <nl> + ucsdet_close ( charsetDetector ); <nl> return ; <nl> } <nl>  <nl> NAN_METHOD ( DetectCharacterEncoding ) { <nl> obj -> Set ( Nan :: New < v8 :: String >(" confidence "). ToLocalChecked (), Nan :: New < v8 :: Number >( confidence )); <nl>  <nl> info . GetReturnValue (). Set ( obj ); <nl> + ucsdet_close ( charsetDetector ); <nl> } <nl>  <nl> void Init ( v8 :: Local < v8 :: Object > exports ) {
HeaderTableRecord :: HeaderTableRecord ( const char * n , HdrType theId , HdrFieldType <nl> const HeaderTableRecord & <nl> HeaderLookupTable_t :: lookup ( const char * buf , const std :: size_t len ) const { <nl> const HeaderTableRecord * r = HttpHeaderHashTable :: lookup ( buf , len ); <nl> - if (! r ) <nl> + if (! r || r -> id == Http :: HdrType :: OTHER ) <nl> return BadHdr ; <nl> return * r ; <nl> }
rb_xml_reader_attribute_hash ( VALUE rb_reader ) <nl> } <nl>  <nl> c_node = xmlTextReaderExpand ( c_reader ); <nl> + if ( c_node == NULL ) { <nl> + return Qnil ; <nl> + } <nl> + <nl> c_property = c_node -> properties ; <nl> while ( c_property != NULL ) { <nl> VALUE rb_name = NOKOGIRI_STR_NEW2 ( c_property -> name );
static RList * patch_relocs ( RBin * b ) { <nl>  <nl> size_t nimports = 0 ; <nl> int i ; <nl> - for ( i = 0 ; i < bin -> hdr . f_nsyms ; i ++) { <nl> - if ( is_imported_symbol (& bin -> symbols [ i ])) { <nl> - nimports ++; <nl> + if ( bin -> symbols ) { <nl> + for ( i = 0 ; i < bin -> hdr . f_nsyms ; i ++) { <nl> + if ( is_imported_symbol (& bin -> symbols [ i ])) { <nl> + nimports ++; <nl> + } <nl> + i += bin -> symbols [ i ]. n_numaux ; <nl> } <nl> - i += bin -> symbols [ i ]. n_numaux ; <nl> } <nl> ut64 m_vaddr = UT64_MAX ; <nl> if ( nimports ) {
R_API bool r_crbtree_insert ( RRBTree * tree , void * data , RRBComparator cmp , void * <nl> r_return_val_if_fail ( tree && data && cmp , false ); <nl> bool inserted = false ; <nl>  <nl> - if ( tree -> root == NULL ) { <nl> + if (! tree -> root ) { <nl> tree -> root = _node_new ( data , NULL ); <nl> - if ( tree -> root == NULL ) { <nl> + if (! tree -> root ) { <nl> return false ; <nl> } <nl> inserted = true ;
static RBinSymbol * bin_symbol_from_symbol ( RCoreSymCacheElement * element , RCoreSy <nl>  <nl> static RCoreSymCacheElement * parseDragons ( RBinFile * bf , RBuffer * buf , int off , int bits , R_OWN char * file_name ) { <nl> D eprintf (" Dragons at 0x % x \ n ", off ); <nl> - ut64 size = r_buf_size ( buf ); <nl> + st64 size = r_buf_size ( buf ); <nl> if ( off >= size ) { <nl> return NULL ; <nl> } <nl> static RCoreSymCacheElement * parseDragons ( RBinFile * bf , RBuffer * buf , int off , i <nl> if (! size ) { <nl> return NULL ; <nl> } <nl> + if ( size < 32 ) { <nl> + return NULL ; <nl> + } <nl> ut8 * b = malloc ( size ); <nl> if (! b ) { <nl> return NULL ;
R_API void r_core_anal_esil ( RCore * core , const char * str , const char * target ) { <nl> arch = R2_ARCH_MIPS ; <nl> } <nl>  <nl> - const char * sn = r_reg_get_name ( core -> anal -> reg , R_REG_NAME_SN ); <nl> - if (! sn ) { <nl> - eprintf (" Warning : No SN reg alias for current architecture .\ n "); <nl> - } <nl> r_reg_arena_push ( core -> anal -> reg ); <nl>  <nl> IterCtx ictx = { start , end , fcn , NULL }; <nl> R_API void r_core_anal_esil ( RCore * core , const char * str , const char * target ) { <nl> goto repeat ; <nl> } <nl> } <nl> + const char * sn = r_reg_get_name ( core -> anal -> reg , R_REG_NAME_SN ); <nl> + if (! sn ) { <nl> + eprintf (" Warning : No SN reg alias for current architecture .\ n "); <nl> + } <nl> if ( sn && op . type == R_ANAL_OP_TYPE_SWI ) { <nl> r_strf_buffer ( 64 ); <nl> r_flag_space_set ( core -> flags , R_FLAGS_FS_SYSCALLS );
R_API RBinJavaAttrInfo * r_bin_java_bootstrap_methods_attr_new ( RBinJavaObj * bin , <nl> offset += 6 ; <nl> if ( attr ) { <nl> attr -> type = R_BIN_JAVA_ATTR_TYPE_BOOTSTRAP_METHODS_ATTR ; <nl> + if ( offset + 8 > sz ) { <nl> + free ( attr ); <nl> + return NULL ; <nl> + } <nl> attr -> info . bootstrap_methods_attr . num_bootstrap_methods = R_BIN_JAVA_USHORT ( buffer , offset ); <nl> offset += 2 ; <nl> attr -> info . bootstrap_methods_attr . bootstrap_methods = r_list_newf ( r_bin_java_bootstrap_method_free );
static pyc_object * get_object ( RBuffer * buffer ) { <nl> break ; <nl> case TYPE_UNKNOWN : <nl> eprintf (" Get not implemented for type 0x % x \ n ", type ); <nl> - r_list_pop ( refs ); <nl> + // r_list_pop ( refs ); <nl> free_object ( ret ); <nl> return NULL ; <nl> case 0 :
static int r_core_cmd_subst_i ( RCore * core , char * cmd , char * colon , bool * tmpseek <nl> cmd = sc + 1 ; <nl> continue ; <nl> } <nl> + char op0 = 0 ; <nl> if (* p ) { <nl> // workaround : D <nl> if ( p [ 0 ] == '@') { <nl> static int r_core_cmd_subst_i ( RCore * core , char * cmd , char * colon , bool * tmpseek <nl> if ( p [ 1 ] == '@' || ( p [ 1 ] && p [ 2 ] == '@')) { <nl> char * q = strchr ( p + 1 , '"'); <nl> if ( q ) { <nl> + op0 = * q ; <nl> * q = 0 ; <nl> } <nl> haveQuote = q != NULL ; <nl> static int r_core_cmd_subst_i ( RCore * core , char * cmd , char * colon , bool * tmpseek <nl> cmd = p + 1 ; <nl> } else { <nl> if (* p == '"') { <nl> - cmd = p + 1 ; <nl> + cmd = p ; <nl> } else { <nl> - * p = '"'; <nl> + * p = op0 ; <nl> cmd = p ; <nl> } <nl> }
R_API void r_core_fini ( RCore * c ) { <nl> // TODO : sync all dbs ? <nl> // r_core_file_free ( c -> file ); <nl> // c -> file = NULL ; <nl> - free ( c -> table_query ); <nl> + R_FREE ( c -> table_query ); <nl> r_list_free ( c -> files ); <nl> r_list_free ( c -> watchers ); <nl> r_list_free ( c -> scriptstack );
int modbus_reply ( modbus_t * ctx , const uint8_t * req , <nl> break ; <nl> case MODBUS_FC_WRITE_MULTIPLE_COILS : { <nl> int nb = ( req [ offset + 3 ] << 8 ) + req [ offset + 4 ]; <nl> + int nb_bits = req [ offset + 5 ]; <nl> int mapping_address = address - mb_mapping -> start_bits ; <nl>  <nl> - if ( nb < 1 || MODBUS_MAX_WRITE_BITS < nb ) { <nl> + if ( nb < 1 || MODBUS_MAX_WRITE_BITS < nb || nb_bits * 8 < nb ) { <nl> /* May be the indication has been truncated on reading because of <nl> * invalid address ( eg . nb is 0 but the request contains values to <nl> * write ) so it ' s necessary to flush . */ <nl> int modbus_reply ( modbus_t * ctx , const uint8_t * req , <nl> break ; <nl> case MODBUS_FC_WRITE_MULTIPLE_REGISTERS : { <nl> int nb = ( req [ offset + 3 ] << 8 ) + req [ offset + 4 ]; <nl> + int nb_bytes = req [ offset + 5 ]; <nl> int mapping_address = address - mb_mapping -> start_registers ; <nl>  <nl> - if ( nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb ) { <nl> + if ( nb < 1 || MODBUS_MAX_WRITE_REGISTERS < nb || nb_bytes * 8 < nb ) { <nl> rsp_length = response_exception ( <nl> ctx , & sft , MODBUS_EXCEPTION_ILLEGAL_DATA_VALUE , rsp , TRUE , <nl> " Illegal number of values % d in write_registers ( max % d )\ n ",
ngx_http_auth_spnego_handler ( <nl> /* If basic auth is enabled and basic creds are supplied <nl> * attempt basic auth . If we attempt basic auth , we do <nl> * not fall through to real SPNEGO */ <nl> - if ( NGX_DECLINED == ngx_http_auth_spnego_basic ( r , ctx , alcf )) { <nl> + if ( NGX_OK != ngx_http_auth_spnego_basic ( r , ctx , alcf )) { <nl> spnego_debug0 (" Basic auth failed "); <nl> if ( NGX_ERROR == ngx_http_auth_spnego_headers_basic_only ( r , ctx , alcf )) { <nl> spnego_debug0 (" Error setting headers ");
static ExprList * exprListAppendList ( <nl> int nInit = pList ? pList -> nExpr : 0 ; <nl> for ( i = 0 ; i < pAppend -> nExpr ; i ++){ <nl> Expr * pDup = sqlite3ExprDup ( pParse -> db , pAppend -> a [ i ]. pExpr , 0 ); <nl> + assert ( pDup == 0 || ! ExprHasProperty ( pDup , EP_MemToken ) ); <nl> if ( bIntToNull && pDup && pDup -> op == TK_INTEGER ){ <nl> pDup -> op = TK_NULL ; <nl> pDup -> flags &= ~( EP_IntValue | EP_IsTrue | EP_IsFalse ); <nl> + pDup -> u . zToken = 0 ; <nl> } <nl> pList = sqlite3ExprListAppend ( pParse , pList , pDup ); <nl> if ( pList ) pList -> a [ nInit + i ]. sortFlags = pAppend -> a [ i ]. sortFlags ;
static void do_viewlog ( HttpRequest req , HttpResponse res ) { <nl> StringBuffer_append ( res -> outputbuffer , "< br >< p >< form >< textarea cols = 120 rows = 30 readonly >"); <nl> while (( n = fread ( buf , sizeof ( char ), sizeof ( buf ) - 1 , f )) > 0 ) { <nl> buf [ n ] = 0 ; <nl> - StringBuffer_append ( res -> outputbuffer , "% s ", buf ); <nl> + escapeHTML ( res -> outputbuffer , buf ); <nl> } <nl> fclose ( f ); <nl> StringBuffer_append ( res -> outputbuffer , "</ textarea ></ form >");
static void handle_PORT ( ctrl_t * ctrl , char * str ) <nl>  <nl> /* Convert PORT command ' s argument to IP address + port */ <nl> sscanf ( str , "% d ,% d ,% d ,% d ,% d ,% d ", & a , & b , & c , & d , & e , & f ); <nl> - sprintf ( addr , "% d .% d .% d .% d ", a , b , c , d ); <nl> + snprintf ( addr , sizeof ( addr ), "% d .% d .% d .% d ", a , b , c , d ); <nl>  <nl> /* Check IPv4 address using inet_aton (), throw away converted result */ <nl> if (! inet_aton ( addr , &( sin . sin_addr ))) {
PackLinuxElf32 :: PackLinuxElf32help1 ( InputFile * f ) <nl> e_phnum = get_te16 (& ehdri . e_phnum ); <nl> e_shnum = get_te16 (& ehdri . e_shnum ); <nl> unsigned const e_phentsize = get_te16 (& ehdri . e_phentsize ); <nl> - if ( ehdri . e_ident [ Elf32_Ehdr :: EI_CLASS ]!= Elf32_Ehdr :: ELFCLASS32 <nl> + if ( memcmp (( char const *)& ehdri , "\ x7f \ x45 \ x4c \ x46 ", 4 ) // "\ 177ELF " <nl> + || ehdri . e_ident [ Elf32_Ehdr :: EI_CLASS ]!= Elf32_Ehdr :: ELFCLASS32 <nl> || sizeof ( Elf32_Phdr ) != e_phentsize <nl> || ( Elf32_Ehdr :: ELFDATA2MSB == ehdri . e_ident [ Elf32_Ehdr :: EI_DATA ] <nl> && & N_BELE_RTP :: be_policy != bele ) <nl> PackLinuxElf64 :: PackLinuxElf64help1 ( InputFile * f ) <nl> e_phnum = get_te16 (& ehdri . e_phnum ); <nl> e_shnum = get_te16 (& ehdri . e_shnum ); <nl> unsigned const e_phentsize = get_te16 (& ehdri . e_phentsize ); <nl> - if ( ehdri . e_ident [ Elf64_Ehdr :: EI_CLASS ]!= Elf64_Ehdr :: ELFCLASS64 <nl> + if ( memcmp (( char const *)& ehdri , "\ x7f \ x45 \ x4c \ x46 ", 4 ) // "\ 177ELF " <nl> + || ehdri . e_ident [ Elf64_Ehdr :: EI_CLASS ]!= Elf64_Ehdr :: ELFCLASS64 <nl> || sizeof ( Elf64_Phdr ) != e_phentsize <nl> || ( Elf64_Ehdr :: ELFDATA2MSB == ehdri . e_ident [ Elf64_Ehdr :: EI_DATA ] <nl> && & N_BELE_RTP :: be_policy != bele ) <nl> PackLinuxElf64 :: invert_pt_dynamic ( Elf64_Dyn const * dynp , upx_uint64_t headway ) <nl> } <nl> if ( file_size <= dt_offsets [ n_off ]) { <nl> char msg [ 60 ]; snprintf ( msg , sizeof ( msg ), " bad DT_ {%# x } = %# x ( beyond EOF )", <nl> - dt_names [ k ], dt_offsets [ n_off ]); <nl> + k , dt_offsets [ n_off ]); <nl> throwCantPack ( msg ); <nl> } <nl> n_off += !! dt_offsets [ n_off ];
rndr_quote ( struct buf * ob , const struct buf * text , void * opaque ) <nl> if (! text || ! text -> size ) <nl> return 0 ; <nl>  <nl> + struct html_renderopt * options = opaque ; <nl> + <nl> BUFPUTSL ( ob , "< q >"); <nl> - bufput ( ob , text -> data , text -> size ); <nl> + <nl> + if ( options -> flags & HTML_ESCAPE ) <nl> + escape_html ( ob , text -> data , text -> size ); <nl> + else <nl> + bufput ( ob , text -> data , text -> size ); <nl> + <nl> BUFPUTSL ( ob , "</ q >"); <nl>  <nl> return 1 ;
uint32_t sftp_parse_path ( struct sftpjob * job , char ** strp ) { <nl> uint32_t sftp_parse_handle ( struct sftpjob * job , struct handleid * id ) { <nl> uint32_t len , rc ; <nl>  <nl> - if (( rc = sftp_parse_uint32 ( job , & len )) != SSH_FX_OK || len != 8 || <nl> - ( rc = sftp_parse_uint32 ( job , & id -> id )) != SSH_FX_OK || <nl> + if (( rc = sftp_parse_uint32 ( job , & len )) != SSH_FX_OK ) <nl> + return rc ; <nl> + if ( len != 8 ) <nl> + return SSH_FX_BAD_MESSAGE ; <nl> + if (( rc = sftp_parse_uint32 ( job , & id -> id )) != SSH_FX_OK || <nl> ( rc = sftp_parse_uint32 ( job , & id -> tag ) != SSH_FX_OK )) <nl> return rc ; <nl> return SSH_FX_OK ;
class TensorListResize : public OpKernel { <nl> void Compute ( OpKernelContext * c ) override { <nl> const TensorList * input_list = nullptr ; <nl> OP_REQUIRES_OK ( c , GetInputList ( c , 0 , & input_list )); <nl> + OP_REQUIRES ( c , TensorShapeUtils :: IsScalar ( c -> input ( 1 ). shape ()), <nl> + errors :: InvalidArgument (" size must be a scalar ")); <nl> int32_t size = c -> input ( 1 ). scalar < int32 >()(); <nl> OP_REQUIRES ( <nl> c , size >= 0 ,
class Conv2DBackpropInputOp : public OpKernel { <nl> const Tensor & filter = context -> input ( 1 ); <nl> const Tensor & out_backprop = context -> input ( 2 ); <nl>  <nl> + OP_REQUIRES ( <nl> + context , out_backprop . dims () == 4 , <nl> + errors :: InvalidArgument (" input_sizes must be 4 - dimensional , got : ", <nl> + out_backprop . dims ())); <nl> + <nl> TensorShape input_shape ; <nl> OP_REQUIRES_OK ( context , <nl> Conv2DBackpropComputeInputShape ( input_sizes , filter . shape (), <nl> class Conv2DCustomBackpropInputOp : public OpKernel { <nl> const Tensor & input_sizes = context -> input ( 0 ); <nl> const Tensor & filter = context -> input ( 1 ); <nl> const Tensor & out_backprop = context -> input ( 2 ); <nl> + OP_REQUIRES ( <nl> + context , out_backprop . dims () == 4 , <nl> + errors :: InvalidArgument (" input_sizes must be 4 - dimensional , got : ", <nl> + out_backprop . dims ())); <nl>  <nl> TensorShape input_shape ; <nl> OP_REQUIRES_OK ( context ,
constexpr char kRelu6 [] = " RELU6 "; <nl> constexpr char kRelu1 [] = " RELU_N1_TO_1 "; <nl>  <nl> bool L2NormalizeReduceAxis ( Value sq_op , DenseElementsAttr axis ) { <nl> + if ( axis . getNumElements () == 0 ) { <nl> + return false ; <nl> + } <nl> if ( sq_op . getType (). cast < ShapedType >(). getRank () - 1 == <nl> * axis . getValues < int >(). begin () || <nl> * axis . getValues < int >(). begin () == - 1 ) {
TfLiteStatus Prepare ( TfLiteContext * context , TfLiteNode * node ) { <nl> if ( data_type != kTfLiteFloat32 ) { <nl> TF_LITE_ENSURE_EQ ( context , filter -> quantization . type , <nl> kTfLiteAffineQuantization ); <nl> + TF_LITE_ENSURE ( context , filter -> quantization . type != kTfLiteNoQuantization ); <nl> const auto * affine_quantization = <nl> reinterpret_cast < TfLiteAffineQuantization *>( <nl> filter -> quantization . params ); <nl> TfLiteStatus Prepare ( TfLiteContext * context , TfLiteNode * node ) { <nl> } <nl>  <nl> if ( is_hybrid ) { <nl> + TF_LITE_ENSURE ( context , filter -> quantization . type != kTfLiteNoQuantization ); <nl> const auto * affine_quantization = <nl> reinterpret_cast < TfLiteAffineQuantization *>( <nl> filter -> quantization . params ); <nl> TfLiteStatus EvalHybridPerChannel ( TfLiteContext * context , TfLiteNode * node , <nl> op_params . weights_offset = 0 ; <nl> op_params . float_activation_min = output_activation_min ; <nl> op_params . float_activation_max = output_activation_max ; <nl> + TF_LITE_ENSURE ( context , filter -> quantization . type != kTfLiteNoQuantization ); <nl> const auto * affine_quantization = <nl> reinterpret_cast < TfLiteAffineQuantization *>( filter -> quantization . params ); <nl> if ( kernel_type == kReference ) {
class UnravelIndexOp : public OpKernel { <nl> dims_tensor . shape (). DebugString (), "\"")); <nl>  <nl> auto dims = dims_tensor . vec < Tidx >(); <nl> + // Make sure dims does not contain a zero <nl> + for ( int i = 0 ; i < dims . size (); i ++) { <nl> + OP_REQUIRES ( <nl> + ctx , dims ( i ) != 0 , <nl> + errors :: InvalidArgument (" Input dims cannot contain a dim of zero , " <nl> + " but dims contains zero at index ", <nl> + i )); <nl> + } <nl>  <nl> // Chek to make sure indices is not out of boundary <nl> Eigen :: Tensor < Tidx , 0 , Eigen :: RowMajor > dims_prod_eigen = dims . prod ();
class DeleteSessionTensorOp : public OpKernel { <nl>  <nl> void Compute ( OpKernelContext * ctx ) override { <nl> const Tensor & handle = ctx -> input ( 0 ); <nl> + OP_REQUIRES ( ctx , TensorShapeUtils :: IsScalar ( handle . shape ()), <nl> + errors :: InvalidArgument ("` handle ` must be scalar ")); <nl> const string & name = handle . scalar < tstring >()(); <nl> auto session_state = ctx -> session_state (); <nl> OP_REQUIRES ( ctx , session_state != nullptr ,
limitations under the License . <nl> # include " tensorflow / core / framework / common_shape_fns . h " <nl> # include " tensorflow / core / framework / op . h " <nl> # include " tensorflow / core / framework / shape_inference . h " <nl> +# include " tensorflow / core / framework / types . pb . h " <nl> # include " tensorflow / core / platform / errors . h " <nl>  <nl> namespace tensorflow { <nl> REGISTER_OP (" DeserializeSparse ") <nl> . Attr (" Tserialized : { string , variant } = DT_STRING ") <nl> . SetShapeFn ([]( InferenceContext * c ) { <nl> // serialized sparse is [?, ..., ?, 3 ] vector . <nl> + ShapeHandle unused_shape ; <nl> + TF_RETURN_IF_ERROR ( c -> WithRankAtLeast ( c -> input ( 0 ), 1 , & unused_shape )); <nl> DimensionHandle unused ; <nl> TF_RETURN_IF_ERROR ( c -> WithValue ( c -> Dim ( c -> input ( 0 ), - 1 ), 3 , & unused )); <nl> c -> set_output ( 0 , c -> Matrix ( InferenceContext :: kUnknownDim ,
class SparseMatMulOp : public OpKernel { <nl> if ( transpose_b ) { <nl> // TODO ( agarwal ): avoid transposing the matrix here and directly handle <nl> // transpose in CreateDenseSlices . <nl> + OP_REQUIRES ( ctx , right -> dim_size ( 0 ) != 0 , <nl> + errors :: InvalidArgument (" b has an entry 0 in it ' s shape .")); <nl> + OP_REQUIRES ( ctx , right -> dim_size ( 1 ) != 0 , <nl> + errors :: InvalidArgument (" b has an entry 0 in it ' s shape .")); <nl> right_tr . reset ( <nl> new Tensor ( right -> dtype (), <nl> TensorShape ({ right -> dim_size ( 1 ), right -> dim_size ( 0 )})));
Status ConcatShapeHelper ( InferenceContext * c , int start_value_index , <nl> } <nl>  <nl> // Minimum required number of dimensions . <nl> - const int min_rank = concat_dim < 0 ? - concat_dim : concat_dim + 1 ; <nl> + const int64 min_rank = concat_dim < 0 ? - concat_dim : concat_dim + 1 ; <nl>  <nl> ShapeHandle output_before ; <nl> ShapeHandle output_after ;
Status GetTensorArray ( OpKernelContext * ctx , TensorArray ** tensor_array ) { <nl> TF_RETURN_IF_ERROR ( GetHandle ( ctx , & container , & ta_handle )); <nl> ResourceMgr * rm = ctx -> resource_manager (); <nl> if ( rm == nullptr ) return errors :: Internal (" No resource manager ."); <nl> - TF_RETURN_IF_ERROR ( <nl> - ctx -> step_container ()-> Lookup ( rm , container + ta_handle , tensor_array )); <nl> + ScopedStepContainer * sc = ctx -> step_container (); <nl> + if ( sc == nullptr ) return errors :: Internal (" No step container ."); <nl> + TF_RETURN_IF_ERROR ( sc -> Lookup ( rm , container + ta_handle , tensor_array )); <nl> return OkStatus (); <nl> } else { <nl> return LookupResource ( ctx , HandleFromInput ( ctx , 0 ), tensor_array );
class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel { <nl> const int32_t feature_dim = stats_summary_indices ( idx , 1 ); <nl> const int32_t bucket_id = stats_summary_indices ( idx , 2 ); <nl> const int32_t stat_dim = stats_summary_indices ( idx , 3 ); <nl> + OP_REQUIRES ( context , stat_dim < stats_dims , <nl> + errors :: InvalidArgument ( <nl> + " Stat dim , the sum of logits dim and hessian dim in " <nl> + " stats_summary_indices , cannot be greater than stats " <nl> + " dims , the last value in stats_summary_shape , which was ", <nl> + stats_dims , ". At index (", idx , <nl> + ", 4 ), stats_summary_indices contains value ", stat_dim )); <nl> std :: pair < FeatureMapIterator , bool > const & f_insert_result = f_map . insert ( <nl> FeatureMapIterator :: value_type ( feature_dim , BucketMap ())); <nl> auto & b_map = f_insert_result . first -> second ;
Status QuantizeV2Shape ( InferenceContext * c ) { <nl> if (! s . ok () && s . code () != error :: NOT_FOUND ) { <nl> return s ; <nl> } <nl> + if ( axis < - 1 ) { <nl> + return errors :: InvalidArgument (" axis should be at least - 1 , got ", axis ); <nl> + } <nl> const int minmax_rank = ( axis == - 1 ) ? 0 : 1 ; <nl> TF_RETURN_IF_ERROR ( shape_inference :: UnchangedShape ( c )); <nl> ShapeHandle minmax ;
TfLiteStatus Eval ( TfLiteContext * context , TfLiteNode * node ) { <nl> TF_LITE_ENSURE_OK ( context , <nl> GetOutputSafe ( context , node , kOutputTensor , & output )); <nl>  <nl> + // Prevent division by 0 in the helper <nl> + TF_LITE_ENSURE ( context , NumElements ( params ) > 0 ); <nl> + <nl> switch ( indices -> type ) { <nl> case kTfLiteInt32 : <nl> return EvalGatherNd < int32_t >( context , params , indices , output );
class SymbolicShapeRefiner { <nl> GetUnknownOutputShape ( node , output_port ); <nl> InferenceContext * ctx = GetContext ( node ); <nl> if ( ctx == nullptr ) { <nl> - return errors :: InvalidArgument (" Missing context "); <nl> + return errors :: InvalidArgument (" SetUnknownShape : Missing context "); <nl> + } <nl> + if ( output_port < 0 || output_port >= ctx -> num_outputs ()) { <nl> + return errors :: InvalidArgument ( <nl> + " SetUnknownShape : output_port must be in [ 0 , ", ctx -> num_outputs (), <nl> + ") but was ", output_port ); <nl> } <nl> ctx -> set_output ( output_port , shape ); <nl> return Status :: OK ();
TfLiteStatus Prepare ( TfLiteContext * context , TfLiteNode * node ) { <nl>  <nl> TF_LITE_ENSURE_EQ ( context , NumDimensions ( input ), 4 ); <nl> TF_LITE_ENSURE_EQ ( context , NumDimensions ( filter ), 4 ); <nl> + TF_LITE_ENSURE ( context , params -> dilation_height_factor > 0 ); <nl> + TF_LITE_ENSURE ( context , params -> dilation_width_factor > 0 ); <nl>  <nl> const TfLiteType data_type = input -> type ; <nl> 
TfLiteStatus Eval ( TfLiteContext * context , TfLiteNode * node ) { <nl> TF_LITE_ENSURE_OK ( context , GetInputSafe ( context , node , 2 , & value )); <nl>  <nl> const int num_rows = SizeOfDimension ( value , 0 ); <nl> + TF_LITE_ENSURE ( context , num_rows != 0 ); <nl> const int row_bytes = value -> bytes / num_rows ; <nl> void * pointer = nullptr ; <nl> DynamicBuffer buf ;
class SvdOpGpu : public AsyncOpKernel { <nl> OP_REQUIRES_OK_ASYNC ( context , context -> allocate_output ( 2 , shapeV , & outputV ), <nl> done ); <nl>  <nl> + // If there are zero batches , we are done . <nl> + if ( shapeRaw . num_elements () == 0 ) { <nl> + done (); <nl> + return ; <nl> + } <nl> + <nl> if ( n == 0 || m == 0 ) { <nl> if ( n == m || ! compute_uv_ || ! full_matrices_ ) { <nl> // S , U , and V are all empty . Nothing to do .
class UnbatchGradResource : public ResourceBase { <nl> const Tensor & data_t = context -> input ( 0 ); <nl> const Tensor & batch_index_t = context -> input ( 1 ); <nl> const Tensor & grad_t = context -> input ( 2 ); <nl> + const Tensor & batch_key_t = context -> input ( 3 ); <nl>  <nl> mutex_lock ml ( mu_ ); <nl> + if ( batch_key_t . NumElements () != 1 ) { <nl> + return errors :: InvalidArgument (" Expected ` id ` to be scalar . Received ", <nl> + batch_key_t . DebugString ()); <nl> + } <nl>  <nl> const int64_t batch_key = context -> input ( 3 ). scalar < int64_t >()(); <nl> // Mark our tensor as available . <nl> class UnbatchGradResource : public ResourceBase { <nl> " batch_index is empty while the tensor isn ' t ."); <nl> } <nl> std :: unordered_set < int64_t > missing_tensors ; <nl> + if ( batch_index_t . NumElements () != batch_index_t . dim_size ( 0 ) * 3 ) { <nl> + return errors :: InvalidArgument ( <nl> + " batch_index should contain ", batch_index_t . dim_size ( 0 ) * 3 , <nl> + " elements . Received ", batch_index_t . NumElements ()); <nl> + } <nl> const auto batch_index = <nl> batch_index_t . shaped < int64_t , 2 >({ batch_index_t . dim_size ( 0 ), 3 }); <nl> for ( int i = 0 ; i < batch_index_t . dim_size ( 0 ); ++ i ) {
TfLiteStatus Prepare ( TfLiteContext * context , TfLiteNode * node ) { <nl> const int rank = params -> rank ; <nl> const int batch_size = input -> dims -> data [ 0 ]; <nl> const int num_filters = weights_feature -> dims -> data [ 0 ]; <nl> + TF_LITE_ENSURE ( context , rank != 0 ); <nl> TF_LITE_ENSURE_EQ ( context , num_filters % rank , 0 ); <nl> const int num_units = num_filters / rank ; <nl> const int memory_size = weights_time -> dims -> data [ 1 ];
inline Status SparseTensor :: Split ( const SparseTensor & input_tensor , <nl> for ( int i = 0 ; i < input_tensor . indices (). dim_size ( 0 ); ++ i ) { <nl> const int dim = input_tensor . indices (). matrix < int64 >()( i , split_dim ); <nl> int slice_index = GetSliceIndex ( dim , split_size , residual ); <nl> + if ( slice_index >= num_values . size ()) { <nl> + return errors :: InvalidArgument (" Slice index ", slice_index , <nl> + " is larger than num_split ."); <nl> + } <nl> num_values [ slice_index ]++; <nl> } <nl> 
int64_t OpLevelCostEstimator :: CalculateTensorSize ( <nl> int64_t count = CalculateTensorElementCount ( tensor , found_unknown_shapes ); <nl> int size = DataTypeSize ( BaseType ( tensor . dtype ())); <nl> VLOG ( 2 ) << " Count : " << count << " DataTypeSize : " << size ; <nl> - return count * size ; <nl> + int64_t tensor_size = MultiplyWithoutOverflow ( count , size ); <nl> + if ( tensor_size < 0 ) { <nl> + VLOG ( 1 ) << " Overflow encountered when computing tensor size , multiplying " <nl> + << count << " with " << size ; <nl> + return - 1 ; <nl> + } <nl> + return tensor_size ; <nl> } <nl>  <nl> int64_t OpLevelCostEstimator :: CalculateInputSize ( const OpInfo & op_info ,
Status ConstantFolding :: IsSimplifiableReshape ( <nl> int32_t dim = outputs [ 0 ]-> flat < int32 >()( i ); <nl> shp . push_back ( dim ); <nl> } <nl> - TF_CHECK_OK ( TensorShapeUtils :: MakeShape ( shp , & new_dims )); <nl> + s = TensorShapeUtils :: MakeShape ( shp , & new_dims ); <nl> + if (! s . ok ()) return s ; <nl> } else { <nl> std :: vector < int64_t > shp ; <nl> for ( int i = 0 ; i < outputs [ 0 ]-> NumElements (); ++ i ) { <nl> int64_t dim = outputs [ 0 ]-> flat < int64_t >()( i ); <nl> shp . push_back ( dim ); <nl> } <nl> - TF_CHECK_OK ( TensorShapeUtils :: MakeShape ( shp , & new_dims )); <nl> + s = TensorShapeUtils :: MakeShape ( shp , & new_dims ); <nl> + if (! s . ok ()) return s ; <nl> } <nl>  <nl> if (! shape . IsCompatibleWith ( new_dims )) {
class ParameterizedTruncatedNormalOp : public OpKernel { <nl> ctx , TensorShapeUtils :: IsVector ( shape_tensor . shape ()), <nl> errors :: InvalidArgument (" Input shape should be a vector , got shape : ", <nl> shape_tensor . shape (). DebugString ())); <nl> + OP_REQUIRES ( ctx , shape_tensor . NumElements () > 0 , <nl> + errors :: InvalidArgument (" Shape tensor must not be empty , got ", <nl> + shape_tensor . DebugString ())); <nl> int32 num_batches = shape_tensor . flat < int32 >()( 0 ); <nl>  <nl> int32 samples_per_batch = 1 ;
class QuantizeAndDequantizeV2Op : public OpKernel { <nl>  <nl> void Compute ( OpKernelContext * ctx ) override { <nl> const Tensor & input = ctx -> input ( 0 ); <nl> + OP_REQUIRES ( <nl> + ctx , axis_ >= - 1 , <nl> + errors :: InvalidArgument (" Axis must be at least - 1 . Found ", axis_ )); <nl> OP_REQUIRES ( <nl> ctx , ( axis_ == - 1 || axis_ < input . shape (). dims ()), <nl> errors :: InvalidArgument (" Shape must be at least rank ", axis_ + 1 ,
limitations under the License . <nl> // <nl> // Input : <nl> // Tensor [ 0 ]: Hash functions . Dim . size == 2 , DataType : Float . <nl> -// Tensor [ 0 ]. Dim [ 0 ]: Num of hash functions . <nl> +// Tensor [ 0 ]. Dim [ 0 ]: Num of hash functions . Must be at least 1 . <nl> // Tensor [ 0 ]. Dim [ 1 ]: Num of projected output bits generated by <nl> // each hash function . <nl> // In sparse case , Tensor [ 0 ]. Dim [ 1 ] + ceil ( log2 ( Tensor [ 0 ]. Dim [ 0 ] )) <= 32 . <nl> TfLiteStatus Resize ( TfLiteContext * context , TfLiteNode * node ) { <nl> const TfLiteTensor * input ; <nl> TF_LITE_ENSURE_OK ( context , GetInputSafe ( context , node , 1 , & input )); <nl> TF_LITE_ENSURE ( context , NumDimensions ( input ) >= 1 ); <nl> + TF_LITE_ENSURE ( context , SizeOfDimension ( input , 0 ) >= 1 ); <nl>  <nl> if ( NumInputs ( node ) == 3 ) { <nl> const TfLiteTensor * weight ;
class QuantizedMulOp : public OpKernel { <nl> tensor_num_elements = x . NumElements (); <nl> tensor_offset = offset_x ; <nl> } <nl> + if ( vector_num_elements == 0 ) { <nl> + context -> SetStatus ( <nl> + errors :: InvalidArgument (" vector must have at least 1 element ")); <nl> + return ; <nl> + } <nl> VectorTensorMultiply < T , Toutput >( <nl> vector_data , vector_offset , vector_num_elements , tensor_data , <nl> tensor_offset , tensor_num_elements , z_data );
TfLiteStatus PopulateQuantizedLstmParams8x8_16 ( <nl> context , <nl> GetOutputSafe ( context , node , lstm :: full :: kOutputTensor , & output_tensor )); <nl>  <nl> + TF_LITE_ENSURE ( context , <nl> + cell_state -> quantization . type != kTfLiteNoQuantization ); <nl> auto * cell_state_params = <nl> static_cast < TfLiteAffineQuantization *>( cell_state -> quantization . params ); <nl> + TF_LITE_ENSURE ( context , <nl> + output_tensor -> quantization . type != kTfLiteNoQuantization ); <nl> auto * proj_params = static_cast < TfLiteAffineQuantization *>( <nl> output_tensor -> quantization . params ); <nl> if ( cell_clip > 0 . 0 ) { <nl> TfLiteStatus PopulateQuantizedLstmParams8x8_16 ( <nl> TfLiteTensor * intermediate ; <nl> TF_LITE_ENSURE_OK ( context , <nl> GetIntermediatesSafe ( context , node , i , & intermediate )); <nl> + TF_LITE_ENSURE ( context , <nl> + intermediate -> quantization . type != kTfLiteNoQuantization ); <nl> auto * params = static_cast < TfLiteAffineQuantization *>( <nl> intermediate -> quantization . params ); <nl> intermediate_scale . push_back ( params -> scale -> data [ 0 ]); <nl> TfLiteStatus PopulateQuantizedLstmParams8x8_16 ( <nl> // is ignored . <nl> TfLiteTensor * hidden ; <nl> TF_LITE_ENSURE_OK ( context , GetIntermediatesSafe ( context , node , 4 , & hidden )); <nl> + TF_LITE_ENSURE ( context , hidden -> quantization . type != kTfLiteNoQuantization ); <nl> auto * hidden_params = <nl> static_cast < TfLiteAffineQuantization *>( hidden -> quantization . params ); <nl> intermediate_scale . push_back ( hidden_params -> scale -> data [ 0 ]); <nl> TfLiteStatus PopulatePrecomputedZPTimesWeightsWithBias ( TfLiteContext * context , <nl>  <nl> const TfLiteTensor * intermediate = <nl> & context -> tensors [ node -> intermediates -> data [ 4 ]]; <nl> + TF_LITE_ENSURE ( context , <nl> + intermediate -> quantization . type != kTfLiteNoQuantization ); <nl> const auto * params = <nl> static_cast < TfLiteAffineQuantization *>( intermediate -> quantization . params ); <nl> const int32_t hidden_zp = params -> zero_point -> data [ 0 ];
TfLiteStatus ResizeOutputTensors ( TfLiteContext * context , TfLiteNode * node , <nl> } <nl> } <nl>  <nl> + TF_LITE_ENSURE ( context , axis_value >= 0 ); <nl> + TF_LITE_ENSURE ( context , axis_value < NumDimensions ( input )); <nl> const int input_size = SizeOfDimension ( input , axis_value ); <nl>  <nl> if ( minus_one_index != - 1 ) {
limitations under the License . <nl> # include " tensorflow / core / framework / log_memory . h " <nl> # include " tensorflow / core / framework / op_kernel . h " <nl> # include " tensorflow / core / framework / types . h " <nl> +# include " tensorflow / core / framework / types . pb . h " <nl> # include " tensorflow / core / graph / algorithm . h " <nl> # include " tensorflow / core / graph / node_builder . h " <nl> # include " tensorflow / core / graph / subgraph . h " <nl> bool IsConstantFoldable ( <nl> std :: unordered_map < const Node *, std :: vector < Tensor >>* <nl> shape_replacement_map ) { <nl> if ( n -> IsConstant ()) { <nl> - return true ; <nl> + // Skip constant folding resources as they cannot be deep copied . <nl> + return n -> output_type ( 0 ) != DT_RESOURCE ; <nl> } <nl> if ( MaybeReplaceShapeOp ( n , shape_map , shape_replacement_map )) { <nl> return true ;
TfLiteStatus PrepareImpl ( TfLiteContext * context , TfLiteNode * node ) { <nl> } <nl>  <nl> TF_LITE_ENSURE_EQ ( context , NumDimensions ( filter ), 2 ); <nl> + TF_LITE_ENSURE ( context , filter -> dims -> data [ 1 ] != 0 ); <nl> const int batch_size = input_size / filter -> dims -> data [ 1 ]; <nl> const int num_units = filter -> dims -> data [ 0 ]; <nl> 
class QuantizeAndDequantizeV4GradientOp : public OpKernel { <nl> OP_REQUIRES ( ctx , <nl> input_min_tensor . dims () == 0 || input_min_tensor . dims () == 1 , <nl> errors :: InvalidArgument ( <nl> - " Input min tensor must have dimension 1 . Recieved ", <nl> + " Input min tensor must have dimension 0 or 1 . Received ", <nl> input_min_tensor . dims (), ".")); <nl> const Tensor & input_max_tensor = ctx -> input ( 3 ); <nl> OP_REQUIRES ( ctx , <nl> input_max_tensor . dims () == 0 || input_max_tensor . dims () == 1 , <nl> errors :: InvalidArgument ( <nl> - " Input max tensor must have dimension 1 . Recieved ", <nl> + " Input max tensor must have dimension 0 or 1 . Received ", <nl> input_max_tensor . dims (), ".")); <nl> if ( axis_ != - 1 ) { <nl> OP_REQUIRES ( <nl> class QuantizeAndDequantizeV4GradientOp : public OpKernel { <nl> ctx -> allocate_output ( 2 , min_max_shape , & input_max_backprop )); <nl>  <nl> if ( axis_ == - 1 ) { <nl> + OP_REQUIRES ( ctx , TensorShapeUtils :: IsScalar ( input_min_tensor . shape ()), <nl> + errors :: InvalidArgument ( <nl> + " input_min must be a scalar if axis is unspecified ")); <nl> + OP_REQUIRES ( ctx , TensorShapeUtils :: IsScalar ( input_max_tensor . shape ()), <nl> + errors :: InvalidArgument ( <nl> + " input_max must be a scalar if axis is unspecified ")); <nl> functor :: QuantizeAndDequantizeOneScaleGradientFunctor < Device , T > f ; <nl> f ( ctx -> eigen_device < Device >(), gradient . template flat < T >(), <nl> input . template flat < T >(), input_min_tensor . scalar < T >(),
dumpppp ( f ) <nl> printf ("% s aborted packet :\ n ", dir ); <nl> q = " "; <nl> } <nl> + if ( pkt -> cnt >= sizeof ( pkt -> buf )) { <nl> + printf ("% s over - long packet truncated :\ n ", dir ); <nl> + q = " "; <nl> + } <nl> nb = pkt -> cnt ; <nl> p = pkt -> buf ; <nl> pkt -> cnt = 0 ; <nl> dumpppp ( f ) <nl> c ^= 0x20 ; <nl> pkt -> esc = 0 ; <nl> } <nl> - pkt -> buf [ pkt -> cnt ++] = c ; <nl> + if ( pkt -> cnt < sizeof ( pkt -> buf )) <nl> + pkt -> buf [ pkt -> cnt ++] = c ; <nl> break ; <nl> } <nl> }
-/* Copyright ( c ) 2002 - 2006 Sam Trenholme <nl> +/* Copyright ( c ) 2002 - 2023 Sam Trenholme <nl> * <nl> * TERMS <nl> * <nl> int decomp_get_rddata ( js_string * compressed , js_string * out , <nl> /* Variable length data ( length determined by rdlength ) */ <nl> else if ( subtype == RRSUB_VARIABLE ) { <nl> len = rdlength - total ; <nl> - if ( len == 0 ) { <nl> + if ( len <= 0 ) { <nl> break ; <nl> } <nl> if ( decomp_append_bytes ( compressed , out ,
bool WebGLRenderingContextBase :: ValidateHTMLImageElement ( <nl> } <nl>  <nl> if ( WouldTaintOrigin ( image , security_origin )) { <nl> - exception_state . ThrowSecurityError (" The cross - origin image at " + <nl> - url . ElidedString () + <nl> - " may not be loaded ."); <nl> + exception_state . ThrowSecurityError ( <nl> + " The image element contains cross - origin data , and may not be loaded ."); <nl> return false ; <nl> } <nl> return true ;
void EventBindings :: AttachFilteredEvent ( <nl> filter = base :: DictionaryValue :: From ( std :: move ( filter_value )); <nl> } <nl>  <nl> - // Hold onto a weak reference to | filter | so that it can be used after passing <nl> - // ownership to | event_filter |. <nl> - base :: DictionaryValue * filter_weak = filter . get (); <nl> int id = g_event_filter . Get (). AddEventMatcher ( <nl> event_name , ParseEventMatcher ( std :: move ( filter ))); <nl> + if ( id == - 1 ) { <nl> + args . GetReturnValue (). Set ( static_cast < int32_t >(- 1 )); <nl> + return ; <nl> + } <nl> attached_matcher_ids_ . insert ( id ); <nl>  <nl> // Only send IPCs the first time a filter gets added . <nl> + const EventMatcher * matcher = g_event_filter . Get (). GetEventMatcher ( id ); <nl> + DCHECK ( matcher ); <nl> + base :: DictionaryValue * filter_weak = matcher -> value (); <nl> std :: string extension_id = context ()-> GetExtensionID (); <nl> if ( AddFilter ( event_name , extension_id , * filter_weak )) { <nl> bool lazy = ExtensionFrameHelper :: IsContextForEventPage ( context ());
bool EditorClientBlackBerry :: shouldChangeSelectedRange ( Range * fromRange , Range * <nl>  <nl> Frame * frame = m_webPagePrivate -> focusedOrMainFrame (); <nl> if ( frame && frame -> document ()) { <nl> - if ( frame -> document ()-> focusedNode () && frame -> document ()-> focusedNode ()-> hasTagName ( HTMLNames :: selectTag )) <nl> - return false ; <nl> + if ( Node * focusedNode = frame -> document ()-> focusedNode ()) { <nl> + if ( focusedNode -> hasTagName ( HTMLNames :: selectTag )) <nl> + return false ; <nl> + if ( focusedNode -> isElementNode () && DOMSupport :: isPopupInputField ( static_cast < Element *>( focusedNode ))) <nl> + return false ; <nl> + } <nl>  <nl> // Check if this change does not represent a focus change and input is active and if so ensure the keyboard is visible . <nl> if ( m_webPagePrivate -> m_inputHandler -> isInputMode () && fromRange && toRange && ( fromRange -> startContainer () == toRange -> startContainer ()))
# include " grit / chromium_strings . h " <nl> # include " grit / generated_resources . h " <nl> # include " net / base / cert_status_flags . h " <nl> +# include " net / base / escape . h " <nl> # include " net / base / net_errors . h " <nl> # include " net / base / ssl_info . h " <nl> # include " ui / base / l10n / l10n_util . h " <nl> SSLErrorInfo SSLErrorInfo :: CreateError ( ErrorType error_type , <nl> details = <nl> l10n_util :: GetStringFUTF16 ( IDS_CERT_ERROR_COMMON_NAME_INVALID_DETAILS , <nl> UTF8ToUTF16 ( request_url . host ()), <nl> - UTF8ToUTF16 ( dns_names [ i ]), <nl> + net :: EscapeForHTML ( <nl> + UTF8ToUTF16 ( dns_names [ i ])), <nl> UTF8ToUTF16 ( request_url . host ())); <nl> short_description = l10n_util :: GetStringUTF16 ( <nl> IDS_CERT_ERROR_COMMON_NAME_INVALID_DESCRIPTION ); <nl> SSLErrorInfo SSLErrorInfo :: CreateError ( ErrorType error_type , <nl> extra_info . push_back ( <nl> l10n_util :: GetStringFUTF16 ( <nl> IDS_CERT_ERROR_COMMON_NAME_INVALID_EXTRA_INFO_2 , <nl> - UTF8ToUTF16 ( cert -> subject (). common_name ), <nl> + net :: EscapeForHTML ( UTF8ToUTF16 ( cert -> subject (). common_name )), <nl> UTF8ToUTF16 ( request_url . host ()))); <nl> break ; <nl> }
void SerializedScriptValue :: transferArrayBuffers ( v8 :: Isolate * isolate , const Arr <nl>  <nl> DOMArrayBufferBase * toTransfer = arrayBuffers [ i ]; <nl> if (! isNeuterable ) <nl> - toTransfer = DOMArrayBuffer :: create ( arrayBuffers [ i ]-> buffer ()); <nl> + toTransfer = DOMArrayBuffer :: create ( arrayBuffers [ i ]-> buffer ()-> data (), arrayBuffers [ i ]-> buffer ()-> byteLength ()); <nl> bool result = toTransfer -> transfer ( contents -> at ( i )); <nl> if (! result ) { <nl> exceptionState . throwDOMException ( DataCloneError , " ArrayBuffer at index " + String :: number ( i ) + " could not be transferred .");
void RenderThreadImpl :: EnsureWebKitInitialized () { <nl>  <nl> webkit_platform_support_ . reset ( new RendererWebKitPlatformSupportImpl ); <nl> blink :: initialize ( webkit_platform_support_ . get ()); <nl> - main_thread_compositor_task_runner_ = <nl> - make_scoped_refptr ( new SchedulerProxyTaskRunner < <nl> - & blink :: WebSchedulerProxy :: postCompositorTask >()); <nl> + main_thread_compositor_task_runner_ = base :: MessageLoopProxy :: current (); <nl>  <nl> v8 :: Isolate * isolate = blink :: mainThreadIsolate (); <nl> 
ChildProcessTerminationInfo ChildProcessLauncherHelper :: GetTerminationInfo ( <nl> if (! java_peer_avaiable_on_client_thread_ ) <nl> return info ; <nl>  <nl> - Java_ChildProcessLauncherHelperImpl_getTerminationInfo ( <nl> + Java_ChildProcessLauncherHelperImpl_getTerminationInfoAndStop ( <nl> AttachCurrentThread (), java_peer_ , reinterpret_cast < intptr_t >(& info )); <nl>  <nl> base :: android :: ApplicationState app_state =
IN_PROC_BROWSER_TEST_F ( SSLUITest , TestRunsCachedInsecureContent ) { <nl> CheckAuthenticationBrokenState ( tab , 0 , true , false ); <nl> } <nl>  <nl> -# if defined ( OS_WIN ) <nl> -// See http :// crbug . com / 47170 <nl> -# define MAYBE_TestCNInvalidStickiness FLAKY_TestCNInvalidStickiness <nl> -# else <nl> -# define MAYBE_TestCNInvalidStickiness TestCNInvalidStickiness <nl> -# endif <nl> - <nl> // This test ensures the CN invalid status does not ' stick ' to a certificate <nl> // ( see bug # 1044942 ) and that it depends on the host - name . <nl> - IN_PROC_BROWSER_TEST_F ( SSLUITest , MAYBE_TestCNInvalidStickiness ) { <nl> +// Disabled , see http :// crbug . com / 68448 and http :// crbug . com / 49377 . <nl> + IN_PROC_BROWSER_TEST_F ( SSLUITest , DISABLED_TestCNInvalidStickiness ) { <nl> ASSERT_TRUE ( https_server_ . Start ()); <nl> ASSERT_TRUE ( https_server_mismatched_ . Start ()); <nl> 
FFMPEG_TEST_CASE ( Cr112976 , " security / 112976 . ogg ", PIPELINE_OK , PIPELINE_OK , <nl> " d23bacec582c94b8a6dc53b0971bf67e "); <nl> FFMPEG_TEST_CASE ( Cr116927 , " security / 116927 . ogv ", PIPELINE_ERROR_DECODE , <nl> PIPELINE_ERROR_DECODE , kNullHash , kNullHash ); <nl> + FFMPEG_TEST_CASE ( Cr117912 , " security / 117912 . webm ", DEMUXER_ERROR_COULD_NOT_OPEN , <nl> + DEMUXER_ERROR_COULD_NOT_OPEN , kNullHash , kNullHash ); <nl> FFMPEG_TEST_CASE ( Cr123481 , " security / 123481 . ogv ", PIPELINE_OK , <nl> PIPELINE_OK , " e6dd853fcbd746c8bb2ab2b8fc376fc7 ", <nl> " da909399f17e8f8ad7f1fcb3c4ccc33a "); <nl> + FFMPEG_TEST_CASE ( Cr132779 , " security / 132779 . webm ", <nl> + DEMUXER_ERROR_COULD_NOT_PARSE , DEMUXER_ERROR_COULD_NOT_PARSE , <nl> + kNullHash , kNullHash ); <nl>  <nl> // General MKV test cases . <nl> FFMPEG_TEST_CASE ( MKV_0 , " security / nested_tags_lang . mka . 627 . 628 ", PIPELINE_OK , <nl> FFMPEG_TEST_CASE ( WEBM_4 , " security / out . webm . 68798 . 1929 ", <nl> kNullHash , kNullHash ); <nl> FFMPEG_TEST_CASE ( WEBM_5 , " content / frame_size_change . webm ", PIPELINE_OK , <nl> PIPELINE_OK , " d8fcf2896b7400a2261bac9e9ea930f8 ", kNullHash ); <nl> - FFMPEG_TEST_CASE ( WEBM_6 , " security / 117912 . webm ", DEMUXER_ERROR_COULD_NOT_OPEN , <nl> - DEMUXER_ERROR_COULD_NOT_OPEN , kNullHash , kNullHash ); <nl>  <nl> // Audio Functional Tests <nl> FFMPEG_TEST_CASE ( AUDIO_GAMING_0 , " content / gaming / a_220_00 . mp3 ", PIPELINE_OK ,
Node :: InsertionNotificationRequest HTMLLinkElement :: InsertedInto ( <nl> if (! insertion_point . isConnected ()) <nl> return kInsertionDone ; <nl> DCHECK ( isConnected ()); <nl> + <nl> + GetDocument (). GetStyleEngine (). AddStyleSheetCandidateNode (* this ); <nl> + <nl> if (! ShouldLoadLink () && IsInShadowTree ()) { <nl> String message = " HTML element < link > is ignored in shadow tree ."; <nl> GetDocument (). AddConsoleMessage ( ConsoleMessage :: Create ( <nl> Node :: InsertionNotificationRequest HTMLLinkElement :: InsertedInto ( <nl> return kInsertionDone ; <nl> } <nl>  <nl> - GetDocument (). GetStyleEngine (). AddStyleSheetCandidateNode (* this ); <nl> - <nl> Process (); <nl>  <nl> if ( link_ )
void WebPagePrivate :: willComposite () <nl> { <nl> if (! m_page -> settings ()-> developerExtrasEnabled ()) <nl> return ; <nl> - InspectorInstrumentation :: willComposite ( m_page ); <nl> + m_page -> inspectorController ()-> willComposite (); <nl> } <nl>  <nl> void WebPagePrivate :: didComposite () <nl> { <nl> if (! m_page -> settings ()-> developerExtrasEnabled ()) <nl> return ; <nl> - InspectorInstrumentation :: didComposite ( m_page ); <nl> + m_page -> inspectorController ()-> didComposite (); <nl> } <nl>  <nl> void WebPage :: updateNotificationPermission ( const BlackBerry :: Platform :: String & requestId , bool allowed )
void XSSAuditor :: init ( Document * document , XSSAuditorDelegate * auditorDelegate ) <nl> // FIXME : Combine the two report URLs in some reasonable way . <nl> if ( auditorDelegate ) <nl> auditorDelegate -> setReportURL ( xssProtectionReportURL . copy ()); <nl> - FormData * httpBody = documentLoader -> originalRequest (). httpBody (); <nl> + FormData * httpBody = documentLoader -> request (). httpBody (); <nl> if ( httpBody && ! httpBody -> isEmpty ()) { <nl> httpBodyAsString = httpBody -> flattenToString (); <nl> if (! httpBodyAsString . isEmpty ()) {
void ContainerNode :: parserInsertBefore ( PassRefPtrWillBeRawPtr < Node > newChild , No <nl> while ( RefPtrWillBeRawPtr < ContainerNode > parent = newChild -> parentNode ()) <nl> parent -> parserRemoveChild (* newChild ); <nl>  <nl> + if ( nextChild . parentNode () != this ) <nl> + return ; <nl> + <nl> if ( document () != newChild -> document ()) <nl> document (). adoptNode ( newChild . get (), ASSERT_NO_EXCEPTION ); <nl> 
ScrollAnchor :: ExamineResult ScrollAnchor :: Examine ( <nl> LayoutRect visible_rect = <nl> ScrollerLayoutBox ( scroller_ )-> OverflowClipRect ( LayoutPoint ()); <nl>  <nl> + const ComputedStyle * style = ScrollerLayoutBox ( scroller_ )-> Style (); <nl> + LayoutRectOutsets scroll_padding ( <nl> + MinimumValueForLength ( style -> ScrollPaddingTop (), visible_rect . Height ()), <nl> + MinimumValueForLength ( style -> ScrollPaddingRight (), visible_rect . Width ()), <nl> + MinimumValueForLength ( style -> ScrollPaddingBottom (), <nl> + visible_rect . Height ()), <nl> + MinimumValueForLength ( style -> ScrollPaddingLeft (), visible_rect . Width ())); <nl> + visible_rect . Contract ( scroll_padding ); <nl> + <nl> bool occupies_space = <nl> candidate_rect . Width () > 0 && candidate_rect . Height () > 0 ; <nl> if ( occupies_space && visible_rect . Intersects ( candidate_rect )) {
void AppCacheGroup :: AddCache ( AppCache * complete_cache ) { <nl> void AppCacheGroup :: RemoveCache ( AppCache * cache ) { <nl> DCHECK ( cache -> associated_hosts (). empty ()); <nl> if ( cache == newest_complete_cache_ ) { <nl> - CancelUpdate (); <nl> AppCache * tmp_cache = newest_complete_cache_ ; <nl> newest_complete_cache_ = nullptr ; <nl> + CancelUpdate (); <nl> tmp_cache -> set_owning_group ( nullptr ); // may cause this group to be deleted <nl> } else { <nl> scoped_refptr < AppCacheGroup > protect ( this );
void SignatureUtil :: CheckSignature ( <nl> for ( DWORD i = 0 ; i < prov_data -> csSigners ; ++ i ) { <nl> const CERT_CHAIN_CONTEXT * cert_chain_context = <nl> prov_data -> pasSigners [ i ]. pChainContext ; <nl> + if (! cert_chain_context ) <nl> + break ; <nl> for ( DWORD j = 0 ; j < cert_chain_context -> cChain ; ++ j ) { <nl> CERT_SIMPLE_CHAIN * simple_chain = cert_chain_context -> rgpChain [ j ]; <nl> ClientDownloadRequest_CertificateChain * chain = <nl> signature_info -> add_certificate_chain (); <nl> + if (! simple_chain ) <nl> + break ; <nl> for ( DWORD k = 0 ; k < simple_chain -> cElement ; ++ k ) { <nl> CERT_CHAIN_ELEMENT * element = simple_chain -> rgpElement [ k ]; <nl> chain -> add_element ()-> set_certificate (
bool IsSensitiveURL ( const GURL & url ) { <nl> bool is_google_com_chrome_url = <nl> EndsWith ( url . host (), " google . com ", true ) && <nl> StartsWithASCII ( url . path (), "/ chrome ", true ); <nl> - std :: string url_without_query = <nl> - url . spec (). substr ( 0 , url . spec (). find_first_of ('?')); <nl> + GURL :: Replacements replacements ; <nl> + replacements . ClearQuery (); <nl> + replacements . ClearRef (); <nl> + GURL url_without_query = url . ReplaceComponents ( replacements ); <nl> return is_webstore_gallery_url || is_google_com_chrome_url || <nl> - extension_urls :: IsWebstoreUpdateUrl ( GURL ( url_without_query )) || <nl> + extension_urls :: IsWebstoreUpdateUrl ( url_without_query ) || <nl> extension_urls :: IsBlacklistUpdateUrl ( url ); <nl> } <nl> 
ChromeGeolocationPermissionContext :: ChromeGeolocationPermissionContext ( <nl> new GeolocationInfoBarQueueController ( <nl> base :: Bind ( <nl> & ChromeGeolocationPermissionContext :: NotifyPermissionSet , <nl> - this ), <nl> + base :: Unretained ( this )), <nl> profile ))) { <nl> } <nl> 
void GpuProcessHost :: OnProcessCrashed ( int exit_code ) { <nl> int process_crash_exit_code = exit_code ; <nl> base :: debug :: Alias (& process_crash_exit_code ); <nl>  <nl> + // Record crash before doing anything that could start a new GPU process . <nl> + RecordProcessCrash (); <nl> + <nl> // If the GPU process crashed while compiling a shader , we may have invalid <nl> // cached binaries . Completely clear the shader cache to force shader binaries <nl> // to be re - created . <nl> void GpuProcessHost :: OnProcessCrashed ( int exit_code ) { <nl> } <nl> } <nl> SendOutstandingReplies ( EstablishChannelStatus :: GPU_HOST_INVALID ); <nl> - RecordProcessCrash (); <nl>  <nl> ChildProcessTerminationInfo info = <nl> process_ -> GetTerminationInfo ( true /* known_dead */); <nl> void GpuProcessHost :: DidFailInitialize () { <nl> UMA_HISTOGRAM_BOOLEAN (" GPU . GPUProcessInitialized ", false ); <nl> status_ = FAILURE ; <nl> GpuDataManagerImpl * gpu_data_manager = GpuDataManagerImpl :: GetInstance (); <nl> - gpu_data_manager -> FallBackToNextGpuMode (); <nl> + if ( kind_ == GPU_PROCESS_KIND_SANDBOXED ) <nl> + gpu_data_manager -> FallBackToNextGpuMode (); <nl> RunRequestGPUInfoCallbacks ( gpu_data_manager -> GetGPUInfo ()); <nl> } <nl> 
void WebProcessProxy :: addExistingWebPage ( WebPageProxy * webPage , uint64_t pageID ) <nl> m_pageMap . set ( pageID , webPage ); <nl> globalPageMap (). set ( pageID , webPage ); <nl> # if PLATFORM ( MAC ) <nl> - if ( pageIsProcessSuppressible ( webPage )); <nl> + if ( pageIsProcessSuppressible ( webPage )) <nl> m_processSuppressiblePages . add ( pageID ); <nl> updateProcessSuppressionState (); <nl> # endif
void ImageLoader :: DoUpdateFromElement ( BypassMainWorldBehavior bypass_behavior , <nl> resource_request . SetRequestContext ( WebURLRequest :: kRequestContextPing ); <nl> } <nl>  <nl> + // Plug - ins should not load via service workers as plug - ins may have their <nl> + // own origin checking logic that may get confused if service workers <nl> + // respond with resources from another origin . <nl> + // https :// w3c . github . io / ServiceWorker /# implementer - concerns <nl> + if ( GetElement ()-> IsHTMLElement () && <nl> + ToHTMLElement ( GetElement ())-> IsPluginElement ()) { <nl> + resource_request . SetServiceWorkerMode ( <nl> + WebURLRequest :: ServiceWorkerMode :: kNone ); <nl> + } <nl> + <nl> FetchParameters params ( resource_request , resource_loader_options ); <nl> ConfigureRequest ( params , bypass_behavior , * element_ , <nl> document . GetClientHintsPreferences ());
IN_PROC_BROWSER_TEST_F ( WebUIBidiCheckerBrowserTestLTR , <nl> RunBidiCheckerOnPage ( url ); <nl> } <nl>  <nl> -# if defined ( OS_WIN ) <nl> -// TestSettings tests are flaky http :// crbug . com / 95425 <nl> -# define MAYBE_TestSettingsFramePasswords DISABLED_TestSettingsFramePasswords <nl> -# else <nl> -# define MAYBE_TestSettingsFramePasswords TestSettingsFramePasswords <nl> -# endif <nl> - <nl> +// TestSettingsFramePasswords test is flaky http :// crbug . com / 95425 <nl> IN_PROC_BROWSER_TEST_F ( WebUIBidiCheckerBrowserTestRTL , <nl> - MAYBE_TestSettingsFramePasswords ) { <nl> + DISABLED_TestSettingsFramePasswords ) { <nl> std :: string url ( chrome :: kChromeUISettingsFrameURL ); <nl> url += " passwords "; <nl> RunBidiCheckerOnPage ( url );
void V8Window :: namedPropertyGetterCustom ( v8 :: Local < v8 :: Name > name , const v8 :: Pro <nl> if (! info . Holder ()-> GetRealNamedProperty ( nameString ). IsEmpty ()) <nl> return ; <nl>  <nl> + // Frame could have been detached in call to GetRealNamedProperty . <nl> + frame = window -> frame (); <nl> + // window is detached . <nl> + if (! frame ) <nl> + return ; <nl> + <nl> // Search named items in the document . <nl> Document * doc = frame -> document (); <nl> 
inline static void debugGLCommand ( const char * command , int line ) <nl> ASSERT_NOT_REACHED (); <nl> } <nl>  <nl> -# define DEBUG_GL_COMMANDS <nl> - <nl> -# ifdef DEBUG_GL_COMMANDS <nl> +# ifndef NDEBUG <nl> # define GL_CMD ( x ) { x , debugGLCommand (# x , __LINE__ ); } <nl> # else <nl> -# define GL_CMD ( x ) x <nl> +# define GL_CMD ( x ) x ; <nl> # endif <nl>  <nl> struct TextureMapperGLData {
void SetSitesMuted ( const TabStripModel & tab_strip , <nl>  <nl> bool IsSiteMuted ( const TabStripModel & tab_strip , const int index ) { <nl> content :: WebContents * web_contents = tab_strip . GetWebContentsAt ( index ); <nl> + <nl> + // TODO ( steimel ): Why was this not a problem for AreAllTabsMuted ? Is this <nl> + // going to be a problem for SetSitesMuted ? <nl> + // Prevent crashes with null WebContents ( https :// crbug . com / 797647 ). <nl> + if (! web_contents ) <nl> + return false ; <nl> + <nl> GURL url = web_contents -> GetLastCommittedURL (); <nl>  <nl> // chrome :// URLs don ' t have content settings but can be muted , so just check
WebContents * DevToolsWindow :: OpenURLFromTab ( <nl> DCHECK ( source == main_web_contents_ ); <nl> if (! params . url . SchemeIs ( content :: kChromeDevToolsScheme )) { <nl> WebContents * inspected_web_contents = GetInspectedWebContents (); <nl> - return inspected_web_contents ? <nl> - inspected_web_contents -> OpenURL ( params ) : NULL ; <nl> + if (! inspected_web_contents ) <nl> + return nullptr ; <nl> + content :: OpenURLParams modified = params ; <nl> + modified . referrer = content :: Referrer (); <nl> + return inspected_web_contents -> OpenURL ( modified ); <nl> } <nl> bindings_ -> Reload (); <nl> return main_web_contents_ ;
class SystemTrayDelegate : public ash :: SystemTrayDelegate , <nl> } <nl>  <nl> virtual const std :: string GetUserEmail () const OVERRIDE { <nl> - return UserManager :: Get ()-> GetLoggedInUser (). email (); <nl> + return UserManager :: Get ()-> GetLoggedInUser (). display_email (); <nl> } <nl>  <nl> virtual const SkBitmap & GetUserImage () const OVERRIDE {
void Document :: open () <nl>  <nl> if ( m_frame ) <nl> m_frame -> loader (). didExplicitOpen (); <nl> - if ( m_loadEventProgress != LoadEventInProgress && m_loadEventProgress != UnloadEventInProgress ) <nl> + if ( m_loadEventProgress != LoadEventInProgress && pageDismissalEventBeingDispatched () == NoDismissal ) <nl> m_loadEventProgress = LoadEventNotRun ; <nl> } <nl> 
void HTMLFormElement :: scheduleFormSubmission ( FormSubmission * submission ) { <nl> return ; <nl> } <nl>  <nl> + if (! document (). contentSecurityPolicy ()-> allowFormAction ( <nl> + submission -> action ())) { <nl> + return ; <nl> + } <nl> + <nl> if ( protocolIsJavaScript ( submission -> action ())) { <nl> - if (! document (). contentSecurityPolicy ()-> allowFormAction ( <nl> - submission -> action ())) <nl> - return ; <nl> document (). frame ()-> script (). executeScriptIfJavaScriptURL ( <nl> submission -> action (), this ); <nl> return ;
enum class FullscreenSource { <nl> // The distance from the toolbar bottom to the anchor point for InfoBars . <nl> - ( NSInteger ) infoBarAnchorPointY ; <nl>  <nl> -// Toggles the AppKit Fullscreen API . By default , doing so enters Canonical <nl> -// Fullscreen . <nl> +// Enter fullscreen by toggling the AppKit Fullscreen API . <nl> - ( void ) enterAppKitFullscreen ; <nl> -- ( void ) exitAppKitFullscreen ; <nl> + <nl> +// Exit fullscreen by toggling the AppKit Fullscreen API . If | async | is true , <nl> +// call - toggleFullscreen : asynchronously . <nl> +- ( void ) exitAppKitFullscreenAsync :( BOOL ) async ; <nl>  <nl> // Returns where the fullscreen button should be positioned in the window . <nl> // Returns NSZeroRect if there is no fullscreen button ( if currently in
base :: string16 GetUninstallSurveyUrl () { <nl> bool NavigateToUrlWithEdge ( const base :: string16 & url ) { <nl> base :: string16 protocol_url = L " microsoft - edge :" + url ; <nl> SHELLEXECUTEINFO info = { sizeof ( info ) }; <nl> - info . fMask = SEE_MASK_NOASYNC | SEE_MASK_FLAG_NO_UI ; <nl> + info . fMask = SEE_MASK_NOASYNC ; <nl> info . lpVerb = L " open "; <nl> info . lpFile = protocol_url . c_str (); <nl> info . nShow = SW_SHOWNORMAL ;
Element * VisibleSelection :: rootEditableElement () const <nl>  <nl> Node * VisibleSelection :: nonBoundaryShadowTreeRootNode () const <nl> { <nl> - return start (). deprecatedNode () ? start (). deprecatedNode ()-> nonBoundaryShadowTreeRootNode () : 0 ; <nl> + return start (). deprecatedNode () && ! start (). deprecatedNode ()-> isShadowRoot () ? start (). deprecatedNode ()-> nonBoundaryShadowTreeRootNode () : 0 ; <nl> } <nl>  <nl> VisibleSelection :: ChangeObserver :: ChangeObserver ()
void FileSystemManagerImpl :: CreateWriter ( const GURL & file_path , <nl> CreateWriterCallback callback ) { <nl> DCHECK_CURRENTLY_ON ( BrowserThread :: IO ); <nl>  <nl> + if (! base :: FeatureList :: IsEnabled ( blink :: features :: kWritableFilesAPI )) { <nl> + bindings_ . ReportBadMessage (" FileSystemManager . CreateWriter "); <nl> + return ; <nl> + } <nl> + <nl> FileSystemURL url ( context_ -> CrackURL ( file_path )); <nl> base :: Optional < base :: File :: Error > opt_error = ValidateFileSystemURL ( url ); <nl> if ( opt_error ) {
void ContentSettingsStore :: ClearContentSettingsForExtension ( <nl> { <nl> base :: AutoLock lock ( lock_ ); <nl> OriginIdentifierValueMap * map = GetValueMap ( ext_id , scope ); <nl> - // TODO ( bauerb ): This is for debugging http :// crbug . com / 128652 . <nl> - // Remove once the bug is fixed . <nl> if (! map ) { <nl> - char ext_id_buffer [ 33 ]; <nl> - base :: strlcpy ( ext_id_buffer , ext_id . c_str (), sizeof ( ext_id_buffer )); <nl> - base :: debug :: Alias ( ext_id_buffer ); <nl> - // Do a clean crash . <nl> - CHECK ( false ); <nl> + // Fail gracefully in Release builds . <nl> + NOTREACHED (); <nl> + return ; <nl> } <nl> notify = ! map -> empty (); <nl> map -> clear ();
void OnSuggestionModelAdded ( UiScene * scene , <nl> description_text -> SetDrawPhase ( kPhaseForeground ); <nl> description_text -> SetType ( kTypeOmniboxSuggestionDescriptionText ); <nl> description_text -> set_hit_testable ( false ); <nl> - content_text -> SetTextLayoutMode ( TextLayoutMode :: kSingleLineFixedWidth ); <nl> + description_text -> SetTextLayoutMode ( TextLayoutMode :: kSingleLineFixedWidth ); <nl> description_text -> SetSize ( kSuggestionTextFieldWidthDMM , 0 ); <nl> description_text -> SetTextAlignment ( UiTexture :: kTextAlignmentLeft ); <nl> BindColor ( model , description_text . get (),
void DownloadUIAdapterDelegate :: OpenItem ( const OfflineItem & item , <nl> int64_t offline_id ) { <nl> JNIEnv * env = AttachCurrentThread (); <nl> Java_OfflinePageDownloadBridge_openItem ( <nl> - env , ConvertUTF8ToJavaString ( env , item . page_url . spec ()), offline_id ); <nl> + env , ConvertUTF8ToJavaString ( env , item . page_url . spec ()), offline_id , <nl> + offline_pages :: ShouldOfflinePagesInDownloadHomeOpenInCct ()); <nl> } <nl>  <nl> // TODO ( dewittj ): Move to Download UI Adapter .
PlatformFileForTransit GetFileHandleForProcess ( base :: PlatformFile handle , <nl> DWORD options = DUPLICATE_SAME_ACCESS ; <nl> if ( close_source_handle ) <nl> options |= DUPLICATE_CLOSE_SOURCE ; <nl> - if (!:: DuplicateHandle (:: GetCurrentProcess (), <nl> + if ( handle == INVALID_HANDLE_VALUE || <nl> + !:: DuplicateHandle (:: GetCurrentProcess (), <nl> handle , <nl> process , <nl> & out_handle ,
-// Copyright ( c ) 2011 The Chromium Authors . All rights reserved . <nl> +// Copyright ( c ) 2012 The Chromium Authors . All rights reserved . <nl> // Use of this source code is governed by a BSD - style license that can be <nl> // found in the LICENSE file . <nl>  <nl> void ProfileImplIOData :: LazyInitializeInternal ( <nl> ftp_factory_ . reset ( <nl> new net :: FtpNetworkLayer ( io_thread_globals -> host_resolver . get ())); <nl> main_context -> set_ftp_transaction_factory ( ftp_factory_ . get ()); <nl> + media_request_context_ -> set_ftp_transaction_factory ( ftp_factory_ . get ()); <nl>  <nl> main_context -> set_chrome_url_data_manager_backend ( <nl> chrome_url_data_manager_backend ());
# include " base / metrics / histogram_macros . h " <nl> # include " base / pickle . h " <nl> # include " base / strings / stringprintf . h " <nl> +# include " base / trace_event / trace_event . h " <nl> # include " components / sync / base / time . h " <nl> # include " components / sync / device_info / device_info . h " <nl> # include " components / sync / device_info / device_info_util . h " <nl> class FactoryImpl : public base :: SupportsWeakPtr < FactoryImpl > { <nl> std :: unique_ptr < ModelTypeStore :: RecordList > record_list , <nl> const base :: Optional < syncer :: ModelError >& error , <nl> std :: unique_ptr < syncer :: MetadataBatch > metadata_batch ) { <nl> + // Remove after fixing https :// crbug . com / 902203 . <nl> + TRACE_EVENT0 (" browser ", " FactoryImpl :: OnReadAllMetadata "); <nl> if ( error ) { <nl> std :: move ( callback ). Run ( error , /* store =*/ nullptr , <nl> /* metadata_batch =*/ nullptr );
int CSSStyleSheet :: addRule ( const String & selector , const String & style , Exceptio <nl> return addRule ( selector , style , length (), ec ); <nl> } <nl>  <nl> - <nl> PassRefPtr < CSSRuleList > CSSStyleSheet :: cssRules ( bool omitCharsetRules ) <nl> { <nl> - if ( doc () && ! doc ()-> securityOrigin ()-> canRequest ( baseURL ())) <nl> + KURL url = finalURL (); <nl> + if (! url . isEmpty () && doc () && ! doc ()-> securityOrigin ()-> canRequest ( url )) <nl> return 0 ; <nl> return CSSRuleList :: create ( this , omitCharsetRules ); <nl> }
